{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/cactus/source/css/rtl.styl","path":"css/rtl.styl","modified":1,"renderable":1},{"_id":"themes/cactus/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/cactus/source/images/apple-touch-icon.png","path":"images/apple-touch-icon.png","modified":1,"renderable":1},{"_id":"themes/cactus/source/images/favicon-192x192.png","path":"images/favicon-192x192.png","modified":1,"renderable":1},{"_id":"themes/cactus/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/cactus/source/images/favicon.ico","path":"images/favicon.ico","modified":1,"renderable":1},{"_id":"themes/cactus/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/clipboard/clipboard.min.js","path":"lib/clipboard/clipboard.min.js","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.woff","path":"lib/vazir-font/Vazir-Black.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.woff2","path":"lib/vazir-font/Vazir-Black.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.woff","path":"lib/vazir-font/Vazir-Bold.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.woff2","path":"lib/vazir-font/Vazir-Bold.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.woff2","path":"lib/vazir-font/Vazir-Light.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.woff","path":"lib/vazir-font/Vazir-Light.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.woff","path":"lib/vazir-font/Vazir-Medium.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.woff2","path":"lib/vazir-font/Vazir-Medium.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.woff","path":"lib/vazir-font/Vazir-Thin.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.woff2","path":"lib/vazir-font/Vazir-Thin.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/font-face.css","path":"lib/vazir-font/font-face.css","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir.woff","path":"lib/vazir-font/Vazir.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir.woff2","path":"lib/vazir-font/Vazir.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/images/logo.png","path":"images/logo.png","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/jquery/jquery.min.js","path":"lib/jquery/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.ttf","path":"lib/vazir-font/Vazir-Black.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.eot","path":"lib/vazir-font/Vazir-Black.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.eot","path":"lib/vazir-font/Vazir-Bold.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.ttf","path":"lib/vazir-font/Vazir-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.eot","path":"lib/vazir-font/Vazir-Light.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.ttf","path":"lib/vazir-font/Vazir-Light.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.eot","path":"lib/vazir-font/Vazir-Medium.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.ttf","path":"lib/vazir-font/Vazir-Medium.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.eot","path":"lib/vazir-font/Vazir-Thin.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.ttf","path":"lib/vazir-font/Vazir-Thin.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir.eot","path":"lib/vazir-font/Vazir.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir.ttf","path":"lib/vazir-font/Vazir.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.eot","path":"lib/font-awesome/webfonts/fa-regular-400.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.ttf","path":"lib/font-awesome/webfonts/fa-regular-400.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.woff","path":"lib/font-awesome/webfonts/fa-regular-400.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/justified-gallery/css/justifiedGallery.min.css","path":"lib/justified-gallery/css/justifiedGallery.min.css","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/justified-gallery/js/jquery.justifiedGallery.min.js","path":"lib/justified-gallery/js/jquery.justifiedGallery.min.js","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.woff","path":"lib/font-awesome/webfonts/fa-brands-400.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.ttf","path":"lib/font-awesome/webfonts/fa-brands-400.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.woff","path":"lib/font-awesome/webfonts/fa-solid-900.woff","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.eot","path":"lib/font-awesome/webfonts/fa-brands-400.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.svg","path":"lib/font-awesome/webfonts/fa-regular-400.svg","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.eot","path":"lib/font-awesome/webfonts/fa-solid-900.eot","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Italic.ttf","path":"lib/meslo-LG/MesloLGM-Italic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-BoldItalic.ttf","path":"lib/meslo-LG/MesloLGM-BoldItalic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-BoldItalic.ttf","path":"lib/meslo-LG/MesloLGS-BoldItalic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.ttf","path":"lib/font-awesome/webfonts/fa-solid-900.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-BoldItalic.ttf","path":"lib/meslo-LG/MesloLGL-BoldItalic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Italic.ttf","path":"lib/meslo-LG/MesloLGS-Italic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Italic.ttf","path":"lib/meslo-LG/MesloLGL-Italic.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Bold.ttf","path":"lib/meslo-LG/MesloLGS-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Bold.ttf","path":"lib/meslo-LG/MesloLGM-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Regular.ttf","path":"lib/meslo-LG/MesloLGM-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Regular.ttf","path":"lib/meslo-LG/MesloLGS-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Regular.ttf","path":"lib/meslo-LG/MesloLGL-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Bold.ttf","path":"lib/meslo-LG/MesloLGL-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.svg","path":"lib/font-awesome/webfonts/fa-solid-900.svg","modified":1,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.svg","path":"lib/font-awesome/webfonts/fa-brands-400.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"7625da6180505b0dd4bee6c710cd4e805ea54598","modified":1571037787793},{"_id":"themes/cactus/.gitignore","hash":"c5345a2c5fa6c136dbe2020a405e541b4755a259","modified":1570532430816},{"_id":"themes/cactus/LICENSE","hash":"346ece39a983b0e7858c11f785cd846cef9eb875","modified":1570532430817},{"_id":"themes/cactus/.stylintrc","hash":"eb5f48e83657928cb0cbee031373b2cd36ca0083","modified":1570532430816},{"_id":"themes/cactus/README.md","hash":"859d11941c46be4f7b4a6d62297ccbeb4f732bc9","modified":1570532430817},{"_id":"themes/cactus/.jshintrc","hash":"2548bd6ce44422edc7e6f9f68061ab47f26c4f57","modified":1570532430816},{"_id":"themes/cactus/gulpfile.js","hash":"2bae290993507026a509665ee5a5326b616f8d68","modified":1570532430817},{"_id":"themes/cactus/_config.yml","hash":"7ef7291bd08dc0556ee8821bb0630e06f20fe816","modified":1571039430082},{"_id":"themes/cactus/package.json","hash":"5bbdbc429e9d46acf97baf7ac5654edde0781064","modified":1570532430823},{"_id":"source/_data/projects.json","hash":"40a1da9035cf239083c12e2b5e09782d638f9ca0","modified":1571205336932},{"_id":"source/about/index.md","hash":"3d13a37e2e8a753b914f63c3976462a4eda66b9a","modified":1570531791007},{"_id":"source/_posts/blockchain.md","hash":"4fdaaf77252b7e65b1e35c827ddfea467bc028ec","modified":1571035161716},{"_id":"source/_posts/btc-data-dat.md","hash":"378493b252d088b981bbfb94f2731d6790eae703","modified":1571037923831},{"_id":"source/_posts/btc-wallet.md","hash":"a95da1f60477f13b77e7660952adf3f9e7a5b732","modified":1571037934654},{"_id":"source/_posts/btc.md","hash":"3ed71a152011912a3cc0956a706e9345ddf95b59","modified":1571037920084},{"_id":"source/_posts/cosmos-ibc-store.md","hash":"0f9bb7f986032e5ce95afd4845fe2238f403c8a7","modified":1574750033483},{"_id":"source/_posts/cosmos-store.md","hash":"e93de32c561f8063edb3c71951d777e808b59ebe","modified":1574757732994},{"_id":"source/_posts/crypto.md","hash":"bf45c6d1a98fb40e0cb3266bc7cc56bac50c0ae1","modified":1571034958550},{"_id":"source/_posts/dai-code.md","hash":"effaeea3e72463b421ee174d3dc738eaae018412","modified":1571035982933},{"_id":"source/_posts/dai.md","hash":"9df45f0506cd009fa51e80675455aa77af65a997","modified":1571035965726},{"_id":"source/_posts/elastic-kibana.md","hash":"e1cb784d4a54124aeab07afb3022be36dc9ff5ce","modified":1571034077808},{"_id":"source/_posts/elastic-painless.md","hash":"b6f95c2d48b41a804cc4cfd98f4e1caa26df5933","modified":1571034088123},{"_id":"source/_posts/elastic-logstash.md","hash":"e93671cd3dbdd03b2b5bb7c4b93be785faa0cc3e","modified":1571034083703},{"_id":"source/_posts/elastic-search-dsl.md","hash":"38cf3bf890f7f2629d67c374ac9e739198217cfb","modified":1571034092299},{"_id":"source/_posts/elastic-template.md","hash":"c5d7868b591a1e1dba06080f566203b4013e006e","modified":1571104858965},{"_id":"source/_posts/elastic.md","hash":"531416411b5b3b41f42fd834f3edca87ac0d2f74","modified":1571034100972},{"_id":"source/_posts/eth-build.md","hash":"50f2ff0a1ee7e6194511e019b31c0a3fcede86d6","modified":1571035799618},{"_id":"source/_posts/eth-casper.md","hash":"9203bedadd0010e497e8c292f56f6e512ab01af0","modified":1571035913874},{"_id":"source/_posts/eos-code.md","hash":"e952727e2295ddec83ba046af6b499e29053c795","modified":1571035581817},{"_id":"source/_posts/eos.md","hash":"ca654f0706331f39ceeaca0445f819a52b888c9e","modified":1571035463967},{"_id":"source/_posts/eth-erc.md","hash":"0c4f3dfc1184881c1f9ab4454493175f423347aa","modified":1571036017089},{"_id":"source/_posts/eth-jsre-api.md","hash":"0e8e9b0c119944a5982fe4d0e546303009896bf4","modified":1571036056741},{"_id":"source/_posts/eth-p2p-udp.md","hash":"251b4ea11293c3f973d3e256f5880e601caf934a","modified":1571036085669},{"_id":"source/_posts/eth-contract.md","hash":"5a98f52a5c96dd8cfdf341eeb4e2cdf482cdd422","modified":1571035895621},{"_id":"source/_posts/eth-rlp.md","hash":"3f50fadf253c353323020c33239da4818f7d529a","modified":1571035730308},{"_id":"source/_posts/eth-state.md","hash":"a246a7791f93400df8df5974f9b5834f9d9fc5cc","modified":1571036120646},{"_id":"source/_posts/eth.md","hash":"9109abb33549552cfaf63bd055dec020e68b46a6","modified":1571035845748},{"_id":"source/_posts/fabric-pbft.md","hash":"4a24b928fe75631200acfd31e89bab0b94e951bb","modified":1571036990625},{"_id":"source/_posts/fabric-code-consensus-event.md","hash":"f3fa0043a2d98ce238a0f52f32221e52d1ca3fff","modified":1571036984048},{"_id":"source/_posts/fabric-performance.md","hash":"8c5e8b519d86d3a6f16b6ac7828cf2caaf9fd8d5","modified":1571036907722},{"_id":"source/_posts/fabric-example.md","hash":"5c1ee2bce0c3c4fa69a163723c09f64634e973d7","modified":1571036779696},{"_id":"source/_posts/fabric_peer.jpg","hash":"c9c7d0e437a9f0b5a8d3bd54939af0f98a2e2c63","modified":1571036444856},{"_id":"source/_posts/floodlight-sdn.md","hash":"9a1d290bb5fd9f529111b949329fcc09a9b29cbd","modified":1571034107845},{"_id":"source/_posts/fabric.md","hash":"bebf5d4ec354ced6907fe7fb9bc839b3f23a7227","modified":1571036697064},{"_id":"source/_posts/fabric_macro.jpg","hash":"c926c6151cf76b28be6b08e2d9fe527b9ec0c933","modified":1571036444855},{"_id":"source/_posts/how-to-set-up-a-blog.md","hash":"bd0f83dfabe914d2c4d19af3a1d410376d5005f8","modified":1571020277620},{"_id":"source/_posts/kibana-plugin-development.md","hash":"cfa5d34b8f2baa4ca93df93c1437002394d83bcd","modified":1571034117352},{"_id":"source/_posts/kibana-plugin.md","hash":"5cb56e0f54392161522b0bcb5ed64ca327f95fc5","modified":1571034124369},{"_id":"source/_posts/kibana-timeline.md","hash":"d69d7f026c9c3c37f4194b083209f469320698c5","modified":1571034130627},{"_id":"source/_posts/web3j.md","hash":"91a246b50b08c46b2baf61afb182c78dd50d9e61","modified":1571036154674},{"_id":"source/_posts/zilliqa.md","hash":"dc4e632e2c512656b3f344e7caf133c7c995cda3","modified":1571035225020},{"_id":"source/_posts/wallet-connection.md","hash":"fc12cd8e5fed041ff6b1387a94f70ef1026325e4","modified":1571034873925},{"_id":"source/_posts/maven.md","hash":"8775be53ed73bfb3ebb736f68214828589f6cdbb","modified":1571034177697},{"_id":"source/_posts/zilliqa-network.md","hash":"78316e5e5b52d395a05b579472286964c2560fe1","modified":1571035279167},{"_id":"source/categories/index.md","hash":"16c18d7a4433fb5c7c44ebe660ca6c1ad2693f38","modified":1571021903348},{"_id":"source/search/index.md","hash":"82aa576fd412f51d6e4965a0f4a5e3f4fb8bd4e5","modified":1571032024769},{"_id":"themes/cactus/languages/ca.yml","hash":"b79dd2c21dc6697c635e92db1f661a4b8d5d2305","modified":1570532430817},{"_id":"themes/cactus/languages/default.yml","hash":"703548ad90034d4e5207a27eb50f726dc27e4c0c","modified":1570532430818},{"_id":"themes/cactus/languages/en.yml","hash":"703548ad90034d4e5207a27eb50f726dc27e4c0c","modified":1570532430818},{"_id":"themes/cactus/languages/es.yml","hash":"2b1fc8b0d636123e9ee39017fa20053bd1913a5a","modified":1570532430818},{"_id":"themes/cactus/languages/fr.yml","hash":"4fea266d3c522903f3eee4fffee6e66c44775005","modified":1570532430818},{"_id":"themes/cactus/languages/fa.yml","hash":"63f32e50953af1c4bd0308a4fca5862b5287c2cb","modified":1570532430818},{"_id":"themes/cactus/languages/it.yml","hash":"62800bcae1f2d2454f87f4bcf4d7593848424f61","modified":1570532430818},{"_id":"themes/cactus/languages/nl.yml","hash":"ac0573352ad2c737a7686bcca498b985e7bd6447","modified":1570532430818},{"_id":"themes/cactus/languages/pl.yml","hash":"8a2d6dc874d86c38d42c2c861c39590647b5d536","modified":1570532430818},{"_id":"themes/cactus/languages/pt-br.yml","hash":"4859aba788a050c2d5d0b997693b0c8c24b349f7","modified":1570532430819},{"_id":"themes/cactus/languages/ru.yml","hash":"81b57fcd1977ef534f4bf303dbc1b4710cc7f057","modified":1570532430819},{"_id":"themes/cactus/languages/tr.yml","hash":"2702914007e6bade9d6861078c0e179ac05bf48c","modified":1570532430819},{"_id":"themes/cactus/languages/vi.yml","hash":"f84893c3ec3e45875c90069e14b17ed3016ed973","modified":1570532430819},{"_id":"themes/cactus/languages/zh-CN.yml","hash":"8f81faaad9a0615b09dbc23868484a55ec958f6f","modified":1570532430819},{"_id":"themes/cactus/languages/zh-TW.yml","hash":"2f4e050c9b35a67f4a7278cec3a949533c2ac16a","modified":1570532430819},{"_id":"themes/cactus/layout/archive.ejs","hash":"53de8817e37be01b3ba8fa5ca31b9cafa2f3c011","modified":1570532430822},{"_id":"themes/cactus/layout/index.ejs","hash":"6a1d161481c7d5418496128aa7cf470160536949","modified":1571039598265},{"_id":"themes/cactus/layout/layout.ejs","hash":"8504004f2ed78914f806c6699d9bd722318cbe56","modified":1570532430822},{"_id":"themes/cactus/layout/page.ejs","hash":"c5465d5315a7544aa466b01fd8cfb62917a8bb1d","modified":1570532430823},{"_id":"themes/cactus/scripts/merge-configs.js","hash":"2048c3415d96b17b9d84aa44bc0c25f1210525f8","modified":1570532430823},{"_id":"themes/cactus/scripts/meta.js","hash":"fa6055a39851c9953d033e70c1614547b94dce60","modified":1570532430823},{"_id":"themes/cactus/scripts/page_title.js","hash":"fa662dbdb82779af1b95e35ed7ccdf4866a53dee","modified":1570532430824},{"_id":"themes/cactus/scripts/thumbnail.js","hash":"df8829fd8c3119650037eba5ec11bdce06acff9d","modified":1570532430824},{"_id":"themes/cactus/layout/post.ejs","hash":"a7d164ce888a60cd3eddd9c04bc6762428fa66bb","modified":1570532430823},{"_id":"source/_posts/eth-code-tx-event.md","hash":"90bca5b44575c2d2264e8f87aa4ef0c7457dcd9d","modified":1571035701961},{"_id":"themes/cactus/layout/_partial/comments.ejs","hash":"4cf8d0059e5f8bc8ae1dd1a426293583fd398052","modified":1570532430819},{"_id":"themes/cactus/layout/_partial/footer.ejs","hash":"c3a80e347cb11022baf5e65fb4d0209b8d205693","modified":1570532430820},{"_id":"themes/cactus/layout/_partial/head.ejs","hash":"b7db191b7ad066b1f3f9c34d8a4b77e1ee815215","modified":1570532430820},{"_id":"themes/cactus/layout/_partial/header.ejs","hash":"6b534801486f6baa989bd351915a9156b838b777","modified":1570532430820},{"_id":"themes/cactus/layout/_partial/pagination.ejs","hash":"23bf862b3b8a3cd831850504d9b5a24d21b005e7","modified":1570532430820},{"_id":"themes/cactus/layout/_partial/scripts.ejs","hash":"83d912956b00537e0b20a9905f14885ff3899ed4","modified":1570532430822},{"_id":"themes/cactus/layout/_partial/search.ejs","hash":"8b4bf9cf5db0ce762a31fc3baae0f2fc004bece4","modified":1570532430822},{"_id":"themes/cactus/layout/_partial/styles.ejs","hash":"be1b54388eb02176dd4722285dda19e3dce2e62e","modified":1570532430822},{"_id":"themes/cactus/source/_data/projects.json","hash":"e866bb8ed316a0709f581ee3076e1166b51c0c4d","modified":1570850595121},{"_id":"themes/cactus/source/css/_extend.styl","hash":"2c8751d132e62f5f068dc3a184d160670737ba1f","modified":1570532430824},{"_id":"themes/cactus/source/css/_fonts.styl","hash":"354809b5a64e8a47a66c66fd1a28ac597c1460a6","modified":1570532430825},{"_id":"themes/cactus/source/css/_mixins.styl","hash":"1a9e309523df9685e8d088dcff0a809c58e2c392","modified":1570532430835},{"_id":"themes/cactus/source/css/_variables.styl","hash":"95a10a7ee9f2d5f272813286eee0d3202cb0fcea","modified":1570862178459},{"_id":"themes/cactus/source/css/_util.styl","hash":"2bfeb2e2605dd5235693b00c71a212646d2e0410","modified":1570532430837},{"_id":"themes/cactus/source/css/rtl.styl","hash":"98355abe9ef3a398a5b4cb40d3d33bf86ac8d1d4","modified":1570532430837},{"_id":"themes/cactus/source/css/style.styl","hash":"9a946631f0e59addc57c39bd7f2081b3e9256ab1","modified":1570532430837},{"_id":"themes/cactus/source/images/apple-touch-icon.png","hash":"57e2def34682655f41a0be2d083f16765ba7858b","modified":1570532430837},{"_id":"themes/cactus/source/images/favicon-192x192.png","hash":"96e6fcbbb13a5914a6131391e210eb7dfd13d692","modified":1570532430838},{"_id":"themes/cactus/source/js/main.js","hash":"584c5a69ac81a483a1c4377a2e2cf326c2795e7b","modified":1570532430840},{"_id":"themes/cactus/source/images/favicon.ico","hash":"189f9842bcb79a6f8f9e8445bc8bbd773443826b","modified":1570532430838},{"_id":"themes/cactus/source/js/search.js","hash":"a74d0c601f820160825a2e4ad13618074d714933","modified":1570532430840},{"_id":"themes/cactus/layout/_partial/post/category.ejs","hash":"b5bfa049f17868fb09d9d2a7e1d5279fa0381d37","modified":1570532430821},{"_id":"themes/cactus/layout/_partial/post/actions_mobile.ejs","hash":"79b234ff3c264e66b2e71c819228e62bf92b48e4","modified":1570532430820},{"_id":"themes/cactus/layout/_partial/post/actions_desktop.ejs","hash":"38aadd1ed890303dde582b722486138afee09b0a","modified":1570532430820},{"_id":"themes/cactus/layout/_partial/post/date.ejs","hash":"6f2d1aa9562df343b797d25705f1945323c465fb","modified":1570532430821},{"_id":"themes/cactus/layout/_partial/post/gallery.ejs","hash":"9aecd8908e8a684f33dc20c02497c0f1774137c7","modified":1570532430821},{"_id":"themes/cactus/layout/_partial/post/share.ejs","hash":"847a400e79b775246ca9067e40c3f104d571413d","modified":1570532430821},{"_id":"themes/cactus/layout/_partial/post/tag.ejs","hash":"e08fae30da060f49c087f6c121868b08eb55c795","modified":1570532430821},{"_id":"themes/cactus/layout/_partial/post/title.ejs","hash":"a060f1c6e3718494a6b1d0e1981ea0bf4e549828","modified":1570532430822},{"_id":"themes/cactus/source/css/_colors/classic.styl","hash":"0f0ec41a4165814ce69688425d5ac4d701b7cc70","modified":1570532430824},{"_id":"themes/cactus/source/css/_colors/dark.styl","hash":"9c9655b42b85f754b8a573a1d4634c23c680e1bf","modified":1570532430824},{"_id":"themes/cactus/source/css/_colors/light.styl","hash":"d09f781cb02394850737b3a9efc6693307d5bf09","modified":1570532430824},{"_id":"themes/cactus/source/css/_colors/white.styl","hash":"2b25ad24573bded8b42f9d80112eab9fadbed1a5","modified":1570532430824},{"_id":"themes/cactus/source/css/_highlight/agate.styl","hash":"53027913ed8d4f75ac3e49e76aad824f0df62da3","modified":1570532430825},{"_id":"themes/cactus/source/css/_highlight/androidstudio.styl","hash":"2af0861725f97f0ee2ded67c3d2d4548c62b2d16","modified":1570532430825},{"_id":"themes/cactus/source/css/_highlight/arduino-light.styl","hash":"15e8572585cd708221c513dea4bdd89d8fe56c10","modified":1570532430825},{"_id":"themes/cactus/source/css/_highlight/arta.styl","hash":"b3e81e3e694ceb8deed178adb8b91013c5120e30","modified":1570532430825},{"_id":"themes/cactus/source/css/_highlight/ascetic.styl","hash":"32cff3bef6fac3760fe78f203096477052a90552","modified":1570532430825},{"_id":"themes/cactus/source/css/_highlight/atelier-dune-dark.styl","hash":"c196ff0ee064af0e507823694ae39020addfc280","modified":1570532430826},{"_id":"themes/cactus/source/css/_highlight/atelier-cave-dark.styl","hash":"ce63dd8548688d88254405eedfa75b1d7c82449e","modified":1570532430825},{"_id":"themes/cactus/source/css/_highlight/atelier-cave-light.styl","hash":"a5be0744a7ecf4a08f600ade4cfd555afc67bc15","modified":1570532430826},{"_id":"themes/cactus/source/css/_highlight/atelier-dune-light.styl","hash":"931435fbc6f974e8ce9e32722680035d248a9dc1","modified":1570532430826},{"_id":"themes/cactus/source/css/_highlight/atelier-estuary-dark.styl","hash":"0bb16a4eff93688f40787abc2f9e56e7d5cc93e7","modified":1570532430826},{"_id":"themes/cactus/source/css/_highlight/atelier-estuary-light.styl","hash":"344276ca9b27e51d4c907f76afe5d13cf8e60bdf","modified":1570532430826},{"_id":"themes/cactus/source/css/_highlight/atelier-forest-dark.styl","hash":"effbc5d75fa87203c847039869c22031b40d5b7d","modified":1570532430826},{"_id":"themes/cactus/source/css/_highlight/atelier-forest-light.styl","hash":"95228d9f2102fad425536aac44b80b2cba1f5950","modified":1570532430826},{"_id":"themes/cactus/source/css/_highlight/atelier-heath-dark.styl","hash":"9a2e9a1d0a01bbdf158560c3ed1c134e098b2c68","modified":1570532430827},{"_id":"themes/cactus/source/css/_highlight/atelier-heath-light.styl","hash":"8c8c2e445abef85273be966d59770e9ced6aac21","modified":1570532430827},{"_id":"themes/cactus/source/css/_highlight/atelier-lakeside-dark.styl","hash":"10ee3882fca7b97a37bd309d2d35fce9868647bb","modified":1570532430827},{"_id":"themes/cactus/source/css/_highlight/atelier-lakeside-light.styl","hash":"2c54cb9bdb259ae3b5b29f63ac2469ed34b08578","modified":1570532430827},{"_id":"themes/cactus/source/css/_highlight/atelier-plateau-dark.styl","hash":"84c80e6f67f62fce958d25817c277d2360272617","modified":1570532430827},{"_id":"themes/cactus/source/css/_highlight/atelier-plateau-light.styl","hash":"d1a05fdd1ededc9063d181ab25bad55a164aeb4a","modified":1570532430827},{"_id":"themes/cactus/source/css/_highlight/atelier-savanna-dark.styl","hash":"e32c1c70def8060fce5e790979a126da650ac642","modified":1570532430827},{"_id":"themes/cactus/source/css/_highlight/atelier-savanna-light.styl","hash":"f8244c93711c7cb59dd79d2df966806b30d171ea","modified":1570532430827},{"_id":"themes/cactus/source/css/_highlight/atelier-seaside-dark.styl","hash":"2edf385215bbe1985b1a10106525d362667d28c2","modified":1570532430828},{"_id":"themes/cactus/source/css/_highlight/atelier-seaside-light.styl","hash":"0597342da6e2d0c5bdcc7d42dabb07322b1a4177","modified":1570532430828},{"_id":"themes/cactus/source/css/_highlight/atelier-sulphurpool-dark.styl","hash":"538a14321193cd8abf2ddc484306631e54149ffb","modified":1570532430828},{"_id":"themes/cactus/source/css/_highlight/atelier-sulphurpool-light.styl","hash":"efa52713efc468abeeb2b9299704371583b857de","modified":1570532430828},{"_id":"themes/cactus/source/css/_highlight/brown-paper.styl","hash":"c2326ba20a5020a66ca7895258d18833327d4334","modified":1570532430828},{"_id":"themes/cactus/source/css/_highlight/color-brewer.styl","hash":"2a439d6214430e2f45dd4939b4dfe1fe1a20aa0f","modified":1570532430829},{"_id":"themes/cactus/source/css/_highlight/codepen-embed.styl","hash":"8b7b34484f76a6c2c3b1a9e49abb9b382f439ae8","modified":1570532430828},{"_id":"themes/cactus/source/css/_highlight/dark.styl","hash":"f5e6e75958de59e87fc6be3a1668e870e20bc836","modified":1570532430829},{"_id":"themes/cactus/source/css/_highlight/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1570532430828},{"_id":"themes/cactus/source/css/_highlight/darkula.styl","hash":"9717efa9194837ba3fb4d762997d33075dcf8bfa","modified":1570532430829},{"_id":"themes/cactus/source/css/_highlight/docco.styl","hash":"b1c176378bb275f2e8caa759f36294e42d614bf1","modified":1570532430829},{"_id":"themes/cactus/source/css/_highlight/far.styl","hash":"aaac3028f5e33123cd123a583cddc9290c45ec8e","modified":1570532430829},{"_id":"themes/cactus/source/css/_highlight/foundation.styl","hash":"bf8ddc94b4ad995b8b8805b5a4cf95004553fdac","modified":1570532430829},{"_id":"themes/cactus/source/css/_highlight/github-gist.styl","hash":"48211a03d33e7f7ada0b261162bea06676155a71","modified":1570532430829},{"_id":"themes/cactus/source/css/_highlight/googlecode.styl","hash":"bda816beee7b439814b514e6869dc678822be1bc","modified":1570532430830},{"_id":"themes/cactus/source/css/_highlight/github.styl","hash":"3336aeba324c6d34a6fd41fef9b47bc598f7064c","modified":1570532430830},{"_id":"themes/cactus/source/css/_highlight/grayscale.styl","hash":"bf37d8b8d1e602126c51526f0cc28807440228ed","modified":1570532430830},{"_id":"themes/cactus/source/css/_highlight/gruvbox-dark.styl","hash":"76b744c14fd5600bea64731c05df97c2df75523f","modified":1570532430830},{"_id":"themes/cactus/source/css/_highlight/highlightjs.styl","hash":"0e198b7a59191c7a39b641a4ddd22c948edb9358","modified":1570532430830},{"_id":"themes/cactus/source/css/_highlight/hopscotch.styl","hash":"1378a6bc67a32c0cbff72ab771268b53f9aa586d","modified":1570532430830},{"_id":"themes/cactus/source/css/_highlight/hybrid.styl","hash":"b8eb5c69d12f2ee5ebc50265ae271699d7f1a8d3","modified":1570532430830},{"_id":"themes/cactus/source/css/_highlight/index.styl","hash":"002d5596f6379cc87dbd43d9145bc764aa666be1","modified":1570532430831},{"_id":"themes/cactus/source/css/_highlight/idea.styl","hash":"a02967cb51c16a34e0ee895d33ded2b823d35b21","modified":1570532430830},{"_id":"themes/cactus/source/css/_highlight/kimbie.dark.styl","hash":"45dbb168f22d739d0109745d2decd66b5f94e786","modified":1570532430831},{"_id":"themes/cactus/source/css/_highlight/kimbie.styl","hash":"51b889ca7c6fe178cfbbe28d875a6ea427184441","modified":1570532430831},{"_id":"themes/cactus/source/css/_highlight/kimbie.light.styl","hash":"61f8baed25be05288c8604d5070afbcd9f183f49","modified":1570532430831},{"_id":"themes/cactus/source/css/_highlight/ir-black.styl","hash":"53e5d74326a4527b92272bbd6946d4fec92720e8","modified":1570532430831},{"_id":"themes/cactus/source/css/_highlight/magula.styl","hash":"16d323f989b1420a0f72ef989242ece9bf17a456","modified":1570532430831},{"_id":"themes/cactus/source/css/_highlight/mono-blue.styl","hash":"4c89a6ae29de67c0700585af82a60607e85df928","modified":1570532430831},{"_id":"themes/cactus/source/css/_highlight/monokai-sublime.styl","hash":"c385b11345894be7e6ce3c5f08663e199933b8e4","modified":1570532430832},{"_id":"themes/cactus/source/css/_highlight/monokai.styl","hash":"f87be027848ea6bee623a08ad1e17b2f5b7937ee","modified":1570532430832},{"_id":"themes/cactus/source/css/_highlight/obsidian.styl","hash":"199e28326be8590883f0813ebbd54fcfaa4750fd","modified":1570532430832},{"_id":"themes/cactus/source/css/_highlight/paraiso-dark.styl","hash":"f1537bd868579fa018ecdbfd2eb922dcf3ba2cac","modified":1570532430832},{"_id":"themes/cactus/source/css/_highlight/paraiso-light.styl","hash":"d224d1df0eb3395d9eea1344cee945c228af2911","modified":1570532430832},{"_id":"themes/cactus/source/css/_highlight/paraiso.styl","hash":"75f181eece6b71d033ea0c8d6cf00ae7efb9e29b","modified":1570532430832},{"_id":"themes/cactus/source/css/_highlight/pojoaque.jpg","hash":"c5fe6533b88b21f8d90d3d03954c6b29baa67791","modified":1570532430832},{"_id":"themes/cactus/source/css/_highlight/pojoaque.styl","hash":"4e7b6b046b8575ac749f6aec4e953a62ada27a36","modified":1570532430832},{"_id":"themes/cactus/source/css/_highlight/railscasts.styl","hash":"b6674db9210e0c4444e4835fff2d1361f3ebd64c","modified":1570532430833},{"_id":"themes/cactus/source/css/_highlight/rainbow.styl","hash":"c0cf97aae3e10fdcd10414547a711c9effbc39b8","modified":1570532430833},{"_id":"themes/cactus/source/css/_highlight/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1570532430833},{"_id":"themes/cactus/source/css/_highlight/school-book.styl","hash":"d43560fe519a931ce6da7d57416d7aa148441b83","modified":1570532430833},{"_id":"themes/cactus/source/css/_highlight/solarized-dark.styl","hash":"90c9da5aa594383697e5b18892a7f95beb053f55","modified":1570532430833},{"_id":"themes/cactus/source/css/_highlight/sunburst.styl","hash":"af3eec0fd56151e55bbd49c31b151f36717611d8","modified":1570532430833},{"_id":"themes/cactus/source/css/_highlight/solarized-light.styl","hash":"aa0dd3fd25c464183b59c5575c9bee8756b397f2","modified":1570532430833},{"_id":"themes/cactus/source/css/_highlight/tomorrow-night-blue.styl","hash":"f24c17d0ab815dcfaab3438cb9fe2ab4839f5e0d","modified":1570532430833},{"_id":"themes/cactus/source/css/_highlight/tomorrow-night-eighties.styl","hash":"28d751075ebabf7d0327a36f725076fe82fdf626","modified":1570532430834},{"_id":"themes/cactus/source/css/_highlight/tomorrow-night-bright.styl","hash":"7674fecb6d27350727dc0d2dc93bc018382ebbd0","modified":1570532430834},{"_id":"themes/cactus/source/css/_highlight/tomorrow-night.styl","hash":"16ba09b2db501e4e3e2e7d62595d9bf935bf27c4","modified":1570532430834},{"_id":"themes/cactus/source/css/_highlight/vs.styl","hash":"959a746f4b37aacb5d1d6ff1d57e0c045289d75d","modified":1570532430834},{"_id":"themes/cactus/source/css/_highlight/tomorrow.styl","hash":"15779cf6846725c7c35fc56cac39047d7e0aec1c","modified":1570532430834},{"_id":"themes/cactus/source/css/_highlight/xcode.styl","hash":"5e8532ae8366dcf6a4ef5e4813dc3d42ab3d0a50","modified":1570532430834},{"_id":"themes/cactus/source/css/_highlight/zenburn.styl","hash":"68ff9332ccc03f9389b15b713415cde016f8088f","modified":1570532430834},{"_id":"themes/cactus/source/css/_partial/archive.styl","hash":"ef8fc52337c4c7b010cad7c427cb78009b30f9d8","modified":1570532430835},{"_id":"themes/cactus/source/css/_partial/article.styl","hash":"c6a3c395ceb4aacba8c995bcde7b58a7ca501919","modified":1570532430835},{"_id":"themes/cactus/source/css/_partial/categories.styl","hash":"a43f00e61b3507f130b8a3f8108a4eeca147c2a0","modified":1570532430835},{"_id":"themes/cactus/source/css/_partial/comments.styl","hash":"1e90f1fb9d4c155df518cacb5a537e9de9c042c1","modified":1570532430835},{"_id":"themes/cactus/source/css/_partial/footer.styl","hash":"d9b13e402808175dc90761cc4fdfe3d4808034f8","modified":1570532430835},{"_id":"themes/cactus/source/css/_partial/header.styl","hash":"b64021d680f856d24dc17bc8f53674bfe2e241e4","modified":1570532430835},{"_id":"themes/cactus/source/css/_partial/pagination.styl","hash":"950bf517bbe7adb9a9aa4eb5ddec74ffc7598787","modified":1570532430836},{"_id":"themes/cactus/source/css/_partial/index.styl","hash":"59c99f4ea3a73bf47ce030df166c5e33d5de31fb","modified":1570532430836},{"_id":"themes/cactus/source/css/_partial/tags.styl","hash":"d571d5c7c960300d29c5f0ec3fe1140322ecd6b3","modified":1570532430836},{"_id":"themes/cactus/source/css/_partial/search.styl","hash":"159be002780c62a77f46947cf854a7342fba24f4","modified":1570532430836},{"_id":"themes/cactus/source/css/_partial/tooltip.styl","hash":"2daff581ec3efaec840cbfdee512195919c32629","modified":1570532430836},{"_id":"themes/cactus/source/lib/clipboard/clipboard.min.js","hash":"ee60ca5ba9401456105ef703a98092369b579c80","modified":1570532430840},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.woff","hash":"37443d0040f0d7af381c955e4c15919a15d0349e","modified":1570532430877},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.woff2","hash":"0a257c8b60e0f20802c1dc8daeed2d3cb0d44f17","modified":1570532430878},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.woff","hash":"df15fd1e74b6f4a50bea57e2b44d9627f38495b5","modified":1570532430880},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.woff2","hash":"62447a951d48b21c4696ae72df4bc4adef636e26","modified":1570532430880},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.woff2","hash":"ef07a250766fea840c1049e67c0405d9216ee0a8","modified":1570532430882},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.woff","hash":"32ae5c0d1d5943c8bb8e0f6ab07c3269c6f8b8a8","modified":1570532430882},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.woff","hash":"f5653059b2a5929516e4aab02329a978600b9b67","modified":1570532430885},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.woff2","hash":"668400ae92700965f03f2371faaee0ab8c8347c3","modified":1570532430885},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.woff","hash":"ad4d46a99a1daf6353c86c79ac3a2b030213859c","modified":1570532430887},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.woff2","hash":"c3be79b553ec394db71268d604b1d29183b867dc","modified":1570532430887},{"_id":"themes/cactus/source/lib/vazir-font/font-face.css","hash":"8f2bf6b59ae1f2ed4c2fead6cea4b8314fcf62e5","modified":1570532430889},{"_id":"themes/cactus/source/lib/vazir-font/Vazir.woff","hash":"bbee70033f0f5882e9869e417b69c6a38f56f187","modified":1570532430889},{"_id":"themes/cactus/source/lib/vazir-font/Vazir.woff2","hash":"30ce165216db078951a690a6ad665b9b78f5dd81","modified":1570532430889},{"_id":"themes/cactus/source/images/logo.png","hash":"0e3029251dfda26adee2761f71377297e8c26871","modified":1570532430839},{"_id":"themes/cactus/source/lib/jquery/jquery.min.js","hash":"0dc32db4aa9c5f03f3b38c47d883dbd4fed13aae","modified":1570532430857},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.ttf","hash":"594dc3344ad14903c247615427d1009709f0f5a4","modified":1570532430877},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.eot","hash":"13d026ff857c853cbd0dc519b6e58669db309441","modified":1570532430876},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.eot","hash":"f76ec625e15522ff60d21f7a9a3b71c65bc27556","modified":1570532430878},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.ttf","hash":"2e6c9df9f775373fb1988ae8529aa8f05313dae6","modified":1570532430879},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.eot","hash":"3edffd7bb61eee8cd46b57225f9f9e5264e3362b","modified":1570532430881},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.ttf","hash":"9f1e2934098a6a4a7c5584c8f3fa24a707070da3","modified":1570532430882},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.eot","hash":"1f5a73db7947ef22c8a2bb19d6449b80496c03c4","modified":1570532430883},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.ttf","hash":"295f7e02c9b157e7ea63ad09613b00ceab85c5cd","modified":1570532430884},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.eot","hash":"08e1503d1181188690fd9c81860d6c890c1465f6","modified":1570532430885},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.ttf","hash":"a6aa450ee6e0f85786474ca6b04827ef97e81af4","modified":1570532430886},{"_id":"themes/cactus/source/lib/vazir-font/Vazir.eot","hash":"31a9219c25fe1991fb745ec8dbbcf45c6094a702","modified":1570532430888},{"_id":"themes/cactus/source/lib/vazir-font/Vazir.ttf","hash":"f22b219824026e490a581ddb3b36b07997dff0e3","modified":1570532430888},{"_id":"themes/cactus/source/css/_partial/post/actions_desktop.styl","hash":"dc726537928fc0d7703e73c0a5e4b82ad1731d59","modified":1570532430836},{"_id":"themes/cactus/source/css/_partial/post/actions_mobile.styl","hash":"0d2966c1d870392476864af8ee3ba312ba30cb82","modified":1570532430836},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.eot","hash":"42ff503f20e97503cef8e5b2ec10ae07699d7c01","modified":1570532430848},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"9784edb76f8a2ed595ea4bf74d46cda4eff3b303","modified":1570532430849},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.ttf","hash":"c140085833a38abec6b7df99d4ccac93eb266031","modified":1570532430849},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.woff","hash":"7b3f44b4d3028f3c87ddf0f4bd62511c9bf4a87e","modified":1570532430849},{"_id":"themes/cactus/source/lib/justified-gallery/css/justifiedGallery.min.css","hash":"92bb6e468a1db7fbd99ccb960e15e28572254263","modified":1570532430857},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"92da6e3c7121e21cdfde25ef08797a3937a683e1","modified":1570532430856},{"_id":"themes/cactus/source/lib/justified-gallery/js/jquery.justifiedGallery.min.js","hash":"82ab395176c927ffbb2f7c95132ee0a06cd5d64a","modified":1570532430857},{"_id":"themes/cactus/source/lib/font-awesome/css/all.min.css","hash":"cf1a3fd771900af34f2af22142beecfb47367548","modified":1570532430841},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"d902f8db3e021155f177f698a252fb98d6e61768","modified":1570532430847},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.woff","hash":"f9d835a0f9248b1bb33d66968e87c4a50103ed8d","modified":1570532430847},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.ttf","hash":"19e302760e39e25a5f8d90d6cd0164ef6cd74f8c","modified":1570532430847},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.woff","hash":"80d33a73cbb60e206ef6f5c898988641576c7dda","modified":1570532430856},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.eot","hash":"644ece8263d2f96b087eebf7f6d4e309e5898eb5","modified":1570532430842},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.svg","hash":"33e86c0ad6fb9c5c0c8c2af4cb2d790c6b14a8aa","modified":1570532430849},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.eot","hash":"10740942ec6b3f4985529d343402d0bf32f9f847","modified":1570532430851},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Italic.ttf","hash":"93ebc5098cf57a32b7b8d297681f31692c09bdfa","modified":1570532430872},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-BoldItalic.ttf","hash":"b542b9591fbf33925d93f0695b6e123a9f0cfd43","modified":1570532430871},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-BoldItalic.ttf","hash":"926035f0156cccf1b0ca507347f39bf9c510f51e","modified":1570532430874},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.ttf","hash":"c445864a9646948e0d7ff44930ad732ee61427d8","modified":1570532430856},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-BoldItalic.ttf","hash":"b7d24ab1e4fad720f31a2b0cca1904ce1740d846","modified":1570532430865},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Italic.ttf","hash":"9d757cc9f928fc83b2133283dd639c12b11d94ad","modified":1570532430875},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Italic.ttf","hash":"9a23c6898b0943bd3d96c04df9a0f66e919451d8","modified":1570532430867},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Bold.ttf","hash":"f9918fb93d6ab6850f5d38069a999c311af78816","modified":1570532430873},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Bold.ttf","hash":"58be4b7760e9a84daa81929d046f9a15c4fd1c1a","modified":1570532430869},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Regular.ttf","hash":"20ce1fc7ae1254558ca044ae48283faaa58897e5","modified":1570532430872},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Regular.ttf","hash":"de559f8d70d5b1ab2810597bfd0b1b9506f3ef01","modified":1570532430876},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Regular.ttf","hash":"6c090d6bff3928fbf8a5f4104e58ed7f421aea7c","modified":1570532430868},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Bold.ttf","hash":"34f7db59f1d023294e69976aa20b7d52b86165a4","modified":1570532430864},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.svg","hash":"ed6c1ed8f24df909f40fe5e5c652d7ff9570c821","modified":1570532430854},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.svg","hash":"b0bb9e6ac7709206b9510f1718516d89aead5b21","modified":1570532430846},{"_id":"public/search.xml","hash":"f1f60d7de6977e5eb105e83c8f462de957288004","modified":1574757867447},{"_id":"public/categories/index.html","hash":"8cc0ed311e949de5fff13f12e35cfe6dc6c894ac","modified":1574757868702},{"_id":"public/search/index.html","hash":"677c135cabc8fa1a66564b9dc4ff4d3df0466934","modified":1574757868702},{"_id":"public/about/index.html","hash":"ed233f8174fb7a2581e1a24d2c9e29cee3a2d156","modified":1574757868793},{"_id":"public/2019/04/14/fabric-pbft/index.html","hash":"a8bc862ade4549b5589a6af4656772bc774c5b5a","modified":1574757868794},{"_id":"public/archives/index.html","hash":"65f02e4276f3074218c79ca93c4874586cbe3251","modified":1574757868794},{"_id":"public/archives/2017/index.html","hash":"431a807fa92513de08ec3b8c7ec822e1c07d5785","modified":1574757868794},{"_id":"public/archives/page/2/index.html","hash":"f828bc58248e35c36a62c97fec5cd7af3ca0de84","modified":1574757868794},{"_id":"public/archives/page/3/index.html","hash":"d727341d5f2bcb403feb9a20c82c8f5f2b9911aa","modified":1574757868795},{"_id":"public/archives/page/4/index.html","hash":"ee467f3f7559906796af17174130733ee4e480ba","modified":1574757868795},{"_id":"public/archives/2017/10/index.html","hash":"44e2a2cc76e3c651c8fb37ba5321976e688bcfbb","modified":1574757868795},{"_id":"public/archives/2019/index.html","hash":"e0b59a2670c815df27e73fae963673a066b47fa6","modified":1574757868795},{"_id":"public/archives/2017/page/2/index.html","hash":"d724eadafa65f11b15aa420289b9ae987ec4ba8d","modified":1574757868795},{"_id":"public/archives/2019/page/2/index.html","hash":"38e57e26fc1c7cac532af2402c190866df0cca6f","modified":1574757868795},{"_id":"public/archives/2017/10/page/2/index.html","hash":"0ba62977bf6f6903b0d972a42861432a5fff813d","modified":1574757868795},{"_id":"public/archives/2019/page/3/index.html","hash":"357d45fdef5cd976778d140eadf2adbc943ad479","modified":1574757868795},{"_id":"public/archives/2019/10/index.html","hash":"19c9e9c717ddb6050c365541a23a290423214e27","modified":1574757868795},{"_id":"public/archives/2019/04/index.html","hash":"7c3eaac62d82ae7be30131992c633ec0d0c51d19","modified":1574757868795},{"_id":"public/archives/2019/10/page/2/index.html","hash":"dede62b49d663f7d8e36a074a45ca0555e4a5c72","modified":1574757868795},{"_id":"public/archives/2019/10/page/3/index.html","hash":"761cc0376abf523049fb13c5e5d236c07eefa582","modified":1574757868795},{"_id":"public/categories/eth/index.html","hash":"e6e81be707b74416b1a3de7a44be2e242933b767","modified":1574757868795},{"_id":"public/categories/eth/page/2/index.html","hash":"1276da36c1d86c329d8953272379de0bc171d615","modified":1574757868795},{"_id":"public/categories/eos/index.html","hash":"52ca49b5a35d3df54782aedb5e783f31327ee74d","modified":1574757868795},{"_id":"public/categories/btc/index.html","hash":"f3f639b2af4dc550b9929dad43f87b2e52aa31c4","modified":1574757868795},{"_id":"public/categories/fabric/index.html","hash":"3b92b56426a717360a1e6ca10bfe2b69b9327475","modified":1574757868796},{"_id":"public/categories/enjoy/index.html","hash":"d61228099c615c450fe218343a5e5b625009cd44","modified":1574757868797},{"_id":"public/categories/blockchain/index.html","hash":"4148b34a9ce567a0aa5f5ac857440b412f9a1643","modified":1574757868797},{"_id":"public/categories/java/index.html","hash":"04df84c093830474f9ac2018a63a5612235f7ade","modified":1574757868797},{"_id":"public/index.html","hash":"461116f39168d517eb18658f55f7b15923eaaf24","modified":1574757868797},{"_id":"public/categories/elk/index.html","hash":"852aeeff2ea608e70a71649a17de29cee6e252e6","modified":1574757868797},{"_id":"public/categories/zilliqa/index.html","hash":"1c404cbacb8f9f1510d6eea25728fff3c00be943","modified":1574757868798},{"_id":"public/categories/enjoyment/index.html","hash":"4ed0cdc478ceb9e26b30a8c2b80cf52bfb757424","modified":1574757868798},{"_id":"public/page/3/index.html","hash":"4235c68bb50222a342b45c0cccf6e5747b0620a1","modified":1574757868798},{"_id":"public/page/4/index.html","hash":"86b0e8c71bf6580f6de86f9afb9b1d36c8d5310c","modified":1574757868798},{"_id":"public/page/2/index.html","hash":"81a6fb693a7a29baa32866c254c9798993a861cc","modified":1574757868798},{"_id":"public/2019/10/14/web3j/index.html","hash":"28c983ef22864e2bc158e8d2ceaa6790b9c60657","modified":1574757868798},{"_id":"public/2019/10/14/fabric-performance/index.html","hash":"f83678e47f90936d7ab1c51b76ba78c3c39914d5","modified":1574757868798},{"_id":"public/2019/10/14/eth-state/index.html","hash":"3c4042e5b3856fa61403bf5f19f4298c621753ca","modified":1574757868798},{"_id":"public/2019/10/14/fabric/index.html","hash":"3a559e7bd6bf99da2dffd089d440d54d38e8a3fa","modified":1574757868798},{"_id":"public/2019/10/14/eth-p2p-udp/index.html","hash":"8de41395b76125fc9e123931d08f893cc00d4118","modified":1574757868798},{"_id":"public/2019/10/14/eth-erc/index.html","hash":"91d3607963ca5a306dc4b5239497955ea2b989c7","modified":1574757868798},{"_id":"public/2019/10/14/dai-code/index.html","hash":"425fb4e8af5cd9efaf4974fefac7c0deb8cafc13","modified":1574757868798},{"_id":"public/2019/10/14/dai/index.html","hash":"13bfa1cb15402df33ff4257b679f17243a43f62f","modified":1574757868798},{"_id":"public/2019/10/14/eth-casper/index.html","hash":"1511d84cee3c02ec1ffe9906e561bee07f67a4ab","modified":1574757868798},{"_id":"public/2019/10/14/eth-contract/index.html","hash":"486cd8d6078872fd13db99a68c65d783a0600e84","modified":1574757868798},{"_id":"public/2019/10/14/eth/index.html","hash":"653b90e65b60e1d6444f469df3643f8e6e5c7c93","modified":1574757868798},{"_id":"public/2019/10/14/eth-build/index.html","hash":"f1d794c9a6e2f7f42f632d7772fb87a2eb098b31","modified":1574757868798},{"_id":"public/2019/10/14/eth-rlp/index.html","hash":"3b35312cc70f8cc853955a3b4fd5dc5c217a4770","modified":1574757868798},{"_id":"public/2019/10/14/eos-code/index.html","hash":"82e8dd59caaf93140928b334bb7230dd469e3566","modified":1574757868798},{"_id":"public/2019/10/14/eth-jsre-api/index.html","hash":"ff8bba961707f1a7187ec4e75fc41f0aa9f31ecd","modified":1574757868798},{"_id":"public/2019/10/14/eth-code-tx-event/index.html","hash":"98b670b1eb90c72a747213ef9575ad951dbab87a","modified":1574757868798},{"_id":"public/2019/10/14/eos/index.html","hash":"41ff40b0727a1d1a44dae338477fa2438fbf9639","modified":1574757868798},{"_id":"public/2019/10/14/zilliqa-network/index.html","hash":"cc12732a508dc0b0d3039c1a8fa9e44e3e475652","modified":1574757868799},{"_id":"public/2019/10/14/zilliqa/index.html","hash":"dd4e18a03ff77733344f98714283dbdacba2c785","modified":1574757868799},{"_id":"public/2019/10/14/blockchain/index.html","hash":"1482fc38ba4eb8d0feecbb7529bf90372bf84225","modified":1574757868799},{"_id":"public/2019/10/14/crypto/index.html","hash":"5fe2a958dc3d27926644875647951948f3360bb1","modified":1574757868799},{"_id":"public/2019/10/14/wallet-connection/index.html","hash":"2431253e79e5f327da12229178fe798736de61b1","modified":1574757868799},{"_id":"public/2019/10/12/how-to-set-up-a-blog/index.html","hash":"5efbce3b62e5c81c5e5ee36a511bd54edea1f4b1","modified":1574757868799},{"_id":"public/2019/04/14/btc-data-dat/index.html","hash":"786bacebf19eb2b2f908dee743d8ed7c85d91b4c","modified":1574757868799},{"_id":"public/2019/04/14/btc-wallet/index.html","hash":"336f947b75b8eafe44b4b5f38b37997b19339547","modified":1574757868799},{"_id":"public/2019/04/14/fabric-code-consensus-event/index.html","hash":"f1aaaf21efd4405ab74388f0a969cbdef1620fee","modified":1574757868799},{"_id":"public/2019/04/14/btc/index.html","hash":"8a91e1d6c6088671f3cc94bfd6eefc2e2b717ea5","modified":1574757868799},{"_id":"public/2019/04/11/fabric-example/index.html","hash":"eab142873876401918f392bc8242056fe7c68df2","modified":1574757868799},{"_id":"public/2017/10/14/elastic/index.html","hash":"0386377b0f248c15451681b92b3824b7b064ba60","modified":1574757868799},{"_id":"public/2017/10/14/elastic-painless/index.html","hash":"7704940d5adbdac1a8dfaacf100155dd87c7ce55","modified":1574757868799},{"_id":"public/2017/10/14/floodlight-sdn/index.html","hash":"547f03517e27c3448d654bfd103e3cc56f5205a4","modified":1574757868799},{"_id":"public/2017/10/14/elastic-template/index.html","hash":"f88ad8afb757f32ffa472e530beb2e206e3b5339","modified":1574757868799},{"_id":"public/2017/10/14/kibana-plugin-development/index.html","hash":"cd4eeb4629c6d4d56fd568b99ccae93f7137f669","modified":1574757868799},{"_id":"public/2017/10/14/elastic-logstash/index.html","hash":"5b7a16d97a58d688032182c02a315ac29139142e","modified":1574757868799},{"_id":"public/2017/10/14/kibana-plugin/index.html","hash":"6a639dde58dab588eca74271c834f89d77884e47","modified":1574757868799},{"_id":"public/2017/10/14/kibana-timeline/index.html","hash":"025c49b07015178f65f61793f10d951befe3611c","modified":1574757868799},{"_id":"public/2017/10/14/elastic-kibana/index.html","hash":"1d5f702da78f55029c448348e9743afea23396bf","modified":1574757868800},{"_id":"public/2017/10/14/elastic-search-dsl/index.html","hash":"a4beb7016f0f2f9d2e038230a6e979aaab8e1561","modified":1574757868800},{"_id":"public/2017/10/14/maven/index.html","hash":"038f6b62802f125d1fe447b41c66a147db3335a9","modified":1574757868800},{"_id":"public/2019/11/25/cosmos-ibc-store/index.html","hash":"c20f72e2e158bfb645b1f2ee85fecf21b1f66a25","modified":1574757868810},{"_id":"public/archives/page/5/index.html","hash":"0ca84b0fcd9e81a0e659e8e3ea5731c38c360b21","modified":1574757868810},{"_id":"public/archives/2019/page/4/index.html","hash":"392aab3bcfe1e4b01061e2fea43b63f743226d6a","modified":1574757868810},{"_id":"public/archives/2019/11/index.html","hash":"4856d4eb1b638cb67bfdc6146a3907cd1acb79ca","modified":1574757868810},{"_id":"public/categories/cosmos/index.html","hash":"a74d464759527ef96d1d16b63883018f1c4317b3","modified":1574757868810},{"_id":"public/page/5/index.html","hash":"f90925efe6a28126c5c62825b50dbac0079c50d0","modified":1574757868810},{"_id":"public/2019/11/26/cosmos-store/index.html","hash":"28b903dc5f8cae04ee0e0f3cafd379c47041aa77","modified":1574757868810},{"_id":"public/images/apple-touch-icon.png","hash":"57e2def34682655f41a0be2d083f16765ba7858b","modified":1574757868810},{"_id":"public/images/favicon.ico","hash":"189f9842bcb79a6f8f9e8445bc8bbd773443826b","modified":1574757868810},{"_id":"public/lib/vazir-font/Vazir-Bold.woff","hash":"df15fd1e74b6f4a50bea57e2b44d9627f38495b5","modified":1574757868810},{"_id":"public/lib/vazir-font/Vazir-Black.woff2","hash":"0a257c8b60e0f20802c1dc8daeed2d3cb0d44f17","modified":1574757868810},{"_id":"public/lib/vazir-font/Vazir-Black.woff","hash":"37443d0040f0d7af381c955e4c15919a15d0349e","modified":1574757868810},{"_id":"public/lib/vazir-font/Vazir-Bold.woff2","hash":"62447a951d48b21c4696ae72df4bc4adef636e26","modified":1574757868810},{"_id":"public/lib/vazir-font/Vazir-Light.woff2","hash":"ef07a250766fea840c1049e67c0405d9216ee0a8","modified":1574757868811},{"_id":"public/lib/vazir-font/Vazir-Light.woff","hash":"32ae5c0d1d5943c8bb8e0f6ab07c3269c6f8b8a8","modified":1574757868811},{"_id":"public/lib/vazir-font/Vazir-Medium.woff","hash":"f5653059b2a5929516e4aab02329a978600b9b67","modified":1574757868811},{"_id":"public/lib/vazir-font/Vazir-Thin.woff","hash":"ad4d46a99a1daf6353c86c79ac3a2b030213859c","modified":1574757868811},{"_id":"public/lib/vazir-font/Vazir-Thin.woff2","hash":"c3be79b553ec394db71268d604b1d29183b867dc","modified":1574757868811},{"_id":"public/lib/vazir-font/Vazir-Medium.woff2","hash":"668400ae92700965f03f2371faaee0ab8c8347c3","modified":1574757868811},{"_id":"public/lib/vazir-font/Vazir.woff","hash":"bbee70033f0f5882e9869e417b69c6a38f56f187","modified":1574757868811},{"_id":"public/lib/vazir-font/Vazir.woff2","hash":"30ce165216db078951a690a6ad665b9b78f5dd81","modified":1574757868811},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff","hash":"7b3f44b4d3028f3c87ddf0f4bd62511c9bf4a87e","modified":1574757868811},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.eot","hash":"42ff503f20e97503cef8e5b2ec10ae07699d7c01","modified":1574757868811},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.ttf","hash":"c140085833a38abec6b7df99d4ccac93eb266031","modified":1574757868811},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"9784edb76f8a2ed595ea4bf74d46cda4eff3b303","modified":1574757868811},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"92da6e3c7121e21cdfde25ef08797a3937a683e1","modified":1574757868811},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"d902f8db3e021155f177f698a252fb98d6e61768","modified":1574757868811},{"_id":"public/images/favicon-192x192.png","hash":"96e6fcbbb13a5914a6131391e210eb7dfd13d692","modified":1574757869289},{"_id":"public/lib/vazir-font/Vazir-Black.ttf","hash":"594dc3344ad14903c247615427d1009709f0f5a4","modified":1574757869290},{"_id":"public/lib/vazir-font/Vazir-Black.eot","hash":"13d026ff857c853cbd0dc519b6e58669db309441","modified":1574757869290},{"_id":"public/lib/vazir-font/Vazir-Bold.eot","hash":"f76ec625e15522ff60d21f7a9a3b71c65bc27556","modified":1574757869290},{"_id":"public/lib/vazir-font/Vazir-Light.eot","hash":"3edffd7bb61eee8cd46b57225f9f9e5264e3362b","modified":1574757869290},{"_id":"public/lib/vazir-font/Vazir-Light.ttf","hash":"9f1e2934098a6a4a7c5584c8f3fa24a707070da3","modified":1574757869291},{"_id":"public/lib/vazir-font/Vazir-Medium.eot","hash":"1f5a73db7947ef22c8a2bb19d6449b80496c03c4","modified":1574757869291},{"_id":"public/lib/vazir-font/Vazir-Medium.ttf","hash":"295f7e02c9b157e7ea63ad09613b00ceab85c5cd","modified":1574757869291},{"_id":"public/lib/vazir-font/Vazir-Thin.eot","hash":"08e1503d1181188690fd9c81860d6c890c1465f6","modified":1574757869291},{"_id":"public/lib/vazir-font/Vazir.eot","hash":"31a9219c25fe1991fb745ec8dbbcf45c6094a702","modified":1574757869291},{"_id":"public/lib/vazir-font/Vazir-Bold.ttf","hash":"2e6c9df9f775373fb1988ae8529aa8f05313dae6","modified":1574757869291},{"_id":"public/lib/vazir-font/Vazir-Thin.ttf","hash":"a6aa450ee6e0f85786474ca6b04827ef97e81af4","modified":1574757869291},{"_id":"public/lib/vazir-font/Vazir.ttf","hash":"f22b219824026e490a581ddb3b36b07997dff0e3","modified":1574757869292},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff","hash":"f9d835a0f9248b1bb33d66968e87c4a50103ed8d","modified":1574757869292},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.ttf","hash":"19e302760e39e25a5f8d90d6cd0164ef6cd74f8c","modified":1574757869292},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff","hash":"80d33a73cbb60e206ef6f5c898988641576c7dda","modified":1574757869292},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.eot","hash":"644ece8263d2f96b087eebf7f6d4e309e5898eb5","modified":1574757869293},{"_id":"public/css/rtl.css","hash":"c2c2bc4ce311b3129275e009e903088b45e7ed77","modified":1574757869300},{"_id":"public/js/main.js","hash":"584c5a69ac81a483a1c4377a2e2cf326c2795e7b","modified":1574757869301},{"_id":"public/js/search.js","hash":"a74d0c601f820160825a2e4ad13618074d714933","modified":1574757869301},{"_id":"public/lib/vazir-font/font-face.css","hash":"8f2bf6b59ae1f2ed4c2fead6cea4b8314fcf62e5","modified":1574757869301},{"_id":"public/lib/justified-gallery/css/justifiedGallery.min.css","hash":"92bb6e468a1db7fbd99ccb960e15e28572254263","modified":1574757869302},{"_id":"public/css/style.css","hash":"ca4e1956edbd7224ad77186c4fab4f07ae4dedb5","modified":1574757869302},{"_id":"public/lib/clipboard/clipboard.min.js","hash":"ee60ca5ba9401456105ef703a98092369b579c80","modified":1574757869311},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.svg","hash":"33e86c0ad6fb9c5c0c8c2af4cb2d790c6b14a8aa","modified":1574757869311},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.eot","hash":"10740942ec6b3f4985529d343402d0bf32f9f847","modified":1574757869311},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.ttf","hash":"c445864a9646948e0d7ff44930ad732ee61427d8","modified":1574757869311},{"_id":"public/lib/justified-gallery/js/jquery.justifiedGallery.min.js","hash":"82ab395176c927ffbb2f7c95132ee0a06cd5d64a","modified":1574757869321},{"_id":"public/images/logo.png","hash":"0e3029251dfda26adee2761f71377297e8c26871","modified":1574757869321},{"_id":"public/lib/meslo-LG/MesloLGM-BoldItalic.ttf","hash":"b542b9591fbf33925d93f0695b6e123a9f0cfd43","modified":1574757869367},{"_id":"public/lib/meslo-LG/MesloLGL-BoldItalic.ttf","hash":"b7d24ab1e4fad720f31a2b0cca1904ce1740d846","modified":1574757869368},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"cf1a3fd771900af34f2af22142beecfb47367548","modified":1574757869371},{"_id":"public/lib/meslo-LG/MesloLGS-BoldItalic.ttf","hash":"926035f0156cccf1b0ca507347f39bf9c510f51e","modified":1574757869371},{"_id":"public/lib/meslo-LG/MesloLGM-Italic.ttf","hash":"93ebc5098cf57a32b7b8d297681f31692c09bdfa","modified":1574757869371},{"_id":"public/lib/meslo-LG/MesloLGS-Italic.ttf","hash":"9d757cc9f928fc83b2133283dd639c12b11d94ad","modified":1574757869371},{"_id":"public/lib/meslo-LG/MesloLGL-Italic.ttf","hash":"9a23c6898b0943bd3d96c04df9a0f66e919451d8","modified":1574757869372},{"_id":"public/lib/meslo-LG/MesloLGM-Bold.ttf","hash":"58be4b7760e9a84daa81929d046f9a15c4fd1c1a","modified":1574757869377},{"_id":"public/lib/meslo-LG/MesloLGL-Regular.ttf","hash":"6c090d6bff3928fbf8a5f4104e58ed7f421aea7c","modified":1574757869377},{"_id":"public/lib/meslo-LG/MesloLGL-Bold.ttf","hash":"34f7db59f1d023294e69976aa20b7d52b86165a4","modified":1574757869377},{"_id":"public/lib/meslo-LG/MesloLGS-Regular.ttf","hash":"de559f8d70d5b1ab2810597bfd0b1b9506f3ef01","modified":1574757869379},{"_id":"public/lib/meslo-LG/MesloLGM-Regular.ttf","hash":"20ce1fc7ae1254558ca044ae48283faaa58897e5","modified":1574757869381},{"_id":"public/lib/meslo-LG/MesloLGS-Bold.ttf","hash":"f9918fb93d6ab6850f5d38069a999c311af78816","modified":1574757869381},{"_id":"public/lib/jquery/jquery.min.js","hash":"0dc32db4aa9c5f03f3b38c47d883dbd4fed13aae","modified":1574757869383},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.svg","hash":"b0bb9e6ac7709206b9510f1718516d89aead5b21","modified":1574757869384},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.svg","hash":"ed6c1ed8f24df909f40fe5e5c652d7ff9570c821","modified":1574757869385}],"Category":[{"name":"btc","_id":"ck3fm69sg0004t6xv1be7s3d4"},{"name":"cosmos","_id":"ck3fm69sw0009t6xvkndkd51t"},{"name":"blockchain","_id":"ck3fm69tc000gt6xv4i87p24p"},{"name":"eth","_id":"ck3fm69tg000lt6xvu8visr1f"},{"name":"elk","_id":"ck3fm69tl000pt6xvbnuymqxi"},{"name":"eos","_id":"ck3fm69ut001ht6xvwn2qjqlv"},{"name":"fabric","_id":"ck3fm69uv001kt6xvvpu3me62"},{"name":"enjoy","_id":"ck3fm69v1001rt6xvnah1dc9l"},{"name":"enjoyment","_id":"ck3fm69v3001ut6xvf3tlgbyy"},{"name":"java","_id":"ck3fm69v4001wt6xvaua0bvbr"},{"name":"zilliqa","_id":"ck3fm69xa002jt6xvgdhxo4vu"}],"Data":[{"_id":"projects","data":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}],"Page":[{"title":"about","date":"2019-10-08T07:30:25.000Z","_content":"\n\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-10-08 15:30:25\n---\n\n\n","updated":"2019-10-08T10:49:51.007Z","path":"about/index.html","comments":1,"layout":"page","_id":"ck3fm69ry0000t6xv0j4hjcxp","content":"","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":""},{"title":"categories","date":"2019-10-12T03:37:20.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-10-12 11:37:20\ntype: \"categories\"\n---\n","updated":"2019-10-14T02:58:23.348Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ck3fm69s90002t6xv8ogcngo6","content":"","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":""},{"title":"search","date":"2019-10-10T05:56:44.000Z","type":"search","_content":"","source":"search/index.md","raw":"---\ntitle: search\ndate: 2019-10-10 13:56:44\ntype: search\n---\n","updated":"2019-10-14T05:47:04.769Z","path":"search/index.html","comments":1,"layout":"page","_id":"ck3fm69sk0005t6xv8b1gsqfr","content":"","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":""}],"Post":[{"title":"btc_wallet","date":"2019-04-14T06:41:55.000Z","_content":"\n### 比特币钱包gocoin学习笔记\n\n> <https://github.com/piotrnar/gocoin>\n>\n> **Gocoin** is a full **Bitcoin** solution written in Go language (golang).\n>\n> The software architecture is focused on maximum performance of the node and cold storage security of the wallet.\n>\n> The **wallet** is designed to be used offline. It is deterministic and password seeded. As long as you remember the password, you do not need any backups ever. Wallet can be used without the client, but with the provided **balio** tool instead.\n>\n> The **client** (p2p node) is an application independent from the **wallet**. It keeps the entire UTXO set in RAM, providing the best block processing performance on the market.\n\n\n\n#### blockdb\n\n- cache, 缓存池，新产生block，添加入缓存池，当缓存池满了之后，踢掉最老使用的block\n- 写缓存channel，当channel满了之后，flush channel 到db文件中\n\n\n\n#### unspent_db\n\n如介绍中提到的，会将所有的utxo都存在内存里。\n\n- map, key为txid, v为txid下的所有的outs。问题是key的长度为8？txid长度为32，只取前8位？不会存在冲突吗\n- update为整体修改，即txid下所有的outs。\n- 存于文件，程序启动时从文件读取，必要时存入文件(如程序退出时)\n\n\n\n#### wallet/db.go\n\n账户系统，addr - utxo - balance\n\n```\nvar (\n\tAllBalancesP2KH, AllBalancesP2SH, AllBalancesP2WKH map[[20]byte]*OneAllAddrBal\n\tAllBalancesP2WSH                                   map[[32]byte]*OneAllAddrBal\n)\n\ntype OneAllAddrInp [utxo.UtxoIdxLen + 4]byte\n\ntype OneAllAddrBal struct {\n\tValue   uint64 // Highest bit of it means P2SH\n\tunsp    []OneAllAddrInp\n\tunspMap map[OneAllAddrInp]bool\n}\n\n```\n\n看起来主要是存于内存中，map的key为addr，OneAllAddrInp为txid的前8位(unspend_db中map的key)+n(第几个out)\n\n其中，根据out中script可以判断是什么地址的签名。\n\n```\nif out.IsP2KH() {\n\t\tcopy(uidx[:], out.PKScr[3:23])\n\t\trec = AllBalancesP2KH[uidx]\n\t\tif rec == nil {\n\t\t\trec = &OneAllAddrBal{}\n\t\t\tAllBalancesP2KH[uidx] = rec\n\t\t}\n} else if out.IsP2SH() {\n\tcopy(uidx[:], out.PKScr[2:22])\n\trec = AllBalancesP2SH[uidx]\n\tif rec == nil {\n\t\trec = &OneAllAddrBal{}\n\t\tAllBalancesP2SH[uidx] = rec\n\t}\n} else if out.IsP2WPKH() {\n\tcopy(uidx[:], out.PKScr[2:22])\n\trec = AllBalancesP2WKH[uidx]\n\tif rec == nil {\n\t\trec = &OneAllAddrBal{}\n\t\tAllBalancesP2WKH[uidx] = rec\n\t}\n} else if out.IsP2WSH() {\n\tvar uidx [32]byte\n\tcopy(uidx[:], out.PKScr[2:34])\n\trec = AllBalancesP2WSH[uidx]\n\tif rec == nil {\n\t\trec = &OneAllAddrBal{}\n\t\tAllBalancesP2WSH[uidx] = rec\n\t}\n} else {\n\tcontinue\n}\n\n\n\nfunc (out *UtxoTxOut) IsP2KH() bool {\n\treturn len(out.PKScr) == 25 && out.PKScr[0] == 0x76 && out.PKScr[1] == 0xa9 &&\n\t\tout.PKScr[2] == 0x14 && out.PKScr[23] == 0x88 && out.PKScr[24] == 0xac\n}\n\nfunc (r *UtxoTxOut) IsP2SH() bool {\n\treturn len(r.PKScr) == 23 && r.PKScr[0] == 0xa9 && r.PKScr[1] == 0x14 && r.PKScr[22] == 0x87\n}\n\nfunc (r *UtxoTxOut) IsP2WPKH() bool {\n\treturn len(r.PKScr) == 22 && r.PKScr[0] == 0 && r.PKScr[1] == 20\n}\n\nfunc (r *UtxoTxOut) IsP2WSH() bool {\n\treturn len(r.PKScr) == 34 && r.PKScr[0] == 0 && r.PKScr[1] == 32\n}\n\n```\n\n\n\n\n\n#### 分叉处理\n\n首先，收到来自peer的区块都会存下来，只是使用trust字段来表面这是主链上的块还是分叉链上的块。在保存到磁盘时同样会保存trust字段。\n\n其次，如果出现分叉了，会统计两条链的算力(这里为什么不是统计区块高度而是难度值让我有点费解)，然后如果分叉链的算力大于主链，会进行主链重置。跟eth的处理类似，首先找到共同的主块(分叉开始的地方)，然后废除的一方进行utxo的undo, 块的删除，然后新链进行utxo的doing。\n\n代码大致位于lib/chain/下，如blockdb.go,chain_accept.go等\n\n\n\n分叉算力统计算法\n\n```\n// Returns true if b1 has more POW than b2\nfunc (b1 *BlockTreeNode) MorePOW(b2 *BlockTreeNode) bool {\n\tvar b1sum, b2sum float64\n\tfor b1.Height > b2.Height {\n\t\tb1sum += btc.GetDifficulty(b1.Bits())\n\t\tb1 = b1.Parent\n\t}\n\tfor b2.Height > b1.Height {\n\t\tb2sum += btc.GetDifficulty(b2.Bits())\n\t\tb2 = b2.Parent\n\t}\n\tfor b1 != b2 {\n\t\tb1sum += btc.GetDifficulty(b1.Bits())\n\t\tb2sum += btc.GetDifficulty(b2.Bits())\n\t\tb1 = b1.Parent\n\t\tb2 = b2.Parent\n\t}\n\treturn b1sum > b2sum\n}\n\n```\n\n\n\n\n\n#### 关于地址\n\n之前想通过input中的script直接算出地址，是不可行的。\n\n普通的*P2PKH*的input中签名包含两部分pk+sig，所以拿到是可以通过pk解析出地址的。\n\n但P2SH script的签名是不包含pk的，所以是解析不到的。\n\n普遍而言，还是在out中找好了\n","source":"_posts/btc-wallet.md","raw":"---\ntitle: btc_wallet\ncategories:\n  - btc\ndate: 2019-4-14 14:41:55\ntags:\n---\n\n### 比特币钱包gocoin学习笔记\n\n> <https://github.com/piotrnar/gocoin>\n>\n> **Gocoin** is a full **Bitcoin** solution written in Go language (golang).\n>\n> The software architecture is focused on maximum performance of the node and cold storage security of the wallet.\n>\n> The **wallet** is designed to be used offline. It is deterministic and password seeded. As long as you remember the password, you do not need any backups ever. Wallet can be used without the client, but with the provided **balio** tool instead.\n>\n> The **client** (p2p node) is an application independent from the **wallet**. It keeps the entire UTXO set in RAM, providing the best block processing performance on the market.\n\n\n\n#### blockdb\n\n- cache, 缓存池，新产生block，添加入缓存池，当缓存池满了之后，踢掉最老使用的block\n- 写缓存channel，当channel满了之后，flush channel 到db文件中\n\n\n\n#### unspent_db\n\n如介绍中提到的，会将所有的utxo都存在内存里。\n\n- map, key为txid, v为txid下的所有的outs。问题是key的长度为8？txid长度为32，只取前8位？不会存在冲突吗\n- update为整体修改，即txid下所有的outs。\n- 存于文件，程序启动时从文件读取，必要时存入文件(如程序退出时)\n\n\n\n#### wallet/db.go\n\n账户系统，addr - utxo - balance\n\n```\nvar (\n\tAllBalancesP2KH, AllBalancesP2SH, AllBalancesP2WKH map[[20]byte]*OneAllAddrBal\n\tAllBalancesP2WSH                                   map[[32]byte]*OneAllAddrBal\n)\n\ntype OneAllAddrInp [utxo.UtxoIdxLen + 4]byte\n\ntype OneAllAddrBal struct {\n\tValue   uint64 // Highest bit of it means P2SH\n\tunsp    []OneAllAddrInp\n\tunspMap map[OneAllAddrInp]bool\n}\n\n```\n\n看起来主要是存于内存中，map的key为addr，OneAllAddrInp为txid的前8位(unspend_db中map的key)+n(第几个out)\n\n其中，根据out中script可以判断是什么地址的签名。\n\n```\nif out.IsP2KH() {\n\t\tcopy(uidx[:], out.PKScr[3:23])\n\t\trec = AllBalancesP2KH[uidx]\n\t\tif rec == nil {\n\t\t\trec = &OneAllAddrBal{}\n\t\t\tAllBalancesP2KH[uidx] = rec\n\t\t}\n} else if out.IsP2SH() {\n\tcopy(uidx[:], out.PKScr[2:22])\n\trec = AllBalancesP2SH[uidx]\n\tif rec == nil {\n\t\trec = &OneAllAddrBal{}\n\t\tAllBalancesP2SH[uidx] = rec\n\t}\n} else if out.IsP2WPKH() {\n\tcopy(uidx[:], out.PKScr[2:22])\n\trec = AllBalancesP2WKH[uidx]\n\tif rec == nil {\n\t\trec = &OneAllAddrBal{}\n\t\tAllBalancesP2WKH[uidx] = rec\n\t}\n} else if out.IsP2WSH() {\n\tvar uidx [32]byte\n\tcopy(uidx[:], out.PKScr[2:34])\n\trec = AllBalancesP2WSH[uidx]\n\tif rec == nil {\n\t\trec = &OneAllAddrBal{}\n\t\tAllBalancesP2WSH[uidx] = rec\n\t}\n} else {\n\tcontinue\n}\n\n\n\nfunc (out *UtxoTxOut) IsP2KH() bool {\n\treturn len(out.PKScr) == 25 && out.PKScr[0] == 0x76 && out.PKScr[1] == 0xa9 &&\n\t\tout.PKScr[2] == 0x14 && out.PKScr[23] == 0x88 && out.PKScr[24] == 0xac\n}\n\nfunc (r *UtxoTxOut) IsP2SH() bool {\n\treturn len(r.PKScr) == 23 && r.PKScr[0] == 0xa9 && r.PKScr[1] == 0x14 && r.PKScr[22] == 0x87\n}\n\nfunc (r *UtxoTxOut) IsP2WPKH() bool {\n\treturn len(r.PKScr) == 22 && r.PKScr[0] == 0 && r.PKScr[1] == 20\n}\n\nfunc (r *UtxoTxOut) IsP2WSH() bool {\n\treturn len(r.PKScr) == 34 && r.PKScr[0] == 0 && r.PKScr[1] == 32\n}\n\n```\n\n\n\n\n\n#### 分叉处理\n\n首先，收到来自peer的区块都会存下来，只是使用trust字段来表面这是主链上的块还是分叉链上的块。在保存到磁盘时同样会保存trust字段。\n\n其次，如果出现分叉了，会统计两条链的算力(这里为什么不是统计区块高度而是难度值让我有点费解)，然后如果分叉链的算力大于主链，会进行主链重置。跟eth的处理类似，首先找到共同的主块(分叉开始的地方)，然后废除的一方进行utxo的undo, 块的删除，然后新链进行utxo的doing。\n\n代码大致位于lib/chain/下，如blockdb.go,chain_accept.go等\n\n\n\n分叉算力统计算法\n\n```\n// Returns true if b1 has more POW than b2\nfunc (b1 *BlockTreeNode) MorePOW(b2 *BlockTreeNode) bool {\n\tvar b1sum, b2sum float64\n\tfor b1.Height > b2.Height {\n\t\tb1sum += btc.GetDifficulty(b1.Bits())\n\t\tb1 = b1.Parent\n\t}\n\tfor b2.Height > b1.Height {\n\t\tb2sum += btc.GetDifficulty(b2.Bits())\n\t\tb2 = b2.Parent\n\t}\n\tfor b1 != b2 {\n\t\tb1sum += btc.GetDifficulty(b1.Bits())\n\t\tb2sum += btc.GetDifficulty(b2.Bits())\n\t\tb1 = b1.Parent\n\t\tb2 = b2.Parent\n\t}\n\treturn b1sum > b2sum\n}\n\n```\n\n\n\n\n\n#### 关于地址\n\n之前想通过input中的script直接算出地址，是不可行的。\n\n普通的*P2PKH*的input中签名包含两部分pk+sig，所以拿到是可以通过pk解析出地址的。\n\n但P2SH script的签名是不包含pk的，所以是解析不到的。\n\n普遍而言，还是在out中找好了\n","slug":"btc-wallet","published":1,"updated":"2019-10-14T07:25:34.654Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69s20001t6xv2z74fwdn","content":"<h3 id=\"比特币钱包gocoin学习笔记\"><a href=\"#比特币钱包gocoin学习笔记\" class=\"headerlink\" title=\"比特币钱包gocoin学习笔记\"></a>比特币钱包gocoin学习笔记</h3><blockquote>\n<p><a href=\"https://github.com/piotrnar/gocoin\">https://github.com/piotrnar/gocoin</a></p>\n<p><strong>Gocoin</strong> is a full <strong>Bitcoin</strong> solution written in Go language (golang).</p>\n<p>The software architecture is focused on maximum performance of the node and cold storage security of the wallet.</p>\n<p>The <strong>wallet</strong> is designed to be used offline. It is deterministic and password seeded. As long as you remember the password, you do not need any backups ever. Wallet can be used without the client, but with the provided <strong>balio</strong> tool instead.</p>\n<p>The <strong>client</strong> (p2p node) is an application independent from the <strong>wallet</strong>. It keeps the entire UTXO set in RAM, providing the best block processing performance on the market.</p>\n</blockquote>\n<h4 id=\"blockdb\"><a href=\"#blockdb\" class=\"headerlink\" title=\"blockdb\"></a>blockdb</h4><ul>\n<li>cache, 缓存池，新产生block，添加入缓存池，当缓存池满了之后，踢掉最老使用的block</li>\n<li>写缓存channel，当channel满了之后，flush channel 到db文件中</li>\n</ul>\n<h4 id=\"unspent-db\"><a href=\"#unspent-db\" class=\"headerlink\" title=\"unspent_db\"></a>unspent_db</h4><p>如介绍中提到的，会将所有的utxo都存在内存里。</p>\n<ul>\n<li>map, key为txid, v为txid下的所有的outs。问题是key的长度为8？txid长度为32，只取前8位？不会存在冲突吗</li>\n<li>update为整体修改，即txid下所有的outs。</li>\n<li>存于文件，程序启动时从文件读取，必要时存入文件(如程序退出时)</li>\n</ul>\n<h4 id=\"wallet-db-go\"><a href=\"#wallet-db-go\" class=\"headerlink\" title=\"wallet/db.go\"></a>wallet/db.go</h4><p>账户系统，addr - utxo - balance</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var (</span><br><span class=\"line\">\tAllBalancesP2KH, AllBalancesP2SH, AllBalancesP2WKH map[[20]byte]*OneAllAddrBal</span><br><span class=\"line\">\tAllBalancesP2WSH                                   map[[32]byte]*OneAllAddrBal</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type OneAllAddrInp [utxo.UtxoIdxLen + 4]byte</span><br><span class=\"line\"></span><br><span class=\"line\">type OneAllAddrBal struct &#123;</span><br><span class=\"line\">\tValue   uint64 // Highest bit of it means P2SH</span><br><span class=\"line\">\tunsp    []OneAllAddrInp</span><br><span class=\"line\">\tunspMap map[OneAllAddrInp]bool</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>看起来主要是存于内存中，map的key为addr，OneAllAddrInp为txid的前8位(unspend_db中map的key)+n(第几个out)</p>\n<p>其中，根据out中script可以判断是什么地址的签名。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if out.IsP2KH() &#123;</span><br><span class=\"line\">\t\tcopy(uidx[:], out.PKScr[3:23])</span><br><span class=\"line\">\t\trec = AllBalancesP2KH[uidx]</span><br><span class=\"line\">\t\tif rec == nil &#123;</span><br><span class=\"line\">\t\t\trec = &amp;OneAllAddrBal&#123;&#125;</span><br><span class=\"line\">\t\t\tAllBalancesP2KH[uidx] = rec</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">&#125; else if out.IsP2SH() &#123;</span><br><span class=\"line\">\tcopy(uidx[:], out.PKScr[2:22])</span><br><span class=\"line\">\trec = AllBalancesP2SH[uidx]</span><br><span class=\"line\">\tif rec == nil &#123;</span><br><span class=\"line\">\t\trec = &amp;OneAllAddrBal&#123;&#125;</span><br><span class=\"line\">\t\tAllBalancesP2SH[uidx] = rec</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125; else if out.IsP2WPKH() &#123;</span><br><span class=\"line\">\tcopy(uidx[:], out.PKScr[2:22])</span><br><span class=\"line\">\trec = AllBalancesP2WKH[uidx]</span><br><span class=\"line\">\tif rec == nil &#123;</span><br><span class=\"line\">\t\trec = &amp;OneAllAddrBal&#123;&#125;</span><br><span class=\"line\">\t\tAllBalancesP2WKH[uidx] = rec</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125; else if out.IsP2WSH() &#123;</span><br><span class=\"line\">\tvar uidx [32]byte</span><br><span class=\"line\">\tcopy(uidx[:], out.PKScr[2:34])</span><br><span class=\"line\">\trec = AllBalancesP2WSH[uidx]</span><br><span class=\"line\">\tif rec == nil &#123;</span><br><span class=\"line\">\t\trec = &amp;OneAllAddrBal&#123;&#125;</span><br><span class=\"line\">\t\tAllBalancesP2WSH[uidx] = rec</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">\tcontinue</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">func (out *UtxoTxOut) IsP2KH() bool &#123;</span><br><span class=\"line\">\treturn len(out.PKScr) == 25 &amp;&amp; out.PKScr[0] == 0x76 &amp;&amp; out.PKScr[1] == 0xa9 &amp;&amp;</span><br><span class=\"line\">\t\tout.PKScr[2] == 0x14 &amp;&amp; out.PKScr[23] == 0x88 &amp;&amp; out.PKScr[24] == 0xac</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (r *UtxoTxOut) IsP2SH() bool &#123;</span><br><span class=\"line\">\treturn len(r.PKScr) == 23 &amp;&amp; r.PKScr[0] == 0xa9 &amp;&amp; r.PKScr[1] == 0x14 &amp;&amp; r.PKScr[22] == 0x87</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (r *UtxoTxOut) IsP2WPKH() bool &#123;</span><br><span class=\"line\">\treturn len(r.PKScr) == 22 &amp;&amp; r.PKScr[0] == 0 &amp;&amp; r.PKScr[1] == 20</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (r *UtxoTxOut) IsP2WSH() bool &#123;</span><br><span class=\"line\">\treturn len(r.PKScr) == 34 &amp;&amp; r.PKScr[0] == 0 &amp;&amp; r.PKScr[1] == 32</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"分叉处理\"><a href=\"#分叉处理\" class=\"headerlink\" title=\"分叉处理\"></a>分叉处理</h4><p>首先，收到来自peer的区块都会存下来，只是使用trust字段来表面这是主链上的块还是分叉链上的块。在保存到磁盘时同样会保存trust字段。</p>\n<p>其次，如果出现分叉了，会统计两条链的算力(这里为什么不是统计区块高度而是难度值让我有点费解)，然后如果分叉链的算力大于主链，会进行主链重置。跟eth的处理类似，首先找到共同的主块(分叉开始的地方)，然后废除的一方进行utxo的undo, 块的删除，然后新链进行utxo的doing。</p>\n<p>代码大致位于lib/chain/下，如blockdb.go,chain_accept.go等</p>\n<p>分叉算力统计算法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Returns true if b1 has more POW than b2</span><br><span class=\"line\">func (b1 *BlockTreeNode) MorePOW(b2 *BlockTreeNode) bool &#123;</span><br><span class=\"line\">\tvar b1sum, b2sum float64</span><br><span class=\"line\">\tfor b1.Height &gt; b2.Height &#123;</span><br><span class=\"line\">\t\tb1sum += btc.GetDifficulty(b1.Bits())</span><br><span class=\"line\">\t\tb1 = b1.Parent</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor b2.Height &gt; b1.Height &#123;</span><br><span class=\"line\">\t\tb2sum += btc.GetDifficulty(b2.Bits())</span><br><span class=\"line\">\t\tb2 = b2.Parent</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor b1 != b2 &#123;</span><br><span class=\"line\">\t\tb1sum += btc.GetDifficulty(b1.Bits())</span><br><span class=\"line\">\t\tb2sum += btc.GetDifficulty(b2.Bits())</span><br><span class=\"line\">\t\tb1 = b1.Parent</span><br><span class=\"line\">\t\tb2 = b2.Parent</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn b1sum &gt; b2sum</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"关于地址\"><a href=\"#关于地址\" class=\"headerlink\" title=\"关于地址\"></a>关于地址</h4><p>之前想通过input中的script直接算出地址，是不可行的。</p>\n<p>普通的<em>P2PKH</em>的input中签名包含两部分pk+sig，所以拿到是可以通过pk解析出地址的。</p>\n<p>但P2SH script的签名是不包含pk的，所以是解析不到的。</p>\n<p>普遍而言，还是在out中找好了</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h3 id=\"比特币钱包gocoin学习笔记\"><a href=\"#比特币钱包gocoin学习笔记\" class=\"headerlink\" title=\"比特币钱包gocoin学习笔记\"></a>比特币钱包gocoin学习笔记</h3><blockquote>\n<p><a href=\"https://github.com/piotrnar/gocoin\">https://github.com/piotrnar/gocoin</a></p>\n<p><strong>Gocoin</strong> is a full <strong>Bitcoin</strong> solution written in Go language (golang).</p>\n<p>The software architecture is focused on maximum performance of the node and cold storage security of the wallet.</p>\n<p>The <strong>wallet</strong> is designed to be used offline. It is deterministic and password seeded. As long as you remember the password, you do not need any backups ever. Wallet can be used without the client, but with the provided <strong>balio</strong> tool instead.</p>\n<p>The <strong>client</strong> (p2p node) is an application independent from the <strong>wallet</strong>. It keeps the entire UTXO set in RAM, providing the best block processing performance on the market.</p>\n</blockquote>\n<h4 id=\"blockdb\"><a href=\"#blockdb\" class=\"headerlink\" title=\"blockdb\"></a>blockdb</h4><ul>\n<li>cache, 缓存池，新产生block，添加入缓存池，当缓存池满了之后，踢掉最老使用的block</li>\n<li>写缓存channel，当channel满了之后，flush channel 到db文件中</li>\n</ul>\n<h4 id=\"unspent-db\"><a href=\"#unspent-db\" class=\"headerlink\" title=\"unspent_db\"></a>unspent_db</h4><p>如介绍中提到的，会将所有的utxo都存在内存里。</p>\n<ul>\n<li>map, key为txid, v为txid下的所有的outs。问题是key的长度为8？txid长度为32，只取前8位？不会存在冲突吗</li>\n<li>update为整体修改，即txid下所有的outs。</li>\n<li>存于文件，程序启动时从文件读取，必要时存入文件(如程序退出时)</li>\n</ul>\n<h4 id=\"wallet-db-go\"><a href=\"#wallet-db-go\" class=\"headerlink\" title=\"wallet/db.go\"></a>wallet/db.go</h4><p>账户系统，addr - utxo - balance</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var (</span><br><span class=\"line\">\tAllBalancesP2KH, AllBalancesP2SH, AllBalancesP2WKH map[[20]byte]*OneAllAddrBal</span><br><span class=\"line\">\tAllBalancesP2WSH                                   map[[32]byte]*OneAllAddrBal</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type OneAllAddrInp [utxo.UtxoIdxLen + 4]byte</span><br><span class=\"line\"></span><br><span class=\"line\">type OneAllAddrBal struct &#123;</span><br><span class=\"line\">\tValue   uint64 // Highest bit of it means P2SH</span><br><span class=\"line\">\tunsp    []OneAllAddrInp</span><br><span class=\"line\">\tunspMap map[OneAllAddrInp]bool</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>看起来主要是存于内存中，map的key为addr，OneAllAddrInp为txid的前8位(unspend_db中map的key)+n(第几个out)</p>\n<p>其中，根据out中script可以判断是什么地址的签名。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if out.IsP2KH() &#123;</span><br><span class=\"line\">\t\tcopy(uidx[:], out.PKScr[3:23])</span><br><span class=\"line\">\t\trec = AllBalancesP2KH[uidx]</span><br><span class=\"line\">\t\tif rec == nil &#123;</span><br><span class=\"line\">\t\t\trec = &amp;OneAllAddrBal&#123;&#125;</span><br><span class=\"line\">\t\t\tAllBalancesP2KH[uidx] = rec</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">&#125; else if out.IsP2SH() &#123;</span><br><span class=\"line\">\tcopy(uidx[:], out.PKScr[2:22])</span><br><span class=\"line\">\trec = AllBalancesP2SH[uidx]</span><br><span class=\"line\">\tif rec == nil &#123;</span><br><span class=\"line\">\t\trec = &amp;OneAllAddrBal&#123;&#125;</span><br><span class=\"line\">\t\tAllBalancesP2SH[uidx] = rec</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125; else if out.IsP2WPKH() &#123;</span><br><span class=\"line\">\tcopy(uidx[:], out.PKScr[2:22])</span><br><span class=\"line\">\trec = AllBalancesP2WKH[uidx]</span><br><span class=\"line\">\tif rec == nil &#123;</span><br><span class=\"line\">\t\trec = &amp;OneAllAddrBal&#123;&#125;</span><br><span class=\"line\">\t\tAllBalancesP2WKH[uidx] = rec</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125; else if out.IsP2WSH() &#123;</span><br><span class=\"line\">\tvar uidx [32]byte</span><br><span class=\"line\">\tcopy(uidx[:], out.PKScr[2:34])</span><br><span class=\"line\">\trec = AllBalancesP2WSH[uidx]</span><br><span class=\"line\">\tif rec == nil &#123;</span><br><span class=\"line\">\t\trec = &amp;OneAllAddrBal&#123;&#125;</span><br><span class=\"line\">\t\tAllBalancesP2WSH[uidx] = rec</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">\tcontinue</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">func (out *UtxoTxOut) IsP2KH() bool &#123;</span><br><span class=\"line\">\treturn len(out.PKScr) == 25 &amp;&amp; out.PKScr[0] == 0x76 &amp;&amp; out.PKScr[1] == 0xa9 &amp;&amp;</span><br><span class=\"line\">\t\tout.PKScr[2] == 0x14 &amp;&amp; out.PKScr[23] == 0x88 &amp;&amp; out.PKScr[24] == 0xac</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (r *UtxoTxOut) IsP2SH() bool &#123;</span><br><span class=\"line\">\treturn len(r.PKScr) == 23 &amp;&amp; r.PKScr[0] == 0xa9 &amp;&amp; r.PKScr[1] == 0x14 &amp;&amp; r.PKScr[22] == 0x87</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (r *UtxoTxOut) IsP2WPKH() bool &#123;</span><br><span class=\"line\">\treturn len(r.PKScr) == 22 &amp;&amp; r.PKScr[0] == 0 &amp;&amp; r.PKScr[1] == 20</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (r *UtxoTxOut) IsP2WSH() bool &#123;</span><br><span class=\"line\">\treturn len(r.PKScr) == 34 &amp;&amp; r.PKScr[0] == 0 &amp;&amp; r.PKScr[1] == 32</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"分叉处理\"><a href=\"#分叉处理\" class=\"headerlink\" title=\"分叉处理\"></a>分叉处理</h4><p>首先，收到来自peer的区块都会存下来，只是使用trust字段来表面这是主链上的块还是分叉链上的块。在保存到磁盘时同样会保存trust字段。</p>\n<p>其次，如果出现分叉了，会统计两条链的算力(这里为什么不是统计区块高度而是难度值让我有点费解)，然后如果分叉链的算力大于主链，会进行主链重置。跟eth的处理类似，首先找到共同的主块(分叉开始的地方)，然后废除的一方进行utxo的undo, 块的删除，然后新链进行utxo的doing。</p>\n<p>代码大致位于lib/chain/下，如blockdb.go,chain_accept.go等</p>\n<p>分叉算力统计算法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Returns true if b1 has more POW than b2</span><br><span class=\"line\">func (b1 *BlockTreeNode) MorePOW(b2 *BlockTreeNode) bool &#123;</span><br><span class=\"line\">\tvar b1sum, b2sum float64</span><br><span class=\"line\">\tfor b1.Height &gt; b2.Height &#123;</span><br><span class=\"line\">\t\tb1sum += btc.GetDifficulty(b1.Bits())</span><br><span class=\"line\">\t\tb1 = b1.Parent</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor b2.Height &gt; b1.Height &#123;</span><br><span class=\"line\">\t\tb2sum += btc.GetDifficulty(b2.Bits())</span><br><span class=\"line\">\t\tb2 = b2.Parent</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor b1 != b2 &#123;</span><br><span class=\"line\">\t\tb1sum += btc.GetDifficulty(b1.Bits())</span><br><span class=\"line\">\t\tb2sum += btc.GetDifficulty(b2.Bits())</span><br><span class=\"line\">\t\tb1 = b1.Parent</span><br><span class=\"line\">\t\tb2 = b2.Parent</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn b1sum &gt; b2sum</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"关于地址\"><a href=\"#关于地址\" class=\"headerlink\" title=\"关于地址\"></a>关于地址</h4><p>之前想通过input中的script直接算出地址，是不可行的。</p>\n<p>普通的<em>P2PKH</em>的input中签名包含两部分pk+sig，所以拿到是可以通过pk解析出地址的。</p>\n<p>但P2SH script的签名是不包含pk的，所以是解析不到的。</p>\n<p>普遍而言，还是在out中找好了</p>\n"},{"title":"cosmos-ibc-store","date":"2019-11-25T06:18:49.000Z","_content":"\n## Cosmos-ibc存储\n\ncosmos ibc是实现跨链的协议。其中会涉及到一些数据存储，这里对相关存储进行归纳。\n\n存储使用key-value形式。\n\ncosmos-sdk版本为fedekunze/ibc - 94ffaeb9f746d13b68678423d4aee0828f652fd4\n\n\n\n+ Client。\n\n| Key                              | Value          | 备注                                                   |\n| -------------------------------- | -------------- | ------------------------------------------------------ |\n| client/`clientID`/roots/`height` | Hash-root      | 用于merkle树验证的数据结构                             |\n| client/`clientID`/consensusState | consensusState | 另一条链的共识状态，包含root、验证节点、区块高度等信息 |\n| clients/`clientID`/state         | bool           | clientID是否由于恶意而被冻结(不可用)                   |\n| clients/`clientID`/type          | []byte         | 另一条链的共识算法(tendermint)                         |\n\nclient用于验证/存储/更新另一条链的信息状态\n\n\n\n+ Connection\n\n| Key                            | Value                                   | 备注               |\n| ------------------------------ | --------------------------------------- | ------------------ |\n| connections/`connectionID`     | Connection(state/clientID/counterParty) | 连接信息           |\n| clients/`clientID`/connections | []connectionIDs                         | clientID下的连接们 |\n|                                |                                         |                    |\n\n+ Channel\n\nPath = ports/`portID`/channel/`channelID`\n\n| Key                   | Value                                         | 备注     |\n| --------------------- | :-------------------------------------------- | -------- |\n| Path                  | Channel(state/ordering/counterParty/connHops) | 通道信息 |\n| Path/nextSequenceSend | Sequence（uint64）                            |          |\n| Path/nextSequenceRecv | Sequence（uint64）                            |          |\n\n\n\n+ Packet\n\n","source":"_posts/cosmos-ibc-store.md","raw":"---\ntitle: cosmos-ibc-store\ncategories:\n  - cosmos\ndate: 2019-11-25 14:18:49\ntags:\n---\n\n## Cosmos-ibc存储\n\ncosmos ibc是实现跨链的协议。其中会涉及到一些数据存储，这里对相关存储进行归纳。\n\n存储使用key-value形式。\n\ncosmos-sdk版本为fedekunze/ibc - 94ffaeb9f746d13b68678423d4aee0828f652fd4\n\n\n\n+ Client。\n\n| Key                              | Value          | 备注                                                   |\n| -------------------------------- | -------------- | ------------------------------------------------------ |\n| client/`clientID`/roots/`height` | Hash-root      | 用于merkle树验证的数据结构                             |\n| client/`clientID`/consensusState | consensusState | 另一条链的共识状态，包含root、验证节点、区块高度等信息 |\n| clients/`clientID`/state         | bool           | clientID是否由于恶意而被冻结(不可用)                   |\n| clients/`clientID`/type          | []byte         | 另一条链的共识算法(tendermint)                         |\n\nclient用于验证/存储/更新另一条链的信息状态\n\n\n\n+ Connection\n\n| Key                            | Value                                   | 备注               |\n| ------------------------------ | --------------------------------------- | ------------------ |\n| connections/`connectionID`     | Connection(state/clientID/counterParty) | 连接信息           |\n| clients/`clientID`/connections | []connectionIDs                         | clientID下的连接们 |\n|                                |                                         |                    |\n\n+ Channel\n\nPath = ports/`portID`/channel/`channelID`\n\n| Key                   | Value                                         | 备注     |\n| --------------------- | :-------------------------------------------- | -------- |\n| Path                  | Channel(state/ordering/counterParty/connHops) | 通道信息 |\n| Path/nextSequenceSend | Sequence（uint64）                            |          |\n| Path/nextSequenceRecv | Sequence（uint64）                            |          |\n\n\n\n+ Packet\n\n","slug":"cosmos-ibc-store","published":1,"updated":"2019-11-26T06:33:53.483Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69sa0003t6xv6cp9rp4p","content":"<h2 id=\"Cosmos-ibc存储\"><a href=\"#Cosmos-ibc存储\" class=\"headerlink\" title=\"Cosmos-ibc存储\"></a>Cosmos-ibc存储</h2><p>cosmos ibc是实现跨链的协议。其中会涉及到一些数据存储，这里对相关存储进行归纳。</p>\n<p>存储使用key-value形式。</p>\n<p>cosmos-sdk版本为fedekunze/ibc - 94ffaeb9f746d13b68678423d4aee0828f652fd4</p>\n<ul>\n<li>Client。</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Key</th>\n<th>Value</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>client/<code>clientID</code>/roots/<code>height</code></td>\n<td>Hash-root</td>\n<td>用于merkle树验证的数据结构</td>\n</tr>\n<tr>\n<td>client/<code>clientID</code>/consensusState</td>\n<td>consensusState</td>\n<td>另一条链的共识状态，包含root、验证节点、区块高度等信息</td>\n</tr>\n<tr>\n<td>clients/<code>clientID</code>/state</td>\n<td>bool</td>\n<td>clientID是否由于恶意而被冻结(不可用)</td>\n</tr>\n<tr>\n<td>clients/<code>clientID</code>/type</td>\n<td>[]byte</td>\n<td>另一条链的共识算法(tendermint)</td>\n</tr>\n</tbody></table>\n<p>client用于验证/存储/更新另一条链的信息状态</p>\n<ul>\n<li>Connection</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Key</th>\n<th>Value</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>connections/<code>connectionID</code></td>\n<td>Connection(state/clientID/counterParty)</td>\n<td>连接信息</td>\n</tr>\n<tr>\n<td>clients/<code>clientID</code>/connections</td>\n<td>[]connectionIDs</td>\n<td>clientID下的连接们</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li>Channel</li>\n</ul>\n<p>Path = ports/<code>portID</code>/channel/<code>channelID</code></p>\n<table>\n<thead>\n<tr>\n<th>Key</th>\n<th align=\"left\">Value</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Path</td>\n<td align=\"left\">Channel(state/ordering/counterParty/connHops)</td>\n<td>通道信息</td>\n</tr>\n<tr>\n<td>Path/nextSequenceSend</td>\n<td align=\"left\">Sequence（uint64）</td>\n<td></td>\n</tr>\n<tr>\n<td>Path/nextSequenceRecv</td>\n<td align=\"left\">Sequence（uint64）</td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li>Packet</li>\n</ul>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Cosmos-ibc存储\"><a href=\"#Cosmos-ibc存储\" class=\"headerlink\" title=\"Cosmos-ibc存储\"></a>Cosmos-ibc存储</h2><p>cosmos ibc是实现跨链的协议。其中会涉及到一些数据存储，这里对相关存储进行归纳。</p>\n<p>存储使用key-value形式。</p>\n<p>cosmos-sdk版本为fedekunze/ibc - 94ffaeb9f746d13b68678423d4aee0828f652fd4</p>\n<ul>\n<li>Client。</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Key</th>\n<th>Value</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>client/<code>clientID</code>/roots/<code>height</code></td>\n<td>Hash-root</td>\n<td>用于merkle树验证的数据结构</td>\n</tr>\n<tr>\n<td>client/<code>clientID</code>/consensusState</td>\n<td>consensusState</td>\n<td>另一条链的共识状态，包含root、验证节点、区块高度等信息</td>\n</tr>\n<tr>\n<td>clients/<code>clientID</code>/state</td>\n<td>bool</td>\n<td>clientID是否由于恶意而被冻结(不可用)</td>\n</tr>\n<tr>\n<td>clients/<code>clientID</code>/type</td>\n<td>[]byte</td>\n<td>另一条链的共识算法(tendermint)</td>\n</tr>\n</tbody></table>\n<p>client用于验证/存储/更新另一条链的信息状态</p>\n<ul>\n<li>Connection</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Key</th>\n<th>Value</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>connections/<code>connectionID</code></td>\n<td>Connection(state/clientID/counterParty)</td>\n<td>连接信息</td>\n</tr>\n<tr>\n<td>clients/<code>clientID</code>/connections</td>\n<td>[]connectionIDs</td>\n<td>clientID下的连接们</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li>Channel</li>\n</ul>\n<p>Path = ports/<code>portID</code>/channel/<code>channelID</code></p>\n<table>\n<thead>\n<tr>\n<th>Key</th>\n<th align=\"left\">Value</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Path</td>\n<td align=\"left\">Channel(state/ordering/counterParty/connHops)</td>\n<td>通道信息</td>\n</tr>\n<tr>\n<td>Path/nextSequenceSend</td>\n<td align=\"left\">Sequence（uint64）</td>\n<td></td>\n</tr>\n<tr>\n<td>Path/nextSequenceRecv</td>\n<td align=\"left\">Sequence（uint64）</td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li>Packet</li>\n</ul>\n"},{"title":"cosmos-store","date":"2019-11-26T06:34:13.000Z","_content":"\n\n\n###  Cosmos state\n\n 在使用时有用到查询存储的值的api，这个api不仅返回了key对应的value，还返回了proof。使用proof可证明这个value的确存储在链上。这是怎么证明的呢？\n\n翻了下源码，大概了解到是怎么证明的了。随手也记录一下。\n\n首先，在cosms-sdk中的设计是插件式，可以据情况使用`x/`包下的插件。\n\n在存储上的话，使用的是`store/rootmulti/store.go`..  ，根据包名猜测下是会有多颗树，然后每颗一个root，多个root又组成一颗树。根据上面的插件，所以就是据情况多个插件，多颗树吧。\n\n#### 源码分析\n\n`store/rootmulti/store.go`\n\n```\ntype Store struct {\n\t\tdb           dbm.DB  //用于持久化存储的db\n\t\tlastCommitID types.CommitID\n\t\tpruningOpts  types.PruningOptions\n\t\tstoresParams map[types.StoreKey]storeParams //1\n\t\tstores       map[types.StoreKey]types.CommitKVStore //2\n\t\tkeysByName   map[string]types.StoreKey  //3\n\t\tlazyLoading  bool\n\n\t\ttraceWriter  io.Writer\n\t\ttraceContext types.TraceContext\n\n\t\tinterBlockCache types.MultiStorePersistentCache\n}\n```\n\n主要看到1、2、3处为map结构。3的话比较明显是key是string类型，value是封装的某Key类型，这个某Key类型刚好是1和2的 key，注意到1的value类型是storeParams，好像只是参数，不是我想要的树结构。但是2的类型`types.CommitKVStore`，看起来有点像。`types.CommitKVStore`是接口类型，实现有`store/transient/store.go`和`store/iavl/store.go`，这里iavl好像很熟悉...gaia中对store实例化默认选择的是iavl。那么`ival`就是我想找的答案啦。\n\n\n\n#####  ival\n\n`store/iavl/store.go`里有我想找的tree结构，但...时间限制..我没看实现🤦‍♀️\n\n简单而言，我选择从测试入手... 首先是这里面的tree的存储是带有版本的..相当于会根据版本存储\n\n```\n//store/iavl/store_test.go\n\nvar (\n\ttreeData = map[string]string{\n\t\t\"hello\": \"goodbye\",\n\t\t\"aloha\": \"shalom\",\n\t}\n\tnMoreData = 0\n)\n\nfunc newAlohaTree(t *testing.T, db dbm.DB) (*iavl.MutableTree, types.CommitID) {\n\ttree := iavl.NewMutableTree(db, cacheSize)\n\tfor k, v := range treeData {\n\t\ttree.Set([]byte(k), []byte(v))  //\"hello\" => \"goodbye\"; \"aloha\" =>\"shalom\"\n\t}\n\tfor i := 0; i < nMoreData; i++ {\n\t\tkey := cmn.RandBytes(12)\n\t\tvalue := cmn.RandBytes(50)\n\t\ttree.Set(key, value)\n\t}\n\thash, ver, err := tree.SaveVersion()\n\trequire.Nil(t, err)\n\treturn tree, types.CommitID{Version: ver, Hash: hash}\n}\n\n\nfunc TestGetImmutable(t *testing.T) {\n\tdb := dbm.NewMemDB()\n\ttree, cID := newAlohaTree(t, db)   //初始化tree并且放入一些key-value对，并且saveVersion一次\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//version=1\n\tstore := UnsafeNewStore(tree, 10, 10)\n\t//\t将tree中的key=\"hello\"的value由\"goodbye\"更改为\"adios\"\n\trequire.True(t, tree.Set([]byte(\"hello\"), []byte(\"adios\")))  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\thash, ver, err := tree.SaveVersion()  //ver再次更新，此时version=2\n\tcID = types.CommitID{Version: ver, Hash: hash}  //hash => root\n\trequire.Nil(t, err)\n\t_, err = store.GetImmutable(cID.Version + 1)\n\trequire.Error(t, err)   //查询version=3的存储树，当然是没有的啦，err信息为找不到\n\n\tnewStore, err := store.GetImmutable(cID.Version - 1)  //查询version=1的存储树，\n\trequire.NoError(t, err)                           //此时hello的value为goodbye\n\trequire.Equal(t, newStore.Get([]byte(\"hello\")), []byte(\"goodbye\"))\n\n\tnewStore, err = store.GetImmutable(cID.Version)   //查询version=2的存储树\n\trequire.NoError(t, err)\t\t\t\t\t\t\t\t\t\t\t\t\t//此时hello的value已更新为adios\n\trequire.Equal(t, newStore.Get([]byte(\"hello\")), []byte(\"adios\"))\n\n  //abci Query接口实现，查询key=hello，version=2的value，并且返回证据\n\tres := newStore.Query(abci.RequestQuery{Data: []byte(\"hello\"), Height: cID.Version, Path: \"/key\", Prove: true})\n\trequire.Equal(t, res.Value, []byte(\"adios\"))\n\trequire.NotNil(t, res.Proof)\n\n\trequire.Panics(t, func() { newStore.Set(nil, nil) })\n\trequire.Panics(t, func() { newStore.Delete(nil) })\n\trequire.Panics(t, func() { newStore.Commit() })\n}\n\n```\n\n\n\n##### rootmulti\n\n然后再回来看`rootmulti/store`\n\n同样，还是看测试`store/rootmulti/store_test.go`\n\n```\nfunc TestHashStableWithEmptyCommit(t *testing.T) {\n\tvar db dbm.DB = dbm.NewMemDB()\n\tms := newMultiStoreWithMounts(db)\n\terr := ms.LoadLatestVersion()\n\trequire.Nil(t, err)\n\n\tcommitID := types.CommitID{}\n\tcheckStore(t, ms, commitID, commitID)\n\n\tk, v := []byte(\"wind\"), []byte(\"blows\")\n  //key=store1下的一棵树store1\n\tstore1 := ms.getStoreByName(\"store1\").(types.KVStore)\n\t//store1设置k-v\n\tstore1.Set(k, v)\n\n //ms.Commit, 会调用store1.SaveVersion方法\n\tcID := ms.Commit()\n\trequire.Equal(t, int64(1), cID.Version)\n\thash := cID.Hash\n\t// make an empty commit, it should update version, but not affect hash\n\tcID = ms.Commit()\n\trequire.Equal(t, int64(2), cID.Version)\n\trequire.Equal(t, hash, cID.Hash)\n}\n```\n\n更多测试可在``store/rootmulti/store_test.go`中。\n\n\n\n结论是，首先会添加多个key值，每个key一个树，然后这些树的roothash作为rootmulti树的叶子节点，组成树，计算出来的root-hash会作为apphash存储在区块头中。那些小树的叶子节点的值就是存储的具体的内容啦。\n\n\n\n证明key-value确实在区块头的方式是，首先证明key-value在某颗小树上(store-key下)，其次计算出小树的roothash，再使用roothash计算出apphash，与区块头的apphash对比即可证明。\n\n在使用的时候，选择的区块高度，证明为到这个区块为止，这个数据是存在的。\n\n\n\n最后结论草草结尾，有时间再细化。","source":"_posts/cosmos-store.md","raw":"---\ntitle: cosmos-store\ncategories:\n  - cosmos\ndate: 2019-11-26 14:34:13\ntags:\n---\n\n\n\n###  Cosmos state\n\n 在使用时有用到查询存储的值的api，这个api不仅返回了key对应的value，还返回了proof。使用proof可证明这个value的确存储在链上。这是怎么证明的呢？\n\n翻了下源码，大概了解到是怎么证明的了。随手也记录一下。\n\n首先，在cosms-sdk中的设计是插件式，可以据情况使用`x/`包下的插件。\n\n在存储上的话，使用的是`store/rootmulti/store.go`..  ，根据包名猜测下是会有多颗树，然后每颗一个root，多个root又组成一颗树。根据上面的插件，所以就是据情况多个插件，多颗树吧。\n\n#### 源码分析\n\n`store/rootmulti/store.go`\n\n```\ntype Store struct {\n\t\tdb           dbm.DB  //用于持久化存储的db\n\t\tlastCommitID types.CommitID\n\t\tpruningOpts  types.PruningOptions\n\t\tstoresParams map[types.StoreKey]storeParams //1\n\t\tstores       map[types.StoreKey]types.CommitKVStore //2\n\t\tkeysByName   map[string]types.StoreKey  //3\n\t\tlazyLoading  bool\n\n\t\ttraceWriter  io.Writer\n\t\ttraceContext types.TraceContext\n\n\t\tinterBlockCache types.MultiStorePersistentCache\n}\n```\n\n主要看到1、2、3处为map结构。3的话比较明显是key是string类型，value是封装的某Key类型，这个某Key类型刚好是1和2的 key，注意到1的value类型是storeParams，好像只是参数，不是我想要的树结构。但是2的类型`types.CommitKVStore`，看起来有点像。`types.CommitKVStore`是接口类型，实现有`store/transient/store.go`和`store/iavl/store.go`，这里iavl好像很熟悉...gaia中对store实例化默认选择的是iavl。那么`ival`就是我想找的答案啦。\n\n\n\n#####  ival\n\n`store/iavl/store.go`里有我想找的tree结构，但...时间限制..我没看实现🤦‍♀️\n\n简单而言，我选择从测试入手... 首先是这里面的tree的存储是带有版本的..相当于会根据版本存储\n\n```\n//store/iavl/store_test.go\n\nvar (\n\ttreeData = map[string]string{\n\t\t\"hello\": \"goodbye\",\n\t\t\"aloha\": \"shalom\",\n\t}\n\tnMoreData = 0\n)\n\nfunc newAlohaTree(t *testing.T, db dbm.DB) (*iavl.MutableTree, types.CommitID) {\n\ttree := iavl.NewMutableTree(db, cacheSize)\n\tfor k, v := range treeData {\n\t\ttree.Set([]byte(k), []byte(v))  //\"hello\" => \"goodbye\"; \"aloha\" =>\"shalom\"\n\t}\n\tfor i := 0; i < nMoreData; i++ {\n\t\tkey := cmn.RandBytes(12)\n\t\tvalue := cmn.RandBytes(50)\n\t\ttree.Set(key, value)\n\t}\n\thash, ver, err := tree.SaveVersion()\n\trequire.Nil(t, err)\n\treturn tree, types.CommitID{Version: ver, Hash: hash}\n}\n\n\nfunc TestGetImmutable(t *testing.T) {\n\tdb := dbm.NewMemDB()\n\ttree, cID := newAlohaTree(t, db)   //初始化tree并且放入一些key-value对，并且saveVersion一次\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//version=1\n\tstore := UnsafeNewStore(tree, 10, 10)\n\t//\t将tree中的key=\"hello\"的value由\"goodbye\"更改为\"adios\"\n\trequire.True(t, tree.Set([]byte(\"hello\"), []byte(\"adios\")))  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\thash, ver, err := tree.SaveVersion()  //ver再次更新，此时version=2\n\tcID = types.CommitID{Version: ver, Hash: hash}  //hash => root\n\trequire.Nil(t, err)\n\t_, err = store.GetImmutable(cID.Version + 1)\n\trequire.Error(t, err)   //查询version=3的存储树，当然是没有的啦，err信息为找不到\n\n\tnewStore, err := store.GetImmutable(cID.Version - 1)  //查询version=1的存储树，\n\trequire.NoError(t, err)                           //此时hello的value为goodbye\n\trequire.Equal(t, newStore.Get([]byte(\"hello\")), []byte(\"goodbye\"))\n\n\tnewStore, err = store.GetImmutable(cID.Version)   //查询version=2的存储树\n\trequire.NoError(t, err)\t\t\t\t\t\t\t\t\t\t\t\t\t//此时hello的value已更新为adios\n\trequire.Equal(t, newStore.Get([]byte(\"hello\")), []byte(\"adios\"))\n\n  //abci Query接口实现，查询key=hello，version=2的value，并且返回证据\n\tres := newStore.Query(abci.RequestQuery{Data: []byte(\"hello\"), Height: cID.Version, Path: \"/key\", Prove: true})\n\trequire.Equal(t, res.Value, []byte(\"adios\"))\n\trequire.NotNil(t, res.Proof)\n\n\trequire.Panics(t, func() { newStore.Set(nil, nil) })\n\trequire.Panics(t, func() { newStore.Delete(nil) })\n\trequire.Panics(t, func() { newStore.Commit() })\n}\n\n```\n\n\n\n##### rootmulti\n\n然后再回来看`rootmulti/store`\n\n同样，还是看测试`store/rootmulti/store_test.go`\n\n```\nfunc TestHashStableWithEmptyCommit(t *testing.T) {\n\tvar db dbm.DB = dbm.NewMemDB()\n\tms := newMultiStoreWithMounts(db)\n\terr := ms.LoadLatestVersion()\n\trequire.Nil(t, err)\n\n\tcommitID := types.CommitID{}\n\tcheckStore(t, ms, commitID, commitID)\n\n\tk, v := []byte(\"wind\"), []byte(\"blows\")\n  //key=store1下的一棵树store1\n\tstore1 := ms.getStoreByName(\"store1\").(types.KVStore)\n\t//store1设置k-v\n\tstore1.Set(k, v)\n\n //ms.Commit, 会调用store1.SaveVersion方法\n\tcID := ms.Commit()\n\trequire.Equal(t, int64(1), cID.Version)\n\thash := cID.Hash\n\t// make an empty commit, it should update version, but not affect hash\n\tcID = ms.Commit()\n\trequire.Equal(t, int64(2), cID.Version)\n\trequire.Equal(t, hash, cID.Hash)\n}\n```\n\n更多测试可在``store/rootmulti/store_test.go`中。\n\n\n\n结论是，首先会添加多个key值，每个key一个树，然后这些树的roothash作为rootmulti树的叶子节点，组成树，计算出来的root-hash会作为apphash存储在区块头中。那些小树的叶子节点的值就是存储的具体的内容啦。\n\n\n\n证明key-value确实在区块头的方式是，首先证明key-value在某颗小树上(store-key下)，其次计算出小树的roothash，再使用roothash计算出apphash，与区块头的apphash对比即可证明。\n\n在使用的时候，选择的区块高度，证明为到这个区块为止，这个数据是存在的。\n\n\n\n最后结论草草结尾，有时间再细化。","slug":"cosmos-store","published":1,"updated":"2019-11-26T08:42:12.994Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69so0006t6xvnm6lw2hr","content":"<h3 id=\"Cosmos-state\"><a href=\"#Cosmos-state\" class=\"headerlink\" title=\"Cosmos state\"></a>Cosmos state</h3><p> 在使用时有用到查询存储的值的api，这个api不仅返回了key对应的value，还返回了proof。使用proof可证明这个value的确存储在链上。这是怎么证明的呢？</p>\n<p>翻了下源码，大概了解到是怎么证明的了。随手也记录一下。</p>\n<p>首先，在cosms-sdk中的设计是插件式，可以据情况使用<code>x/</code>包下的插件。</p>\n<p>在存储上的话，使用的是<code>store/rootmulti/store.go</code>..  ，根据包名猜测下是会有多颗树，然后每颗一个root，多个root又组成一颗树。根据上面的插件，所以就是据情况多个插件，多颗树吧。</p>\n<h4 id=\"源码分析\"><a href=\"#源码分析\" class=\"headerlink\" title=\"源码分析\"></a>源码分析</h4><p><code>store/rootmulti/store.go</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Store struct &#123;</span><br><span class=\"line\">\t\tdb           dbm.DB  //用于持久化存储的db</span><br><span class=\"line\">\t\tlastCommitID types.CommitID</span><br><span class=\"line\">\t\tpruningOpts  types.PruningOptions</span><br><span class=\"line\">\t\tstoresParams map[types.StoreKey]storeParams //1</span><br><span class=\"line\">\t\tstores       map[types.StoreKey]types.CommitKVStore //2</span><br><span class=\"line\">\t\tkeysByName   map[string]types.StoreKey  //3</span><br><span class=\"line\">\t\tlazyLoading  bool</span><br><span class=\"line\"></span><br><span class=\"line\">\t\ttraceWriter  io.Writer</span><br><span class=\"line\">\t\ttraceContext types.TraceContext</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tinterBlockCache types.MultiStorePersistentCache</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>主要看到1、2、3处为map结构。3的话比较明显是key是string类型，value是封装的某Key类型，这个某Key类型刚好是1和2的 key，注意到1的value类型是storeParams，好像只是参数，不是我想要的树结构。但是2的类型<code>types.CommitKVStore</code>，看起来有点像。<code>types.CommitKVStore</code>是接口类型，实现有<code>store/transient/store.go</code>和<code>store/iavl/store.go</code>，这里iavl好像很熟悉…gaia中对store实例化默认选择的是iavl。那么<code>ival</code>就是我想找的答案啦。</p>\n<h5 id=\"ival\"><a href=\"#ival\" class=\"headerlink\" title=\"ival\"></a>ival</h5><p><code>store/iavl/store.go</code>里有我想找的tree结构，但…时间限制..我没看实现🤦‍♀️</p>\n<p>简单而言，我选择从测试入手… 首先是这里面的tree的存储是带有版本的..相当于会根据版本存储</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//store/iavl/store_test.go</span><br><span class=\"line\"></span><br><span class=\"line\">var (</span><br><span class=\"line\">\ttreeData = map[string]string&#123;</span><br><span class=\"line\">\t\t&quot;hello&quot;: &quot;goodbye&quot;,</span><br><span class=\"line\">\t\t&quot;aloha&quot;: &quot;shalom&quot;,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tnMoreData = 0</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func newAlohaTree(t *testing.T, db dbm.DB) (*iavl.MutableTree, types.CommitID) &#123;</span><br><span class=\"line\">\ttree := iavl.NewMutableTree(db, cacheSize)</span><br><span class=\"line\">\tfor k, v := range treeData &#123;</span><br><span class=\"line\">\t\ttree.Set([]byte(k), []byte(v))  //&quot;hello&quot; =&gt; &quot;goodbye&quot;; &quot;aloha&quot; =&gt;&quot;shalom&quot;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor i := 0; i &lt; nMoreData; i++ &#123;</span><br><span class=\"line\">\t\tkey := cmn.RandBytes(12)</span><br><span class=\"line\">\t\tvalue := cmn.RandBytes(50)</span><br><span class=\"line\">\t\ttree.Set(key, value)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\thash, ver, err := tree.SaveVersion()</span><br><span class=\"line\">\trequire.Nil(t, err)</span><br><span class=\"line\">\treturn tree, types.CommitID&#123;Version: ver, Hash: hash&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">func TestGetImmutable(t *testing.T) &#123;</span><br><span class=\"line\">\tdb := dbm.NewMemDB()</span><br><span class=\"line\">\ttree, cID := newAlohaTree(t, db)   //初始化tree并且放入一些key-value对，并且saveVersion一次</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//version=1</span><br><span class=\"line\">\tstore := UnsafeNewStore(tree, 10, 10)</span><br><span class=\"line\">\t//\t将tree中的key=&quot;hello&quot;的value由&quot;goodbye&quot;更改为&quot;adios&quot;</span><br><span class=\"line\">\trequire.True(t, tree.Set([]byte(&quot;hello&quot;), []byte(&quot;adios&quot;)))  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</span><br><span class=\"line\">\thash, ver, err := tree.SaveVersion()  //ver再次更新，此时version=2</span><br><span class=\"line\">\tcID = types.CommitID&#123;Version: ver, Hash: hash&#125;  //hash =&gt; root</span><br><span class=\"line\">\trequire.Nil(t, err)</span><br><span class=\"line\">\t_, err = store.GetImmutable(cID.Version + 1)</span><br><span class=\"line\">\trequire.Error(t, err)   //查询version=3的存储树，当然是没有的啦，err信息为找不到</span><br><span class=\"line\"></span><br><span class=\"line\">\tnewStore, err := store.GetImmutable(cID.Version - 1)  //查询version=1的存储树，</span><br><span class=\"line\">\trequire.NoError(t, err)                           //此时hello的value为goodbye</span><br><span class=\"line\">\trequire.Equal(t, newStore.Get([]byte(&quot;hello&quot;)), []byte(&quot;goodbye&quot;))</span><br><span class=\"line\"></span><br><span class=\"line\">\tnewStore, err = store.GetImmutable(cID.Version)   //查询version=2的存储树</span><br><span class=\"line\">\trequire.NoError(t, err)\t\t\t\t\t\t\t\t\t\t\t\t\t//此时hello的value已更新为adios</span><br><span class=\"line\">\trequire.Equal(t, newStore.Get([]byte(&quot;hello&quot;)), []byte(&quot;adios&quot;))</span><br><span class=\"line\"></span><br><span class=\"line\">  //abci Query接口实现，查询key=hello，version=2的value，并且返回证据</span><br><span class=\"line\">\tres := newStore.Query(abci.RequestQuery&#123;Data: []byte(&quot;hello&quot;), Height: cID.Version, Path: &quot;/key&quot;, Prove: true&#125;)</span><br><span class=\"line\">\trequire.Equal(t, res.Value, []byte(&quot;adios&quot;))</span><br><span class=\"line\">\trequire.NotNil(t, res.Proof)</span><br><span class=\"line\"></span><br><span class=\"line\">\trequire.Panics(t, func() &#123; newStore.Set(nil, nil) &#125;)</span><br><span class=\"line\">\trequire.Panics(t, func() &#123; newStore.Delete(nil) &#125;)</span><br><span class=\"line\">\trequire.Panics(t, func() &#123; newStore.Commit() &#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"rootmulti\"><a href=\"#rootmulti\" class=\"headerlink\" title=\"rootmulti\"></a>rootmulti</h5><p>然后再回来看<code>rootmulti/store</code></p>\n<p>同样，还是看测试<code>store/rootmulti/store_test.go</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func TestHashStableWithEmptyCommit(t *testing.T) &#123;</span><br><span class=\"line\">\tvar db dbm.DB = dbm.NewMemDB()</span><br><span class=\"line\">\tms := newMultiStoreWithMounts(db)</span><br><span class=\"line\">\terr := ms.LoadLatestVersion()</span><br><span class=\"line\">\trequire.Nil(t, err)</span><br><span class=\"line\"></span><br><span class=\"line\">\tcommitID := types.CommitID&#123;&#125;</span><br><span class=\"line\">\tcheckStore(t, ms, commitID, commitID)</span><br><span class=\"line\"></span><br><span class=\"line\">\tk, v := []byte(&quot;wind&quot;), []byte(&quot;blows&quot;)</span><br><span class=\"line\">  //key=store1下的一棵树store1</span><br><span class=\"line\">\tstore1 := ms.getStoreByName(&quot;store1&quot;).(types.KVStore)</span><br><span class=\"line\">\t//store1设置k-v</span><br><span class=\"line\">\tstore1.Set(k, v)</span><br><span class=\"line\"></span><br><span class=\"line\"> //ms.Commit, 会调用store1.SaveVersion方法</span><br><span class=\"line\">\tcID := ms.Commit()</span><br><span class=\"line\">\trequire.Equal(t, int64(1), cID.Version)</span><br><span class=\"line\">\thash := cID.Hash</span><br><span class=\"line\">\t// make an empty commit, it should update version, but not affect hash</span><br><span class=\"line\">\tcID = ms.Commit()</span><br><span class=\"line\">\trequire.Equal(t, int64(2), cID.Version)</span><br><span class=\"line\">\trequire.Equal(t, hash, cID.Hash)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>更多测试可在``store/rootmulti/store_test.go`中。</p>\n<p>结论是，首先会添加多个key值，每个key一个树，然后这些树的roothash作为rootmulti树的叶子节点，组成树，计算出来的root-hash会作为apphash存储在区块头中。那些小树的叶子节点的值就是存储的具体的内容啦。</p>\n<p>证明key-value确实在区块头的方式是，首先证明key-value在某颗小树上(store-key下)，其次计算出小树的roothash，再使用roothash计算出apphash，与区块头的apphash对比即可证明。</p>\n<p>在使用的时候，选择的区块高度，证明为到这个区块为止，这个数据是存在的。</p>\n<p>最后结论草草结尾，有时间再细化。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h3 id=\"Cosmos-state\"><a href=\"#Cosmos-state\" class=\"headerlink\" title=\"Cosmos state\"></a>Cosmos state</h3><p> 在使用时有用到查询存储的值的api，这个api不仅返回了key对应的value，还返回了proof。使用proof可证明这个value的确存储在链上。这是怎么证明的呢？</p>\n<p>翻了下源码，大概了解到是怎么证明的了。随手也记录一下。</p>\n<p>首先，在cosms-sdk中的设计是插件式，可以据情况使用<code>x/</code>包下的插件。</p>\n<p>在存储上的话，使用的是<code>store/rootmulti/store.go</code>..  ，根据包名猜测下是会有多颗树，然后每颗一个root，多个root又组成一颗树。根据上面的插件，所以就是据情况多个插件，多颗树吧。</p>\n<h4 id=\"源码分析\"><a href=\"#源码分析\" class=\"headerlink\" title=\"源码分析\"></a>源码分析</h4><p><code>store/rootmulti/store.go</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Store struct &#123;</span><br><span class=\"line\">\t\tdb           dbm.DB  //用于持久化存储的db</span><br><span class=\"line\">\t\tlastCommitID types.CommitID</span><br><span class=\"line\">\t\tpruningOpts  types.PruningOptions</span><br><span class=\"line\">\t\tstoresParams map[types.StoreKey]storeParams //1</span><br><span class=\"line\">\t\tstores       map[types.StoreKey]types.CommitKVStore //2</span><br><span class=\"line\">\t\tkeysByName   map[string]types.StoreKey  //3</span><br><span class=\"line\">\t\tlazyLoading  bool</span><br><span class=\"line\"></span><br><span class=\"line\">\t\ttraceWriter  io.Writer</span><br><span class=\"line\">\t\ttraceContext types.TraceContext</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tinterBlockCache types.MultiStorePersistentCache</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>主要看到1、2、3处为map结构。3的话比较明显是key是string类型，value是封装的某Key类型，这个某Key类型刚好是1和2的 key，注意到1的value类型是storeParams，好像只是参数，不是我想要的树结构。但是2的类型<code>types.CommitKVStore</code>，看起来有点像。<code>types.CommitKVStore</code>是接口类型，实现有<code>store/transient/store.go</code>和<code>store/iavl/store.go</code>，这里iavl好像很熟悉…gaia中对store实例化默认选择的是iavl。那么<code>ival</code>就是我想找的答案啦。</p>\n<h5 id=\"ival\"><a href=\"#ival\" class=\"headerlink\" title=\"ival\"></a>ival</h5><p><code>store/iavl/store.go</code>里有我想找的tree结构，但…时间限制..我没看实现🤦‍♀️</p>\n<p>简单而言，我选择从测试入手… 首先是这里面的tree的存储是带有版本的..相当于会根据版本存储</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//store/iavl/store_test.go</span><br><span class=\"line\"></span><br><span class=\"line\">var (</span><br><span class=\"line\">\ttreeData = map[string]string&#123;</span><br><span class=\"line\">\t\t&quot;hello&quot;: &quot;goodbye&quot;,</span><br><span class=\"line\">\t\t&quot;aloha&quot;: &quot;shalom&quot;,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tnMoreData = 0</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func newAlohaTree(t *testing.T, db dbm.DB) (*iavl.MutableTree, types.CommitID) &#123;</span><br><span class=\"line\">\ttree := iavl.NewMutableTree(db, cacheSize)</span><br><span class=\"line\">\tfor k, v := range treeData &#123;</span><br><span class=\"line\">\t\ttree.Set([]byte(k), []byte(v))  //&quot;hello&quot; =&gt; &quot;goodbye&quot;; &quot;aloha&quot; =&gt;&quot;shalom&quot;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor i := 0; i &lt; nMoreData; i++ &#123;</span><br><span class=\"line\">\t\tkey := cmn.RandBytes(12)</span><br><span class=\"line\">\t\tvalue := cmn.RandBytes(50)</span><br><span class=\"line\">\t\ttree.Set(key, value)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\thash, ver, err := tree.SaveVersion()</span><br><span class=\"line\">\trequire.Nil(t, err)</span><br><span class=\"line\">\treturn tree, types.CommitID&#123;Version: ver, Hash: hash&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">func TestGetImmutable(t *testing.T) &#123;</span><br><span class=\"line\">\tdb := dbm.NewMemDB()</span><br><span class=\"line\">\ttree, cID := newAlohaTree(t, db)   //初始化tree并且放入一些key-value对，并且saveVersion一次</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//version=1</span><br><span class=\"line\">\tstore := UnsafeNewStore(tree, 10, 10)</span><br><span class=\"line\">\t//\t将tree中的key=&quot;hello&quot;的value由&quot;goodbye&quot;更改为&quot;adios&quot;</span><br><span class=\"line\">\trequire.True(t, tree.Set([]byte(&quot;hello&quot;), []byte(&quot;adios&quot;)))  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</span><br><span class=\"line\">\thash, ver, err := tree.SaveVersion()  //ver再次更新，此时version=2</span><br><span class=\"line\">\tcID = types.CommitID&#123;Version: ver, Hash: hash&#125;  //hash =&gt; root</span><br><span class=\"line\">\trequire.Nil(t, err)</span><br><span class=\"line\">\t_, err = store.GetImmutable(cID.Version + 1)</span><br><span class=\"line\">\trequire.Error(t, err)   //查询version=3的存储树，当然是没有的啦，err信息为找不到</span><br><span class=\"line\"></span><br><span class=\"line\">\tnewStore, err := store.GetImmutable(cID.Version - 1)  //查询version=1的存储树，</span><br><span class=\"line\">\trequire.NoError(t, err)                           //此时hello的value为goodbye</span><br><span class=\"line\">\trequire.Equal(t, newStore.Get([]byte(&quot;hello&quot;)), []byte(&quot;goodbye&quot;))</span><br><span class=\"line\"></span><br><span class=\"line\">\tnewStore, err = store.GetImmutable(cID.Version)   //查询version=2的存储树</span><br><span class=\"line\">\trequire.NoError(t, err)\t\t\t\t\t\t\t\t\t\t\t\t\t//此时hello的value已更新为adios</span><br><span class=\"line\">\trequire.Equal(t, newStore.Get([]byte(&quot;hello&quot;)), []byte(&quot;adios&quot;))</span><br><span class=\"line\"></span><br><span class=\"line\">  //abci Query接口实现，查询key=hello，version=2的value，并且返回证据</span><br><span class=\"line\">\tres := newStore.Query(abci.RequestQuery&#123;Data: []byte(&quot;hello&quot;), Height: cID.Version, Path: &quot;/key&quot;, Prove: true&#125;)</span><br><span class=\"line\">\trequire.Equal(t, res.Value, []byte(&quot;adios&quot;))</span><br><span class=\"line\">\trequire.NotNil(t, res.Proof)</span><br><span class=\"line\"></span><br><span class=\"line\">\trequire.Panics(t, func() &#123; newStore.Set(nil, nil) &#125;)</span><br><span class=\"line\">\trequire.Panics(t, func() &#123; newStore.Delete(nil) &#125;)</span><br><span class=\"line\">\trequire.Panics(t, func() &#123; newStore.Commit() &#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"rootmulti\"><a href=\"#rootmulti\" class=\"headerlink\" title=\"rootmulti\"></a>rootmulti</h5><p>然后再回来看<code>rootmulti/store</code></p>\n<p>同样，还是看测试<code>store/rootmulti/store_test.go</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func TestHashStableWithEmptyCommit(t *testing.T) &#123;</span><br><span class=\"line\">\tvar db dbm.DB = dbm.NewMemDB()</span><br><span class=\"line\">\tms := newMultiStoreWithMounts(db)</span><br><span class=\"line\">\terr := ms.LoadLatestVersion()</span><br><span class=\"line\">\trequire.Nil(t, err)</span><br><span class=\"line\"></span><br><span class=\"line\">\tcommitID := types.CommitID&#123;&#125;</span><br><span class=\"line\">\tcheckStore(t, ms, commitID, commitID)</span><br><span class=\"line\"></span><br><span class=\"line\">\tk, v := []byte(&quot;wind&quot;), []byte(&quot;blows&quot;)</span><br><span class=\"line\">  //key=store1下的一棵树store1</span><br><span class=\"line\">\tstore1 := ms.getStoreByName(&quot;store1&quot;).(types.KVStore)</span><br><span class=\"line\">\t//store1设置k-v</span><br><span class=\"line\">\tstore1.Set(k, v)</span><br><span class=\"line\"></span><br><span class=\"line\"> //ms.Commit, 会调用store1.SaveVersion方法</span><br><span class=\"line\">\tcID := ms.Commit()</span><br><span class=\"line\">\trequire.Equal(t, int64(1), cID.Version)</span><br><span class=\"line\">\thash := cID.Hash</span><br><span class=\"line\">\t// make an empty commit, it should update version, but not affect hash</span><br><span class=\"line\">\tcID = ms.Commit()</span><br><span class=\"line\">\trequire.Equal(t, int64(2), cID.Version)</span><br><span class=\"line\">\trequire.Equal(t, hash, cID.Hash)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>更多测试可在``store/rootmulti/store_test.go`中。</p>\n<p>结论是，首先会添加多个key值，每个key一个树，然后这些树的roothash作为rootmulti树的叶子节点，组成树，计算出来的root-hash会作为apphash存储在区块头中。那些小树的叶子节点的值就是存储的具体的内容啦。</p>\n<p>证明key-value确实在区块头的方式是，首先证明key-value在某颗小树上(store-key下)，其次计算出小树的roothash，再使用roothash计算出apphash，与区块头的apphash对比即可证明。</p>\n<p>在使用的时候，选择的区块高度，证明为到这个区块为止，这个数据是存在的。</p>\n<p>最后结论草草结尾，有时间再细化。</p>\n"},{"title":"crypto","date":"2019-10-14T06:34:52.000Z","_content":"\n## 区块链中使用到的密码学\n\n#### 哈希算法\n\n将任意长度的消息压缩为固定长度的二进制串，其输出称为哈希值，也称为散列值。\n\n哈希函数的性质包括\n\n- 抗碰撞性，所谓碰撞是指两个不同的消息在同一个哈希函数作用下，具有相同的哈希值，哈希函数的扛碰撞性是指寻找两个能够产生碰撞的消息在计算上是不可行的。\n- 原像不可逆，指的是知道输入值，很容易通过哈希计算出哈希值，但知道哈希值，没有办法计算出原来的输入值。\n- 难题友好性，没有便捷的方法去产生一满足特殊要求的哈希值。\n\n哈希函数的应用，在区块链中，可用于验证消息的完整性。\n\n#### 加密\n\n- 对称加密，加密解密钥匙为同一把\n- 非对称加密，钥匙分为私钥和公钥，私钥加密，公钥解密\n\n区块链中所使用的公钥密码算法是椭圆曲线算法。椭圆曲线函数的特性为曲线上的两个不同的点相加所得到的点仍在原曲线上，即P + P + P + P .. = k*P = Q，其中P、Q为均曲线上的点。且有特性如下，已知k和点P，求Q容易，但已知点P,Q，求k超超难，运用在实际中，k对应为私钥，Q对应为公钥。\n\n#### 数字签名\n\n数字签名可保证消息的真实性和不可否认性。数字签名为使用私钥对消息摘要进行签名生成数字签名，验证数字签名时使用消息摘要，公钥、数字签名带入算法即可验证。\n\n其中，签名算法，例如ECDSA，又或者BLS.. (<u>emm，虽然有说签名就是公钥密码“反过来”实现的.但签名的算法其实没看懂</u>.)， 然后BLS的优势是签名长度短，在当前应用中，使用BLS签名的主要是与VRF一起使用，如DFINITY项目~\n\n#### 数字证书\n\n一般使用上是对方持有你的公钥，你用私钥加密，发送给对方，对方使用你的公钥进行解密，问题在于万一对方持有的你的公钥被替换了，对方无法确认公钥是否是属于你的，解决方式呢，就是存在一个证书中心，所有人都持有证书中心的公钥，证书中心使用自己的私钥，对你的公钥和一些相关信息进行一起加密，生成数字证书，你在发送信息的时候附带上数字证书一起发送。\n\n数字证书使用的示例之一为，https协议，网页加密。\n\n首先，客户端向服务器发出加密请求，服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端，客户端(浏览器)的证书管理器中，有受信任的根证书颁发机构列表，客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内(证书中心是否可靠)。如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告，如果这张证书不是由受信任的机构颁发的，浏览器会发出另一种警告，如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。\n\n\n\n#### 应用\n\n消息传输安全体系。\n\n当发送方A向B发送数据时，需要考虑的问题有\n\n- 数据的安全性，即数据不被偷窥\n- 数据的完整性，即数据不被篡改\n- 数据的真实性，即数据确实来自发送方，传输过程中没有被替换\n- 数据的不可否认性，即发送方不能抵赖发送了消息\n\n\n\n上述算法对应安全体系中，关系如下\n\n![img](https://images2015.cnblogs.com/blog/802212/201703/802212-20170307221220969-754021676.png)\n\n\n\n##### MAC 与数字签名的对比\n\nMAC，消息认证码。由消息和密钥生成MAC值，可用于确认完整性和真实性。\n\n其实看起来和数字签名是有点像的，区别在于，MAC使用对称加密，加密解密的密钥是一样的，数字签名使用非对称加密，所以MAC不能保证发送方可以否认发送过数据，而数字签名却可以保证他不能抵赖(私钥只有你自己知道)。\n\n\n### 签名\n\n\n\n#### 数字签名、数字证书\n\n数字签名目前的实现方法之一为公私钥对，A将其公钥拿给B，B给A发消息的时候使用A的公钥进行加密，A收到消息后使用A的私钥进行解密。\n\n数字签名，A发送消息给B，把消息进行哈希算法生成摘要，使用私钥对消息进行加密，生成的称为数字签名，发送时发送消息和数字签名。B收到消息后，使用A的公钥解密数字签名，证明确实是A发出的消息，另对消息求哈希与数字签名解密出来的哈希对比，可验证消息完整性。\n\n数字证书，引入第三方可信机构，大家认为其公钥都是可信的，可信机构使用私钥对A的公钥及相关信息进行加密，称为数字证书，B使用可信机构公钥进行解密得到A的公钥，可保证A公钥确实A的公钥。\n\n\n\n通常而言，公钥进行加密，私钥进行数字签名。\n\n数字签名的作用，\n\n- 一方面是消息的加密解密，\n- 一方面可保证消息的完整性且不被篡改。\n\n\n\n#### 区块链中的数字签名\n\n区块链中所使用的公钥密码算法是椭圆曲线算法。\n\n椭圆曲线的数学意义为，两个椭圆曲线上的点相加所得到的点依然在原椭圆曲线上，即k*P = Q，P为椭圆上的点，在已知k、P，求点Q比较容易，但是反过来，已知点PQ,求k却是相当困难的。这个问题成为椭圆曲线上点群的离散对数问题。椭圆曲线密码体制正是利用这个设计，实际应用中，k作为私钥，q作为公钥。\n\n椭圆曲线算法具有两个明显的有点：\n\n- 短的密钥长度，这意味着小的带宽和存储要求。\n- 所有的用户可以选择同一基域上的不同椭圆曲线，可使所有的用户使用同样的操作完成域运算。\n\n\n\n椭圆曲线签名与验证签名：\n\n- 发送消息包含消息本身、公钥、和数字签名。数字签名为，对消息求哈希后使用私钥进行签名\n- 验证过程为，将消息取哈希、公钥、数字签名带入算法进行计算，根据计算结果可判定验证是否通过\n\n\n\n数字签名的作用，\n\n- 保证用户的账户不能被冒名顶替\n- 确保用户不能否认其所签名的交易\n\n\n\n#### 区块链中的密码学\n\n- 哈希算法，对消息A取哈希得到固定长度串B，可理解为摘要。A计算得到B，B很难计算出得到A。哈希碰撞的问题为不同的串得到相同的哈希，取决于哈希桶的大小，故当前很多哈希算法桶取值蛮大，如128、256等(桶大小为2的128或256次方，哈希碰撞的可能性基本很小很小)\n- merkle树，对数据块进行取哈希，两两拼凑，再取哈希，最后得到根哈希，整个结构形成树，称为merkle树，验证某数据块只需得到相应非叶子节点哈希进行计算即可，可进行轻量验证\n- 公钥密码\n\n\n\n#### 多重签名\n\n多重签名，某条消息是由多个公钥(m个)进行签名，签名验证时需要n个公钥进行解密，其中m>=n。可以是3/2, 5/3等。\n\n例如，动用这笔资金需要多个私钥签名，通常这笔资金或数字资产会保存在一个多重签名的地址或帐号里（就比特币而言，多重签名地址通常以`3`开头）。在实际的操作过程中，一个多重签名地址可以关联n个私钥，在需要转账等操作时，只要其中的m个私钥签名就可以把资金转移了，其中m要小于等于n，也就是说m/n小于1，可以是2/3, 3/5等等，是要在建立这个多重签名地址的时候确定好的。\n","source":"_posts/crypto.md","raw":"---\ntitle: crypto\ncategories:\n  - blockchain\ndate: 2019-10-14 14:34:52\ntags:\n---\n\n## 区块链中使用到的密码学\n\n#### 哈希算法\n\n将任意长度的消息压缩为固定长度的二进制串，其输出称为哈希值，也称为散列值。\n\n哈希函数的性质包括\n\n- 抗碰撞性，所谓碰撞是指两个不同的消息在同一个哈希函数作用下，具有相同的哈希值，哈希函数的扛碰撞性是指寻找两个能够产生碰撞的消息在计算上是不可行的。\n- 原像不可逆，指的是知道输入值，很容易通过哈希计算出哈希值，但知道哈希值，没有办法计算出原来的输入值。\n- 难题友好性，没有便捷的方法去产生一满足特殊要求的哈希值。\n\n哈希函数的应用，在区块链中，可用于验证消息的完整性。\n\n#### 加密\n\n- 对称加密，加密解密钥匙为同一把\n- 非对称加密，钥匙分为私钥和公钥，私钥加密，公钥解密\n\n区块链中所使用的公钥密码算法是椭圆曲线算法。椭圆曲线函数的特性为曲线上的两个不同的点相加所得到的点仍在原曲线上，即P + P + P + P .. = k*P = Q，其中P、Q为均曲线上的点。且有特性如下，已知k和点P，求Q容易，但已知点P,Q，求k超超难，运用在实际中，k对应为私钥，Q对应为公钥。\n\n#### 数字签名\n\n数字签名可保证消息的真实性和不可否认性。数字签名为使用私钥对消息摘要进行签名生成数字签名，验证数字签名时使用消息摘要，公钥、数字签名带入算法即可验证。\n\n其中，签名算法，例如ECDSA，又或者BLS.. (<u>emm，虽然有说签名就是公钥密码“反过来”实现的.但签名的算法其实没看懂</u>.)， 然后BLS的优势是签名长度短，在当前应用中，使用BLS签名的主要是与VRF一起使用，如DFINITY项目~\n\n#### 数字证书\n\n一般使用上是对方持有你的公钥，你用私钥加密，发送给对方，对方使用你的公钥进行解密，问题在于万一对方持有的你的公钥被替换了，对方无法确认公钥是否是属于你的，解决方式呢，就是存在一个证书中心，所有人都持有证书中心的公钥，证书中心使用自己的私钥，对你的公钥和一些相关信息进行一起加密，生成数字证书，你在发送信息的时候附带上数字证书一起发送。\n\n数字证书使用的示例之一为，https协议，网页加密。\n\n首先，客户端向服务器发出加密请求，服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端，客户端(浏览器)的证书管理器中，有受信任的根证书颁发机构列表，客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内(证书中心是否可靠)。如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告，如果这张证书不是由受信任的机构颁发的，浏览器会发出另一种警告，如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。\n\n\n\n#### 应用\n\n消息传输安全体系。\n\n当发送方A向B发送数据时，需要考虑的问题有\n\n- 数据的安全性，即数据不被偷窥\n- 数据的完整性，即数据不被篡改\n- 数据的真实性，即数据确实来自发送方，传输过程中没有被替换\n- 数据的不可否认性，即发送方不能抵赖发送了消息\n\n\n\n上述算法对应安全体系中，关系如下\n\n![img](https://images2015.cnblogs.com/blog/802212/201703/802212-20170307221220969-754021676.png)\n\n\n\n##### MAC 与数字签名的对比\n\nMAC，消息认证码。由消息和密钥生成MAC值，可用于确认完整性和真实性。\n\n其实看起来和数字签名是有点像的，区别在于，MAC使用对称加密，加密解密的密钥是一样的，数字签名使用非对称加密，所以MAC不能保证发送方可以否认发送过数据，而数字签名却可以保证他不能抵赖(私钥只有你自己知道)。\n\n\n### 签名\n\n\n\n#### 数字签名、数字证书\n\n数字签名目前的实现方法之一为公私钥对，A将其公钥拿给B，B给A发消息的时候使用A的公钥进行加密，A收到消息后使用A的私钥进行解密。\n\n数字签名，A发送消息给B，把消息进行哈希算法生成摘要，使用私钥对消息进行加密，生成的称为数字签名，发送时发送消息和数字签名。B收到消息后，使用A的公钥解密数字签名，证明确实是A发出的消息，另对消息求哈希与数字签名解密出来的哈希对比，可验证消息完整性。\n\n数字证书，引入第三方可信机构，大家认为其公钥都是可信的，可信机构使用私钥对A的公钥及相关信息进行加密，称为数字证书，B使用可信机构公钥进行解密得到A的公钥，可保证A公钥确实A的公钥。\n\n\n\n通常而言，公钥进行加密，私钥进行数字签名。\n\n数字签名的作用，\n\n- 一方面是消息的加密解密，\n- 一方面可保证消息的完整性且不被篡改。\n\n\n\n#### 区块链中的数字签名\n\n区块链中所使用的公钥密码算法是椭圆曲线算法。\n\n椭圆曲线的数学意义为，两个椭圆曲线上的点相加所得到的点依然在原椭圆曲线上，即k*P = Q，P为椭圆上的点，在已知k、P，求点Q比较容易，但是反过来，已知点PQ,求k却是相当困难的。这个问题成为椭圆曲线上点群的离散对数问题。椭圆曲线密码体制正是利用这个设计，实际应用中，k作为私钥，q作为公钥。\n\n椭圆曲线算法具有两个明显的有点：\n\n- 短的密钥长度，这意味着小的带宽和存储要求。\n- 所有的用户可以选择同一基域上的不同椭圆曲线，可使所有的用户使用同样的操作完成域运算。\n\n\n\n椭圆曲线签名与验证签名：\n\n- 发送消息包含消息本身、公钥、和数字签名。数字签名为，对消息求哈希后使用私钥进行签名\n- 验证过程为，将消息取哈希、公钥、数字签名带入算法进行计算，根据计算结果可判定验证是否通过\n\n\n\n数字签名的作用，\n\n- 保证用户的账户不能被冒名顶替\n- 确保用户不能否认其所签名的交易\n\n\n\n#### 区块链中的密码学\n\n- 哈希算法，对消息A取哈希得到固定长度串B，可理解为摘要。A计算得到B，B很难计算出得到A。哈希碰撞的问题为不同的串得到相同的哈希，取决于哈希桶的大小，故当前很多哈希算法桶取值蛮大，如128、256等(桶大小为2的128或256次方，哈希碰撞的可能性基本很小很小)\n- merkle树，对数据块进行取哈希，两两拼凑，再取哈希，最后得到根哈希，整个结构形成树，称为merkle树，验证某数据块只需得到相应非叶子节点哈希进行计算即可，可进行轻量验证\n- 公钥密码\n\n\n\n#### 多重签名\n\n多重签名，某条消息是由多个公钥(m个)进行签名，签名验证时需要n个公钥进行解密，其中m>=n。可以是3/2, 5/3等。\n\n例如，动用这笔资金需要多个私钥签名，通常这笔资金或数字资产会保存在一个多重签名的地址或帐号里（就比特币而言，多重签名地址通常以`3`开头）。在实际的操作过程中，一个多重签名地址可以关联n个私钥，在需要转账等操作时，只要其中的m个私钥签名就可以把资金转移了，其中m要小于等于n，也就是说m/n小于1，可以是2/3, 3/5等等，是要在建立这个多重签名地址的时候确定好的。\n","slug":"crypto","published":1,"updated":"2019-10-14T06:35:58.550Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69ss0007t6xvswwfzn4s","content":"<h2 id=\"区块链中使用到的密码学\"><a href=\"#区块链中使用到的密码学\" class=\"headerlink\" title=\"区块链中使用到的密码学\"></a>区块链中使用到的密码学</h2><h4 id=\"哈希算法\"><a href=\"#哈希算法\" class=\"headerlink\" title=\"哈希算法\"></a>哈希算法</h4><p>将任意长度的消息压缩为固定长度的二进制串，其输出称为哈希值，也称为散列值。</p>\n<p>哈希函数的性质包括</p>\n<ul>\n<li>抗碰撞性，所谓碰撞是指两个不同的消息在同一个哈希函数作用下，具有相同的哈希值，哈希函数的扛碰撞性是指寻找两个能够产生碰撞的消息在计算上是不可行的。</li>\n<li>原像不可逆，指的是知道输入值，很容易通过哈希计算出哈希值，但知道哈希值，没有办法计算出原来的输入值。</li>\n<li>难题友好性，没有便捷的方法去产生一满足特殊要求的哈希值。</li>\n</ul>\n<p>哈希函数的应用，在区块链中，可用于验证消息的完整性。</p>\n<h4 id=\"加密\"><a href=\"#加密\" class=\"headerlink\" title=\"加密\"></a>加密</h4><ul>\n<li>对称加密，加密解密钥匙为同一把</li>\n<li>非对称加密，钥匙分为私钥和公钥，私钥加密，公钥解密</li>\n</ul>\n<p>区块链中所使用的公钥密码算法是椭圆曲线算法。椭圆曲线函数的特性为曲线上的两个不同的点相加所得到的点仍在原曲线上，即P + P + P + P .. = k*P = Q，其中P、Q为均曲线上的点。且有特性如下，已知k和点P，求Q容易，但已知点P,Q，求k超超难，运用在实际中，k对应为私钥，Q对应为公钥。</p>\n<h4 id=\"数字签名\"><a href=\"#数字签名\" class=\"headerlink\" title=\"数字签名\"></a>数字签名</h4><p>数字签名可保证消息的真实性和不可否认性。数字签名为使用私钥对消息摘要进行签名生成数字签名，验证数字签名时使用消息摘要，公钥、数字签名带入算法即可验证。</p>\n<p>其中，签名算法，例如ECDSA，又或者BLS.. (<u>emm，虽然有说签名就是公钥密码“反过来”实现的.但签名的算法其实没看懂</u>.)， 然后BLS的优势是签名长度短，在当前应用中，使用BLS签名的主要是与VRF一起使用，如DFINITY项目~</p>\n<h4 id=\"数字证书\"><a href=\"#数字证书\" class=\"headerlink\" title=\"数字证书\"></a>数字证书</h4><p>一般使用上是对方持有你的公钥，你用私钥加密，发送给对方，对方使用你的公钥进行解密，问题在于万一对方持有的你的公钥被替换了，对方无法确认公钥是否是属于你的，解决方式呢，就是存在一个证书中心，所有人都持有证书中心的公钥，证书中心使用自己的私钥，对你的公钥和一些相关信息进行一起加密，生成数字证书，你在发送信息的时候附带上数字证书一起发送。</p>\n<p>数字证书使用的示例之一为，https协议，网页加密。</p>\n<p>首先，客户端向服务器发出加密请求，服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端，客户端(浏览器)的证书管理器中，有受信任的根证书颁发机构列表，客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内(证书中心是否可靠)。如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告，如果这张证书不是由受信任的机构颁发的，浏览器会发出另一种警告，如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。</p>\n<h4 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h4><p>消息传输安全体系。</p>\n<p>当发送方A向B发送数据时，需要考虑的问题有</p>\n<ul>\n<li>数据的安全性，即数据不被偷窥</li>\n<li>数据的完整性，即数据不被篡改</li>\n<li>数据的真实性，即数据确实来自发送方，传输过程中没有被替换</li>\n<li>数据的不可否认性，即发送方不能抵赖发送了消息</li>\n</ul>\n<p>上述算法对应安全体系中，关系如下</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/802212/201703/802212-20170307221220969-754021676.png\" alt=\"img\"></p>\n<h5 id=\"MAC-与数字签名的对比\"><a href=\"#MAC-与数字签名的对比\" class=\"headerlink\" title=\"MAC 与数字签名的对比\"></a>MAC 与数字签名的对比</h5><p>MAC，消息认证码。由消息和密钥生成MAC值，可用于确认完整性和真实性。</p>\n<p>其实看起来和数字签名是有点像的，区别在于，MAC使用对称加密，加密解密的密钥是一样的，数字签名使用非对称加密，所以MAC不能保证发送方可以否认发送过数据，而数字签名却可以保证他不能抵赖(私钥只有你自己知道)。</p>\n<h3 id=\"签名\"><a href=\"#签名\" class=\"headerlink\" title=\"签名\"></a>签名</h3><h4 id=\"数字签名、数字证书\"><a href=\"#数字签名、数字证书\" class=\"headerlink\" title=\"数字签名、数字证书\"></a>数字签名、数字证书</h4><p>数字签名目前的实现方法之一为公私钥对，A将其公钥拿给B，B给A发消息的时候使用A的公钥进行加密，A收到消息后使用A的私钥进行解密。</p>\n<p>数字签名，A发送消息给B，把消息进行哈希算法生成摘要，使用私钥对消息进行加密，生成的称为数字签名，发送时发送消息和数字签名。B收到消息后，使用A的公钥解密数字签名，证明确实是A发出的消息，另对消息求哈希与数字签名解密出来的哈希对比，可验证消息完整性。</p>\n<p>数字证书，引入第三方可信机构，大家认为其公钥都是可信的，可信机构使用私钥对A的公钥及相关信息进行加密，称为数字证书，B使用可信机构公钥进行解密得到A的公钥，可保证A公钥确实A的公钥。</p>\n<p>通常而言，公钥进行加密，私钥进行数字签名。</p>\n<p>数字签名的作用，</p>\n<ul>\n<li>一方面是消息的加密解密，</li>\n<li>一方面可保证消息的完整性且不被篡改。</li>\n</ul>\n<h4 id=\"区块链中的数字签名\"><a href=\"#区块链中的数字签名\" class=\"headerlink\" title=\"区块链中的数字签名\"></a>区块链中的数字签名</h4><p>区块链中所使用的公钥密码算法是椭圆曲线算法。</p>\n<p>椭圆曲线的数学意义为，两个椭圆曲线上的点相加所得到的点依然在原椭圆曲线上，即k*P = Q，P为椭圆上的点，在已知k、P，求点Q比较容易，但是反过来，已知点PQ,求k却是相当困难的。这个问题成为椭圆曲线上点群的离散对数问题。椭圆曲线密码体制正是利用这个设计，实际应用中，k作为私钥，q作为公钥。</p>\n<p>椭圆曲线算法具有两个明显的有点：</p>\n<ul>\n<li>短的密钥长度，这意味着小的带宽和存储要求。</li>\n<li>所有的用户可以选择同一基域上的不同椭圆曲线，可使所有的用户使用同样的操作完成域运算。</li>\n</ul>\n<p>椭圆曲线签名与验证签名：</p>\n<ul>\n<li>发送消息包含消息本身、公钥、和数字签名。数字签名为，对消息求哈希后使用私钥进行签名</li>\n<li>验证过程为，将消息取哈希、公钥、数字签名带入算法进行计算，根据计算结果可判定验证是否通过</li>\n</ul>\n<p>数字签名的作用，</p>\n<ul>\n<li>保证用户的账户不能被冒名顶替</li>\n<li>确保用户不能否认其所签名的交易</li>\n</ul>\n<h4 id=\"区块链中的密码学\"><a href=\"#区块链中的密码学\" class=\"headerlink\" title=\"区块链中的密码学\"></a>区块链中的密码学</h4><ul>\n<li>哈希算法，对消息A取哈希得到固定长度串B，可理解为摘要。A计算得到B，B很难计算出得到A。哈希碰撞的问题为不同的串得到相同的哈希，取决于哈希桶的大小，故当前很多哈希算法桶取值蛮大，如128、256等(桶大小为2的128或256次方，哈希碰撞的可能性基本很小很小)</li>\n<li>merkle树，对数据块进行取哈希，两两拼凑，再取哈希，最后得到根哈希，整个结构形成树，称为merkle树，验证某数据块只需得到相应非叶子节点哈希进行计算即可，可进行轻量验证</li>\n<li>公钥密码</li>\n</ul>\n<h4 id=\"多重签名\"><a href=\"#多重签名\" class=\"headerlink\" title=\"多重签名\"></a>多重签名</h4><p>多重签名，某条消息是由多个公钥(m个)进行签名，签名验证时需要n个公钥进行解密，其中m&gt;=n。可以是3/2, 5/3等。</p>\n<p>例如，动用这笔资金需要多个私钥签名，通常这笔资金或数字资产会保存在一个多重签名的地址或帐号里（就比特币而言，多重签名地址通常以<code>3</code>开头）。在实际的操作过程中，一个多重签名地址可以关联n个私钥，在需要转账等操作时，只要其中的m个私钥签名就可以把资金转移了，其中m要小于等于n，也就是说m/n小于1，可以是2/3, 3/5等等，是要在建立这个多重签名地址的时候确定好的。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"区块链中使用到的密码学\"><a href=\"#区块链中使用到的密码学\" class=\"headerlink\" title=\"区块链中使用到的密码学\"></a>区块链中使用到的密码学</h2><h4 id=\"哈希算法\"><a href=\"#哈希算法\" class=\"headerlink\" title=\"哈希算法\"></a>哈希算法</h4><p>将任意长度的消息压缩为固定长度的二进制串，其输出称为哈希值，也称为散列值。</p>\n<p>哈希函数的性质包括</p>\n<ul>\n<li>抗碰撞性，所谓碰撞是指两个不同的消息在同一个哈希函数作用下，具有相同的哈希值，哈希函数的扛碰撞性是指寻找两个能够产生碰撞的消息在计算上是不可行的。</li>\n<li>原像不可逆，指的是知道输入值，很容易通过哈希计算出哈希值，但知道哈希值，没有办法计算出原来的输入值。</li>\n<li>难题友好性，没有便捷的方法去产生一满足特殊要求的哈希值。</li>\n</ul>\n<p>哈希函数的应用，在区块链中，可用于验证消息的完整性。</p>\n<h4 id=\"加密\"><a href=\"#加密\" class=\"headerlink\" title=\"加密\"></a>加密</h4><ul>\n<li>对称加密，加密解密钥匙为同一把</li>\n<li>非对称加密，钥匙分为私钥和公钥，私钥加密，公钥解密</li>\n</ul>\n<p>区块链中所使用的公钥密码算法是椭圆曲线算法。椭圆曲线函数的特性为曲线上的两个不同的点相加所得到的点仍在原曲线上，即P + P + P + P .. = k*P = Q，其中P、Q为均曲线上的点。且有特性如下，已知k和点P，求Q容易，但已知点P,Q，求k超超难，运用在实际中，k对应为私钥，Q对应为公钥。</p>\n<h4 id=\"数字签名\"><a href=\"#数字签名\" class=\"headerlink\" title=\"数字签名\"></a>数字签名</h4><p>数字签名可保证消息的真实性和不可否认性。数字签名为使用私钥对消息摘要进行签名生成数字签名，验证数字签名时使用消息摘要，公钥、数字签名带入算法即可验证。</p>\n<p>其中，签名算法，例如ECDSA，又或者BLS.. (<u>emm，虽然有说签名就是公钥密码“反过来”实现的.但签名的算法其实没看懂</u>.)， 然后BLS的优势是签名长度短，在当前应用中，使用BLS签名的主要是与VRF一起使用，如DFINITY项目~</p>\n<h4 id=\"数字证书\"><a href=\"#数字证书\" class=\"headerlink\" title=\"数字证书\"></a>数字证书</h4><p>一般使用上是对方持有你的公钥，你用私钥加密，发送给对方，对方使用你的公钥进行解密，问题在于万一对方持有的你的公钥被替换了，对方无法确认公钥是否是属于你的，解决方式呢，就是存在一个证书中心，所有人都持有证书中心的公钥，证书中心使用自己的私钥，对你的公钥和一些相关信息进行一起加密，生成数字证书，你在发送信息的时候附带上数字证书一起发送。</p>\n<p>数字证书使用的示例之一为，https协议，网页加密。</p>\n<p>首先，客户端向服务器发出加密请求，服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端，客户端(浏览器)的证书管理器中，有受信任的根证书颁发机构列表，客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内(证书中心是否可靠)。如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告，如果这张证书不是由受信任的机构颁发的，浏览器会发出另一种警告，如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。</p>\n<h4 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h4><p>消息传输安全体系。</p>\n<p>当发送方A向B发送数据时，需要考虑的问题有</p>\n<ul>\n<li>数据的安全性，即数据不被偷窥</li>\n<li>数据的完整性，即数据不被篡改</li>\n<li>数据的真实性，即数据确实来自发送方，传输过程中没有被替换</li>\n<li>数据的不可否认性，即发送方不能抵赖发送了消息</li>\n</ul>\n<p>上述算法对应安全体系中，关系如下</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/802212/201703/802212-20170307221220969-754021676.png\" alt=\"img\"></p>\n<h5 id=\"MAC-与数字签名的对比\"><a href=\"#MAC-与数字签名的对比\" class=\"headerlink\" title=\"MAC 与数字签名的对比\"></a>MAC 与数字签名的对比</h5><p>MAC，消息认证码。由消息和密钥生成MAC值，可用于确认完整性和真实性。</p>\n<p>其实看起来和数字签名是有点像的，区别在于，MAC使用对称加密，加密解密的密钥是一样的，数字签名使用非对称加密，所以MAC不能保证发送方可以否认发送过数据，而数字签名却可以保证他不能抵赖(私钥只有你自己知道)。</p>\n<h3 id=\"签名\"><a href=\"#签名\" class=\"headerlink\" title=\"签名\"></a>签名</h3><h4 id=\"数字签名、数字证书\"><a href=\"#数字签名、数字证书\" class=\"headerlink\" title=\"数字签名、数字证书\"></a>数字签名、数字证书</h4><p>数字签名目前的实现方法之一为公私钥对，A将其公钥拿给B，B给A发消息的时候使用A的公钥进行加密，A收到消息后使用A的私钥进行解密。</p>\n<p>数字签名，A发送消息给B，把消息进行哈希算法生成摘要，使用私钥对消息进行加密，生成的称为数字签名，发送时发送消息和数字签名。B收到消息后，使用A的公钥解密数字签名，证明确实是A发出的消息，另对消息求哈希与数字签名解密出来的哈希对比，可验证消息完整性。</p>\n<p>数字证书，引入第三方可信机构，大家认为其公钥都是可信的，可信机构使用私钥对A的公钥及相关信息进行加密，称为数字证书，B使用可信机构公钥进行解密得到A的公钥，可保证A公钥确实A的公钥。</p>\n<p>通常而言，公钥进行加密，私钥进行数字签名。</p>\n<p>数字签名的作用，</p>\n<ul>\n<li>一方面是消息的加密解密，</li>\n<li>一方面可保证消息的完整性且不被篡改。</li>\n</ul>\n<h4 id=\"区块链中的数字签名\"><a href=\"#区块链中的数字签名\" class=\"headerlink\" title=\"区块链中的数字签名\"></a>区块链中的数字签名</h4><p>区块链中所使用的公钥密码算法是椭圆曲线算法。</p>\n<p>椭圆曲线的数学意义为，两个椭圆曲线上的点相加所得到的点依然在原椭圆曲线上，即k*P = Q，P为椭圆上的点，在已知k、P，求点Q比较容易，但是反过来，已知点PQ,求k却是相当困难的。这个问题成为椭圆曲线上点群的离散对数问题。椭圆曲线密码体制正是利用这个设计，实际应用中，k作为私钥，q作为公钥。</p>\n<p>椭圆曲线算法具有两个明显的有点：</p>\n<ul>\n<li>短的密钥长度，这意味着小的带宽和存储要求。</li>\n<li>所有的用户可以选择同一基域上的不同椭圆曲线，可使所有的用户使用同样的操作完成域运算。</li>\n</ul>\n<p>椭圆曲线签名与验证签名：</p>\n<ul>\n<li>发送消息包含消息本身、公钥、和数字签名。数字签名为，对消息求哈希后使用私钥进行签名</li>\n<li>验证过程为，将消息取哈希、公钥、数字签名带入算法进行计算，根据计算结果可判定验证是否通过</li>\n</ul>\n<p>数字签名的作用，</p>\n<ul>\n<li>保证用户的账户不能被冒名顶替</li>\n<li>确保用户不能否认其所签名的交易</li>\n</ul>\n<h4 id=\"区块链中的密码学\"><a href=\"#区块链中的密码学\" class=\"headerlink\" title=\"区块链中的密码学\"></a>区块链中的密码学</h4><ul>\n<li>哈希算法，对消息A取哈希得到固定长度串B，可理解为摘要。A计算得到B，B很难计算出得到A。哈希碰撞的问题为不同的串得到相同的哈希，取决于哈希桶的大小，故当前很多哈希算法桶取值蛮大，如128、256等(桶大小为2的128或256次方，哈希碰撞的可能性基本很小很小)</li>\n<li>merkle树，对数据块进行取哈希，两两拼凑，再取哈希，最后得到根哈希，整个结构形成树，称为merkle树，验证某数据块只需得到相应非叶子节点哈希进行计算即可，可进行轻量验证</li>\n<li>公钥密码</li>\n</ul>\n<h4 id=\"多重签名\"><a href=\"#多重签名\" class=\"headerlink\" title=\"多重签名\"></a>多重签名</h4><p>多重签名，某条消息是由多个公钥(m个)进行签名，签名验证时需要n个公钥进行解密，其中m&gt;=n。可以是3/2, 5/3等。</p>\n<p>例如，动用这笔资金需要多个私钥签名，通常这笔资金或数字资产会保存在一个多重签名的地址或帐号里（就比特币而言，多重签名地址通常以<code>3</code>开头）。在实际的操作过程中，一个多重签名地址可以关联n个私钥，在需要转账等操作时，只要其中的m个私钥签名就可以把资金转移了，其中m要小于等于n，也就是说m/n小于1，可以是2/3, 3/5等等，是要在建立这个多重签名地址的时候确定好的。</p>\n"},{"title":"dai_code","date":"2019-10-14T06:52:07.000Z","_content":"\n## dai结构及源码解析\n\n![合约调用图](<https://user-images.githubusercontent.com/5028/58217074-3ec06880-7d55-11e9-91e2-c9bec7172bc4.png>)\n\n结构图如上所示，vat左边的主要是**管理控制修改**vat及vat右边各合约各**参数**的合约，红线file为调用各合约中file方法，也就是修改各合约中相应参数。如vat中file为P427L-9Y552-5433E-8DSR3-58Z68\n\n```\n    function file(bytes32 what, uint data) external note auth {\n        if (what == \"Line\") Line = data;\n        else revert();\n    }\n    function file(bytes32 ilk, bytes32 what, uint data) external note auth {\n        if (what == \"spot\") ilks[ilk].spot = data;\n        else if (what == \"line\") ilks[ilk].line = data;\n        else if (what == \"dust\") ilks[ilk].dust = data;\n        else revert();\n    }\n```\n\nvat是CDP的主要逻辑合约。\n\ncat为清算触发合约，通过调用cat.bite方法，当满足清算条件就会触发清算。具体逻辑稍后提及。\n\nvow为结算合约，通过vow的结算条件可触发flop和flap。\n\nflip为抵押物拍卖合约，拍卖由cat触发，拍卖逻辑稍后提及。\n\nflop和flap分别为债务拍卖和盈余拍卖，由vow触发。\n\n\n\n### vat\n\n变量\n\n```\n//抵押物id对应的参数\nmapping (bytes32 => Ilk)                       public ilks;  \n//抵押物id => 个人地址 => 个人债务\nmapping (bytes32 => mapping (address => Urn )) public urns;  \n//抵押物id => 个人地址 => 个人抵押物总值\nmapping (bytes32 => mapping (address => uint)) public gem;  \n//个人地址 => 含有的dai，统计作用\nmapping (address => uint256)                   public dai;  \n//清算地址 => 清算总值， 统计作用\nmapping (address => uint256)                   public sin;\n\n struct Urn {\n        uint256 ink;   // 锁定的抵押物值\n        uint256 art;   // 借贷的dai\n }\n //以抵押物id为个体\n struct Ilk {\n        uint256 Art;   // 总借贷dai\n        uint256 rate;  // 可借贷比率\n        uint256 spot;  // 价格安全线\n        uint256 line;  // 总借贷上线\n        uint256 dust;  // 总借贷下限\n } //rate和spot的作用主要是满足ink * spot >= art * rate可借贷，不然就不能借贷或者需要清算了。\n\n```\n\n主要讲讲frob方法吧，这个方法可谓是精短又强悍！\n\n```\n//bytes32 i ilk标识， address u cdp所有者，v 抵押物所有者，w 获得dai的所有者，dink 参与的抵押物，dart参与的债务\nfunction frob(bytes32 i, address u, address v, address w, int dink, int dart) external note {\n    // system is live\n    require(live == 1);\n\n    Urn memory urn = urns[i][u];\n    Ilk memory ilk = ilks[i];\n    // ilk has been initialised\n    require(ilk.rate != 0);\n\n    urn.ink = add(urn.ink, dink);\n    urn.art = add(urn.art, dart);\n    ilk.Art = add(ilk.Art, dart);\n\n    int dtab = mul(ilk.rate, dart);\n    uint tab = mul(urn.art, ilk.rate);\n    debt     = add(debt, dtab); //dai总量\n\n    //dart <=0, 赎回抵押物？ dart >0, 借贷\n\n    // either debt has decreased, or debt ceilings are not exceeded\n    require(either(dart <= 0, both(mul(ilk.Art, ilk.rate) <= ilk.line, debt <= Line)));\n    // urn is either less risky than before, or it is safe\n    require(either(both(dart <= 0, dink >= 0), tab <= mul(urn.ink, ilk.spot)));\n    // urn is either more safe, or the owner consents\n    require(either(both(dart <= 0, dink >= 0), wish(u, msg.sender)));\n    // collateral src consents\n    require(either(dink <= 0, wish(v, msg.sender)));\n    // debt dst consents\n    require(either(dart >= 0, wish(w, msg.sender)));\n    // urn has no debt, or a non-dusty amount\n    require(either(urn.art == 0, tab >= ilk.dust));\n\n    gem[i][v] = sub(gem[i][v], dink);\n    dai[w]    = add(dai[w],    dtab);\n    urns[i][u] = urn;\n    ilks[i]    = ilk;\n}\n```\n\n在以上这个方法中，包含了很多种用法，包括新增cdp、偿还等等，例如当dart>0的时候，就是借贷，当dart<0的时候，偿还。\n\n首先，当借贷/增加抵押物时，抵押物为dink >=0, 贷款dart >0。贷款价值为dart * rate，抵押物价值为dink * spot。借贷需要满足的条件如下\n\n- 贷款价值 < 债务上限line, 且该抵押物的总贷款价值<Line上限\n\n- 贷款价值 <= 抵押物价值，这里理解一下rate，当rate > 1，其实就是说可贷的dart其实是小于真正抵押物价值的，用来调控风险。\n- u为调用者，或者调用者是u的下层授权管理（u授权x以操作其cdp）\n- 贷款价值 > 债务下限 dust\n\n当条件判断完毕后，进行扣除/赎回抵押物(gem)，借出/偿还dai。\n\n### cat\n\n```\n function bite(bytes32 ilk, address urn) external returns (uint id) {\n        VatLike.Ilk memory i = vat.ilks(ilk);\n        VatLike.Urn memory u = vat.urns(ilk, urn);\n\n        require(live == 1);\n        //触发清算要求，个人抵押品 * 具有安全边际的抵押品价格 < 个人债务 * 稳定债务乘数(稳定债务)\n        //即抵押品价格下降到一定程度后，触发清算\n        require(mul(u.ink, i.spot) < mul(u.art, i.rate));\n        //取个人抵押品和任何一次清算事件所涵盖的固定债务数量的小值\n        uint lot = min(u.ink, ilks[ilk].lump);\n        //取个人债务 和 抵押品 * 债务 / 抵押品的 小值\n        uint art = min(u.art, mul(lot, u.art) / u.ink);\n        //债务 * 稳定债务乘数(稳定债务)\n        uint tab = mul(art, i.rate);\n\n        require(lot <= 2**255 && art <= 2**255);\n        //清算，将个人抵押品减掉，个人债务也减掉,将减掉的抵押品转移到本地址下(gem)\n        vat.grab(ilk, urn, address(this), address(vow), -int(lot), -int(art));\n        //结算？\n        vow.fess(tab);\n        //触发拍卖\n        id = Kicker(ilks[ilk].flip).kick({ urn: urn\n                                         , gal: address(vow)\n                                         , tab: rmul(tab, ilks[ilk].chop) //所需债务: dai债务 * 清算罚款 / 10 ** 27\n                                         , lot: lot //抵押品\n                                         , bid: 0\n                                         });\n\n        emit Bite(ilk, urn, lot, art, tab, ilks[ilk].flip, id);\n    }\n```\n\n\n\n##### example\n\n补充，借贷的第一步，会有一个join合约，就是帮忙保管币/代币。调用join方法，会将币/代币转移到本合约地址下，然后本合约会调用vat.slip方法，如\n\n```\n    function join(address usr, uint wad) external note {\n        require(int(wad) >= 0);\n        vat.slip(ilk, usr, int(wad)); //gem[ilk][usr] = wad\n        require(gem.transferFrom(msg.sender, address(this), wad));\n    }\n```\n\n测试参数\n\n```\nvat.init(\"gold\");\ngemA = new GemJoin(address(vat), \"gold\", address(gold));\nvat.file(\"gold\", \"spot\", ray(1 ether)); //ray: 10 ** 9\nvat.file(\"gold\", \"line\", rad(1000 ether)); //rad: 10 ** 27\nvat.file(\"Line\",         rad(1000 ether));\ncat.file(\"gold\", \"chop\", ray(1 ether));\n```\n\n\n\n```\naddress urn = address(this);\n//转移币\ngemA.join(urn,                             500 ether);\nvat.file(\"gold\", 'spot', ray(2.5 ether));\nvat.frob(\"gold\", me, me, me, 40 ether, 100 ether);\n//假设rate为 (10 ** 9)\n//借贷判断， 40 * (10 ** 18) * 2.5 * (10 ** 9) >=? 100 * (10 ** 18) * (10 ** 9),满足条件，可借贷\n//vat.urn[gold][me]= ink(40)， art(100)\n\n vat.file(\"gold\", 'spot', ray(2 ether));  //抵押物价格下降\n cat.file(\"gold\", \"chop\", ray(1.1 ether));\n cat.file(\"gold\", \"lump\", 30 ether);\n\n //清算判断\n uint auction = cat.bite(\"gold\", address(this));\n //40 * (10 ** 18) * 2 * (10 ** 9) >=? 100 * (10 ** 18) * (10 ** 9) 很明显，不满足条件，触发清算\n //清算lot=min(u.ink, ilks[ilk].lump) = 30 ether\n // art = min(u.art, mul(lot, u.art) / u.ink); = 75 ether\n //此时vat.urn[gold][me] = ink(10 ether), art(25 ether)\n //\t\t\t\t\t\ttab = art * rate\n //触发拍卖kick中tab为rmul(tab, ilks[ilk].chop)， (75 * (10 ** 18) * (10 ** 9)) * 1.1 * (10 ** 18) / 10 ** 27 = 82.5 * (10 ** 18) 即85 ether\n```\n","source":"_posts/dai-code.md","raw":"---\ntitle: dai_code\ncategories:\n  - eth\ndate: 2019-10-14 14:52:07\ntags:\n---\n\n## dai结构及源码解析\n\n![合约调用图](<https://user-images.githubusercontent.com/5028/58217074-3ec06880-7d55-11e9-91e2-c9bec7172bc4.png>)\n\n结构图如上所示，vat左边的主要是**管理控制修改**vat及vat右边各合约各**参数**的合约，红线file为调用各合约中file方法，也就是修改各合约中相应参数。如vat中file为P427L-9Y552-5433E-8DSR3-58Z68\n\n```\n    function file(bytes32 what, uint data) external note auth {\n        if (what == \"Line\") Line = data;\n        else revert();\n    }\n    function file(bytes32 ilk, bytes32 what, uint data) external note auth {\n        if (what == \"spot\") ilks[ilk].spot = data;\n        else if (what == \"line\") ilks[ilk].line = data;\n        else if (what == \"dust\") ilks[ilk].dust = data;\n        else revert();\n    }\n```\n\nvat是CDP的主要逻辑合约。\n\ncat为清算触发合约，通过调用cat.bite方法，当满足清算条件就会触发清算。具体逻辑稍后提及。\n\nvow为结算合约，通过vow的结算条件可触发flop和flap。\n\nflip为抵押物拍卖合约，拍卖由cat触发，拍卖逻辑稍后提及。\n\nflop和flap分别为债务拍卖和盈余拍卖，由vow触发。\n\n\n\n### vat\n\n变量\n\n```\n//抵押物id对应的参数\nmapping (bytes32 => Ilk)                       public ilks;  \n//抵押物id => 个人地址 => 个人债务\nmapping (bytes32 => mapping (address => Urn )) public urns;  \n//抵押物id => 个人地址 => 个人抵押物总值\nmapping (bytes32 => mapping (address => uint)) public gem;  \n//个人地址 => 含有的dai，统计作用\nmapping (address => uint256)                   public dai;  \n//清算地址 => 清算总值， 统计作用\nmapping (address => uint256)                   public sin;\n\n struct Urn {\n        uint256 ink;   // 锁定的抵押物值\n        uint256 art;   // 借贷的dai\n }\n //以抵押物id为个体\n struct Ilk {\n        uint256 Art;   // 总借贷dai\n        uint256 rate;  // 可借贷比率\n        uint256 spot;  // 价格安全线\n        uint256 line;  // 总借贷上线\n        uint256 dust;  // 总借贷下限\n } //rate和spot的作用主要是满足ink * spot >= art * rate可借贷，不然就不能借贷或者需要清算了。\n\n```\n\n主要讲讲frob方法吧，这个方法可谓是精短又强悍！\n\n```\n//bytes32 i ilk标识， address u cdp所有者，v 抵押物所有者，w 获得dai的所有者，dink 参与的抵押物，dart参与的债务\nfunction frob(bytes32 i, address u, address v, address w, int dink, int dart) external note {\n    // system is live\n    require(live == 1);\n\n    Urn memory urn = urns[i][u];\n    Ilk memory ilk = ilks[i];\n    // ilk has been initialised\n    require(ilk.rate != 0);\n\n    urn.ink = add(urn.ink, dink);\n    urn.art = add(urn.art, dart);\n    ilk.Art = add(ilk.Art, dart);\n\n    int dtab = mul(ilk.rate, dart);\n    uint tab = mul(urn.art, ilk.rate);\n    debt     = add(debt, dtab); //dai总量\n\n    //dart <=0, 赎回抵押物？ dart >0, 借贷\n\n    // either debt has decreased, or debt ceilings are not exceeded\n    require(either(dart <= 0, both(mul(ilk.Art, ilk.rate) <= ilk.line, debt <= Line)));\n    // urn is either less risky than before, or it is safe\n    require(either(both(dart <= 0, dink >= 0), tab <= mul(urn.ink, ilk.spot)));\n    // urn is either more safe, or the owner consents\n    require(either(both(dart <= 0, dink >= 0), wish(u, msg.sender)));\n    // collateral src consents\n    require(either(dink <= 0, wish(v, msg.sender)));\n    // debt dst consents\n    require(either(dart >= 0, wish(w, msg.sender)));\n    // urn has no debt, or a non-dusty amount\n    require(either(urn.art == 0, tab >= ilk.dust));\n\n    gem[i][v] = sub(gem[i][v], dink);\n    dai[w]    = add(dai[w],    dtab);\n    urns[i][u] = urn;\n    ilks[i]    = ilk;\n}\n```\n\n在以上这个方法中，包含了很多种用法，包括新增cdp、偿还等等，例如当dart>0的时候，就是借贷，当dart<0的时候，偿还。\n\n首先，当借贷/增加抵押物时，抵押物为dink >=0, 贷款dart >0。贷款价值为dart * rate，抵押物价值为dink * spot。借贷需要满足的条件如下\n\n- 贷款价值 < 债务上限line, 且该抵押物的总贷款价值<Line上限\n\n- 贷款价值 <= 抵押物价值，这里理解一下rate，当rate > 1，其实就是说可贷的dart其实是小于真正抵押物价值的，用来调控风险。\n- u为调用者，或者调用者是u的下层授权管理（u授权x以操作其cdp）\n- 贷款价值 > 债务下限 dust\n\n当条件判断完毕后，进行扣除/赎回抵押物(gem)，借出/偿还dai。\n\n### cat\n\n```\n function bite(bytes32 ilk, address urn) external returns (uint id) {\n        VatLike.Ilk memory i = vat.ilks(ilk);\n        VatLike.Urn memory u = vat.urns(ilk, urn);\n\n        require(live == 1);\n        //触发清算要求，个人抵押品 * 具有安全边际的抵押品价格 < 个人债务 * 稳定债务乘数(稳定债务)\n        //即抵押品价格下降到一定程度后，触发清算\n        require(mul(u.ink, i.spot) < mul(u.art, i.rate));\n        //取个人抵押品和任何一次清算事件所涵盖的固定债务数量的小值\n        uint lot = min(u.ink, ilks[ilk].lump);\n        //取个人债务 和 抵押品 * 债务 / 抵押品的 小值\n        uint art = min(u.art, mul(lot, u.art) / u.ink);\n        //债务 * 稳定债务乘数(稳定债务)\n        uint tab = mul(art, i.rate);\n\n        require(lot <= 2**255 && art <= 2**255);\n        //清算，将个人抵押品减掉，个人债务也减掉,将减掉的抵押品转移到本地址下(gem)\n        vat.grab(ilk, urn, address(this), address(vow), -int(lot), -int(art));\n        //结算？\n        vow.fess(tab);\n        //触发拍卖\n        id = Kicker(ilks[ilk].flip).kick({ urn: urn\n                                         , gal: address(vow)\n                                         , tab: rmul(tab, ilks[ilk].chop) //所需债务: dai债务 * 清算罚款 / 10 ** 27\n                                         , lot: lot //抵押品\n                                         , bid: 0\n                                         });\n\n        emit Bite(ilk, urn, lot, art, tab, ilks[ilk].flip, id);\n    }\n```\n\n\n\n##### example\n\n补充，借贷的第一步，会有一个join合约，就是帮忙保管币/代币。调用join方法，会将币/代币转移到本合约地址下，然后本合约会调用vat.slip方法，如\n\n```\n    function join(address usr, uint wad) external note {\n        require(int(wad) >= 0);\n        vat.slip(ilk, usr, int(wad)); //gem[ilk][usr] = wad\n        require(gem.transferFrom(msg.sender, address(this), wad));\n    }\n```\n\n测试参数\n\n```\nvat.init(\"gold\");\ngemA = new GemJoin(address(vat), \"gold\", address(gold));\nvat.file(\"gold\", \"spot\", ray(1 ether)); //ray: 10 ** 9\nvat.file(\"gold\", \"line\", rad(1000 ether)); //rad: 10 ** 27\nvat.file(\"Line\",         rad(1000 ether));\ncat.file(\"gold\", \"chop\", ray(1 ether));\n```\n\n\n\n```\naddress urn = address(this);\n//转移币\ngemA.join(urn,                             500 ether);\nvat.file(\"gold\", 'spot', ray(2.5 ether));\nvat.frob(\"gold\", me, me, me, 40 ether, 100 ether);\n//假设rate为 (10 ** 9)\n//借贷判断， 40 * (10 ** 18) * 2.5 * (10 ** 9) >=? 100 * (10 ** 18) * (10 ** 9),满足条件，可借贷\n//vat.urn[gold][me]= ink(40)， art(100)\n\n vat.file(\"gold\", 'spot', ray(2 ether));  //抵押物价格下降\n cat.file(\"gold\", \"chop\", ray(1.1 ether));\n cat.file(\"gold\", \"lump\", 30 ether);\n\n //清算判断\n uint auction = cat.bite(\"gold\", address(this));\n //40 * (10 ** 18) * 2 * (10 ** 9) >=? 100 * (10 ** 18) * (10 ** 9) 很明显，不满足条件，触发清算\n //清算lot=min(u.ink, ilks[ilk].lump) = 30 ether\n // art = min(u.art, mul(lot, u.art) / u.ink); = 75 ether\n //此时vat.urn[gold][me] = ink(10 ether), art(25 ether)\n //\t\t\t\t\t\ttab = art * rate\n //触发拍卖kick中tab为rmul(tab, ilks[ilk].chop)， (75 * (10 ** 18) * (10 ** 9)) * 1.1 * (10 ** 18) / 10 ** 27 = 82.5 * (10 ** 18) 即85 ether\n```\n","slug":"dai-code","published":1,"updated":"2019-10-14T06:53:02.933Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69su0008t6xvxv3i6uc9","content":"<h2 id=\"dai结构及源码解析\"><a href=\"#dai结构及源码解析\" class=\"headerlink\" title=\"dai结构及源码解析\"></a>dai结构及源码解析</h2><p><img src=\"https://user-images.githubusercontent.com/5028/58217074-3ec06880-7d55-11e9-91e2-c9bec7172bc4.png\" alt=\"合约调用图\"></p>\n<p>结构图如上所示，vat左边的主要是<strong>管理控制修改</strong>vat及vat右边各合约各<strong>参数</strong>的合约，红线file为调用各合约中file方法，也就是修改各合约中相应参数。如vat中file为P427L-9Y552-5433E-8DSR3-58Z68</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function file(bytes32 what, uint data) external note auth &#123;</span><br><span class=\"line\">    if (what == &quot;Line&quot;) Line = data;</span><br><span class=\"line\">    else revert();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">function file(bytes32 ilk, bytes32 what, uint data) external note auth &#123;</span><br><span class=\"line\">    if (what == &quot;spot&quot;) ilks[ilk].spot = data;</span><br><span class=\"line\">    else if (what == &quot;line&quot;) ilks[ilk].line = data;</span><br><span class=\"line\">    else if (what == &quot;dust&quot;) ilks[ilk].dust = data;</span><br><span class=\"line\">    else revert();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>vat是CDP的主要逻辑合约。</p>\n<p>cat为清算触发合约，通过调用cat.bite方法，当满足清算条件就会触发清算。具体逻辑稍后提及。</p>\n<p>vow为结算合约，通过vow的结算条件可触发flop和flap。</p>\n<p>flip为抵押物拍卖合约，拍卖由cat触发，拍卖逻辑稍后提及。</p>\n<p>flop和flap分别为债务拍卖和盈余拍卖，由vow触发。</p>\n<h3 id=\"vat\"><a href=\"#vat\" class=\"headerlink\" title=\"vat\"></a>vat</h3><p>变量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//抵押物id对应的参数</span><br><span class=\"line\">mapping (bytes32 =&gt; Ilk)                       public ilks;  </span><br><span class=\"line\">//抵押物id =&gt; 个人地址 =&gt; 个人债务</span><br><span class=\"line\">mapping (bytes32 =&gt; mapping (address =&gt; Urn )) public urns;  </span><br><span class=\"line\">//抵押物id =&gt; 个人地址 =&gt; 个人抵押物总值</span><br><span class=\"line\">mapping (bytes32 =&gt; mapping (address =&gt; uint)) public gem;  </span><br><span class=\"line\">//个人地址 =&gt; 含有的dai，统计作用</span><br><span class=\"line\">mapping (address =&gt; uint256)                   public dai;  </span><br><span class=\"line\">//清算地址 =&gt; 清算总值， 统计作用</span><br><span class=\"line\">mapping (address =&gt; uint256)                   public sin;</span><br><span class=\"line\"></span><br><span class=\"line\"> struct Urn &#123;</span><br><span class=\"line\">        uint256 ink;   // 锁定的抵押物值</span><br><span class=\"line\">        uint256 art;   // 借贷的dai</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"> //以抵押物id为个体</span><br><span class=\"line\"> struct Ilk &#123;</span><br><span class=\"line\">        uint256 Art;   // 总借贷dai</span><br><span class=\"line\">        uint256 rate;  // 可借贷比率</span><br><span class=\"line\">        uint256 spot;  // 价格安全线</span><br><span class=\"line\">        uint256 line;  // 总借贷上线</span><br><span class=\"line\">        uint256 dust;  // 总借贷下限</span><br><span class=\"line\"> &#125; //rate和spot的作用主要是满足ink * spot &gt;= art * rate可借贷，不然就不能借贷或者需要清算了。</span><br></pre></td></tr></table></figure>\n\n<p>主要讲讲frob方法吧，这个方法可谓是精短又强悍！</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//bytes32 i ilk标识， address u cdp所有者，v 抵押物所有者，w 获得dai的所有者，dink 参与的抵押物，dart参与的债务</span><br><span class=\"line\">function frob(bytes32 i, address u, address v, address w, int dink, int dart) external note &#123;</span><br><span class=\"line\">    // system is live</span><br><span class=\"line\">    require(live == 1);</span><br><span class=\"line\"></span><br><span class=\"line\">    Urn memory urn = urns[i][u];</span><br><span class=\"line\">    Ilk memory ilk = ilks[i];</span><br><span class=\"line\">    // ilk has been initialised</span><br><span class=\"line\">    require(ilk.rate != 0);</span><br><span class=\"line\"></span><br><span class=\"line\">    urn.ink = add(urn.ink, dink);</span><br><span class=\"line\">    urn.art = add(urn.art, dart);</span><br><span class=\"line\">    ilk.Art = add(ilk.Art, dart);</span><br><span class=\"line\"></span><br><span class=\"line\">    int dtab = mul(ilk.rate, dart);</span><br><span class=\"line\">    uint tab = mul(urn.art, ilk.rate);</span><br><span class=\"line\">    debt     = add(debt, dtab); //dai总量</span><br><span class=\"line\"></span><br><span class=\"line\">    //dart &lt;=0, 赎回抵押物？ dart &gt;0, 借贷</span><br><span class=\"line\"></span><br><span class=\"line\">    // either debt has decreased, or debt ceilings are not exceeded</span><br><span class=\"line\">    require(either(dart &lt;= 0, both(mul(ilk.Art, ilk.rate) &lt;= ilk.line, debt &lt;= Line)));</span><br><span class=\"line\">    // urn is either less risky than before, or it is safe</span><br><span class=\"line\">    require(either(both(dart &lt;= 0, dink &gt;= 0), tab &lt;= mul(urn.ink, ilk.spot)));</span><br><span class=\"line\">    // urn is either more safe, or the owner consents</span><br><span class=\"line\">    require(either(both(dart &lt;= 0, dink &gt;= 0), wish(u, msg.sender)));</span><br><span class=\"line\">    // collateral src consents</span><br><span class=\"line\">    require(either(dink &lt;= 0, wish(v, msg.sender)));</span><br><span class=\"line\">    // debt dst consents</span><br><span class=\"line\">    require(either(dart &gt;= 0, wish(w, msg.sender)));</span><br><span class=\"line\">    // urn has no debt, or a non-dusty amount</span><br><span class=\"line\">    require(either(urn.art == 0, tab &gt;= ilk.dust));</span><br><span class=\"line\"></span><br><span class=\"line\">    gem[i][v] = sub(gem[i][v], dink);</span><br><span class=\"line\">    dai[w]    = add(dai[w],    dtab);</span><br><span class=\"line\">    urns[i][u] = urn;</span><br><span class=\"line\">    ilks[i]    = ilk;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在以上这个方法中，包含了很多种用法，包括新增cdp、偿还等等，例如当dart&gt;0的时候，就是借贷，当dart&lt;0的时候，偿还。</p>\n<p>首先，当借贷/增加抵押物时，抵押物为dink &gt;=0, 贷款dart &gt;0。贷款价值为dart * rate，抵押物价值为dink * spot。借贷需要满足的条件如下</p>\n<ul>\n<li><p>贷款价值 &lt; 债务上限line, 且该抵押物的总贷款价值&lt;Line上限</p>\n</li>\n<li><p>贷款价值 &lt;= 抵押物价值，这里理解一下rate，当rate &gt; 1，其实就是说可贷的dart其实是小于真正抵押物价值的，用来调控风险。</p>\n</li>\n<li><p>u为调用者，或者调用者是u的下层授权管理（u授权x以操作其cdp）</p>\n</li>\n<li><p>贷款价值 &gt; 债务下限 dust</p>\n</li>\n</ul>\n<p>当条件判断完毕后，进行扣除/赎回抵押物(gem)，借出/偿还dai。</p>\n<h3 id=\"cat\"><a href=\"#cat\" class=\"headerlink\" title=\"cat\"></a>cat</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function bite(bytes32 ilk, address urn) external returns (uint id) &#123;</span><br><span class=\"line\">       VatLike.Ilk memory i = vat.ilks(ilk);</span><br><span class=\"line\">       VatLike.Urn memory u = vat.urns(ilk, urn);</span><br><span class=\"line\"></span><br><span class=\"line\">       require(live == 1);</span><br><span class=\"line\">       //触发清算要求，个人抵押品 * 具有安全边际的抵押品价格 &lt; 个人债务 * 稳定债务乘数(稳定债务)</span><br><span class=\"line\">       //即抵押品价格下降到一定程度后，触发清算</span><br><span class=\"line\">       require(mul(u.ink, i.spot) &lt; mul(u.art, i.rate));</span><br><span class=\"line\">       //取个人抵押品和任何一次清算事件所涵盖的固定债务数量的小值</span><br><span class=\"line\">       uint lot = min(u.ink, ilks[ilk].lump);</span><br><span class=\"line\">       //取个人债务 和 抵押品 * 债务 / 抵押品的 小值</span><br><span class=\"line\">       uint art = min(u.art, mul(lot, u.art) / u.ink);</span><br><span class=\"line\">       //债务 * 稳定债务乘数(稳定债务)</span><br><span class=\"line\">       uint tab = mul(art, i.rate);</span><br><span class=\"line\"></span><br><span class=\"line\">       require(lot &lt;= 2**255 &amp;&amp; art &lt;= 2**255);</span><br><span class=\"line\">       //清算，将个人抵押品减掉，个人债务也减掉,将减掉的抵押品转移到本地址下(gem)</span><br><span class=\"line\">       vat.grab(ilk, urn, address(this), address(vow), -int(lot), -int(art));</span><br><span class=\"line\">       //结算？</span><br><span class=\"line\">       vow.fess(tab);</span><br><span class=\"line\">       //触发拍卖</span><br><span class=\"line\">       id = Kicker(ilks[ilk].flip).kick(&#123; urn: urn</span><br><span class=\"line\">                                        , gal: address(vow)</span><br><span class=\"line\">                                        , tab: rmul(tab, ilks[ilk].chop) //所需债务: dai债务 * 清算罚款 / 10 ** 27</span><br><span class=\"line\">                                        , lot: lot //抵押品</span><br><span class=\"line\">                                        , bid: 0</span><br><span class=\"line\">                                        &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">       emit Bite(ilk, urn, lot, art, tab, ilks[ilk].flip, id);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"example\"><a href=\"#example\" class=\"headerlink\" title=\"example\"></a>example</h5><p>补充，借贷的第一步，会有一个join合约，就是帮忙保管币/代币。调用join方法，会将币/代币转移到本合约地址下，然后本合约会调用vat.slip方法，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function join(address usr, uint wad) external note &#123;</span><br><span class=\"line\">    require(int(wad) &gt;= 0);</span><br><span class=\"line\">    vat.slip(ilk, usr, int(wad)); //gem[ilk][usr] = wad</span><br><span class=\"line\">    require(gem.transferFrom(msg.sender, address(this), wad));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>测试参数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vat.init(&quot;gold&quot;);</span><br><span class=\"line\">gemA = new GemJoin(address(vat), &quot;gold&quot;, address(gold));</span><br><span class=\"line\">vat.file(&quot;gold&quot;, &quot;spot&quot;, ray(1 ether)); //ray: 10 ** 9</span><br><span class=\"line\">vat.file(&quot;gold&quot;, &quot;line&quot;, rad(1000 ether)); //rad: 10 ** 27</span><br><span class=\"line\">vat.file(&quot;Line&quot;,         rad(1000 ether));</span><br><span class=\"line\">cat.file(&quot;gold&quot;, &quot;chop&quot;, ray(1 ether));</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">address urn = address(this);</span><br><span class=\"line\">//转移币</span><br><span class=\"line\">gemA.join(urn,                             500 ether);</span><br><span class=\"line\">vat.file(&quot;gold&quot;, &apos;spot&apos;, ray(2.5 ether));</span><br><span class=\"line\">vat.frob(&quot;gold&quot;, me, me, me, 40 ether, 100 ether);</span><br><span class=\"line\">//假设rate为 (10 ** 9)</span><br><span class=\"line\">//借贷判断， 40 * (10 ** 18) * 2.5 * (10 ** 9) &gt;=? 100 * (10 ** 18) * (10 ** 9),满足条件，可借贷</span><br><span class=\"line\">//vat.urn[gold][me]= ink(40)， art(100)</span><br><span class=\"line\"></span><br><span class=\"line\"> vat.file(&quot;gold&quot;, &apos;spot&apos;, ray(2 ether));  //抵押物价格下降</span><br><span class=\"line\"> cat.file(&quot;gold&quot;, &quot;chop&quot;, ray(1.1 ether));</span><br><span class=\"line\"> cat.file(&quot;gold&quot;, &quot;lump&quot;, 30 ether);</span><br><span class=\"line\"></span><br><span class=\"line\"> //清算判断</span><br><span class=\"line\"> uint auction = cat.bite(&quot;gold&quot;, address(this));</span><br><span class=\"line\"> //40 * (10 ** 18) * 2 * (10 ** 9) &gt;=? 100 * (10 ** 18) * (10 ** 9) 很明显，不满足条件，触发清算</span><br><span class=\"line\"> //清算lot=min(u.ink, ilks[ilk].lump) = 30 ether</span><br><span class=\"line\"> // art = min(u.art, mul(lot, u.art) / u.ink); = 75 ether</span><br><span class=\"line\"> //此时vat.urn[gold][me] = ink(10 ether), art(25 ether)</span><br><span class=\"line\"> //\t\t\t\t\t\ttab = art * rate</span><br><span class=\"line\"> //触发拍卖kick中tab为rmul(tab, ilks[ilk].chop)， (75 * (10 ** 18) * (10 ** 9)) * 1.1 * (10 ** 18) / 10 ** 27 = 82.5 * (10 ** 18) 即85 ether</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"dai结构及源码解析\"><a href=\"#dai结构及源码解析\" class=\"headerlink\" title=\"dai结构及源码解析\"></a>dai结构及源码解析</h2><p><img src=\"https://user-images.githubusercontent.com/5028/58217074-3ec06880-7d55-11e9-91e2-c9bec7172bc4.png\" alt=\"合约调用图\"></p>\n<p>结构图如上所示，vat左边的主要是<strong>管理控制修改</strong>vat及vat右边各合约各<strong>参数</strong>的合约，红线file为调用各合约中file方法，也就是修改各合约中相应参数。如vat中file为P427L-9Y552-5433E-8DSR3-58Z68</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function file(bytes32 what, uint data) external note auth &#123;</span><br><span class=\"line\">    if (what == &quot;Line&quot;) Line = data;</span><br><span class=\"line\">    else revert();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">function file(bytes32 ilk, bytes32 what, uint data) external note auth &#123;</span><br><span class=\"line\">    if (what == &quot;spot&quot;) ilks[ilk].spot = data;</span><br><span class=\"line\">    else if (what == &quot;line&quot;) ilks[ilk].line = data;</span><br><span class=\"line\">    else if (what == &quot;dust&quot;) ilks[ilk].dust = data;</span><br><span class=\"line\">    else revert();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>vat是CDP的主要逻辑合约。</p>\n<p>cat为清算触发合约，通过调用cat.bite方法，当满足清算条件就会触发清算。具体逻辑稍后提及。</p>\n<p>vow为结算合约，通过vow的结算条件可触发flop和flap。</p>\n<p>flip为抵押物拍卖合约，拍卖由cat触发，拍卖逻辑稍后提及。</p>\n<p>flop和flap分别为债务拍卖和盈余拍卖，由vow触发。</p>\n<h3 id=\"vat\"><a href=\"#vat\" class=\"headerlink\" title=\"vat\"></a>vat</h3><p>变量</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//抵押物id对应的参数</span><br><span class=\"line\">mapping (bytes32 =&gt; Ilk)                       public ilks;  </span><br><span class=\"line\">//抵押物id =&gt; 个人地址 =&gt; 个人债务</span><br><span class=\"line\">mapping (bytes32 =&gt; mapping (address =&gt; Urn )) public urns;  </span><br><span class=\"line\">//抵押物id =&gt; 个人地址 =&gt; 个人抵押物总值</span><br><span class=\"line\">mapping (bytes32 =&gt; mapping (address =&gt; uint)) public gem;  </span><br><span class=\"line\">//个人地址 =&gt; 含有的dai，统计作用</span><br><span class=\"line\">mapping (address =&gt; uint256)                   public dai;  </span><br><span class=\"line\">//清算地址 =&gt; 清算总值， 统计作用</span><br><span class=\"line\">mapping (address =&gt; uint256)                   public sin;</span><br><span class=\"line\"></span><br><span class=\"line\"> struct Urn &#123;</span><br><span class=\"line\">        uint256 ink;   // 锁定的抵押物值</span><br><span class=\"line\">        uint256 art;   // 借贷的dai</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"> //以抵押物id为个体</span><br><span class=\"line\"> struct Ilk &#123;</span><br><span class=\"line\">        uint256 Art;   // 总借贷dai</span><br><span class=\"line\">        uint256 rate;  // 可借贷比率</span><br><span class=\"line\">        uint256 spot;  // 价格安全线</span><br><span class=\"line\">        uint256 line;  // 总借贷上线</span><br><span class=\"line\">        uint256 dust;  // 总借贷下限</span><br><span class=\"line\"> &#125; //rate和spot的作用主要是满足ink * spot &gt;= art * rate可借贷，不然就不能借贷或者需要清算了。</span><br></pre></td></tr></table></figure>\n\n<p>主要讲讲frob方法吧，这个方法可谓是精短又强悍！</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//bytes32 i ilk标识， address u cdp所有者，v 抵押物所有者，w 获得dai的所有者，dink 参与的抵押物，dart参与的债务</span><br><span class=\"line\">function frob(bytes32 i, address u, address v, address w, int dink, int dart) external note &#123;</span><br><span class=\"line\">    // system is live</span><br><span class=\"line\">    require(live == 1);</span><br><span class=\"line\"></span><br><span class=\"line\">    Urn memory urn = urns[i][u];</span><br><span class=\"line\">    Ilk memory ilk = ilks[i];</span><br><span class=\"line\">    // ilk has been initialised</span><br><span class=\"line\">    require(ilk.rate != 0);</span><br><span class=\"line\"></span><br><span class=\"line\">    urn.ink = add(urn.ink, dink);</span><br><span class=\"line\">    urn.art = add(urn.art, dart);</span><br><span class=\"line\">    ilk.Art = add(ilk.Art, dart);</span><br><span class=\"line\"></span><br><span class=\"line\">    int dtab = mul(ilk.rate, dart);</span><br><span class=\"line\">    uint tab = mul(urn.art, ilk.rate);</span><br><span class=\"line\">    debt     = add(debt, dtab); //dai总量</span><br><span class=\"line\"></span><br><span class=\"line\">    //dart &lt;=0, 赎回抵押物？ dart &gt;0, 借贷</span><br><span class=\"line\"></span><br><span class=\"line\">    // either debt has decreased, or debt ceilings are not exceeded</span><br><span class=\"line\">    require(either(dart &lt;= 0, both(mul(ilk.Art, ilk.rate) &lt;= ilk.line, debt &lt;= Line)));</span><br><span class=\"line\">    // urn is either less risky than before, or it is safe</span><br><span class=\"line\">    require(either(both(dart &lt;= 0, dink &gt;= 0), tab &lt;= mul(urn.ink, ilk.spot)));</span><br><span class=\"line\">    // urn is either more safe, or the owner consents</span><br><span class=\"line\">    require(either(both(dart &lt;= 0, dink &gt;= 0), wish(u, msg.sender)));</span><br><span class=\"line\">    // collateral src consents</span><br><span class=\"line\">    require(either(dink &lt;= 0, wish(v, msg.sender)));</span><br><span class=\"line\">    // debt dst consents</span><br><span class=\"line\">    require(either(dart &gt;= 0, wish(w, msg.sender)));</span><br><span class=\"line\">    // urn has no debt, or a non-dusty amount</span><br><span class=\"line\">    require(either(urn.art == 0, tab &gt;= ilk.dust));</span><br><span class=\"line\"></span><br><span class=\"line\">    gem[i][v] = sub(gem[i][v], dink);</span><br><span class=\"line\">    dai[w]    = add(dai[w],    dtab);</span><br><span class=\"line\">    urns[i][u] = urn;</span><br><span class=\"line\">    ilks[i]    = ilk;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在以上这个方法中，包含了很多种用法，包括新增cdp、偿还等等，例如当dart&gt;0的时候，就是借贷，当dart&lt;0的时候，偿还。</p>\n<p>首先，当借贷/增加抵押物时，抵押物为dink &gt;=0, 贷款dart &gt;0。贷款价值为dart * rate，抵押物价值为dink * spot。借贷需要满足的条件如下</p>\n<ul>\n<li><p>贷款价值 &lt; 债务上限line, 且该抵押物的总贷款价值&lt;Line上限</p>\n</li>\n<li><p>贷款价值 &lt;= 抵押物价值，这里理解一下rate，当rate &gt; 1，其实就是说可贷的dart其实是小于真正抵押物价值的，用来调控风险。</p>\n</li>\n<li><p>u为调用者，或者调用者是u的下层授权管理（u授权x以操作其cdp）</p>\n</li>\n<li><p>贷款价值 &gt; 债务下限 dust</p>\n</li>\n</ul>\n<p>当条件判断完毕后，进行扣除/赎回抵押物(gem)，借出/偿还dai。</p>\n<h3 id=\"cat\"><a href=\"#cat\" class=\"headerlink\" title=\"cat\"></a>cat</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function bite(bytes32 ilk, address urn) external returns (uint id) &#123;</span><br><span class=\"line\">       VatLike.Ilk memory i = vat.ilks(ilk);</span><br><span class=\"line\">       VatLike.Urn memory u = vat.urns(ilk, urn);</span><br><span class=\"line\"></span><br><span class=\"line\">       require(live == 1);</span><br><span class=\"line\">       //触发清算要求，个人抵押品 * 具有安全边际的抵押品价格 &lt; 个人债务 * 稳定债务乘数(稳定债务)</span><br><span class=\"line\">       //即抵押品价格下降到一定程度后，触发清算</span><br><span class=\"line\">       require(mul(u.ink, i.spot) &lt; mul(u.art, i.rate));</span><br><span class=\"line\">       //取个人抵押品和任何一次清算事件所涵盖的固定债务数量的小值</span><br><span class=\"line\">       uint lot = min(u.ink, ilks[ilk].lump);</span><br><span class=\"line\">       //取个人债务 和 抵押品 * 债务 / 抵押品的 小值</span><br><span class=\"line\">       uint art = min(u.art, mul(lot, u.art) / u.ink);</span><br><span class=\"line\">       //债务 * 稳定债务乘数(稳定债务)</span><br><span class=\"line\">       uint tab = mul(art, i.rate);</span><br><span class=\"line\"></span><br><span class=\"line\">       require(lot &lt;= 2**255 &amp;&amp; art &lt;= 2**255);</span><br><span class=\"line\">       //清算，将个人抵押品减掉，个人债务也减掉,将减掉的抵押品转移到本地址下(gem)</span><br><span class=\"line\">       vat.grab(ilk, urn, address(this), address(vow), -int(lot), -int(art));</span><br><span class=\"line\">       //结算？</span><br><span class=\"line\">       vow.fess(tab);</span><br><span class=\"line\">       //触发拍卖</span><br><span class=\"line\">       id = Kicker(ilks[ilk].flip).kick(&#123; urn: urn</span><br><span class=\"line\">                                        , gal: address(vow)</span><br><span class=\"line\">                                        , tab: rmul(tab, ilks[ilk].chop) //所需债务: dai债务 * 清算罚款 / 10 ** 27</span><br><span class=\"line\">                                        , lot: lot //抵押品</span><br><span class=\"line\">                                        , bid: 0</span><br><span class=\"line\">                                        &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">       emit Bite(ilk, urn, lot, art, tab, ilks[ilk].flip, id);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"example\"><a href=\"#example\" class=\"headerlink\" title=\"example\"></a>example</h5><p>补充，借贷的第一步，会有一个join合约，就是帮忙保管币/代币。调用join方法，会将币/代币转移到本合约地址下，然后本合约会调用vat.slip方法，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function join(address usr, uint wad) external note &#123;</span><br><span class=\"line\">    require(int(wad) &gt;= 0);</span><br><span class=\"line\">    vat.slip(ilk, usr, int(wad)); //gem[ilk][usr] = wad</span><br><span class=\"line\">    require(gem.transferFrom(msg.sender, address(this), wad));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>测试参数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vat.init(&quot;gold&quot;);</span><br><span class=\"line\">gemA = new GemJoin(address(vat), &quot;gold&quot;, address(gold));</span><br><span class=\"line\">vat.file(&quot;gold&quot;, &quot;spot&quot;, ray(1 ether)); //ray: 10 ** 9</span><br><span class=\"line\">vat.file(&quot;gold&quot;, &quot;line&quot;, rad(1000 ether)); //rad: 10 ** 27</span><br><span class=\"line\">vat.file(&quot;Line&quot;,         rad(1000 ether));</span><br><span class=\"line\">cat.file(&quot;gold&quot;, &quot;chop&quot;, ray(1 ether));</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">address urn = address(this);</span><br><span class=\"line\">//转移币</span><br><span class=\"line\">gemA.join(urn,                             500 ether);</span><br><span class=\"line\">vat.file(&quot;gold&quot;, &apos;spot&apos;, ray(2.5 ether));</span><br><span class=\"line\">vat.frob(&quot;gold&quot;, me, me, me, 40 ether, 100 ether);</span><br><span class=\"line\">//假设rate为 (10 ** 9)</span><br><span class=\"line\">//借贷判断， 40 * (10 ** 18) * 2.5 * (10 ** 9) &gt;=? 100 * (10 ** 18) * (10 ** 9),满足条件，可借贷</span><br><span class=\"line\">//vat.urn[gold][me]= ink(40)， art(100)</span><br><span class=\"line\"></span><br><span class=\"line\"> vat.file(&quot;gold&quot;, &apos;spot&apos;, ray(2 ether));  //抵押物价格下降</span><br><span class=\"line\"> cat.file(&quot;gold&quot;, &quot;chop&quot;, ray(1.1 ether));</span><br><span class=\"line\"> cat.file(&quot;gold&quot;, &quot;lump&quot;, 30 ether);</span><br><span class=\"line\"></span><br><span class=\"line\"> //清算判断</span><br><span class=\"line\"> uint auction = cat.bite(&quot;gold&quot;, address(this));</span><br><span class=\"line\"> //40 * (10 ** 18) * 2 * (10 ** 9) &gt;=? 100 * (10 ** 18) * (10 ** 9) 很明显，不满足条件，触发清算</span><br><span class=\"line\"> //清算lot=min(u.ink, ilks[ilk].lump) = 30 ether</span><br><span class=\"line\"> // art = min(u.art, mul(lot, u.art) / u.ink); = 75 ether</span><br><span class=\"line\"> //此时vat.urn[gold][me] = ink(10 ether), art(25 ether)</span><br><span class=\"line\"> //\t\t\t\t\t\ttab = art * rate</span><br><span class=\"line\"> //触发拍卖kick中tab为rmul(tab, ilks[ilk].chop)， (75 * (10 ** 18) * (10 ** 9)) * 1.1 * (10 ** 18) / 10 ** 27 = 82.5 * (10 ** 18) 即85 ether</span><br></pre></td></tr></table></figure>\n\n"},{"title":"elastic_kibana","date":"2017-10-14T05:54:17.000Z","_content":"\n## ES数组对象，以及Kibana相关操作\n\n好久未写过博客，一晃就年底。\n\n前两天需求是在Kibana里生成曲线，关键是数据类型是数组对象。稍微走了写歪路，下面从数据类型开始说起。\n\n### 数据\n\n- mapping:\n\n  ```\n  data: {\n  \tproperties: {\n  \t\tdata_value: {\n  \t\t\ttype: \"long\"\n  \t\t},\n  \t\tindex: {\n  \t\t\ttype: \"long\"\n  \t\t},\n  \t}\n  }\n  ```\n\n- 示例\n\n  ```\n  //example1:\n  {data: [{index: 0, data_value: 200}, {index: 1, data_value: 300}]}\n\n  //example2:\n  {data: [{index: 0, data_value: 200}]}\n  ```\n\n  即data为数组对象，每次含有的index的有可能是多个，有可能是1个。\n\n- 数组对象在es中的存储\n\n  ```\n   //example1:\n   {\n     data: {\n     \t index: [0, 1],\n     \t data_value: [200, 300],\n     }\n   }\n  ```\n\n  在ElasticSearch中对数组对象的访问可通过data.index，data.data\\_value的形式进行。示例中example1的存储如上所示，0和200，1和300之间的关系其实就不再存在了。\n\n  当时我的需求是，需要对index进行分桶，针对每个index，求出metric。如在index=0的桶里，求data.data\\_value的max,桶里边只有example1和example2的数据，理想中的max应该是200,但求出来发现是300...问题就在存储上，data.data_value在存储上其实是[200, 300],与index=0还是1一点关系都没有..\n\n  如果非要实现对index=0下求data_value的max呢?\n\n\n\n### Scripted Fields\n\n当时需求是在Kibana上实现，故以下皆以Kibana作例，若是单纯的写ES的查询或聚合语句，可直接参考script内容。\n\n[How to create Kibana Script Fields](https://www.elastic.co/guide/en/kibana/current/scripted-fields.html)\n\n 在ES中支持查询返回一个script value,即在查询时就进行相应的script计算。[elasticsearch script fields starting](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-script-fields.html).\n\n 既然是script，自然就灵活很多，可以通过添加新的字段，将上面的数组对象中的值转换为key-value格式的，那么在聚合统计操作中选择对应的key即可。\n\n 具体操作为，在Kibana中选择Management中的Index Patterns,选中对应index,选择Scripted field，新建一个(Add Scripted Field)。Name填入如data\\_index\\_0,Language选择painless,Type选择为number。script内容为\n\n```\n  if(params['_source']['data'] != null) {\n\t  for(def item : params['_source']['data']) {\n\t     if(item.index == 0)\n\t       return item.data_value;\n\t  }\n\t}\nreturn null;\n```\n\n 最后选择创建字段即可，在Discover页面中即可看到每条数据中都增加了data\\_index\\_0,其值为index=0时对应的data_value。这样就将对象数组中的数据搬出来以key-value的方式存在了。另外，官方在介绍Scripted Fields时说明尽量不要使用\\_source字段，会使搜索变慢，以后在使用的过程中最好还是使用doc。如获得data.index的方式为doc['data.index'].values,返回值为List。\n","source":"_posts/elastic-kibana.md","raw":"---\ntitle: elastic_kibana\ndate: 2017-10-14 13:54:17\ncategories:\n- elk\n---\n\n## ES数组对象，以及Kibana相关操作\n\n好久未写过博客，一晃就年底。\n\n前两天需求是在Kibana里生成曲线，关键是数据类型是数组对象。稍微走了写歪路，下面从数据类型开始说起。\n\n### 数据\n\n- mapping:\n\n  ```\n  data: {\n  \tproperties: {\n  \t\tdata_value: {\n  \t\t\ttype: \"long\"\n  \t\t},\n  \t\tindex: {\n  \t\t\ttype: \"long\"\n  \t\t},\n  \t}\n  }\n  ```\n\n- 示例\n\n  ```\n  //example1:\n  {data: [{index: 0, data_value: 200}, {index: 1, data_value: 300}]}\n\n  //example2:\n  {data: [{index: 0, data_value: 200}]}\n  ```\n\n  即data为数组对象，每次含有的index的有可能是多个，有可能是1个。\n\n- 数组对象在es中的存储\n\n  ```\n   //example1:\n   {\n     data: {\n     \t index: [0, 1],\n     \t data_value: [200, 300],\n     }\n   }\n  ```\n\n  在ElasticSearch中对数组对象的访问可通过data.index，data.data\\_value的形式进行。示例中example1的存储如上所示，0和200，1和300之间的关系其实就不再存在了。\n\n  当时我的需求是，需要对index进行分桶，针对每个index，求出metric。如在index=0的桶里，求data.data\\_value的max,桶里边只有example1和example2的数据，理想中的max应该是200,但求出来发现是300...问题就在存储上，data.data_value在存储上其实是[200, 300],与index=0还是1一点关系都没有..\n\n  如果非要实现对index=0下求data_value的max呢?\n\n\n\n### Scripted Fields\n\n当时需求是在Kibana上实现，故以下皆以Kibana作例，若是单纯的写ES的查询或聚合语句，可直接参考script内容。\n\n[How to create Kibana Script Fields](https://www.elastic.co/guide/en/kibana/current/scripted-fields.html)\n\n 在ES中支持查询返回一个script value,即在查询时就进行相应的script计算。[elasticsearch script fields starting](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-script-fields.html).\n\n 既然是script，自然就灵活很多，可以通过添加新的字段，将上面的数组对象中的值转换为key-value格式的，那么在聚合统计操作中选择对应的key即可。\n\n 具体操作为，在Kibana中选择Management中的Index Patterns,选中对应index,选择Scripted field，新建一个(Add Scripted Field)。Name填入如data\\_index\\_0,Language选择painless,Type选择为number。script内容为\n\n```\n  if(params['_source']['data'] != null) {\n\t  for(def item : params['_source']['data']) {\n\t     if(item.index == 0)\n\t       return item.data_value;\n\t  }\n\t}\nreturn null;\n```\n\n 最后选择创建字段即可，在Discover页面中即可看到每条数据中都增加了data\\_index\\_0,其值为index=0时对应的data_value。这样就将对象数组中的数据搬出来以key-value的方式存在了。另外，官方在介绍Scripted Fields时说明尽量不要使用\\_source字段，会使搜索变慢，以后在使用的过程中最好还是使用doc。如获得data.index的方式为doc['data.index'].values,返回值为List。\n","slug":"elastic-kibana","published":1,"updated":"2019-10-14T06:21:17.808Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69sy000at6xvf53jnzum","content":"<h2 id=\"ES数组对象，以及Kibana相关操作\"><a href=\"#ES数组对象，以及Kibana相关操作\" class=\"headerlink\" title=\"ES数组对象，以及Kibana相关操作\"></a>ES数组对象，以及Kibana相关操作</h2><p>好久未写过博客，一晃就年底。</p>\n<p>前两天需求是在Kibana里生成曲线，关键是数据类型是数组对象。稍微走了写歪路，下面从数据类型开始说起。</p>\n<h3 id=\"数据\"><a href=\"#数据\" class=\"headerlink\" title=\"数据\"></a>数据</h3><ul>\n<li><p>mapping:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data: &#123;</span><br><span class=\"line\">\tproperties: &#123;</span><br><span class=\"line\">\t\tdata_value: &#123;</span><br><span class=\"line\">\t\t\ttype: &quot;long&quot;</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t\tindex: &#123;</span><br><span class=\"line\">\t\t\ttype: &quot;long&quot;</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//example1:</span><br><span class=\"line\">&#123;data: [&#123;index: 0, data_value: 200&#125;, &#123;index: 1, data_value: 300&#125;]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//example2:</span><br><span class=\"line\">&#123;data: [&#123;index: 0, data_value: 200&#125;]&#125;</span><br></pre></td></tr></table></figure>\n\n<p>即data为数组对象，每次含有的index的有可能是多个，有可能是1个。</p>\n</li>\n<li><p>数组对象在es中的存储</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//example1:</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  data: &#123;</span><br><span class=\"line\">  \t index: [0, 1],</span><br><span class=\"line\">  \t data_value: [200, 300],</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在ElasticSearch中对数组对象的访问可通过data.index，data.data_value的形式进行。示例中example1的存储如上所示，0和200，1和300之间的关系其实就不再存在了。</p>\n<p>当时我的需求是，需要对index进行分桶，针对每个index，求出metric。如在index=0的桶里，求data.data_value的max,桶里边只有example1和example2的数据，理想中的max应该是200,但求出来发现是300…问题就在存储上，data.data_value在存储上其实是[200, 300],与index=0还是1一点关系都没有..</p>\n<p>如果非要实现对index=0下求data_value的max呢?</p>\n</li>\n</ul>\n<h3 id=\"Scripted-Fields\"><a href=\"#Scripted-Fields\" class=\"headerlink\" title=\"Scripted Fields\"></a>Scripted Fields</h3><p>当时需求是在Kibana上实现，故以下皆以Kibana作例，若是单纯的写ES的查询或聚合语句，可直接参考script内容。</p>\n<p><a href=\"https://www.elastic.co/guide/en/kibana/current/scripted-fields.html\" target=\"_blank\" rel=\"noopener\">How to create Kibana Script Fields</a></p>\n<p> 在ES中支持查询返回一个script value,即在查询时就进行相应的script计算。<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-script-fields.html\" target=\"_blank\" rel=\"noopener\">elasticsearch script fields starting</a>.</p>\n<p> 既然是script，自然就灵活很多，可以通过添加新的字段，将上面的数组对象中的值转换为key-value格式的，那么在聚合统计操作中选择对应的key即可。</p>\n<p> 具体操作为，在Kibana中选择Management中的Index Patterns,选中对应index,选择Scripted field，新建一个(Add Scripted Field)。Name填入如data_index_0,Language选择painless,Type选择为number。script内容为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  if(params[&apos;_source&apos;][&apos;data&apos;] != null) &#123;</span><br><span class=\"line\">\t  for(def item : params[&apos;_source&apos;][&apos;data&apos;]) &#123;</span><br><span class=\"line\">\t     if(item.index == 0)</span><br><span class=\"line\">\t       return item.data_value;</span><br><span class=\"line\">\t  &#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">return null;</span><br></pre></td></tr></table></figure>\n\n<p> 最后选择创建字段即可，在Discover页面中即可看到每条数据中都增加了data_index_0,其值为index=0时对应的data_value。这样就将对象数组中的数据搬出来以key-value的方式存在了。另外，官方在介绍Scripted Fields时说明尽量不要使用_source字段，会使搜索变慢，以后在使用的过程中最好还是使用doc。如获得data.index的方式为doc[‘data.index’].values,返回值为List。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"ES数组对象，以及Kibana相关操作\"><a href=\"#ES数组对象，以及Kibana相关操作\" class=\"headerlink\" title=\"ES数组对象，以及Kibana相关操作\"></a>ES数组对象，以及Kibana相关操作</h2><p>好久未写过博客，一晃就年底。</p>\n<p>前两天需求是在Kibana里生成曲线，关键是数据类型是数组对象。稍微走了写歪路，下面从数据类型开始说起。</p>\n<h3 id=\"数据\"><a href=\"#数据\" class=\"headerlink\" title=\"数据\"></a>数据</h3><ul>\n<li><p>mapping:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data: &#123;</span><br><span class=\"line\">\tproperties: &#123;</span><br><span class=\"line\">\t\tdata_value: &#123;</span><br><span class=\"line\">\t\t\ttype: &quot;long&quot;</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t\tindex: &#123;</span><br><span class=\"line\">\t\t\ttype: &quot;long&quot;</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//example1:</span><br><span class=\"line\">&#123;data: [&#123;index: 0, data_value: 200&#125;, &#123;index: 1, data_value: 300&#125;]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//example2:</span><br><span class=\"line\">&#123;data: [&#123;index: 0, data_value: 200&#125;]&#125;</span><br></pre></td></tr></table></figure>\n\n<p>即data为数组对象，每次含有的index的有可能是多个，有可能是1个。</p>\n</li>\n<li><p>数组对象在es中的存储</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//example1:</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  data: &#123;</span><br><span class=\"line\">  \t index: [0, 1],</span><br><span class=\"line\">  \t data_value: [200, 300],</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在ElasticSearch中对数组对象的访问可通过data.index，data.data_value的形式进行。示例中example1的存储如上所示，0和200，1和300之间的关系其实就不再存在了。</p>\n<p>当时我的需求是，需要对index进行分桶，针对每个index，求出metric。如在index=0的桶里，求data.data_value的max,桶里边只有example1和example2的数据，理想中的max应该是200,但求出来发现是300…问题就在存储上，data.data_value在存储上其实是[200, 300],与index=0还是1一点关系都没有..</p>\n<p>如果非要实现对index=0下求data_value的max呢?</p>\n</li>\n</ul>\n<h3 id=\"Scripted-Fields\"><a href=\"#Scripted-Fields\" class=\"headerlink\" title=\"Scripted Fields\"></a>Scripted Fields</h3><p>当时需求是在Kibana上实现，故以下皆以Kibana作例，若是单纯的写ES的查询或聚合语句，可直接参考script内容。</p>\n<p><a href=\"https://www.elastic.co/guide/en/kibana/current/scripted-fields.html\" target=\"_blank\" rel=\"noopener\">How to create Kibana Script Fields</a></p>\n<p> 在ES中支持查询返回一个script value,即在查询时就进行相应的script计算。<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-script-fields.html\" target=\"_blank\" rel=\"noopener\">elasticsearch script fields starting</a>.</p>\n<p> 既然是script，自然就灵活很多，可以通过添加新的字段，将上面的数组对象中的值转换为key-value格式的，那么在聚合统计操作中选择对应的key即可。</p>\n<p> 具体操作为，在Kibana中选择Management中的Index Patterns,选中对应index,选择Scripted field，新建一个(Add Scripted Field)。Name填入如data_index_0,Language选择painless,Type选择为number。script内容为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  if(params[&apos;_source&apos;][&apos;data&apos;] != null) &#123;</span><br><span class=\"line\">\t  for(def item : params[&apos;_source&apos;][&apos;data&apos;]) &#123;</span><br><span class=\"line\">\t     if(item.index == 0)</span><br><span class=\"line\">\t       return item.data_value;</span><br><span class=\"line\">\t  &#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">return null;</span><br></pre></td></tr></table></figure>\n\n<p> 最后选择创建字段即可，在Discover页面中即可看到每条数据中都增加了data_index_0,其值为index=0时对应的data_value。这样就将对象数组中的数据搬出来以key-value的方式存在了。另外，官方在介绍Scripted Fields时说明尽量不要使用_source字段，会使搜索变慢，以后在使用的过程中最好还是使用doc。如获得data.index的方式为doc[‘data.index’].values,返回值为List。</p>\n"},{"title":"elastic_painless","date":"2017-10-14T05:55:33.000Z","_content":"\n## Painless\n\n> Painless is a scripting language developed and maintained by Elastic and optimized for Elasticsearch.\n\n### 数据类型\n\n- def\n\n  动态数据类型，默认值为null。\n\n- 其余的数据类型，和java基本相同。基本数据类型都有，对象类型的，Map,List也都有。基本api也都是java相应的api\n\n跟Java的关系。（Java8）\n\n> Extends Java’s syntax to provide Groovy-style scripting language features that make scripts easier to write.\n\n\n\n### 示例\n\n- 遍历数组\n\n  ```\n  \tfor(def item :  doc['cmd'].values) {\n\n  \t}\n\n  ```\n\n  数据取出来是个对象，如doc['cmd'],需要取相应的值需要调用对应属性，数组的话则是values,数值的话value,日期类的话date\n\n- date类型操作\n\n  ```\n   return doc['begin_at'].date.hourOfDay\n  ```\n\n  这个date的类型对应到java里具体是啥.没搞清楚.有点像Calender的变体，Calendar能获得的属性都有\n\n### 调试\n\n关于调试，一直是我很在意又无奈的事。\n\nKibana添加script fields的话，使用Dev Tools先进行script的验证，看看有没有语法错之类的，成功之后再把scipt部分粘贴进去。简单的转换示例\n\n```\nGET /test/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"script_fields\": {\n    \"test_script\": {\n      \"script\": {\n        \"lang\": \"painless\",\n        \"inline\": \"return doc['begin_at'].date.hourOfDay\"\n      }\n    }\n  },\n  \"size\": 1\n}\n\n```\n\n官方说明的调试是Debug.explain\n\n```\nPUT /hockey/player/1?refresh\n{\"first\":\"johnny\",\"last\":\"gaudreau\",\"goals\":[9,27,1],\"assists\":[17,46,0],\"gp\":[26,82,1]}\n\nPOST /hockey/player/1/_explain\n{\n  \"query\": {\n    \"script\": {\n      \"script\": \"Debug.explain(doc.goals)\"\n    }\n  }\n}\n\n```\n\nby responding\n\n```\n{\n   \"error\": {\n      \"type\": \"script_exception\",\n      \"to_string\": \"[1, 9, 27]\",\n      \"painless_class\": \"org.elasticsearch.index.fielddata.ScriptDocValues.Longs\",\n      \"java_class\": \"org.elasticsearch.index.fielddata.ScriptDocValues$Longs\",\n      ...\n   },\n   \"status\": 500\n}\n```\n","source":"_posts/elastic-painless.md","raw":"---\ntitle: elastic_painless\ndate: 2017-10-14 13:55:33\ncategories:\n- elk\n---\n\n## Painless\n\n> Painless is a scripting language developed and maintained by Elastic and optimized for Elasticsearch.\n\n### 数据类型\n\n- def\n\n  动态数据类型，默认值为null。\n\n- 其余的数据类型，和java基本相同。基本数据类型都有，对象类型的，Map,List也都有。基本api也都是java相应的api\n\n跟Java的关系。（Java8）\n\n> Extends Java’s syntax to provide Groovy-style scripting language features that make scripts easier to write.\n\n\n\n### 示例\n\n- 遍历数组\n\n  ```\n  \tfor(def item :  doc['cmd'].values) {\n\n  \t}\n\n  ```\n\n  数据取出来是个对象，如doc['cmd'],需要取相应的值需要调用对应属性，数组的话则是values,数值的话value,日期类的话date\n\n- date类型操作\n\n  ```\n   return doc['begin_at'].date.hourOfDay\n  ```\n\n  这个date的类型对应到java里具体是啥.没搞清楚.有点像Calender的变体，Calendar能获得的属性都有\n\n### 调试\n\n关于调试，一直是我很在意又无奈的事。\n\nKibana添加script fields的话，使用Dev Tools先进行script的验证，看看有没有语法错之类的，成功之后再把scipt部分粘贴进去。简单的转换示例\n\n```\nGET /test/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"script_fields\": {\n    \"test_script\": {\n      \"script\": {\n        \"lang\": \"painless\",\n        \"inline\": \"return doc['begin_at'].date.hourOfDay\"\n      }\n    }\n  },\n  \"size\": 1\n}\n\n```\n\n官方说明的调试是Debug.explain\n\n```\nPUT /hockey/player/1?refresh\n{\"first\":\"johnny\",\"last\":\"gaudreau\",\"goals\":[9,27,1],\"assists\":[17,46,0],\"gp\":[26,82,1]}\n\nPOST /hockey/player/1/_explain\n{\n  \"query\": {\n    \"script\": {\n      \"script\": \"Debug.explain(doc.goals)\"\n    }\n  }\n}\n\n```\n\nby responding\n\n```\n{\n   \"error\": {\n      \"type\": \"script_exception\",\n      \"to_string\": \"[1, 9, 27]\",\n      \"painless_class\": \"org.elasticsearch.index.fielddata.ScriptDocValues.Longs\",\n      \"java_class\": \"org.elasticsearch.index.fielddata.ScriptDocValues$Longs\",\n      ...\n   },\n   \"status\": 500\n}\n```\n","slug":"elastic-painless","published":1,"updated":"2019-10-14T06:21:28.123Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69t3000bt6xv9zo3a3ma","content":"<h2 id=\"Painless\"><a href=\"#Painless\" class=\"headerlink\" title=\"Painless\"></a>Painless</h2><blockquote>\n<p>Painless is a scripting language developed and maintained by Elastic and optimized for Elasticsearch.</p>\n</blockquote>\n<h3 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h3><ul>\n<li><p>def</p>\n<p>动态数据类型，默认值为null。</p>\n</li>\n<li><p>其余的数据类型，和java基本相同。基本数据类型都有，对象类型的，Map,List也都有。基本api也都是java相应的api</p>\n</li>\n</ul>\n<p>跟Java的关系。（Java8）</p>\n<blockquote>\n<p>Extends Java’s syntax to provide Groovy-style scripting language features that make scripts easier to write.</p>\n</blockquote>\n<h3 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h3><ul>\n<li><p>遍历数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for(def item :  doc[&apos;cmd&apos;].values) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>数据取出来是个对象，如doc[‘cmd’],需要取相应的值需要调用对应属性，数组的话则是values,数值的话value,日期类的话date</p>\n</li>\n<li><p>date类型操作</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return doc[&apos;begin_at&apos;].date.hourOfDay</span><br></pre></td></tr></table></figure>\n\n<p>这个date的类型对应到java里具体是啥.没搞清楚.有点像Calender的变体，Calendar能获得的属性都有</p>\n</li>\n</ul>\n<h3 id=\"调试\"><a href=\"#调试\" class=\"headerlink\" title=\"调试\"></a>调试</h3><p>关于调试，一直是我很在意又无奈的事。</p>\n<p>Kibana添加script fields的话，使用Dev Tools先进行script的验证，看看有没有语法错之类的，成功之后再把scipt部分粘贴进去。简单的转换示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GET /test/_search</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;match_all&quot;: &#123;&#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;script_fields&quot;: &#123;</span><br><span class=\"line\">    &quot;test_script&quot;: &#123;</span><br><span class=\"line\">      &quot;script&quot;: &#123;</span><br><span class=\"line\">        &quot;lang&quot;: &quot;painless&quot;,</span><br><span class=\"line\">        &quot;inline&quot;: &quot;return doc[&apos;begin_at&apos;].date.hourOfDay&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;size&quot;: 1</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>官方说明的调试是Debug.explain</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /hockey/player/1?refresh</span><br><span class=\"line\">&#123;&quot;first&quot;:&quot;johnny&quot;,&quot;last&quot;:&quot;gaudreau&quot;,&quot;goals&quot;:[9,27,1],&quot;assists&quot;:[17,46,0],&quot;gp&quot;:[26,82,1]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">POST /hockey/player/1/_explain</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;script&quot;: &#123;</span><br><span class=\"line\">      &quot;script&quot;: &quot;Debug.explain(doc.goals)&quot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>by responding</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">   &quot;error&quot;: &#123;</span><br><span class=\"line\">      &quot;type&quot;: &quot;script_exception&quot;,</span><br><span class=\"line\">      &quot;to_string&quot;: &quot;[1, 9, 27]&quot;,</span><br><span class=\"line\">      &quot;painless_class&quot;: &quot;org.elasticsearch.index.fielddata.ScriptDocValues.Longs&quot;,</span><br><span class=\"line\">      &quot;java_class&quot;: &quot;org.elasticsearch.index.fielddata.ScriptDocValues$Longs&quot;,</span><br><span class=\"line\">      ...</span><br><span class=\"line\">   &#125;,</span><br><span class=\"line\">   &quot;status&quot;: 500</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Painless\"><a href=\"#Painless\" class=\"headerlink\" title=\"Painless\"></a>Painless</h2><blockquote>\n<p>Painless is a scripting language developed and maintained by Elastic and optimized for Elasticsearch.</p>\n</blockquote>\n<h3 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h3><ul>\n<li><p>def</p>\n<p>动态数据类型，默认值为null。</p>\n</li>\n<li><p>其余的数据类型，和java基本相同。基本数据类型都有，对象类型的，Map,List也都有。基本api也都是java相应的api</p>\n</li>\n</ul>\n<p>跟Java的关系。（Java8）</p>\n<blockquote>\n<p>Extends Java’s syntax to provide Groovy-style scripting language features that make scripts easier to write.</p>\n</blockquote>\n<h3 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h3><ul>\n<li><p>遍历数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for(def item :  doc[&apos;cmd&apos;].values) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>数据取出来是个对象，如doc[‘cmd’],需要取相应的值需要调用对应属性，数组的话则是values,数值的话value,日期类的话date</p>\n</li>\n<li><p>date类型操作</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return doc[&apos;begin_at&apos;].date.hourOfDay</span><br></pre></td></tr></table></figure>\n\n<p>这个date的类型对应到java里具体是啥.没搞清楚.有点像Calender的变体，Calendar能获得的属性都有</p>\n</li>\n</ul>\n<h3 id=\"调试\"><a href=\"#调试\" class=\"headerlink\" title=\"调试\"></a>调试</h3><p>关于调试，一直是我很在意又无奈的事。</p>\n<p>Kibana添加script fields的话，使用Dev Tools先进行script的验证，看看有没有语法错之类的，成功之后再把scipt部分粘贴进去。简单的转换示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GET /test/_search</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;match_all&quot;: &#123;&#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;script_fields&quot;: &#123;</span><br><span class=\"line\">    &quot;test_script&quot;: &#123;</span><br><span class=\"line\">      &quot;script&quot;: &#123;</span><br><span class=\"line\">        &quot;lang&quot;: &quot;painless&quot;,</span><br><span class=\"line\">        &quot;inline&quot;: &quot;return doc[&apos;begin_at&apos;].date.hourOfDay&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;size&quot;: 1</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>官方说明的调试是Debug.explain</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /hockey/player/1?refresh</span><br><span class=\"line\">&#123;&quot;first&quot;:&quot;johnny&quot;,&quot;last&quot;:&quot;gaudreau&quot;,&quot;goals&quot;:[9,27,1],&quot;assists&quot;:[17,46,0],&quot;gp&quot;:[26,82,1]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">POST /hockey/player/1/_explain</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;script&quot;: &#123;</span><br><span class=\"line\">      &quot;script&quot;: &quot;Debug.explain(doc.goals)&quot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>by responding</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">   &quot;error&quot;: &#123;</span><br><span class=\"line\">      &quot;type&quot;: &quot;script_exception&quot;,</span><br><span class=\"line\">      &quot;to_string&quot;: &quot;[1, 9, 27]&quot;,</span><br><span class=\"line\">      &quot;painless_class&quot;: &quot;org.elasticsearch.index.fielddata.ScriptDocValues.Longs&quot;,</span><br><span class=\"line\">      &quot;java_class&quot;: &quot;org.elasticsearch.index.fielddata.ScriptDocValues$Longs&quot;,</span><br><span class=\"line\">      ...</span><br><span class=\"line\">   &#125;,</span><br><span class=\"line\">   &quot;status&quot;: 500</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"elastic_logstash","date":"2017-10-14T05:55:27.000Z","_content":"\n## logstash_config\n\n组成部分为： input, filter, output\n[文档介绍](https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html)\n\n### value\n\n> A plugin can require that the value for a setting be a certain type, such as boolean, list, or hash.\n\n- Array\n\n  users => [ {id => 1, name => bob}, {id => 2, name => jane} ]\n\n- Lists\n\n  path => [ \"/var/log/messages\", \"/var/log/*.log\" ]\n    \t\turis => [ \"http://elastic.co\", \"http://example.net\" ]\n\n- Boolean\n\n  ssl_enable => true\n\n- Bytes\n\n  my_bytes => \"1113\"   # 1113 bytes\n  \t  my_bytes => \"10MiB\"  # 10485760 bytes\n  \t  my_bytes => \"100kib\" # 102400 bytes\n  \t  my_bytes => \"180 mb\" # 180000000 bytes\n\n- Codec\n\n  codec => \"json\"\n  \t  //更多类型https://www.elastic.co/guide/en/logstash/current/codec-plugins.html\n\n- Hash\n\n  match => {\n  \t  \"field1\" => \"value1\"\n  \t  \"field2\" => \"value2\"\n  \t  ...\n  \t}\n\n- Number\n\n  port => 33\n\n- Password\n\n  my_password => \"password\"\n\n- URI\n\n  my_uri => \"http://foo:bar@example.net\"\n\n- Path\n\n  my_path => \"/tmp/logstash\"\n\n- String\n\n  name => \"Hello world\"\n    \t\t  name => 'It\\'s a beautiful day'\n\n- Comments\n\n  # this is a comment\n\n  ```\n  \tinput { # comments can appear at the end of a line, too\n  \t  # ...\n  \t}\n  ```\n\n### filter\n\n- mutate\n\n  mutate { replace => { \"type\" => \"file_test\" } }\n\n- grok\n\n  > Parses unstructured event data into fields\n\n  ```\n  grok {\n    match => { \"message\" => \"%{COMBINEDAPACHELOG}\" }\n  }\n  ```\n\n  [patterns的集合](https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns)\n\n- date\n\n  date {\n    \t\t  match => [ \"timestamp\" , \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n  \t  }\n\n\n- json\n\n  > Parses JSON events\n\n\n\n##### drop example:\n\n```\nfilter {\n\t    grok {\n            match => [\"message\",\"%{TIMESTAMP_ISO8601:logtime} \\[%{NUMBER}\\] \\(\\(%{WORD}\\)\\) %{WORD:loglevel} %{GREEDYDATA:other}\"]\n    }\n\n    if [loglevel]!= \"ERROR\" {\n            drop {}\n    }\n}\n```\n\n### input\n\n[file](https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html)\n\n### output\n\n### filter\n\n- grok\n  \t 消息解析，消息以按行为单位进行解析。基本格式为\n\n    \t grok {\n      match => { \"message\" => \"%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\" }\n    \t}\n\n\n  > Grok sits on top of regular expressions, so any regular expressions are valid in grok as well.\n\n   其中，可将正则组成pattern，如\"%{IP:client}\" IP为pattern的类型, client为变量名，解析出来的变量如client可在后面进行使用。    \n   [自定义pattern](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html#_custom_patterns),总结方式就是在某文件下创建pattern解析方式，如\n\n\n  ```\n   # contents of ./patterns/extra:\n  JAVA_CLASS ([a-zA-Z]+[.][a-zA-Z]+)[.]*.*\n  ```\n\n再在grok中增加字段patterns\\_dir，patterns\\_dir为文件夹，非文件。如\n\n```\n  grok {\n\t  patterns_dir => [\"/Users/xiaoxuez/Library/apache/logstash-5.4.2/patterns\"]\n\t  match => { \"message\" => \"%{TIMESTAMP_ISO8601:timestamp} %{JAVA_CLASS:producer} %{WORD:printer} %{GREEDYDATA:content}\" }\n}\n```\n\n​    \n\n### config\n\n config中还可以使用[if条件语句]()，如  \n\n```\nfilter {\n \t...\n \tif ([producer] =~ /[m].*/) {\n \t\t# do ..\n\t} else {\n\t\t drop { }  #该条消息丢掉 不进入output\n\t}\n```\n\n   }\n\n# =~  为正则匹配运算符，\n\n\n\n## EXAMPLE\n\nfile使用正则匹配\n\n \t path => \"/var/log/%{type}.%{+yyyy.MM.dd.HH}\"\n\n使用变量用[]，如[path]\n\n# ([a-zA-Z]+[.][a-zA-Z]+)[.]*.*  正则匹配类名\n\n```\n  json{\n       source => \"content\"\n       target => \"content\"\n   }\n\n   mutate {\n\t         add_field => {\n\t           \"event_type\" => \"%{[jsoncontent][type]}\"\n\t           \"event_msg\" => \"%{[jsoncontent][event]}\"\n\t         }\n       }\n```\n\n​\t\t\n​\t\t      \n​    \n\n```\n  #控制打印的\nif ([producer] == \"STUDIO\" ) {\n    mutate { replace => { \"type\" => \"System_Airguru_Log\" } }\n} else if ([producer] =~ /[m].*/) {\n    json{\n          source => \"content\"\n          target => \"jsoncontent\"\n      }\n    mutate {\n      replace => { \"type\" => \"Stratege_Airguru_Log\" }\n      add_field => {\n```\n\n  \t\t           \"event_type\" => \"%{[jsoncontent][type]}\"\n  \t\t           \"event_msg\" => \"%{[jsoncontent][event]}\"\n  \t\t         }\n          }\n    } else {\n      drop { }\n    }\t\t\n\n\n\n### Example\n\n#### filter-aggregate\n\n```\ninput {\n  file {\n    path => \"${PROJECT}/logs/**/**/worker.log\"\n    start_position => \"beginning\"\n  }\n}\n\nfilter {\n#  if [path] =~ \".log\" {\n    #消息解析，\n    grok {\n\t\t\tid => \"storm_log_filter\"\n      patterns_dir => [\"${PROJECT}/patterns\"]\n      #match => { \"message\" => \"%{GREEDYDATA:unknow}\" }\n      #match => { \"message\" => \"%{TIMESTAMP_ISO8601:time} %{JAVA_CLASS:producer} %{WORD:printer} %{GREEDYDATA:content}\" }\n      match => { \"path\" => \".*/%{WORD:topology}\\-%{JUST_NUMBER:order}\\-%{JUST_NUMBER:submittime}/[0-9]+/worker.log\" }\n      break_on_match => false\n    }\n\n    aggregate {\n     task_id => \"%{topology}-%{order}-%{submittime}\"\n     code => \"map['counts'] ||= 0; map['counts'] += 1;\"\n     push_map_as_event_on_timeout => true\n     timeout_task_id_field => \"topology_file\"\n     timeout => 360 # 10 minutes timeout\n     timeout_tags => ['_aggregatetimeout']\n   }\n```\n\n​\n\n```\n#  }\n\n}\n\noutput {\n  stdout { codec => rubydebug }\n}\n```\n\n#### filter-basic-grok\n\n```\ninput {\n  file {\n    path => \"/Users/xiaoxuez/Library/apache/logstash-5.4.2/test/file_test_log.log\"\n    start_position => \"beginning\"\n  }\n}\n\nfilter {\n  if [path] =~ \".log\" {\n    #消息解析，\n    grok {\n      match => { \"message\" => \"%{TOMCAT_DATESTAMP:time} %{JAVACLASS:producer} %{WORD} %{GREEDYDATA:content}\" }\n      break_on_match => false\n    }\n```\n\n​\n​\n​\n​\n\n```\n    # if ([producer] !~ /[m].*/ or \"_grokparsefailure\" in [tags]) {\n      # drop { }\n  #  }\n\n    mutate {\n      #  remove_field => [\"message\"]\n    }\n```\n\n​\n\n```\n  }\n\n}\n\noutput {\n  #elasticsearch {\n  #  hosts => [\"localhost:9200\"]\n  #}\n  #输出到 stdout#\n  stdout { codec => rubydebug }\n}\n```\n\n## 坑\n\n- 调式过程中出现解析文件没报错也没任何的东西...\n\n  logstash会监听文件读取信息记录的位置,所以解析过的文件，如果文件内容并没有发生变化(暂且说是内容吧，可能logstash只能监听位置改变而不能识别之前内容有所改变，这个我还未验证过..),那么再次解析的话，将不会解析以前解析过的内容。解决方式是将监听的记录删掉，记录存在于{logstash}/data/plugins/inputs/file/.sincedb*\n","source":"_posts/elastic-logstash.md","raw":"---\ntitle: elastic_logstash\ndate: 2017-10-14 13:55:27\ncategories:\n- elk\n---\n\n## logstash_config\n\n组成部分为： input, filter, output\n[文档介绍](https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html)\n\n### value\n\n> A plugin can require that the value for a setting be a certain type, such as boolean, list, or hash.\n\n- Array\n\n  users => [ {id => 1, name => bob}, {id => 2, name => jane} ]\n\n- Lists\n\n  path => [ \"/var/log/messages\", \"/var/log/*.log\" ]\n    \t\turis => [ \"http://elastic.co\", \"http://example.net\" ]\n\n- Boolean\n\n  ssl_enable => true\n\n- Bytes\n\n  my_bytes => \"1113\"   # 1113 bytes\n  \t  my_bytes => \"10MiB\"  # 10485760 bytes\n  \t  my_bytes => \"100kib\" # 102400 bytes\n  \t  my_bytes => \"180 mb\" # 180000000 bytes\n\n- Codec\n\n  codec => \"json\"\n  \t  //更多类型https://www.elastic.co/guide/en/logstash/current/codec-plugins.html\n\n- Hash\n\n  match => {\n  \t  \"field1\" => \"value1\"\n  \t  \"field2\" => \"value2\"\n  \t  ...\n  \t}\n\n- Number\n\n  port => 33\n\n- Password\n\n  my_password => \"password\"\n\n- URI\n\n  my_uri => \"http://foo:bar@example.net\"\n\n- Path\n\n  my_path => \"/tmp/logstash\"\n\n- String\n\n  name => \"Hello world\"\n    \t\t  name => 'It\\'s a beautiful day'\n\n- Comments\n\n  # this is a comment\n\n  ```\n  \tinput { # comments can appear at the end of a line, too\n  \t  # ...\n  \t}\n  ```\n\n### filter\n\n- mutate\n\n  mutate { replace => { \"type\" => \"file_test\" } }\n\n- grok\n\n  > Parses unstructured event data into fields\n\n  ```\n  grok {\n    match => { \"message\" => \"%{COMBINEDAPACHELOG}\" }\n  }\n  ```\n\n  [patterns的集合](https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns)\n\n- date\n\n  date {\n    \t\t  match => [ \"timestamp\" , \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n  \t  }\n\n\n- json\n\n  > Parses JSON events\n\n\n\n##### drop example:\n\n```\nfilter {\n\t    grok {\n            match => [\"message\",\"%{TIMESTAMP_ISO8601:logtime} \\[%{NUMBER}\\] \\(\\(%{WORD}\\)\\) %{WORD:loglevel} %{GREEDYDATA:other}\"]\n    }\n\n    if [loglevel]!= \"ERROR\" {\n            drop {}\n    }\n}\n```\n\n### input\n\n[file](https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html)\n\n### output\n\n### filter\n\n- grok\n  \t 消息解析，消息以按行为单位进行解析。基本格式为\n\n    \t grok {\n      match => { \"message\" => \"%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\" }\n    \t}\n\n\n  > Grok sits on top of regular expressions, so any regular expressions are valid in grok as well.\n\n   其中，可将正则组成pattern，如\"%{IP:client}\" IP为pattern的类型, client为变量名，解析出来的变量如client可在后面进行使用。    \n   [自定义pattern](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html#_custom_patterns),总结方式就是在某文件下创建pattern解析方式，如\n\n\n  ```\n   # contents of ./patterns/extra:\n  JAVA_CLASS ([a-zA-Z]+[.][a-zA-Z]+)[.]*.*\n  ```\n\n再在grok中增加字段patterns\\_dir，patterns\\_dir为文件夹，非文件。如\n\n```\n  grok {\n\t  patterns_dir => [\"/Users/xiaoxuez/Library/apache/logstash-5.4.2/patterns\"]\n\t  match => { \"message\" => \"%{TIMESTAMP_ISO8601:timestamp} %{JAVA_CLASS:producer} %{WORD:printer} %{GREEDYDATA:content}\" }\n}\n```\n\n​    \n\n### config\n\n config中还可以使用[if条件语句]()，如  \n\n```\nfilter {\n \t...\n \tif ([producer] =~ /[m].*/) {\n \t\t# do ..\n\t} else {\n\t\t drop { }  #该条消息丢掉 不进入output\n\t}\n```\n\n   }\n\n# =~  为正则匹配运算符，\n\n\n\n## EXAMPLE\n\nfile使用正则匹配\n\n \t path => \"/var/log/%{type}.%{+yyyy.MM.dd.HH}\"\n\n使用变量用[]，如[path]\n\n# ([a-zA-Z]+[.][a-zA-Z]+)[.]*.*  正则匹配类名\n\n```\n  json{\n       source => \"content\"\n       target => \"content\"\n   }\n\n   mutate {\n\t         add_field => {\n\t           \"event_type\" => \"%{[jsoncontent][type]}\"\n\t           \"event_msg\" => \"%{[jsoncontent][event]}\"\n\t         }\n       }\n```\n\n​\t\t\n​\t\t      \n​    \n\n```\n  #控制打印的\nif ([producer] == \"STUDIO\" ) {\n    mutate { replace => { \"type\" => \"System_Airguru_Log\" } }\n} else if ([producer] =~ /[m].*/) {\n    json{\n          source => \"content\"\n          target => \"jsoncontent\"\n      }\n    mutate {\n      replace => { \"type\" => \"Stratege_Airguru_Log\" }\n      add_field => {\n```\n\n  \t\t           \"event_type\" => \"%{[jsoncontent][type]}\"\n  \t\t           \"event_msg\" => \"%{[jsoncontent][event]}\"\n  \t\t         }\n          }\n    } else {\n      drop { }\n    }\t\t\n\n\n\n### Example\n\n#### filter-aggregate\n\n```\ninput {\n  file {\n    path => \"${PROJECT}/logs/**/**/worker.log\"\n    start_position => \"beginning\"\n  }\n}\n\nfilter {\n#  if [path] =~ \".log\" {\n    #消息解析，\n    grok {\n\t\t\tid => \"storm_log_filter\"\n      patterns_dir => [\"${PROJECT}/patterns\"]\n      #match => { \"message\" => \"%{GREEDYDATA:unknow}\" }\n      #match => { \"message\" => \"%{TIMESTAMP_ISO8601:time} %{JAVA_CLASS:producer} %{WORD:printer} %{GREEDYDATA:content}\" }\n      match => { \"path\" => \".*/%{WORD:topology}\\-%{JUST_NUMBER:order}\\-%{JUST_NUMBER:submittime}/[0-9]+/worker.log\" }\n      break_on_match => false\n    }\n\n    aggregate {\n     task_id => \"%{topology}-%{order}-%{submittime}\"\n     code => \"map['counts'] ||= 0; map['counts'] += 1;\"\n     push_map_as_event_on_timeout => true\n     timeout_task_id_field => \"topology_file\"\n     timeout => 360 # 10 minutes timeout\n     timeout_tags => ['_aggregatetimeout']\n   }\n```\n\n​\n\n```\n#  }\n\n}\n\noutput {\n  stdout { codec => rubydebug }\n}\n```\n\n#### filter-basic-grok\n\n```\ninput {\n  file {\n    path => \"/Users/xiaoxuez/Library/apache/logstash-5.4.2/test/file_test_log.log\"\n    start_position => \"beginning\"\n  }\n}\n\nfilter {\n  if [path] =~ \".log\" {\n    #消息解析，\n    grok {\n      match => { \"message\" => \"%{TOMCAT_DATESTAMP:time} %{JAVACLASS:producer} %{WORD} %{GREEDYDATA:content}\" }\n      break_on_match => false\n    }\n```\n\n​\n​\n​\n​\n\n```\n    # if ([producer] !~ /[m].*/ or \"_grokparsefailure\" in [tags]) {\n      # drop { }\n  #  }\n\n    mutate {\n      #  remove_field => [\"message\"]\n    }\n```\n\n​\n\n```\n  }\n\n}\n\noutput {\n  #elasticsearch {\n  #  hosts => [\"localhost:9200\"]\n  #}\n  #输出到 stdout#\n  stdout { codec => rubydebug }\n}\n```\n\n## 坑\n\n- 调式过程中出现解析文件没报错也没任何的东西...\n\n  logstash会监听文件读取信息记录的位置,所以解析过的文件，如果文件内容并没有发生变化(暂且说是内容吧，可能logstash只能监听位置改变而不能识别之前内容有所改变，这个我还未验证过..),那么再次解析的话，将不会解析以前解析过的内容。解决方式是将监听的记录删掉，记录存在于{logstash}/data/plugins/inputs/file/.sincedb*\n","slug":"elastic-logstash","published":1,"updated":"2019-10-14T06:21:23.703Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69t8000et6xvr1hw6pbw","content":"<h2 id=\"logstash-config\"><a href=\"#logstash-config\" class=\"headerlink\" title=\"logstash_config\"></a>logstash_config</h2><p>组成部分为： input, filter, output<br><a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\" target=\"_blank\" rel=\"noopener\">文档介绍</a></p>\n<h3 id=\"value\"><a href=\"#value\" class=\"headerlink\" title=\"value\"></a>value</h3><blockquote>\n<p>A plugin can require that the value for a setting be a certain type, such as boolean, list, or hash.</p>\n</blockquote>\n<ul>\n<li><p>Array</p>\n<p>users =&gt; [ {id =&gt; 1, name =&gt; bob}, {id =&gt; 2, name =&gt; jane} ]</p>\n</li>\n<li><p>Lists</p>\n<p>path =&gt; [ “/var/log/messages”, “/var/log/*.log” ]</p>\n<pre><code>uris =&gt; [ &quot;http://elastic.co&quot;, &quot;http://example.net&quot; ]</code></pre></li>\n<li><p>Boolean</p>\n<p>ssl_enable =&gt; true</p>\n</li>\n<li><p>Bytes</p>\n<p>my_bytes =&gt; “1113”   # 1113 bytes</p>\n<pre><code>my_bytes =&gt; &quot;10MiB&quot;  # 10485760 bytes\nmy_bytes =&gt; &quot;100kib&quot; # 102400 bytes\nmy_bytes =&gt; &quot;180 mb&quot; # 180000000 bytes</code></pre></li>\n<li><p>Codec</p>\n<p>codec =&gt; “json”</p>\n<pre><code>//更多类型https://www.elastic.co/guide/en/logstash/current/codec-plugins.html</code></pre></li>\n<li><p>Hash</p>\n<p>match =&gt; {</p>\n<pre><code>  &quot;field1&quot; =&gt; &quot;value1&quot;\n  &quot;field2&quot; =&gt; &quot;value2&quot;\n  ...\n}</code></pre></li>\n<li><p>Number</p>\n<p>port =&gt; 33</p>\n</li>\n<li><p>Password</p>\n<p>my_password =&gt; “password”</p>\n</li>\n<li><p>URI</p>\n<p>my_uri =&gt; “<a href=\"http://foo:bar@example.net&quot;\" target=\"_blank\" rel=\"noopener\">http://foo:bar@example.net&quot;</a></p>\n</li>\n<li><p>Path</p>\n<p>my_path =&gt; “/tmp/logstash”</p>\n</li>\n<li><p>String</p>\n<p>name =&gt; “Hello world”</p>\n<pre><code>name =&gt; &apos;It\\&apos;s a beautiful day&apos;</code></pre></li>\n<li><p>Comments</p>\n<h1 id=\"this-is-a-comment\"><a href=\"#this-is-a-comment\" class=\"headerlink\" title=\"this is a comment\"></a>this is a comment</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input &#123; # comments can appear at the end of a line, too</span><br><span class=\"line\">  # ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h3 id=\"filter\"><a href=\"#filter\" class=\"headerlink\" title=\"filter\"></a>filter</h3><ul>\n<li><p>mutate</p>\n<p>mutate { replace =&gt; { “type” =&gt; “file_test” } }</p>\n</li>\n<li><p>grok</p>\n<blockquote>\n<p>Parses unstructured event data into fields</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grok &#123;</span><br><span class=\"line\">  match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns\">patterns的集合</a></p>\n</li>\n<li><p>date</p>\n<p>date {</p>\n<pre><code>      match =&gt; [ &quot;timestamp&quot; , &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]\n}</code></pre></li>\n</ul>\n<ul>\n<li><p>json</p>\n<blockquote>\n<p>Parses JSON events</p>\n</blockquote>\n</li>\n</ul>\n<h5 id=\"drop-example\"><a href=\"#drop-example\" class=\"headerlink\" title=\"drop example:\"></a>drop example:</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">filter &#123;</span><br><span class=\"line\">\t    grok &#123;</span><br><span class=\"line\">            match =&gt; [&quot;message&quot;,&quot;%&#123;TIMESTAMP_ISO8601:logtime&#125; \\[%&#123;NUMBER&#125;\\] \\(\\(%&#123;WORD&#125;\\)\\) %&#123;WORD:loglevel&#125; %&#123;GREEDYDATA:other&#125;&quot;]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if [loglevel]!= &quot;ERROR&quot; &#123;</span><br><span class=\"line\">            drop &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"input\"><a href=\"#input\" class=\"headerlink\" title=\"input\"></a>input</h3><p><a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html\" target=\"_blank\" rel=\"noopener\">file</a></p>\n<h3 id=\"output\"><a href=\"#output\" class=\"headerlink\" title=\"output\"></a>output</h3><h3 id=\"filter-1\"><a href=\"#filter-1\" class=\"headerlink\" title=\"filter\"></a>filter</h3><ul>\n<li><p>grok</p>\n<pre><code> 消息解析，消息以按行为单位进行解析。基本格式为\n\n   grok {\nmatch =&gt; { &quot;message&quot; =&gt; &quot;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}&quot; }\n  }</code></pre></li>\n</ul>\n<blockquote>\n<p>Grok sits on top of regular expressions, so any regular expressions are valid in grok as well.</p>\n</blockquote>\n<p>   其中，可将正则组成pattern，如”%{IP:client}” IP为pattern的类型, client为变量名，解析出来的变量如client可在后面进行使用。<br>   <a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html#_custom_patterns\" target=\"_blank\" rel=\"noopener\">自定义pattern</a>,总结方式就是在某文件下创建pattern解析方式，如</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> # contents of ./patterns/extra:</span><br><span class=\"line\">JAVA_CLASS ([a-zA-Z]+[.][a-zA-Z]+)[.]*.*</span><br></pre></td></tr></table></figure>\n\n<p>再在grok中增加字段patterns_dir，patterns_dir为文件夹，非文件。如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  grok &#123;</span><br><span class=\"line\">\t  patterns_dir =&gt; [&quot;/Users/xiaoxuez/Library/apache/logstash-5.4.2/patterns&quot;]</span><br><span class=\"line\">\t  match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; %&#123;JAVA_CLASS:producer&#125; %&#123;WORD:printer&#125; %&#123;GREEDYDATA:content&#125;&quot; &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>​    </p>\n<h3 id=\"config\"><a href=\"#config\" class=\"headerlink\" title=\"config\"></a>config</h3><p> config中还可以使用<a href>if条件语句</a>，如  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">filter &#123;</span><br><span class=\"line\"> \t...</span><br><span class=\"line\"> \tif ([producer] =~ /[m].*/) &#123;</span><br><span class=\"line\"> \t\t# do ..</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\t drop &#123; &#125;  #该条消息丢掉 不进入output</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n\n<p>   }</p>\n<h1 id=\"为正则匹配运算符，\"><a href=\"#为正则匹配运算符，\" class=\"headerlink\" title=\"=~  为正则匹配运算符，\"></a>=~  为正则匹配运算符，</h1><h2 id=\"EXAMPLE\"><a href=\"#EXAMPLE\" class=\"headerlink\" title=\"EXAMPLE\"></a>EXAMPLE</h2><p>file使用正则匹配</p>\n<pre><code>path =&gt; &quot;/var/log/%{type}.%{+yyyy.MM.dd.HH}&quot;</code></pre><p>使用变量用[]，如[path]</p>\n<h1 id=\"a-zA-Z-a-zA-Z-正则匹配类名\"><a href=\"#a-zA-Z-a-zA-Z-正则匹配类名\" class=\"headerlink\" title=\"([a-zA-Z]+[.][a-zA-Z]+)[.].  正则匹配类名\"></a>([a-zA-Z]+[.][a-zA-Z]+)[.]<em>.</em>  正则匹配类名</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">json&#123;</span><br><span class=\"line\">     source =&gt; &quot;content&quot;</span><br><span class=\"line\">     target =&gt; &quot;content&quot;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> mutate &#123;</span><br><span class=\"line\">        add_field =&gt; &#123;</span><br><span class=\"line\">          &quot;event_type&quot; =&gt; &quot;%&#123;[jsoncontent][type]&#125;&quot;</span><br><span class=\"line\">          &quot;event_msg&quot; =&gt; &quot;%&#123;[jsoncontent][event]&#125;&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">     &#125;</span><br></pre></td></tr></table></figure>\n\n<p>​<br>​<br>​    </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  #控制打印的</span><br><span class=\"line\">if ([producer] == &quot;STUDIO&quot; ) &#123;</span><br><span class=\"line\">    mutate &#123; replace =&gt; &#123; &quot;type&quot; =&gt; &quot;System_Airguru_Log&quot; &#125; &#125;</span><br><span class=\"line\">&#125; else if ([producer] =~ /[m].*/) &#123;</span><br><span class=\"line\">    json&#123;</span><br><span class=\"line\">          source =&gt; &quot;content&quot;</span><br><span class=\"line\">          target =&gt; &quot;jsoncontent&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    mutate &#123;</span><br><span class=\"line\">      replace =&gt; &#123; &quot;type&quot; =&gt; &quot;Stratege_Airguru_Log&quot; &#125;</span><br><span class=\"line\">      add_field =&gt; &#123;</span><br></pre></td></tr></table></figure>\n\n<pre><code>                 &quot;event_type&quot; =&gt; &quot;%{[jsoncontent][type]}&quot;\n                 &quot;event_msg&quot; =&gt; &quot;%{[jsoncontent][event]}&quot;\n               }\n      }\n} else {\n  drop { }\n}        </code></pre><h3 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h3><h4 id=\"filter-aggregate\"><a href=\"#filter-aggregate\" class=\"headerlink\" title=\"filter-aggregate\"></a>filter-aggregate</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input &#123;</span><br><span class=\"line\">  file &#123;</span><br><span class=\"line\">    path =&gt; &quot;$&#123;PROJECT&#125;/logs/**/**/worker.log&quot;</span><br><span class=\"line\">    start_position =&gt; &quot;beginning&quot;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">filter &#123;</span><br><span class=\"line\">#  if [path] =~ &quot;.log&quot; &#123;</span><br><span class=\"line\">    #消息解析，</span><br><span class=\"line\">    grok &#123;</span><br><span class=\"line\">\t\t\tid =&gt; &quot;storm_log_filter&quot;</span><br><span class=\"line\">      patterns_dir =&gt; [&quot;$&#123;PROJECT&#125;/patterns&quot;]</span><br><span class=\"line\">      #match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;GREEDYDATA:unknow&#125;&quot; &#125;</span><br><span class=\"line\">      #match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:time&#125; %&#123;JAVA_CLASS:producer&#125; %&#123;WORD:printer&#125; %&#123;GREEDYDATA:content&#125;&quot; &#125;</span><br><span class=\"line\">      match =&gt; &#123; &quot;path&quot; =&gt; &quot;.*/%&#123;WORD:topology&#125;\\-%&#123;JUST_NUMBER:order&#125;\\-%&#123;JUST_NUMBER:submittime&#125;/[0-9]+/worker.log&quot; &#125;</span><br><span class=\"line\">      break_on_match =&gt; false</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    aggregate &#123;</span><br><span class=\"line\">     task_id =&gt; &quot;%&#123;topology&#125;-%&#123;order&#125;-%&#123;submittime&#125;&quot;</span><br><span class=\"line\">     code =&gt; &quot;map[&apos;counts&apos;] ||= 0; map[&apos;counts&apos;] += 1;&quot;</span><br><span class=\"line\">     push_map_as_event_on_timeout =&gt; true</span><br><span class=\"line\">     timeout_task_id_field =&gt; &quot;topology_file&quot;</span><br><span class=\"line\">     timeout =&gt; 360 # 10 minutes timeout</span><br><span class=\"line\">     timeout_tags =&gt; [&apos;_aggregatetimeout&apos;]</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<p>​</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">output &#123;</span><br><span class=\"line\">  stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"filter-basic-grok\"><a href=\"#filter-basic-grok\" class=\"headerlink\" title=\"filter-basic-grok\"></a>filter-basic-grok</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input &#123;</span><br><span class=\"line\">  file &#123;</span><br><span class=\"line\">    path =&gt; &quot;/Users/xiaoxuez/Library/apache/logstash-5.4.2/test/file_test_log.log&quot;</span><br><span class=\"line\">    start_position =&gt; &quot;beginning&quot;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">filter &#123;</span><br><span class=\"line\">  if [path] =~ &quot;.log&quot; &#123;</span><br><span class=\"line\">    #消息解析，</span><br><span class=\"line\">    grok &#123;</span><br><span class=\"line\">      match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TOMCAT_DATESTAMP:time&#125; %&#123;JAVACLASS:producer&#125; %&#123;WORD&#125; %&#123;GREEDYDATA:content&#125;&quot; &#125;</span><br><span class=\"line\">      break_on_match =&gt; false</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>​<br>​<br>​<br>​</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  # if ([producer] !~ /[m].*/ or &quot;_grokparsefailure&quot; in [tags]) &#123;</span><br><span class=\"line\">    # drop &#123; &#125;</span><br><span class=\"line\">#  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  mutate &#123;</span><br><span class=\"line\">    #  remove_field =&gt; [&quot;message&quot;]</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>​</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">output &#123;</span><br><span class=\"line\">  #elasticsearch &#123;</span><br><span class=\"line\">  #  hosts =&gt; [&quot;localhost:9200&quot;]</span><br><span class=\"line\">  #&#125;</span><br><span class=\"line\">  #输出到 stdout#</span><br><span class=\"line\">  stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"坑\"><a href=\"#坑\" class=\"headerlink\" title=\"坑\"></a>坑</h2><ul>\n<li><p>调式过程中出现解析文件没报错也没任何的东西…</p>\n<p>logstash会监听文件读取信息记录的位置,所以解析过的文件，如果文件内容并没有发生变化(暂且说是内容吧，可能logstash只能监听位置改变而不能识别之前内容有所改变，这个我还未验证过..),那么再次解析的话，将不会解析以前解析过的内容。解决方式是将监听的记录删掉，记录存在于{logstash}/data/plugins/inputs/file/.sincedb*</p>\n</li>\n</ul>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"logstash-config\"><a href=\"#logstash-config\" class=\"headerlink\" title=\"logstash_config\"></a>logstash_config</h2><p>组成部分为： input, filter, output<br><a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\" target=\"_blank\" rel=\"noopener\">文档介绍</a></p>\n<h3 id=\"value\"><a href=\"#value\" class=\"headerlink\" title=\"value\"></a>value</h3><blockquote>\n<p>A plugin can require that the value for a setting be a certain type, such as boolean, list, or hash.</p>\n</blockquote>\n<ul>\n<li><p>Array</p>\n<p>users =&gt; [ {id =&gt; 1, name =&gt; bob}, {id =&gt; 2, name =&gt; jane} ]</p>\n</li>\n<li><p>Lists</p>\n<p>path =&gt; [ “/var/log/messages”, “/var/log/*.log” ]</p>\n<pre><code>uris =&gt; [ &quot;http://elastic.co&quot;, &quot;http://example.net&quot; ]</code></pre></li>\n<li><p>Boolean</p>\n<p>ssl_enable =&gt; true</p>\n</li>\n<li><p>Bytes</p>\n<p>my_bytes =&gt; “1113”   # 1113 bytes</p>\n<pre><code>my_bytes =&gt; &quot;10MiB&quot;  # 10485760 bytes\nmy_bytes =&gt; &quot;100kib&quot; # 102400 bytes\nmy_bytes =&gt; &quot;180 mb&quot; # 180000000 bytes</code></pre></li>\n<li><p>Codec</p>\n<p>codec =&gt; “json”</p>\n<pre><code>//更多类型https://www.elastic.co/guide/en/logstash/current/codec-plugins.html</code></pre></li>\n<li><p>Hash</p>\n<p>match =&gt; {</p>\n<pre><code>  &quot;field1&quot; =&gt; &quot;value1&quot;\n  &quot;field2&quot; =&gt; &quot;value2&quot;\n  ...\n}</code></pre></li>\n<li><p>Number</p>\n<p>port =&gt; 33</p>\n</li>\n<li><p>Password</p>\n<p>my_password =&gt; “password”</p>\n</li>\n<li><p>URI</p>\n<p>my_uri =&gt; “<a href=\"http://foo:bar@example.net&quot;\" target=\"_blank\" rel=\"noopener\">http://foo:bar@example.net&quot;</a></p>\n</li>\n<li><p>Path</p>\n<p>my_path =&gt; “/tmp/logstash”</p>\n</li>\n<li><p>String</p>\n<p>name =&gt; “Hello world”</p>\n<pre><code>name =&gt; &apos;It\\&apos;s a beautiful day&apos;</code></pre></li>\n<li><p>Comments</p>\n<h1 id=\"this-is-a-comment\"><a href=\"#this-is-a-comment\" class=\"headerlink\" title=\"this is a comment\"></a>this is a comment</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input &#123; # comments can appear at the end of a line, too</span><br><span class=\"line\">  # ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h3 id=\"filter\"><a href=\"#filter\" class=\"headerlink\" title=\"filter\"></a>filter</h3><ul>\n<li><p>mutate</p>\n<p>mutate { replace =&gt; { “type” =&gt; “file_test” } }</p>\n</li>\n<li><p>grok</p>\n<blockquote>\n<p>Parses unstructured event data into fields</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grok &#123;</span><br><span class=\"line\">  match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns\">patterns的集合</a></p>\n</li>\n<li><p>date</p>\n<p>date {</p>\n<pre><code>      match =&gt; [ &quot;timestamp&quot; , &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]\n}</code></pre></li>\n</ul>\n<ul>\n<li><p>json</p>\n<blockquote>\n<p>Parses JSON events</p>\n</blockquote>\n</li>\n</ul>\n<h5 id=\"drop-example\"><a href=\"#drop-example\" class=\"headerlink\" title=\"drop example:\"></a>drop example:</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">filter &#123;</span><br><span class=\"line\">\t    grok &#123;</span><br><span class=\"line\">            match =&gt; [&quot;message&quot;,&quot;%&#123;TIMESTAMP_ISO8601:logtime&#125; \\[%&#123;NUMBER&#125;\\] \\(\\(%&#123;WORD&#125;\\)\\) %&#123;WORD:loglevel&#125; %&#123;GREEDYDATA:other&#125;&quot;]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if [loglevel]!= &quot;ERROR&quot; &#123;</span><br><span class=\"line\">            drop &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"input\"><a href=\"#input\" class=\"headerlink\" title=\"input\"></a>input</h3><p><a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html\" target=\"_blank\" rel=\"noopener\">file</a></p>\n<h3 id=\"output\"><a href=\"#output\" class=\"headerlink\" title=\"output\"></a>output</h3><h3 id=\"filter-1\"><a href=\"#filter-1\" class=\"headerlink\" title=\"filter\"></a>filter</h3><ul>\n<li><p>grok</p>\n<pre><code> 消息解析，消息以按行为单位进行解析。基本格式为\n\n   grok {\nmatch =&gt; { &quot;message&quot; =&gt; &quot;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}&quot; }\n  }</code></pre></li>\n</ul>\n<blockquote>\n<p>Grok sits on top of regular expressions, so any regular expressions are valid in grok as well.</p>\n</blockquote>\n<p>   其中，可将正则组成pattern，如”%{IP:client}” IP为pattern的类型, client为变量名，解析出来的变量如client可在后面进行使用。<br>   <a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html#_custom_patterns\" target=\"_blank\" rel=\"noopener\">自定义pattern</a>,总结方式就是在某文件下创建pattern解析方式，如</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> # contents of ./patterns/extra:</span><br><span class=\"line\">JAVA_CLASS ([a-zA-Z]+[.][a-zA-Z]+)[.]*.*</span><br></pre></td></tr></table></figure>\n\n<p>再在grok中增加字段patterns_dir，patterns_dir为文件夹，非文件。如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  grok &#123;</span><br><span class=\"line\">\t  patterns_dir =&gt; [&quot;/Users/xiaoxuez/Library/apache/logstash-5.4.2/patterns&quot;]</span><br><span class=\"line\">\t  match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; %&#123;JAVA_CLASS:producer&#125; %&#123;WORD:printer&#125; %&#123;GREEDYDATA:content&#125;&quot; &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>​    </p>\n<h3 id=\"config\"><a href=\"#config\" class=\"headerlink\" title=\"config\"></a>config</h3><p> config中还可以使用<a href>if条件语句</a>，如  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">filter &#123;</span><br><span class=\"line\"> \t...</span><br><span class=\"line\"> \tif ([producer] =~ /[m].*/) &#123;</span><br><span class=\"line\"> \t\t# do ..</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\t drop &#123; &#125;  #该条消息丢掉 不进入output</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n\n<p>   }</p>\n<h1 id=\"为正则匹配运算符，\"><a href=\"#为正则匹配运算符，\" class=\"headerlink\" title=\"=~  为正则匹配运算符，\"></a>=~  为正则匹配运算符，</h1><h2 id=\"EXAMPLE\"><a href=\"#EXAMPLE\" class=\"headerlink\" title=\"EXAMPLE\"></a>EXAMPLE</h2><p>file使用正则匹配</p>\n<pre><code>path =&gt; &quot;/var/log/%{type}.%{+yyyy.MM.dd.HH}&quot;</code></pre><p>使用变量用[]，如[path]</p>\n<h1 id=\"a-zA-Z-a-zA-Z-正则匹配类名\"><a href=\"#a-zA-Z-a-zA-Z-正则匹配类名\" class=\"headerlink\" title=\"([a-zA-Z]+[.][a-zA-Z]+)[.].  正则匹配类名\"></a>([a-zA-Z]+[.][a-zA-Z]+)[.]<em>.</em>  正则匹配类名</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">json&#123;</span><br><span class=\"line\">     source =&gt; &quot;content&quot;</span><br><span class=\"line\">     target =&gt; &quot;content&quot;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> mutate &#123;</span><br><span class=\"line\">        add_field =&gt; &#123;</span><br><span class=\"line\">          &quot;event_type&quot; =&gt; &quot;%&#123;[jsoncontent][type]&#125;&quot;</span><br><span class=\"line\">          &quot;event_msg&quot; =&gt; &quot;%&#123;[jsoncontent][event]&#125;&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">     &#125;</span><br></pre></td></tr></table></figure>\n\n<p>​<br>​<br>​    </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  #控制打印的</span><br><span class=\"line\">if ([producer] == &quot;STUDIO&quot; ) &#123;</span><br><span class=\"line\">    mutate &#123; replace =&gt; &#123; &quot;type&quot; =&gt; &quot;System_Airguru_Log&quot; &#125; &#125;</span><br><span class=\"line\">&#125; else if ([producer] =~ /[m].*/) &#123;</span><br><span class=\"line\">    json&#123;</span><br><span class=\"line\">          source =&gt; &quot;content&quot;</span><br><span class=\"line\">          target =&gt; &quot;jsoncontent&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    mutate &#123;</span><br><span class=\"line\">      replace =&gt; &#123; &quot;type&quot; =&gt; &quot;Stratege_Airguru_Log&quot; &#125;</span><br><span class=\"line\">      add_field =&gt; &#123;</span><br></pre></td></tr></table></figure>\n\n<pre><code>                 &quot;event_type&quot; =&gt; &quot;%{[jsoncontent][type]}&quot;\n                 &quot;event_msg&quot; =&gt; &quot;%{[jsoncontent][event]}&quot;\n               }\n      }\n} else {\n  drop { }\n}        </code></pre><h3 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h3><h4 id=\"filter-aggregate\"><a href=\"#filter-aggregate\" class=\"headerlink\" title=\"filter-aggregate\"></a>filter-aggregate</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input &#123;</span><br><span class=\"line\">  file &#123;</span><br><span class=\"line\">    path =&gt; &quot;$&#123;PROJECT&#125;/logs/**/**/worker.log&quot;</span><br><span class=\"line\">    start_position =&gt; &quot;beginning&quot;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">filter &#123;</span><br><span class=\"line\">#  if [path] =~ &quot;.log&quot; &#123;</span><br><span class=\"line\">    #消息解析，</span><br><span class=\"line\">    grok &#123;</span><br><span class=\"line\">\t\t\tid =&gt; &quot;storm_log_filter&quot;</span><br><span class=\"line\">      patterns_dir =&gt; [&quot;$&#123;PROJECT&#125;/patterns&quot;]</span><br><span class=\"line\">      #match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;GREEDYDATA:unknow&#125;&quot; &#125;</span><br><span class=\"line\">      #match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:time&#125; %&#123;JAVA_CLASS:producer&#125; %&#123;WORD:printer&#125; %&#123;GREEDYDATA:content&#125;&quot; &#125;</span><br><span class=\"line\">      match =&gt; &#123; &quot;path&quot; =&gt; &quot;.*/%&#123;WORD:topology&#125;\\-%&#123;JUST_NUMBER:order&#125;\\-%&#123;JUST_NUMBER:submittime&#125;/[0-9]+/worker.log&quot; &#125;</span><br><span class=\"line\">      break_on_match =&gt; false</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    aggregate &#123;</span><br><span class=\"line\">     task_id =&gt; &quot;%&#123;topology&#125;-%&#123;order&#125;-%&#123;submittime&#125;&quot;</span><br><span class=\"line\">     code =&gt; &quot;map[&apos;counts&apos;] ||= 0; map[&apos;counts&apos;] += 1;&quot;</span><br><span class=\"line\">     push_map_as_event_on_timeout =&gt; true</span><br><span class=\"line\">     timeout_task_id_field =&gt; &quot;topology_file&quot;</span><br><span class=\"line\">     timeout =&gt; 360 # 10 minutes timeout</span><br><span class=\"line\">     timeout_tags =&gt; [&apos;_aggregatetimeout&apos;]</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<p>​</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">output &#123;</span><br><span class=\"line\">  stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"filter-basic-grok\"><a href=\"#filter-basic-grok\" class=\"headerlink\" title=\"filter-basic-grok\"></a>filter-basic-grok</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input &#123;</span><br><span class=\"line\">  file &#123;</span><br><span class=\"line\">    path =&gt; &quot;/Users/xiaoxuez/Library/apache/logstash-5.4.2/test/file_test_log.log&quot;</span><br><span class=\"line\">    start_position =&gt; &quot;beginning&quot;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">filter &#123;</span><br><span class=\"line\">  if [path] =~ &quot;.log&quot; &#123;</span><br><span class=\"line\">    #消息解析，</span><br><span class=\"line\">    grok &#123;</span><br><span class=\"line\">      match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TOMCAT_DATESTAMP:time&#125; %&#123;JAVACLASS:producer&#125; %&#123;WORD&#125; %&#123;GREEDYDATA:content&#125;&quot; &#125;</span><br><span class=\"line\">      break_on_match =&gt; false</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>​<br>​<br>​<br>​</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  # if ([producer] !~ /[m].*/ or &quot;_grokparsefailure&quot; in [tags]) &#123;</span><br><span class=\"line\">    # drop &#123; &#125;</span><br><span class=\"line\">#  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  mutate &#123;</span><br><span class=\"line\">    #  remove_field =&gt; [&quot;message&quot;]</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>​</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">output &#123;</span><br><span class=\"line\">  #elasticsearch &#123;</span><br><span class=\"line\">  #  hosts =&gt; [&quot;localhost:9200&quot;]</span><br><span class=\"line\">  #&#125;</span><br><span class=\"line\">  #输出到 stdout#</span><br><span class=\"line\">  stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"坑\"><a href=\"#坑\" class=\"headerlink\" title=\"坑\"></a>坑</h2><ul>\n<li><p>调式过程中出现解析文件没报错也没任何的东西…</p>\n<p>logstash会监听文件读取信息记录的位置,所以解析过的文件，如果文件内容并没有发生变化(暂且说是内容吧，可能logstash只能监听位置改变而不能识别之前内容有所改变，这个我还未验证过..),那么再次解析的话，将不会解析以前解析过的内容。解决方式是将监听的记录删掉，记录存在于{logstash}/data/plugins/inputs/file/.sincedb*</p>\n</li>\n</ul>\n"},{"title":"elastic-search-dsl","date":"2017-10-14T05:52:37.000Z","_content":"\n\n## 查询ElasticSearch\n\n基于书 ElasticSearch服务器开发(第二版) 和官网doc(5.5)做的相应整理。\n\n粗略总结下，查询语句分为简单查询和复合查询，复合查询是由简单查询包装，简单查询可作为复合查询的子句，如bool查询示例。简单查询又分为full-text和exact，match相关的为full-text查询，查询的是经分析后的字段，term相关为确切查询为完整字段。\n\n### 简单查询\n\n简单查询为针对某一特定field为某一特定value进行查询，如match, term, range。\n\n#### match_all\n\n查询所有\n\n```\n \"query\": {\n        \"match_all\": {}\n    }\n```\n\n#### match\n\n- match布尔查询\n\n会将value拿出来加以分析，然后构建相应的查询。分析器默认为创建索引时相同的分析器。\n\n```\n\t// 查询message字段有\"this\" or \"is\" or \"a\" or \"test\"\n\t\"query\": {\n        \"match\" : {\n            \"message\" : \"this is a test\"\n        }\n    }\n```\n\n如上例，分析后将产生4个text， 类似为多条件，使用operator可设置多条件的连接纽带，or/and，默认是or。minimum\\_should\\_match参数为设置满足条件最小数。analyzer参数设置分析器。另外，还支持相关fuzziness模糊查询，以及高频词/低频词查询，这个跟书上的差不多(3.3.5)。\n\n- match_phrase\n\n跟match布尔查询类似，不同的是，从分析后的文本中构建短语查询。\n\n```\n//查询this test之间允许有2个词条的短语。则亦能匹配到\"this is a test\"\n\"query\": {\n        \"match_phrase\" : {\n            \"message\" : {\n                \"query\": \"this test\",\n                \"slop\":2\n            }\n        }\n    }\n```\n\n- match\\_phrase\\_prefix\n\n在match\\_phrase的基础上增加了允许查询文本的最后一个词条只做前缀匹配。\n\n```\n  \"query\": {\n        \"match_phrase_prefix\" : {\n            \"message\" : \"this is a t\"\n        }\n    }\n```\n\n- multi match query\n\n与match查询一样，区别在于可以在多个field中进行查询（查询内容还是一个）。\n\n```\n\t\"query\": {\n\t    \"multi_match\" : {\n\t      \"query\":    \"this is a test\",\n\t      \"fields\": [ \"subject\", \"message\" ]\n\t    }\n\t  }\n```\n\n- common terms query\n\n常用词查询，即将分析过后的词分为高频词和低频词进行查询...\n\n- query string query\n\n支持Lucene查询语法。\n\n- simple query string query\n\n跟上面的query string query差不多，不同的是错误时不会抛出异常，直接丢弃查询无效的部分。\n\n#### term\n\nterm查询的话，就是确切的，未经分析的词条。\n\n- term query\n\n```\n//匹配title字段中含有crime一词的文档\n \"query\": {\n    \"term\" : { \"title\" : \"crime\" }\n  }\n```\n\n- terms query\n\n多词条查询。\n\n```\n\"query\": {\n     \"terms\" : {\n        \"user\" : [\"kimchy\", \"elasticsearch\"]\n        }\n    }\n```\n\n#### range query\n\n范围查询\n\n```\n//查询age在10到20岁之前的文档\n \"query\": {\n        \"range\" : {\n            \"age\" : {\n                \"gte\" : 10,\n                \"lte\" : 20\n            }\n        }\n    }\n    //gte : Greater-than or equal to\n    //gt :  Greater-than\n    //lte : Less-than or equal to\n\t//lt : Less-than\n```\n\n#### exist query\n\n会滤掉给定字段上没有值的文档,即返回的文档再给定字段上一定有值。\n\n```\n \"query\": {\n        \"exists\" : { \"field\" : \"user\" }\n    }\n```\n\n#### prefix query\n\n前缀查询\n\n```\n\t//查询user以ki开头的文档\n\t{ \"query\": {\n\t    \"prefix\" : { \"user\" : \"ki\" }\n\t  }\n\t}\n```\n\n#### Wildcard query\n\n通配符查询，*，?.\n\n```\n \"query\": {\n        \"wildcard\" : { \"user\" : \"ki*y\" }\n    }\n```\n\n#### regexp query\n\n正则匹配\n\n#### type query\n\n```\n \"query\": {\n        \"type\" : {\n            \"value\" : \"my_type\"\n        }\n    }\n```\n\n#### ids query\n\n```\n        \"ids\" : {\n            \"type\" : \"my_type\",\n            \"values\" : [\"1\", \"4\", \"100\"]\n        }\n```\n\n#### constant score query\n\n为查询/过滤返回的文档返回一个常量得分。\n\n### 复合查询\n\n由简单查询包装或组合查询，来进行多个查询的逻辑组合，如bool。\n\n- bool query\n\n```\n// 查询user包含kimchy的， tag包含tech的，age在10到20之外的， 条件tag中有wow和elasticsearch至少有1个条件满足\n \"query\": {\n    \"bool\" : {\n      \"must\" : {\n        \"term\" : { \"user\" : \"kimchy\" }\n      },\n      \"filter\": {\n        \"term\" : { \"tag\" : \"tech\" }\n      },\n      \"must_not\" : {\n        \"range\" : {\n          \"age\" : { \"gte\" : 10, \"lte\" : 20 }\n        }\n      },\n      \"should\" : [\n        { \"term\" : { \"tag\" : \"wow\" } },\n        { \"term\" : { \"tag\" : \"elasticsearch\" } }\n      ],\n      \"minimum_should_match\" : 1,\n    }\n  }\n```\n\n- dis max query\n\n最大分查询\n\n- function_score\n\n> The function_score allows you to modify the score of documents that are retrieved by a query.\n\n- boosting\n\n> The boosting query can be used to effectively demote results that match a given query.\n\n- indices query\n\n索引查询\n\n```\n \"query\": {\n        \"indices\" : {\n            \"indices\" : [\"index1\", \"index2\"],\n            \"query\" : { \"term\" : { \"tag\" : \"wow\" } },\n            \"no_match_query\" : { \"term\" : { \"tag\" : \"kow\" } }\n        }\n    }\n```\n\n#### script query\n\n```\n\"query\": {\n        \"bool\" : {\n            \"must\" : {\n                \"script\" : {\n                    \"script\" : {\n                        \"inline\" : \"doc['num1'].value > params.param1\",\n                        \"lang\"   : \"painless\",\n                        \"params\" : {\n                            \"param1\" : 5\n                        }\n                    }\n                }\n            }\n        }\n    }\n```\n\n#### 结构化\n\n```\n{\n    QUERY_NAME: {\n        ARGUMENT: VALUE,\n        ARGUMENT: VALUE\n    }\n}\n\n```\n\n特定field时\n\n```\n{\n    QUERY_NAME: {\n        FIELD_NAME: {\n            ARGUMENT: VALUE,\n            ARGUMENT: VALUE,...\n        }\n    }\n}\n\n```\n\n复合query时 包上简单结构的。如bool里包match和range\n\n```\n{\n    \"bool\": {\n        \"must\":     { \"match\": { \"tweet\": \"elasticsearch\" }},\n        \"must_not\": { \"match\": { \"name\":  \"mary\" }},\n        \"should\":   { \"match\": { \"tweet\": \"full text\" }},\n        \"filter\":   { \"range\": { \"age\" : { \"gt\" : 30 }} }\n    }\n}\n\n```\n\nbool + bool\n\n```\n{\n    \"bool\": {\n        \"must\": { \"match\":   { \"email\": \"business opportunity\" }},\n        \"should\": [\n            { \"match\":       { \"starred\": true }},\n            { \"bool\": {\n                \"must\":      { \"match\": { \"folder\": \"inbox\" }},\n                \"must_not\":  { \"match\": { \"spam\": true }}\n            }}\n        ],\n        \"minimum_should_match\": 1\n    }\n}\n\n```\n\ncurl -XGET 'localhost:9200/storm*/_analyze?field=message_infos.event.specificType' -d 'FRESH_AIR_VOLUME_LESS'\n","source":"_posts/elastic-search-dsl.md","raw":"---\ntitle: elastic-search-dsl\ndate: 2017-10-14 13:52:37\ncategories:\n- elk\n---\n\n\n## 查询ElasticSearch\n\n基于书 ElasticSearch服务器开发(第二版) 和官网doc(5.5)做的相应整理。\n\n粗略总结下，查询语句分为简单查询和复合查询，复合查询是由简单查询包装，简单查询可作为复合查询的子句，如bool查询示例。简单查询又分为full-text和exact，match相关的为full-text查询，查询的是经分析后的字段，term相关为确切查询为完整字段。\n\n### 简单查询\n\n简单查询为针对某一特定field为某一特定value进行查询，如match, term, range。\n\n#### match_all\n\n查询所有\n\n```\n \"query\": {\n        \"match_all\": {}\n    }\n```\n\n#### match\n\n- match布尔查询\n\n会将value拿出来加以分析，然后构建相应的查询。分析器默认为创建索引时相同的分析器。\n\n```\n\t// 查询message字段有\"this\" or \"is\" or \"a\" or \"test\"\n\t\"query\": {\n        \"match\" : {\n            \"message\" : \"this is a test\"\n        }\n    }\n```\n\n如上例，分析后将产生4个text， 类似为多条件，使用operator可设置多条件的连接纽带，or/and，默认是or。minimum\\_should\\_match参数为设置满足条件最小数。analyzer参数设置分析器。另外，还支持相关fuzziness模糊查询，以及高频词/低频词查询，这个跟书上的差不多(3.3.5)。\n\n- match_phrase\n\n跟match布尔查询类似，不同的是，从分析后的文本中构建短语查询。\n\n```\n//查询this test之间允许有2个词条的短语。则亦能匹配到\"this is a test\"\n\"query\": {\n        \"match_phrase\" : {\n            \"message\" : {\n                \"query\": \"this test\",\n                \"slop\":2\n            }\n        }\n    }\n```\n\n- match\\_phrase\\_prefix\n\n在match\\_phrase的基础上增加了允许查询文本的最后一个词条只做前缀匹配。\n\n```\n  \"query\": {\n        \"match_phrase_prefix\" : {\n            \"message\" : \"this is a t\"\n        }\n    }\n```\n\n- multi match query\n\n与match查询一样，区别在于可以在多个field中进行查询（查询内容还是一个）。\n\n```\n\t\"query\": {\n\t    \"multi_match\" : {\n\t      \"query\":    \"this is a test\",\n\t      \"fields\": [ \"subject\", \"message\" ]\n\t    }\n\t  }\n```\n\n- common terms query\n\n常用词查询，即将分析过后的词分为高频词和低频词进行查询...\n\n- query string query\n\n支持Lucene查询语法。\n\n- simple query string query\n\n跟上面的query string query差不多，不同的是错误时不会抛出异常，直接丢弃查询无效的部分。\n\n#### term\n\nterm查询的话，就是确切的，未经分析的词条。\n\n- term query\n\n```\n//匹配title字段中含有crime一词的文档\n \"query\": {\n    \"term\" : { \"title\" : \"crime\" }\n  }\n```\n\n- terms query\n\n多词条查询。\n\n```\n\"query\": {\n     \"terms\" : {\n        \"user\" : [\"kimchy\", \"elasticsearch\"]\n        }\n    }\n```\n\n#### range query\n\n范围查询\n\n```\n//查询age在10到20岁之前的文档\n \"query\": {\n        \"range\" : {\n            \"age\" : {\n                \"gte\" : 10,\n                \"lte\" : 20\n            }\n        }\n    }\n    //gte : Greater-than or equal to\n    //gt :  Greater-than\n    //lte : Less-than or equal to\n\t//lt : Less-than\n```\n\n#### exist query\n\n会滤掉给定字段上没有值的文档,即返回的文档再给定字段上一定有值。\n\n```\n \"query\": {\n        \"exists\" : { \"field\" : \"user\" }\n    }\n```\n\n#### prefix query\n\n前缀查询\n\n```\n\t//查询user以ki开头的文档\n\t{ \"query\": {\n\t    \"prefix\" : { \"user\" : \"ki\" }\n\t  }\n\t}\n```\n\n#### Wildcard query\n\n通配符查询，*，?.\n\n```\n \"query\": {\n        \"wildcard\" : { \"user\" : \"ki*y\" }\n    }\n```\n\n#### regexp query\n\n正则匹配\n\n#### type query\n\n```\n \"query\": {\n        \"type\" : {\n            \"value\" : \"my_type\"\n        }\n    }\n```\n\n#### ids query\n\n```\n        \"ids\" : {\n            \"type\" : \"my_type\",\n            \"values\" : [\"1\", \"4\", \"100\"]\n        }\n```\n\n#### constant score query\n\n为查询/过滤返回的文档返回一个常量得分。\n\n### 复合查询\n\n由简单查询包装或组合查询，来进行多个查询的逻辑组合，如bool。\n\n- bool query\n\n```\n// 查询user包含kimchy的， tag包含tech的，age在10到20之外的， 条件tag中有wow和elasticsearch至少有1个条件满足\n \"query\": {\n    \"bool\" : {\n      \"must\" : {\n        \"term\" : { \"user\" : \"kimchy\" }\n      },\n      \"filter\": {\n        \"term\" : { \"tag\" : \"tech\" }\n      },\n      \"must_not\" : {\n        \"range\" : {\n          \"age\" : { \"gte\" : 10, \"lte\" : 20 }\n        }\n      },\n      \"should\" : [\n        { \"term\" : { \"tag\" : \"wow\" } },\n        { \"term\" : { \"tag\" : \"elasticsearch\" } }\n      ],\n      \"minimum_should_match\" : 1,\n    }\n  }\n```\n\n- dis max query\n\n最大分查询\n\n- function_score\n\n> The function_score allows you to modify the score of documents that are retrieved by a query.\n\n- boosting\n\n> The boosting query can be used to effectively demote results that match a given query.\n\n- indices query\n\n索引查询\n\n```\n \"query\": {\n        \"indices\" : {\n            \"indices\" : [\"index1\", \"index2\"],\n            \"query\" : { \"term\" : { \"tag\" : \"wow\" } },\n            \"no_match_query\" : { \"term\" : { \"tag\" : \"kow\" } }\n        }\n    }\n```\n\n#### script query\n\n```\n\"query\": {\n        \"bool\" : {\n            \"must\" : {\n                \"script\" : {\n                    \"script\" : {\n                        \"inline\" : \"doc['num1'].value > params.param1\",\n                        \"lang\"   : \"painless\",\n                        \"params\" : {\n                            \"param1\" : 5\n                        }\n                    }\n                }\n            }\n        }\n    }\n```\n\n#### 结构化\n\n```\n{\n    QUERY_NAME: {\n        ARGUMENT: VALUE,\n        ARGUMENT: VALUE\n    }\n}\n\n```\n\n特定field时\n\n```\n{\n    QUERY_NAME: {\n        FIELD_NAME: {\n            ARGUMENT: VALUE,\n            ARGUMENT: VALUE,...\n        }\n    }\n}\n\n```\n\n复合query时 包上简单结构的。如bool里包match和range\n\n```\n{\n    \"bool\": {\n        \"must\":     { \"match\": { \"tweet\": \"elasticsearch\" }},\n        \"must_not\": { \"match\": { \"name\":  \"mary\" }},\n        \"should\":   { \"match\": { \"tweet\": \"full text\" }},\n        \"filter\":   { \"range\": { \"age\" : { \"gt\" : 30 }} }\n    }\n}\n\n```\n\nbool + bool\n\n```\n{\n    \"bool\": {\n        \"must\": { \"match\":   { \"email\": \"business opportunity\" }},\n        \"should\": [\n            { \"match\":       { \"starred\": true }},\n            { \"bool\": {\n                \"must\":      { \"match\": { \"folder\": \"inbox\" }},\n                \"must_not\":  { \"match\": { \"spam\": true }}\n            }}\n        ],\n        \"minimum_should_match\": 1\n    }\n}\n\n```\n\ncurl -XGET 'localhost:9200/storm*/_analyze?field=message_infos.event.specificType' -d 'FRESH_AIR_VOLUME_LESS'\n","slug":"elastic-search-dsl","published":1,"updated":"2019-10-14T06:21:32.299Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69ta000ft6xvjpqm06lj","content":"<h2 id=\"查询ElasticSearch\"><a href=\"#查询ElasticSearch\" class=\"headerlink\" title=\"查询ElasticSearch\"></a>查询ElasticSearch</h2><p>基于书 ElasticSearch服务器开发(第二版) 和官网doc(5.5)做的相应整理。</p>\n<p>粗略总结下，查询语句分为简单查询和复合查询，复合查询是由简单查询包装，简单查询可作为复合查询的子句，如bool查询示例。简单查询又分为full-text和exact，match相关的为full-text查询，查询的是经分析后的字段，term相关为确切查询为完整字段。</p>\n<h3 id=\"简单查询\"><a href=\"#简单查询\" class=\"headerlink\" title=\"简单查询\"></a>简单查询</h3><p>简单查询为针对某一特定field为某一特定value进行查询，如match, term, range。</p>\n<h4 id=\"match-all\"><a href=\"#match-all\" class=\"headerlink\" title=\"match_all\"></a>match_all</h4><p>查询所有</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;match_all&quot;: &#123;&#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"match\"><a href=\"#match\" class=\"headerlink\" title=\"match\"></a>match</h4><ul>\n<li>match布尔查询</li>\n</ul>\n<p>会将value拿出来加以分析，然后构建相应的查询。分析器默认为创建索引时相同的分析器。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 查询message字段有&quot;this&quot; or &quot;is&quot; or &quot;a&quot; or &quot;test&quot;</span><br><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;match&quot; : &#123;</span><br><span class=\"line\">           &quot;message&quot; : &quot;this is a test&quot;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<p>如上例，分析后将产生4个text， 类似为多条件，使用operator可设置多条件的连接纽带，or/and，默认是or。minimum_should_match参数为设置满足条件最小数。analyzer参数设置分析器。另外，还支持相关fuzziness模糊查询，以及高频词/低频词查询，这个跟书上的差不多(3.3.5)。</p>\n<ul>\n<li>match_phrase</li>\n</ul>\n<p>跟match布尔查询类似，不同的是，从分析后的文本中构建短语查询。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询this test之间允许有2个词条的短语。则亦能匹配到&quot;this is a test&quot;</span><br><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">        &quot;match_phrase&quot; : &#123;</span><br><span class=\"line\">            &quot;message&quot; : &#123;</span><br><span class=\"line\">                &quot;query&quot;: &quot;this test&quot;,</span><br><span class=\"line\">                &quot;slop&quot;:2</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>match_phrase_prefix</li>\n</ul>\n<p>在match_phrase的基础上增加了允许查询文本的最后一个词条只做前缀匹配。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">      &quot;match_phrase_prefix&quot; : &#123;</span><br><span class=\"line\">          &quot;message&quot; : &quot;this is a t&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>multi match query</li>\n</ul>\n<p>与match查询一样，区别在于可以在多个field中进行查询（查询内容还是一个）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;multi_match&quot; : &#123;</span><br><span class=\"line\">      &quot;query&quot;:    &quot;this is a test&quot;,</span><br><span class=\"line\">      &quot;fields&quot;: [ &quot;subject&quot;, &quot;message&quot; ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>common terms query</li>\n</ul>\n<p>常用词查询，即将分析过后的词分为高频词和低频词进行查询…</p>\n<ul>\n<li>query string query</li>\n</ul>\n<p>支持Lucene查询语法。</p>\n<ul>\n<li>simple query string query</li>\n</ul>\n<p>跟上面的query string query差不多，不同的是错误时不会抛出异常，直接丢弃查询无效的部分。</p>\n<h4 id=\"term\"><a href=\"#term\" class=\"headerlink\" title=\"term\"></a>term</h4><p>term查询的话，就是确切的，未经分析的词条。</p>\n<ul>\n<li>term query</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//匹配title字段中含有crime一词的文档</span><br><span class=\"line\"> &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;term&quot; : &#123; &quot;title&quot; : &quot;crime&quot; &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>terms query</li>\n</ul>\n<p>多词条查询。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">     &quot;terms&quot; : &#123;</span><br><span class=\"line\">        &quot;user&quot; : [&quot;kimchy&quot;, &quot;elasticsearch&quot;]</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"range-query\"><a href=\"#range-query\" class=\"headerlink\" title=\"range query\"></a>range query</h4><p>范围查询</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询age在10到20岁之前的文档</span><br><span class=\"line\"> &quot;query&quot;: &#123;</span><br><span class=\"line\">        &quot;range&quot; : &#123;</span><br><span class=\"line\">            &quot;age&quot; : &#123;</span><br><span class=\"line\">                &quot;gte&quot; : 10,</span><br><span class=\"line\">                &quot;lte&quot; : 20</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //gte : Greater-than or equal to</span><br><span class=\"line\">    //gt :  Greater-than</span><br><span class=\"line\">    //lte : Less-than or equal to</span><br><span class=\"line\">\t//lt : Less-than</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"exist-query\"><a href=\"#exist-query\" class=\"headerlink\" title=\"exist query\"></a>exist query</h4><p>会滤掉给定字段上没有值的文档,即返回的文档再给定字段上一定有值。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;exists&quot; : &#123; &quot;field&quot; : &quot;user&quot; &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"prefix-query\"><a href=\"#prefix-query\" class=\"headerlink\" title=\"prefix query\"></a>prefix query</h4><p>前缀查询</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询user以ki开头的文档</span><br><span class=\"line\">&#123; &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;prefix&quot; : &#123; &quot;user&quot; : &quot;ki&quot; &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Wildcard-query\"><a href=\"#Wildcard-query\" class=\"headerlink\" title=\"Wildcard query\"></a>Wildcard query</h4><p>通配符查询，*，?.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;wildcard&quot; : &#123; &quot;user&quot; : &quot;ki*y&quot; &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"regexp-query\"><a href=\"#regexp-query\" class=\"headerlink\" title=\"regexp query\"></a>regexp query</h4><p>正则匹配</p>\n<h4 id=\"type-query\"><a href=\"#type-query\" class=\"headerlink\" title=\"type query\"></a>type query</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;type&quot; : &#123;</span><br><span class=\"line\">           &quot;value&quot; : &quot;my_type&quot;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"ids-query\"><a href=\"#ids-query\" class=\"headerlink\" title=\"ids query\"></a>ids query</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;ids&quot; : &#123;</span><br><span class=\"line\">    &quot;type&quot; : &quot;my_type&quot;,</span><br><span class=\"line\">    &quot;values&quot; : [&quot;1&quot;, &quot;4&quot;, &quot;100&quot;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"constant-score-query\"><a href=\"#constant-score-query\" class=\"headerlink\" title=\"constant score query\"></a>constant score query</h4><p>为查询/过滤返回的文档返回一个常量得分。</p>\n<h3 id=\"复合查询\"><a href=\"#复合查询\" class=\"headerlink\" title=\"复合查询\"></a>复合查询</h3><p>由简单查询包装或组合查询，来进行多个查询的逻辑组合，如bool。</p>\n<ul>\n<li>bool query</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 查询user包含kimchy的， tag包含tech的，age在10到20之外的， 条件tag中有wow和elasticsearch至少有1个条件满足</span><br><span class=\"line\"> &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;bool&quot; : &#123;</span><br><span class=\"line\">      &quot;must&quot; : &#123;</span><br><span class=\"line\">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;filter&quot;: &#123;</span><br><span class=\"line\">        &quot;term&quot; : &#123; &quot;tag&quot; : &quot;tech&quot; &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;must_not&quot; : &#123;</span><br><span class=\"line\">        &quot;range&quot; : &#123;</span><br><span class=\"line\">          &quot;age&quot; : &#123; &quot;gte&quot; : 10, &quot;lte&quot; : 20 &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;should&quot; : [</span><br><span class=\"line\">        &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;wow&quot; &#125; &#125;,</span><br><span class=\"line\">        &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;elasticsearch&quot; &#125; &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      &quot;minimum_should_match&quot; : 1,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>dis max query</li>\n</ul>\n<p>最大分查询</p>\n<ul>\n<li>function_score</li>\n</ul>\n<blockquote>\n<p>The function_score allows you to modify the score of documents that are retrieved by a query.</p>\n</blockquote>\n<ul>\n<li>boosting</li>\n</ul>\n<blockquote>\n<p>The boosting query can be used to effectively demote results that match a given query.</p>\n</blockquote>\n<ul>\n<li>indices query</li>\n</ul>\n<p>索引查询</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;indices&quot; : &#123;</span><br><span class=\"line\">           &quot;indices&quot; : [&quot;index1&quot;, &quot;index2&quot;],</span><br><span class=\"line\">           &quot;query&quot; : &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;wow&quot; &#125; &#125;,</span><br><span class=\"line\">           &quot;no_match_query&quot; : &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;kow&quot; &#125; &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"script-query\"><a href=\"#script-query\" class=\"headerlink\" title=\"script query\"></a>script query</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">        &quot;bool&quot; : &#123;</span><br><span class=\"line\">            &quot;must&quot; : &#123;</span><br><span class=\"line\">                &quot;script&quot; : &#123;</span><br><span class=\"line\">                    &quot;script&quot; : &#123;</span><br><span class=\"line\">                        &quot;inline&quot; : &quot;doc[&apos;num1&apos;].value &gt; params.param1&quot;,</span><br><span class=\"line\">                        &quot;lang&quot;   : &quot;painless&quot;,</span><br><span class=\"line\">                        &quot;params&quot; : &#123;</span><br><span class=\"line\">                            &quot;param1&quot; : 5</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"结构化\"><a href=\"#结构化\" class=\"headerlink\" title=\"结构化\"></a>结构化</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    QUERY_NAME: &#123;</span><br><span class=\"line\">        ARGUMENT: VALUE,</span><br><span class=\"line\">        ARGUMENT: VALUE</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>特定field时</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    QUERY_NAME: &#123;</span><br><span class=\"line\">        FIELD_NAME: &#123;</span><br><span class=\"line\">            ARGUMENT: VALUE,</span><br><span class=\"line\">            ARGUMENT: VALUE,...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>复合query时 包上简单结构的。如bool里包match和range</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;bool&quot;: &#123;</span><br><span class=\"line\">        &quot;must&quot;:     &#123; &quot;match&quot;: &#123; &quot;tweet&quot;: &quot;elasticsearch&quot; &#125;&#125;,</span><br><span class=\"line\">        &quot;must_not&quot;: &#123; &quot;match&quot;: &#123; &quot;name&quot;:  &quot;mary&quot; &#125;&#125;,</span><br><span class=\"line\">        &quot;should&quot;:   &#123; &quot;match&quot;: &#123; &quot;tweet&quot;: &quot;full text&quot; &#125;&#125;,</span><br><span class=\"line\">        &quot;filter&quot;:   &#123; &quot;range&quot;: &#123; &quot;age&quot; : &#123; &quot;gt&quot; : 30 &#125;&#125; &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>bool + bool</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;bool&quot;: &#123;</span><br><span class=\"line\">        &quot;must&quot;: &#123; &quot;match&quot;:   &#123; &quot;email&quot;: &quot;business opportunity&quot; &#125;&#125;,</span><br><span class=\"line\">        &quot;should&quot;: [</span><br><span class=\"line\">            &#123; &quot;match&quot;:       &#123; &quot;starred&quot;: true &#125;&#125;,</span><br><span class=\"line\">            &#123; &quot;bool&quot;: &#123;</span><br><span class=\"line\">                &quot;must&quot;:      &#123; &quot;match&quot;: &#123; &quot;folder&quot;: &quot;inbox&quot; &#125;&#125;,</span><br><span class=\"line\">                &quot;must_not&quot;:  &#123; &quot;match&quot;: &#123; &quot;spam&quot;: true &#125;&#125;</span><br><span class=\"line\">            &#125;&#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;minimum_should_match&quot;: 1</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>curl -XGET ‘localhost:9200/storm*/_analyze?field=message_infos.event.specificType’ -d ‘FRESH_AIR_VOLUME_LESS’</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"查询ElasticSearch\"><a href=\"#查询ElasticSearch\" class=\"headerlink\" title=\"查询ElasticSearch\"></a>查询ElasticSearch</h2><p>基于书 ElasticSearch服务器开发(第二版) 和官网doc(5.5)做的相应整理。</p>\n<p>粗略总结下，查询语句分为简单查询和复合查询，复合查询是由简单查询包装，简单查询可作为复合查询的子句，如bool查询示例。简单查询又分为full-text和exact，match相关的为full-text查询，查询的是经分析后的字段，term相关为确切查询为完整字段。</p>\n<h3 id=\"简单查询\"><a href=\"#简单查询\" class=\"headerlink\" title=\"简单查询\"></a>简单查询</h3><p>简单查询为针对某一特定field为某一特定value进行查询，如match, term, range。</p>\n<h4 id=\"match-all\"><a href=\"#match-all\" class=\"headerlink\" title=\"match_all\"></a>match_all</h4><p>查询所有</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;match_all&quot;: &#123;&#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"match\"><a href=\"#match\" class=\"headerlink\" title=\"match\"></a>match</h4><ul>\n<li>match布尔查询</li>\n</ul>\n<p>会将value拿出来加以分析，然后构建相应的查询。分析器默认为创建索引时相同的分析器。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 查询message字段有&quot;this&quot; or &quot;is&quot; or &quot;a&quot; or &quot;test&quot;</span><br><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;match&quot; : &#123;</span><br><span class=\"line\">           &quot;message&quot; : &quot;this is a test&quot;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<p>如上例，分析后将产生4个text， 类似为多条件，使用operator可设置多条件的连接纽带，or/and，默认是or。minimum_should_match参数为设置满足条件最小数。analyzer参数设置分析器。另外，还支持相关fuzziness模糊查询，以及高频词/低频词查询，这个跟书上的差不多(3.3.5)。</p>\n<ul>\n<li>match_phrase</li>\n</ul>\n<p>跟match布尔查询类似，不同的是，从分析后的文本中构建短语查询。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询this test之间允许有2个词条的短语。则亦能匹配到&quot;this is a test&quot;</span><br><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">        &quot;match_phrase&quot; : &#123;</span><br><span class=\"line\">            &quot;message&quot; : &#123;</span><br><span class=\"line\">                &quot;query&quot;: &quot;this test&quot;,</span><br><span class=\"line\">                &quot;slop&quot;:2</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>match_phrase_prefix</li>\n</ul>\n<p>在match_phrase的基础上增加了允许查询文本的最后一个词条只做前缀匹配。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">      &quot;match_phrase_prefix&quot; : &#123;</span><br><span class=\"line\">          &quot;message&quot; : &quot;this is a t&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>multi match query</li>\n</ul>\n<p>与match查询一样，区别在于可以在多个field中进行查询（查询内容还是一个）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;multi_match&quot; : &#123;</span><br><span class=\"line\">      &quot;query&quot;:    &quot;this is a test&quot;,</span><br><span class=\"line\">      &quot;fields&quot;: [ &quot;subject&quot;, &quot;message&quot; ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>common terms query</li>\n</ul>\n<p>常用词查询，即将分析过后的词分为高频词和低频词进行查询…</p>\n<ul>\n<li>query string query</li>\n</ul>\n<p>支持Lucene查询语法。</p>\n<ul>\n<li>simple query string query</li>\n</ul>\n<p>跟上面的query string query差不多，不同的是错误时不会抛出异常，直接丢弃查询无效的部分。</p>\n<h4 id=\"term\"><a href=\"#term\" class=\"headerlink\" title=\"term\"></a>term</h4><p>term查询的话，就是确切的，未经分析的词条。</p>\n<ul>\n<li>term query</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//匹配title字段中含有crime一词的文档</span><br><span class=\"line\"> &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;term&quot; : &#123; &quot;title&quot; : &quot;crime&quot; &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>terms query</li>\n</ul>\n<p>多词条查询。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">     &quot;terms&quot; : &#123;</span><br><span class=\"line\">        &quot;user&quot; : [&quot;kimchy&quot;, &quot;elasticsearch&quot;]</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"range-query\"><a href=\"#range-query\" class=\"headerlink\" title=\"range query\"></a>range query</h4><p>范围查询</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询age在10到20岁之前的文档</span><br><span class=\"line\"> &quot;query&quot;: &#123;</span><br><span class=\"line\">        &quot;range&quot; : &#123;</span><br><span class=\"line\">            &quot;age&quot; : &#123;</span><br><span class=\"line\">                &quot;gte&quot; : 10,</span><br><span class=\"line\">                &quot;lte&quot; : 20</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //gte : Greater-than or equal to</span><br><span class=\"line\">    //gt :  Greater-than</span><br><span class=\"line\">    //lte : Less-than or equal to</span><br><span class=\"line\">\t//lt : Less-than</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"exist-query\"><a href=\"#exist-query\" class=\"headerlink\" title=\"exist query\"></a>exist query</h4><p>会滤掉给定字段上没有值的文档,即返回的文档再给定字段上一定有值。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;exists&quot; : &#123; &quot;field&quot; : &quot;user&quot; &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"prefix-query\"><a href=\"#prefix-query\" class=\"headerlink\" title=\"prefix query\"></a>prefix query</h4><p>前缀查询</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询user以ki开头的文档</span><br><span class=\"line\">&#123; &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;prefix&quot; : &#123; &quot;user&quot; : &quot;ki&quot; &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Wildcard-query\"><a href=\"#Wildcard-query\" class=\"headerlink\" title=\"Wildcard query\"></a>Wildcard query</h4><p>通配符查询，*，?.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;wildcard&quot; : &#123; &quot;user&quot; : &quot;ki*y&quot; &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"regexp-query\"><a href=\"#regexp-query\" class=\"headerlink\" title=\"regexp query\"></a>regexp query</h4><p>正则匹配</p>\n<h4 id=\"type-query\"><a href=\"#type-query\" class=\"headerlink\" title=\"type query\"></a>type query</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;type&quot; : &#123;</span><br><span class=\"line\">           &quot;value&quot; : &quot;my_type&quot;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"ids-query\"><a href=\"#ids-query\" class=\"headerlink\" title=\"ids query\"></a>ids query</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;ids&quot; : &#123;</span><br><span class=\"line\">    &quot;type&quot; : &quot;my_type&quot;,</span><br><span class=\"line\">    &quot;values&quot; : [&quot;1&quot;, &quot;4&quot;, &quot;100&quot;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"constant-score-query\"><a href=\"#constant-score-query\" class=\"headerlink\" title=\"constant score query\"></a>constant score query</h4><p>为查询/过滤返回的文档返回一个常量得分。</p>\n<h3 id=\"复合查询\"><a href=\"#复合查询\" class=\"headerlink\" title=\"复合查询\"></a>复合查询</h3><p>由简单查询包装或组合查询，来进行多个查询的逻辑组合，如bool。</p>\n<ul>\n<li>bool query</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 查询user包含kimchy的， tag包含tech的，age在10到20之外的， 条件tag中有wow和elasticsearch至少有1个条件满足</span><br><span class=\"line\"> &quot;query&quot;: &#123;</span><br><span class=\"line\">    &quot;bool&quot; : &#123;</span><br><span class=\"line\">      &quot;must&quot; : &#123;</span><br><span class=\"line\">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;filter&quot;: &#123;</span><br><span class=\"line\">        &quot;term&quot; : &#123; &quot;tag&quot; : &quot;tech&quot; &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;must_not&quot; : &#123;</span><br><span class=\"line\">        &quot;range&quot; : &#123;</span><br><span class=\"line\">          &quot;age&quot; : &#123; &quot;gte&quot; : 10, &quot;lte&quot; : 20 &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;should&quot; : [</span><br><span class=\"line\">        &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;wow&quot; &#125; &#125;,</span><br><span class=\"line\">        &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;elasticsearch&quot; &#125; &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      &quot;minimum_should_match&quot; : 1,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>dis max query</li>\n</ul>\n<p>最大分查询</p>\n<ul>\n<li>function_score</li>\n</ul>\n<blockquote>\n<p>The function_score allows you to modify the score of documents that are retrieved by a query.</p>\n</blockquote>\n<ul>\n<li>boosting</li>\n</ul>\n<blockquote>\n<p>The boosting query can be used to effectively demote results that match a given query.</p>\n</blockquote>\n<ul>\n<li>indices query</li>\n</ul>\n<p>索引查询</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">       &quot;indices&quot; : &#123;</span><br><span class=\"line\">           &quot;indices&quot; : [&quot;index1&quot;, &quot;index2&quot;],</span><br><span class=\"line\">           &quot;query&quot; : &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;wow&quot; &#125; &#125;,</span><br><span class=\"line\">           &quot;no_match_query&quot; : &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;kow&quot; &#125; &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"script-query\"><a href=\"#script-query\" class=\"headerlink\" title=\"script query\"></a>script query</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;query&quot;: &#123;</span><br><span class=\"line\">        &quot;bool&quot; : &#123;</span><br><span class=\"line\">            &quot;must&quot; : &#123;</span><br><span class=\"line\">                &quot;script&quot; : &#123;</span><br><span class=\"line\">                    &quot;script&quot; : &#123;</span><br><span class=\"line\">                        &quot;inline&quot; : &quot;doc[&apos;num1&apos;].value &gt; params.param1&quot;,</span><br><span class=\"line\">                        &quot;lang&quot;   : &quot;painless&quot;,</span><br><span class=\"line\">                        &quot;params&quot; : &#123;</span><br><span class=\"line\">                            &quot;param1&quot; : 5</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"结构化\"><a href=\"#结构化\" class=\"headerlink\" title=\"结构化\"></a>结构化</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    QUERY_NAME: &#123;</span><br><span class=\"line\">        ARGUMENT: VALUE,</span><br><span class=\"line\">        ARGUMENT: VALUE</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>特定field时</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    QUERY_NAME: &#123;</span><br><span class=\"line\">        FIELD_NAME: &#123;</span><br><span class=\"line\">            ARGUMENT: VALUE,</span><br><span class=\"line\">            ARGUMENT: VALUE,...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>复合query时 包上简单结构的。如bool里包match和range</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;bool&quot;: &#123;</span><br><span class=\"line\">        &quot;must&quot;:     &#123; &quot;match&quot;: &#123; &quot;tweet&quot;: &quot;elasticsearch&quot; &#125;&#125;,</span><br><span class=\"line\">        &quot;must_not&quot;: &#123; &quot;match&quot;: &#123; &quot;name&quot;:  &quot;mary&quot; &#125;&#125;,</span><br><span class=\"line\">        &quot;should&quot;:   &#123; &quot;match&quot;: &#123; &quot;tweet&quot;: &quot;full text&quot; &#125;&#125;,</span><br><span class=\"line\">        &quot;filter&quot;:   &#123; &quot;range&quot;: &#123; &quot;age&quot; : &#123; &quot;gt&quot; : 30 &#125;&#125; &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>bool + bool</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;bool&quot;: &#123;</span><br><span class=\"line\">        &quot;must&quot;: &#123; &quot;match&quot;:   &#123; &quot;email&quot;: &quot;business opportunity&quot; &#125;&#125;,</span><br><span class=\"line\">        &quot;should&quot;: [</span><br><span class=\"line\">            &#123; &quot;match&quot;:       &#123; &quot;starred&quot;: true &#125;&#125;,</span><br><span class=\"line\">            &#123; &quot;bool&quot;: &#123;</span><br><span class=\"line\">                &quot;must&quot;:      &#123; &quot;match&quot;: &#123; &quot;folder&quot;: &quot;inbox&quot; &#125;&#125;,</span><br><span class=\"line\">                &quot;must_not&quot;:  &#123; &quot;match&quot;: &#123; &quot;spam&quot;: true &#125;&#125;</span><br><span class=\"line\">            &#125;&#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;minimum_should_match&quot;: 1</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>curl -XGET ‘localhost:9200/storm*/_analyze?field=message_infos.event.specificType’ -d ‘FRESH_AIR_VOLUME_LESS’</p>\n"},{"title":"elastic_template","date":"2017-10-14T05:55:58.000Z","_content":"\n## Template.json\n\n这个文件即定义[Index Templates](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-templates.html)。\n\n> Index templates allow you to define templates that will automatically be applied when new indices are created.\n\n### 结构分析\n\n#### 外层结构：\n\n```\n{\n\t\"template\": \"nginx_elastic_stack_example\",\n\t\"settings\": {}\n\t\"mappings\": {}\n}\n```\n\n- template: 准确说来，应该叫template pattern，为能匹配到模板的index name pattern。如下面的示例\n\n  //The settings and mappings will be applied to any index name that matches the te* pattern.\n  \"template\": \"te*\",\n\n- settings: [可设置项](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html), 常见的设置项如\n\n  \"settings\" : {\n          \"index\" : {\n              \"number_of_shards\" : 3, //定义一个索引的主分片个数，默认值是5, 这个配置在索引创建后不能修改。\n              \"number_of_replicas\" : 2 //每个主分片的复制分片个数，默认是1。这个配置可以随时在活跃的索引上修改。\n\n\n  ```\n      }\n  }\n  ```\n\n     以上书写格式也可写成\n\n  ```\n     \"settings\" : {\n          \"index.number_of_shards\": 3\n      }\n  ```\n\n  另外，主分片个数的意义在于，分片是存储'索引'下文档的容器，分片的个数就决定了存储的大小。\n\n- mappings: 对这个的解释引用一下原文比较恰当。\n\n  > Mapping is the process of defining how a document, and the fields it contains, are stored and indexed.\n\n  ```\n  \"mappings\": {\n  \t\"type1\": {  //定义类型type1\n  \t}\n  }\n  ```\n\n#### Mapping 结构分析\n\n> Each index has one or more mapping types, which are used to divide the documents in an index into logical groups\n\nmapping type包含以下几项：\n\n- [Meta-fields](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html)，来自文档的元数据字段，以下划线开头，包括_index, \\_type, \\_id, _source等..\n- properties，列出文档中可能包含的字段的映射\n- [参数项](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html)，控制如何动态处理新的字段，如dynamic_templates，analyzer等..\n\n其中，Field的数据类型可以为：\n\n- 简单数据类型，例如text，keyword，date，long，double，boolean，ip..其中，keyword和text的区别对应的是index explicit和index full text content。\n- 嵌套的对象或[nested](https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html)\n- 特别的类型，例如[geo_point](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html)，[geo_shape](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-shape.html)， [completion](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters-completion.html)。\n\n\n\n##### Dynamic Mapping\n\n你可以不用定义mapping,fields， 也可以使用es的search，这都归功于的dynamic mapping。dynamic mapping包括\\_default\\_mapping， Dynamic field mappings，Dynamic templates。[先粘官方链接吧](https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html)\n\n- \\_default\\_mapping:\n\n  > The default mapping, which will be used as the base mapping for any new mapping types, can be customised by adding a mapping type with the name \\_default_ to an index，\n\n  如示例\n\n  ```\n  \"mappings\": {\n      \"_default_\": {  \n        \"_all\": {\n          \"enabled\": false\n        }\n      },\n      \"user\": {}, //user继承自_default_\n      \"blogpost\": {  //blogpost继承自_default_并重写了\"_all\"\n        \"_all\": {\n          \"enabled\": true\n        }\n      }\n    }\n  ```\n\n- Dynamic field mappings: 一般说来，当文档中出现之前未见过的field，es会自动添加新field到映射中，这个功能可以通过设置进行disable，在这个功能是enabled的前提下，es添加新field时会转换类型，由json的数据类型转换到es的数据类型，如string-->text或keyword。其中，有的复杂类型的检测，可以自定义检测格式，例如自定义date的数据格式。官方有[示例](https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-field-mapping.html)。\n\n- [Dynamic templates](https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html#dynamic-templates): 这个重在使用，故直接贴上了链接，官方有示例使用说明。上文提到es自动添加新field到映射中，dynamic templates为定义一些添加模板，既然是模板，就要定义匹配模板的东西..例如match\\_mapping\\_type为指定数据类型，以及通过field name进行全匹配或正则匹配或全虚拟路径匹配(如a.b.*)，然后再加上mapping决定添加的新的field的特性。\n\n### 参数字段分析\n\n待完善补全.. 暂且列出现过的..\n\n#### Mapping\n\n- fields: 适用于当一个字段有多种类型，如当搜索时，希望它是一个text，当排序或者聚合时，希望它是一个keyword。\n\n  \"city\": {\n            \"type\": \"text\",\n            \"fields\": {\n              \"raw\": {\n                \"type\":  \"keyword\"\n              }\n            }\n          }\n\n\n  ```\n  //用于搜索时使用city,排序或聚合时使用city.raw,\n   \"aggs\": {\n      \"Cities\": {\n        \"terms\": {\n          \"field\": \"city.raw\"\n        }\n      }\n    }\n  ```\n\n- norms: 耗内存，如果不关心score，就置为false，尤其是字段仅仅用于filter或aggregation\n\n> Norms store various normalization factors that are later used at query time in order to compute the score of a document relatively to a query.\n\n- index: 决定field的value的index方式，值为analyzed(default, treat as full-text field), not_analyzed (treat as keyword field), no。\n- ignore\\_above: Strings longer than the ignore_above setting will not be indexed or stored.\n- \\_all: 将所有values的内容以空格进行存储，即\\_all的内容大概为[\"..\", \"..\"],可进行分析和索引，但不能存储。\n- dynamic：控制新字段是否被动态添加，所谓新字段，是较之前消息组成的字段而言。\n","source":"_posts/elastic-template.md","raw":"---\ntitle: elastic_template\ndate: 2017-10-14 13:55:58\ncategories:\n- elk\n---\n\n## Template.json\n\n这个文件即定义[Index Templates](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-templates.html)。\n\n> Index templates allow you to define templates that will automatically be applied when new indices are created.\n\n### 结构分析\n\n#### 外层结构：\n\n```\n{\n\t\"template\": \"nginx_elastic_stack_example\",\n\t\"settings\": {}\n\t\"mappings\": {}\n}\n```\n\n- template: 准确说来，应该叫template pattern，为能匹配到模板的index name pattern。如下面的示例\n\n  //The settings and mappings will be applied to any index name that matches the te* pattern.\n  \"template\": \"te*\",\n\n- settings: [可设置项](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html), 常见的设置项如\n\n  \"settings\" : {\n          \"index\" : {\n              \"number_of_shards\" : 3, //定义一个索引的主分片个数，默认值是5, 这个配置在索引创建后不能修改。\n              \"number_of_replicas\" : 2 //每个主分片的复制分片个数，默认是1。这个配置可以随时在活跃的索引上修改。\n\n\n  ```\n      }\n  }\n  ```\n\n     以上书写格式也可写成\n\n  ```\n     \"settings\" : {\n          \"index.number_of_shards\": 3\n      }\n  ```\n\n  另外，主分片个数的意义在于，分片是存储'索引'下文档的容器，分片的个数就决定了存储的大小。\n\n- mappings: 对这个的解释引用一下原文比较恰当。\n\n  > Mapping is the process of defining how a document, and the fields it contains, are stored and indexed.\n\n  ```\n  \"mappings\": {\n  \t\"type1\": {  //定义类型type1\n  \t}\n  }\n  ```\n\n#### Mapping 结构分析\n\n> Each index has one or more mapping types, which are used to divide the documents in an index into logical groups\n\nmapping type包含以下几项：\n\n- [Meta-fields](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html)，来自文档的元数据字段，以下划线开头，包括_index, \\_type, \\_id, _source等..\n- properties，列出文档中可能包含的字段的映射\n- [参数项](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html)，控制如何动态处理新的字段，如dynamic_templates，analyzer等..\n\n其中，Field的数据类型可以为：\n\n- 简单数据类型，例如text，keyword，date，long，double，boolean，ip..其中，keyword和text的区别对应的是index explicit和index full text content。\n- 嵌套的对象或[nested](https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html)\n- 特别的类型，例如[geo_point](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html)，[geo_shape](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-shape.html)， [completion](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters-completion.html)。\n\n\n\n##### Dynamic Mapping\n\n你可以不用定义mapping,fields， 也可以使用es的search，这都归功于的dynamic mapping。dynamic mapping包括\\_default\\_mapping， Dynamic field mappings，Dynamic templates。[先粘官方链接吧](https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html)\n\n- \\_default\\_mapping:\n\n  > The default mapping, which will be used as the base mapping for any new mapping types, can be customised by adding a mapping type with the name \\_default_ to an index，\n\n  如示例\n\n  ```\n  \"mappings\": {\n      \"_default_\": {  \n        \"_all\": {\n          \"enabled\": false\n        }\n      },\n      \"user\": {}, //user继承自_default_\n      \"blogpost\": {  //blogpost继承自_default_并重写了\"_all\"\n        \"_all\": {\n          \"enabled\": true\n        }\n      }\n    }\n  ```\n\n- Dynamic field mappings: 一般说来，当文档中出现之前未见过的field，es会自动添加新field到映射中，这个功能可以通过设置进行disable，在这个功能是enabled的前提下，es添加新field时会转换类型，由json的数据类型转换到es的数据类型，如string-->text或keyword。其中，有的复杂类型的检测，可以自定义检测格式，例如自定义date的数据格式。官方有[示例](https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-field-mapping.html)。\n\n- [Dynamic templates](https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html#dynamic-templates): 这个重在使用，故直接贴上了链接，官方有示例使用说明。上文提到es自动添加新field到映射中，dynamic templates为定义一些添加模板，既然是模板，就要定义匹配模板的东西..例如match\\_mapping\\_type为指定数据类型，以及通过field name进行全匹配或正则匹配或全虚拟路径匹配(如a.b.*)，然后再加上mapping决定添加的新的field的特性。\n\n### 参数字段分析\n\n待完善补全.. 暂且列出现过的..\n\n#### Mapping\n\n- fields: 适用于当一个字段有多种类型，如当搜索时，希望它是一个text，当排序或者聚合时，希望它是一个keyword。\n\n  \"city\": {\n            \"type\": \"text\",\n            \"fields\": {\n              \"raw\": {\n                \"type\":  \"keyword\"\n              }\n            }\n          }\n\n\n  ```\n  //用于搜索时使用city,排序或聚合时使用city.raw,\n   \"aggs\": {\n      \"Cities\": {\n        \"terms\": {\n          \"field\": \"city.raw\"\n        }\n      }\n    }\n  ```\n\n- norms: 耗内存，如果不关心score，就置为false，尤其是字段仅仅用于filter或aggregation\n\n> Norms store various normalization factors that are later used at query time in order to compute the score of a document relatively to a query.\n\n- index: 决定field的value的index方式，值为analyzed(default, treat as full-text field), not_analyzed (treat as keyword field), no。\n- ignore\\_above: Strings longer than the ignore_above setting will not be indexed or stored.\n- \\_all: 将所有values的内容以空格进行存储，即\\_all的内容大概为[\"..\", \"..\"],可进行分析和索引，但不能存储。\n- dynamic：控制新字段是否被动态添加，所谓新字段，是较之前消息组成的字段而言。\n","slug":"elastic-template","published":1,"updated":"2019-10-15T02:00:58.965Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69td000it6xvndl9kj9z","content":"<h2 id=\"Template-json\"><a href=\"#Template-json\" class=\"headerlink\" title=\"Template.json\"></a>Template.json</h2><p>这个文件即定义<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-templates.html\" target=\"_blank\" rel=\"noopener\">Index Templates</a>。</p>\n<blockquote>\n<p>Index templates allow you to define templates that will automatically be applied when new indices are created.</p>\n</blockquote>\n<h3 id=\"结构分析\"><a href=\"#结构分析\" class=\"headerlink\" title=\"结构分析\"></a>结构分析</h3><h4 id=\"外层结构：\"><a href=\"#外层结构：\" class=\"headerlink\" title=\"外层结构：\"></a>外层结构：</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">\t&quot;template&quot;: &quot;nginx_elastic_stack_example&quot;,</span><br><span class=\"line\">\t&quot;settings&quot;: &#123;&#125;</span><br><span class=\"line\">\t&quot;mappings&quot;: &#123;&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>template: 准确说来，应该叫template pattern，为能匹配到模板的index name pattern。如下面的示例</p>\n<p>//The settings and mappings will be applied to any index name that matches the te* pattern.<br>“template”: “te*”,</p>\n</li>\n<li><p>settings: <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html\" target=\"_blank\" rel=\"noopener\">可设置项</a>, 常见的设置项如</p>\n<p>“settings” : {</p>\n<pre><code>&quot;index&quot; : {\n    &quot;number_of_shards&quot; : 3, //定义一个索引的主分片个数，默认值是5, 这个配置在索引创建后不能修改。\n    &quot;number_of_replicas&quot; : 2 //每个主分片的复制分片个数，默认是1。这个配置可以随时在活跃的索引上修改。</code></pre></li>\n</ul>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<pre><code>以上书写格式也可写成</code></pre>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;settings&quot; : &#123;</span><br><span class=\"line\">     &quot;index.number_of_shards&quot;: 3</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n\n<p>  另外，主分片个数的意义在于，分片是存储’索引’下文档的容器，分片的个数就决定了存储的大小。</p>\n<ul>\n<li><p>mappings: 对这个的解释引用一下原文比较恰当。</p>\n<blockquote>\n<p>Mapping is the process of defining how a document, and the fields it contains, are stored and indexed.</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;mappings&quot;: &#123;</span><br><span class=\"line\">\t&quot;type1&quot;: &#123;  //定义类型type1</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h4 id=\"Mapping-结构分析\"><a href=\"#Mapping-结构分析\" class=\"headerlink\" title=\"Mapping 结构分析\"></a>Mapping 结构分析</h4><blockquote>\n<p>Each index has one or more mapping types, which are used to divide the documents in an index into logical groups</p>\n</blockquote>\n<p>mapping type包含以下几项：</p>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html\" target=\"_blank\" rel=\"noopener\">Meta-fields</a>，来自文档的元数据字段，以下划线开头，包括_index, _type, _id, _source等..</li>\n<li>properties，列出文档中可能包含的字段的映射</li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html\" target=\"_blank\" rel=\"noopener\">参数项</a>，控制如何动态处理新的字段，如dynamic_templates，analyzer等..</li>\n</ul>\n<p>其中，Field的数据类型可以为：</p>\n<ul>\n<li>简单数据类型，例如text，keyword，date，long，double，boolean，ip..其中，keyword和text的区别对应的是index explicit和index full text content。</li>\n<li>嵌套的对象或<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html\" target=\"_blank\" rel=\"noopener\">nested</a></li>\n<li>特别的类型，例如<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html\" target=\"_blank\" rel=\"noopener\">geo_point</a>，<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-shape.html\" target=\"_blank\" rel=\"noopener\">geo_shape</a>， <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters-completion.html\" target=\"_blank\" rel=\"noopener\">completion</a>。</li>\n</ul>\n<h5 id=\"Dynamic-Mapping\"><a href=\"#Dynamic-Mapping\" class=\"headerlink\" title=\"Dynamic Mapping\"></a>Dynamic Mapping</h5><p>你可以不用定义mapping,fields， 也可以使用es的search，这都归功于的dynamic mapping。dynamic mapping包括_default_mapping， Dynamic field mappings，Dynamic templates。<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html\" target=\"_blank\" rel=\"noopener\">先粘官方链接吧</a></p>\n<ul>\n<li><p>_default_mapping:</p>\n<blockquote>\n<p>The default mapping, which will be used as the base mapping for any new mapping types, can be customised by adding a mapping type with the name _default_ to an index，</p>\n</blockquote>\n<p>如示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;mappings&quot;: &#123;</span><br><span class=\"line\">    &quot;_default_&quot;: &#123;  </span><br><span class=\"line\">      &quot;_all&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user&quot;: &#123;&#125;, //user继承自_default_</span><br><span class=\"line\">    &quot;blogpost&quot;: &#123;  //blogpost继承自_default_并重写了&quot;_all&quot;</span><br><span class=\"line\">      &quot;_all&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: true</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Dynamic field mappings: 一般说来，当文档中出现之前未见过的field，es会自动添加新field到映射中，这个功能可以通过设置进行disable，在这个功能是enabled的前提下，es添加新field时会转换类型，由json的数据类型转换到es的数据类型，如string–&gt;text或keyword。其中，有的复杂类型的检测，可以自定义检测格式，例如自定义date的数据格式。官方有<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-field-mapping.html\" target=\"_blank\" rel=\"noopener\">示例</a>。</p>\n</li>\n<li><p><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html#dynamic-templates\" target=\"_blank\" rel=\"noopener\">Dynamic templates</a>: 这个重在使用，故直接贴上了链接，官方有示例使用说明。上文提到es自动添加新field到映射中，dynamic templates为定义一些添加模板，既然是模板，就要定义匹配模板的东西..例如match_mapping_type为指定数据类型，以及通过field name进行全匹配或正则匹配或全虚拟路径匹配(如a.b.*)，然后再加上mapping决定添加的新的field的特性。</p>\n</li>\n</ul>\n<h3 id=\"参数字段分析\"><a href=\"#参数字段分析\" class=\"headerlink\" title=\"参数字段分析\"></a>参数字段分析</h3><p>待完善补全.. 暂且列出现过的..</p>\n<h4 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h4><ul>\n<li><p>fields: 适用于当一个字段有多种类型，如当搜索时，希望它是一个text，当排序或者聚合时，希望它是一个keyword。</p>\n<p>“city”: {</p>\n<pre><code>  &quot;type&quot;: &quot;text&quot;,\n  &quot;fields&quot;: {\n    &quot;raw&quot;: {\n      &quot;type&quot;:  &quot;keyword&quot;\n    }\n  }\n}</code></pre></li>\n</ul>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//用于搜索时使用city,排序或聚合时使用city.raw,</span><br><span class=\"line\"> &quot;aggs&quot;: &#123;</span><br><span class=\"line\">    &quot;Cities&quot;: &#123;</span><br><span class=\"line\">      &quot;terms&quot;: &#123;</span><br><span class=\"line\">        &quot;field&quot;: &quot;city.raw&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>norms: 耗内存，如果不关心score，就置为false，尤其是字段仅仅用于filter或aggregation</li>\n</ul>\n<blockquote>\n<p>Norms store various normalization factors that are later used at query time in order to compute the score of a document relatively to a query.</p>\n</blockquote>\n<ul>\n<li>index: 决定field的value的index方式，值为analyzed(default, treat as full-text field), not_analyzed (treat as keyword field), no。</li>\n<li>ignore_above: Strings longer than the ignore_above setting will not be indexed or stored.</li>\n<li>_all: 将所有values的内容以空格进行存储，即_all的内容大概为[“..”, “..”],可进行分析和索引，但不能存储。</li>\n<li>dynamic：控制新字段是否被动态添加，所谓新字段，是较之前消息组成的字段而言。</li>\n</ul>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Template-json\"><a href=\"#Template-json\" class=\"headerlink\" title=\"Template.json\"></a>Template.json</h2><p>这个文件即定义<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-templates.html\" target=\"_blank\" rel=\"noopener\">Index Templates</a>。</p>\n<blockquote>\n<p>Index templates allow you to define templates that will automatically be applied when new indices are created.</p>\n</blockquote>\n<h3 id=\"结构分析\"><a href=\"#结构分析\" class=\"headerlink\" title=\"结构分析\"></a>结构分析</h3><h4 id=\"外层结构：\"><a href=\"#外层结构：\" class=\"headerlink\" title=\"外层结构：\"></a>外层结构：</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">\t&quot;template&quot;: &quot;nginx_elastic_stack_example&quot;,</span><br><span class=\"line\">\t&quot;settings&quot;: &#123;&#125;</span><br><span class=\"line\">\t&quot;mappings&quot;: &#123;&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>template: 准确说来，应该叫template pattern，为能匹配到模板的index name pattern。如下面的示例</p>\n<p>//The settings and mappings will be applied to any index name that matches the te* pattern.<br>“template”: “te*”,</p>\n</li>\n<li><p>settings: <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html\" target=\"_blank\" rel=\"noopener\">可设置项</a>, 常见的设置项如</p>\n<p>“settings” : {</p>\n<pre><code>&quot;index&quot; : {\n    &quot;number_of_shards&quot; : 3, //定义一个索引的主分片个数，默认值是5, 这个配置在索引创建后不能修改。\n    &quot;number_of_replicas&quot; : 2 //每个主分片的复制分片个数，默认是1。这个配置可以随时在活跃的索引上修改。</code></pre></li>\n</ul>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<pre><code>以上书写格式也可写成</code></pre>  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;settings&quot; : &#123;</span><br><span class=\"line\">     &quot;index.number_of_shards&quot;: 3</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n\n<p>  另外，主分片个数的意义在于，分片是存储’索引’下文档的容器，分片的个数就决定了存储的大小。</p>\n<ul>\n<li><p>mappings: 对这个的解释引用一下原文比较恰当。</p>\n<blockquote>\n<p>Mapping is the process of defining how a document, and the fields it contains, are stored and indexed.</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;mappings&quot;: &#123;</span><br><span class=\"line\">\t&quot;type1&quot;: &#123;  //定义类型type1</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h4 id=\"Mapping-结构分析\"><a href=\"#Mapping-结构分析\" class=\"headerlink\" title=\"Mapping 结构分析\"></a>Mapping 结构分析</h4><blockquote>\n<p>Each index has one or more mapping types, which are used to divide the documents in an index into logical groups</p>\n</blockquote>\n<p>mapping type包含以下几项：</p>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html\" target=\"_blank\" rel=\"noopener\">Meta-fields</a>，来自文档的元数据字段，以下划线开头，包括_index, _type, _id, _source等..</li>\n<li>properties，列出文档中可能包含的字段的映射</li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html\" target=\"_blank\" rel=\"noopener\">参数项</a>，控制如何动态处理新的字段，如dynamic_templates，analyzer等..</li>\n</ul>\n<p>其中，Field的数据类型可以为：</p>\n<ul>\n<li>简单数据类型，例如text，keyword，date，long，double，boolean，ip..其中，keyword和text的区别对应的是index explicit和index full text content。</li>\n<li>嵌套的对象或<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html\" target=\"_blank\" rel=\"noopener\">nested</a></li>\n<li>特别的类型，例如<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html\" target=\"_blank\" rel=\"noopener\">geo_point</a>，<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-shape.html\" target=\"_blank\" rel=\"noopener\">geo_shape</a>， <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters-completion.html\" target=\"_blank\" rel=\"noopener\">completion</a>。</li>\n</ul>\n<h5 id=\"Dynamic-Mapping\"><a href=\"#Dynamic-Mapping\" class=\"headerlink\" title=\"Dynamic Mapping\"></a>Dynamic Mapping</h5><p>你可以不用定义mapping,fields， 也可以使用es的search，这都归功于的dynamic mapping。dynamic mapping包括_default_mapping， Dynamic field mappings，Dynamic templates。<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html\" target=\"_blank\" rel=\"noopener\">先粘官方链接吧</a></p>\n<ul>\n<li><p>_default_mapping:</p>\n<blockquote>\n<p>The default mapping, which will be used as the base mapping for any new mapping types, can be customised by adding a mapping type with the name _default_ to an index，</p>\n</blockquote>\n<p>如示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;mappings&quot;: &#123;</span><br><span class=\"line\">    &quot;_default_&quot;: &#123;  </span><br><span class=\"line\">      &quot;_all&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: false</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;user&quot;: &#123;&#125;, //user继承自_default_</span><br><span class=\"line\">    &quot;blogpost&quot;: &#123;  //blogpost继承自_default_并重写了&quot;_all&quot;</span><br><span class=\"line\">      &quot;_all&quot;: &#123;</span><br><span class=\"line\">        &quot;enabled&quot;: true</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Dynamic field mappings: 一般说来，当文档中出现之前未见过的field，es会自动添加新field到映射中，这个功能可以通过设置进行disable，在这个功能是enabled的前提下，es添加新field时会转换类型，由json的数据类型转换到es的数据类型，如string–&gt;text或keyword。其中，有的复杂类型的检测，可以自定义检测格式，例如自定义date的数据格式。官方有<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-field-mapping.html\" target=\"_blank\" rel=\"noopener\">示例</a>。</p>\n</li>\n<li><p><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html#dynamic-templates\" target=\"_blank\" rel=\"noopener\">Dynamic templates</a>: 这个重在使用，故直接贴上了链接，官方有示例使用说明。上文提到es自动添加新field到映射中，dynamic templates为定义一些添加模板，既然是模板，就要定义匹配模板的东西..例如match_mapping_type为指定数据类型，以及通过field name进行全匹配或正则匹配或全虚拟路径匹配(如a.b.*)，然后再加上mapping决定添加的新的field的特性。</p>\n</li>\n</ul>\n<h3 id=\"参数字段分析\"><a href=\"#参数字段分析\" class=\"headerlink\" title=\"参数字段分析\"></a>参数字段分析</h3><p>待完善补全.. 暂且列出现过的..</p>\n<h4 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h4><ul>\n<li><p>fields: 适用于当一个字段有多种类型，如当搜索时，希望它是一个text，当排序或者聚合时，希望它是一个keyword。</p>\n<p>“city”: {</p>\n<pre><code>  &quot;type&quot;: &quot;text&quot;,\n  &quot;fields&quot;: {\n    &quot;raw&quot;: {\n      &quot;type&quot;:  &quot;keyword&quot;\n    }\n  }\n}</code></pre></li>\n</ul>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//用于搜索时使用city,排序或聚合时使用city.raw,</span><br><span class=\"line\"> &quot;aggs&quot;: &#123;</span><br><span class=\"line\">    &quot;Cities&quot;: &#123;</span><br><span class=\"line\">      &quot;terms&quot;: &#123;</span><br><span class=\"line\">        &quot;field&quot;: &quot;city.raw&quot;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>norms: 耗内存，如果不关心score，就置为false，尤其是字段仅仅用于filter或aggregation</li>\n</ul>\n<blockquote>\n<p>Norms store various normalization factors that are later used at query time in order to compute the score of a document relatively to a query.</p>\n</blockquote>\n<ul>\n<li>index: 决定field的value的index方式，值为analyzed(default, treat as full-text field), not_analyzed (treat as keyword field), no。</li>\n<li>ignore_above: Strings longer than the ignore_above setting will not be indexed or stored.</li>\n<li>_all: 将所有values的内容以空格进行存储，即_all的内容大概为[“..”, “..”],可进行分析和索引，但不能存储。</li>\n<li>dynamic：控制新字段是否被动态添加，所谓新字段，是较之前消息组成的字段而言。</li>\n</ul>\n"},{"title":"elastic","date":"2017-10-14T05:59:47.000Z","_content":"\n## Elasticsearch - v5.6\n\nElasticsearch使用Lucene进行索引和搜索。Lucene，全文检索功能库。\n\n### 基本概念\n\n- Cluster,集群\n\n- Node,节点\n\n  节点跟集群的确定关系是通过集群的名字cluster.name\n\n- Index,索引\n\n- Type,类型\n\n- Document,文档\n\n- Shards/Replicas 分片/副本\n\n  ⭐️ 分片优势,水平扩容和提高性能和吞吐(分布式+并行)。    \n  ⭐️ 副本优势，提供高可用性(集群情况下分片和对应的副本决不会在同一个节点上)，扩展搜索量和吞吐。    \n  ⭐️ 副本的数量在索引建立后可以调整，但分片数量则不能再修改。\n\n### 常用概念\n\n- 查询，过滤\n\n  查询和过滤，查询的意思是有多匹配，返回结果包含相关度得分，过滤为匹配否，则不会计算相关度得分\n\n- analyze\n\n  Lucene的目标是提供一个全文检索的功能库，对字段文本的词会进行分析，建立索引时，Lucene会使用你选择的分析器来处理你的文档内容，查询时，查询的字段同样会被同个分析器进行分析。当然，也可以选择不分析。\n\n- mapping\n\n  映射定义的过程是一个文档,和它所包含的字段,存储和索引，字段功能上来说，是输入数据到真正存储结构的映射处理，包括字段分析器选择，字段类型等。\n\n### 常用curl\n\n- 集群相关\n\n  ```\n  //查询集群状态\n  curl -XGET 'localhost:9200/_cat/health?v&pretty'\n\n  //获取节点\n  curl -XGET 'localhost:9200/_cat/nodes?v&pretty'\n  ```\n\n- 索引相关\n\n  ```\n  //获得所有索引\n  curl -XGET 'localhost:9200/_cat/indices?v&pretty'\n  //创建索引\n  curl -XPUT 'localhost:9200/customer?pretty&pretty'\n  //删除索引\n  curl -XDELETE 'localhost:9200/customer?pretty&pretty'\n  //添加索引文件，当指定了id的时候使用PUT(/customer/external/2)，没指定使用POST\n  curl -XPOST 'localhost:9200/customer/external?pretty&pretty' -H 'Content-Type: application/json' -d'\n  {\n    \"name\": \"Jane Doe\"\n  }'\n\n  ```\n\n\n\n- 查询相关\n\n  ```\n  //使用_search\n  curl -XGET 'localhost:9200/bank/_search?pretty' -H 'Content-Type: application/json' -d'\n  {\n  \"query\": { \"match_all\": {} }\n  }\n  '\n  ```\n\n  关于查询和过滤相关的api在隔壁搜索dsl中有详细介绍。\n\n- analyze 相关\n\n  ```\n  //使用索引某字段的分析器分析，可用于查看字段在底层具体结构 uri只能是索引/_analyze,字段加上type\n  GET /test/_analyze?pretty\n  {\n    \"field\": \"analyze.my_text\",\n    \"text\":  \"John Smith\"\n  }\n  ```\n\n### 索引管理操作\n\n- 关闭/打开索引。\n\n```\n \tPOST /storm_2017-10-31/_close\n \tcurl -XPOST 'localhost:9200/storm_2017-10-31/_close'\n \tcurl -XPOST 'localhost:9200/storm_2017-10-31/_open'\n```\n\n- 删除索引。\n\n```\n \tDELETE /index_name\n \tcurl -XDELETE 'localhost:9200/index_name?pretty&pretty'\n\n```\n\n- 修改索引副本数, 可以将一些不重要而且比较老的数据设置副本数为0以节省磁盘空间\n\n```\n \tcurl -XPUT 'localhost:9200/<index_name>/_settings' -d '{\"number_of_replicas\": 0}'\n\n```\n\n\n\n#### 一个相对比较完全查询示例\n\n```\n\t{\n  \"query\":{\n    \"bool\":{\n      \"must\":{\"match_all\":{}},\n      \"filter\":[\n        {\"term\":{\"op\": 25677}},\n        {\"term\":{\"parsed\":true}},\n        {\"term\": {\"device_addr\": 53784}},\n        {\"term\": {\"cmd.data.index\": 0}},\n        {\"range\":{\n          \"@timestamp\":{\n            \"from\":\"2017-12-14T07:00:53.000+00:00\",\n            \"to\":\"2017-12-14T10:41:53.000+00:00\"\n            }}\n        }\n      ]\n    }\n  },\n  \"script_fields\": {\n    \"gm_data_0\": {\n      \"script\": \"if(doc['op'].value == 25677 && params['_source']['cmd']['data'] != null) { for(def item : params['_source']['cmd']['data']) { if(item.index == 0)  return item.data_value;  }} return null;\"\n    }\n  },\n  \"size\":50,\n  \"from\":0,\n  \"sort\":{\"@timestamp\":\"desc\"},\n  \"timeout\":\"51s\"\n}\n```\n\n### 案例\n\n#### 某一索引为yellow原因及修复方法\n\n[原文连接](https://www.datadoghq.com/blog/elasticsearch-unassigned-shards/)\n\n- 查看某一副本分片未分配的原因\n\n```\ncurl -XGET localhost:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason| grep UNASSIGNED\n```\n\n- 查看节点磁盘占用比例\n\n```\ncurl -s 'localhost:9200/_cat/allocation?v'\n```\n\n- 设置当磁盘占用率达到多少时不再分配分片\n\n```\n    curl -XPUT 'localhost:9200/_cluster/settings' -d\n                      '{\n                               \"transient\": {\n                                 \"cluster.routing.allocation.disk.watermark.low\": \"90%\"\n                                    }\n                           }'\n```\n\n- 内存分配问题\n\nES为运行在jvm上的java进程,很有可能报OOM,或者查看gc日志时发现回收达到了瓶颈，解决方法是加内存，但给ES加内存是指增加堆内存，但堆内存的分配最好小于机器总内存的一半，并且小于32G。ES使用的大内存除了堆内存外，Lucene使用时会占据文件缓存，故堆内存越大，可用的缓存空间就越小，磁盘换读的频率就越高。堆内存的分配还是小于总内存的一半，给文件缓存留点内存比较合适。\n\n在查询时，Lucene会将索引部分加载到内存中，这意味着，查询的数据量决定了内存的使用，所以当天数增加，数据量增大的情况下，很容易出现OOM。\n\n当GC出现瓶颈时，会出现ES无法响应的情况，Kibana也会出现对应提示(Status Red)。\n\n使用中发现Kibana出现Status Red，首先查询集群状态，看节点是否工作正常，其次查看各节点日志，查看问题。\n\n另外,swapping的情况对于性能来说是致命的，当内存资源不足时，Linux会将某些内容转移到swapping(硬盘)上，要使用这部分内容的时候，需要先搞到内存中，再使用。所以ES中，最好禁用swapping。\n","source":"_posts/elastic.md","raw":"---\ntitle: elastic\ndate: 2017-10-14 13:59:47\ncategories:\n- elk\n---\n\n## Elasticsearch - v5.6\n\nElasticsearch使用Lucene进行索引和搜索。Lucene，全文检索功能库。\n\n### 基本概念\n\n- Cluster,集群\n\n- Node,节点\n\n  节点跟集群的确定关系是通过集群的名字cluster.name\n\n- Index,索引\n\n- Type,类型\n\n- Document,文档\n\n- Shards/Replicas 分片/副本\n\n  ⭐️ 分片优势,水平扩容和提高性能和吞吐(分布式+并行)。    \n  ⭐️ 副本优势，提供高可用性(集群情况下分片和对应的副本决不会在同一个节点上)，扩展搜索量和吞吐。    \n  ⭐️ 副本的数量在索引建立后可以调整，但分片数量则不能再修改。\n\n### 常用概念\n\n- 查询，过滤\n\n  查询和过滤，查询的意思是有多匹配，返回结果包含相关度得分，过滤为匹配否，则不会计算相关度得分\n\n- analyze\n\n  Lucene的目标是提供一个全文检索的功能库，对字段文本的词会进行分析，建立索引时，Lucene会使用你选择的分析器来处理你的文档内容，查询时，查询的字段同样会被同个分析器进行分析。当然，也可以选择不分析。\n\n- mapping\n\n  映射定义的过程是一个文档,和它所包含的字段,存储和索引，字段功能上来说，是输入数据到真正存储结构的映射处理，包括字段分析器选择，字段类型等。\n\n### 常用curl\n\n- 集群相关\n\n  ```\n  //查询集群状态\n  curl -XGET 'localhost:9200/_cat/health?v&pretty'\n\n  //获取节点\n  curl -XGET 'localhost:9200/_cat/nodes?v&pretty'\n  ```\n\n- 索引相关\n\n  ```\n  //获得所有索引\n  curl -XGET 'localhost:9200/_cat/indices?v&pretty'\n  //创建索引\n  curl -XPUT 'localhost:9200/customer?pretty&pretty'\n  //删除索引\n  curl -XDELETE 'localhost:9200/customer?pretty&pretty'\n  //添加索引文件，当指定了id的时候使用PUT(/customer/external/2)，没指定使用POST\n  curl -XPOST 'localhost:9200/customer/external?pretty&pretty' -H 'Content-Type: application/json' -d'\n  {\n    \"name\": \"Jane Doe\"\n  }'\n\n  ```\n\n\n\n- 查询相关\n\n  ```\n  //使用_search\n  curl -XGET 'localhost:9200/bank/_search?pretty' -H 'Content-Type: application/json' -d'\n  {\n  \"query\": { \"match_all\": {} }\n  }\n  '\n  ```\n\n  关于查询和过滤相关的api在隔壁搜索dsl中有详细介绍。\n\n- analyze 相关\n\n  ```\n  //使用索引某字段的分析器分析，可用于查看字段在底层具体结构 uri只能是索引/_analyze,字段加上type\n  GET /test/_analyze?pretty\n  {\n    \"field\": \"analyze.my_text\",\n    \"text\":  \"John Smith\"\n  }\n  ```\n\n### 索引管理操作\n\n- 关闭/打开索引。\n\n```\n \tPOST /storm_2017-10-31/_close\n \tcurl -XPOST 'localhost:9200/storm_2017-10-31/_close'\n \tcurl -XPOST 'localhost:9200/storm_2017-10-31/_open'\n```\n\n- 删除索引。\n\n```\n \tDELETE /index_name\n \tcurl -XDELETE 'localhost:9200/index_name?pretty&pretty'\n\n```\n\n- 修改索引副本数, 可以将一些不重要而且比较老的数据设置副本数为0以节省磁盘空间\n\n```\n \tcurl -XPUT 'localhost:9200/<index_name>/_settings' -d '{\"number_of_replicas\": 0}'\n\n```\n\n\n\n#### 一个相对比较完全查询示例\n\n```\n\t{\n  \"query\":{\n    \"bool\":{\n      \"must\":{\"match_all\":{}},\n      \"filter\":[\n        {\"term\":{\"op\": 25677}},\n        {\"term\":{\"parsed\":true}},\n        {\"term\": {\"device_addr\": 53784}},\n        {\"term\": {\"cmd.data.index\": 0}},\n        {\"range\":{\n          \"@timestamp\":{\n            \"from\":\"2017-12-14T07:00:53.000+00:00\",\n            \"to\":\"2017-12-14T10:41:53.000+00:00\"\n            }}\n        }\n      ]\n    }\n  },\n  \"script_fields\": {\n    \"gm_data_0\": {\n      \"script\": \"if(doc['op'].value == 25677 && params['_source']['cmd']['data'] != null) { for(def item : params['_source']['cmd']['data']) { if(item.index == 0)  return item.data_value;  }} return null;\"\n    }\n  },\n  \"size\":50,\n  \"from\":0,\n  \"sort\":{\"@timestamp\":\"desc\"},\n  \"timeout\":\"51s\"\n}\n```\n\n### 案例\n\n#### 某一索引为yellow原因及修复方法\n\n[原文连接](https://www.datadoghq.com/blog/elasticsearch-unassigned-shards/)\n\n- 查看某一副本分片未分配的原因\n\n```\ncurl -XGET localhost:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason| grep UNASSIGNED\n```\n\n- 查看节点磁盘占用比例\n\n```\ncurl -s 'localhost:9200/_cat/allocation?v'\n```\n\n- 设置当磁盘占用率达到多少时不再分配分片\n\n```\n    curl -XPUT 'localhost:9200/_cluster/settings' -d\n                      '{\n                               \"transient\": {\n                                 \"cluster.routing.allocation.disk.watermark.low\": \"90%\"\n                                    }\n                           }'\n```\n\n- 内存分配问题\n\nES为运行在jvm上的java进程,很有可能报OOM,或者查看gc日志时发现回收达到了瓶颈，解决方法是加内存，但给ES加内存是指增加堆内存，但堆内存的分配最好小于机器总内存的一半，并且小于32G。ES使用的大内存除了堆内存外，Lucene使用时会占据文件缓存，故堆内存越大，可用的缓存空间就越小，磁盘换读的频率就越高。堆内存的分配还是小于总内存的一半，给文件缓存留点内存比较合适。\n\n在查询时，Lucene会将索引部分加载到内存中，这意味着，查询的数据量决定了内存的使用，所以当天数增加，数据量增大的情况下，很容易出现OOM。\n\n当GC出现瓶颈时，会出现ES无法响应的情况，Kibana也会出现对应提示(Status Red)。\n\n使用中发现Kibana出现Status Red，首先查询集群状态，看节点是否工作正常，其次查看各节点日志，查看问题。\n\n另外,swapping的情况对于性能来说是致命的，当内存资源不足时，Linux会将某些内容转移到swapping(硬盘)上，要使用这部分内容的时候，需要先搞到内存中，再使用。所以ES中，最好禁用swapping。\n","slug":"elastic","published":1,"updated":"2019-10-14T06:21:40.972Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69tf000jt6xv8e6xhjer","content":"<h2 id=\"Elasticsearch-v5-6\"><a href=\"#Elasticsearch-v5-6\" class=\"headerlink\" title=\"Elasticsearch - v5.6\"></a>Elasticsearch - v5.6</h2><p>Elasticsearch使用Lucene进行索引和搜索。Lucene，全文检索功能库。</p>\n<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><ul>\n<li><p>Cluster,集群</p>\n</li>\n<li><p>Node,节点</p>\n<p>节点跟集群的确定关系是通过集群的名字cluster.name</p>\n</li>\n<li><p>Index,索引</p>\n</li>\n<li><p>Type,类型</p>\n</li>\n<li><p>Document,文档</p>\n</li>\n<li><p>Shards/Replicas 分片/副本</p>\n<p>⭐️ 分片优势,水平扩容和提高性能和吞吐(分布式+并行)。<br>⭐️ 副本优势，提供高可用性(集群情况下分片和对应的副本决不会在同一个节点上)，扩展搜索量和吞吐。<br>⭐️ 副本的数量在索引建立后可以调整，但分片数量则不能再修改。</p>\n</li>\n</ul>\n<h3 id=\"常用概念\"><a href=\"#常用概念\" class=\"headerlink\" title=\"常用概念\"></a>常用概念</h3><ul>\n<li><p>查询，过滤</p>\n<p>查询和过滤，查询的意思是有多匹配，返回结果包含相关度得分，过滤为匹配否，则不会计算相关度得分</p>\n</li>\n<li><p>analyze</p>\n<p>Lucene的目标是提供一个全文检索的功能库，对字段文本的词会进行分析，建立索引时，Lucene会使用你选择的分析器来处理你的文档内容，查询时，查询的字段同样会被同个分析器进行分析。当然，也可以选择不分析。</p>\n</li>\n<li><p>mapping</p>\n<p>映射定义的过程是一个文档,和它所包含的字段,存储和索引，字段功能上来说，是输入数据到真正存储结构的映射处理，包括字段分析器选择，字段类型等。</p>\n</li>\n</ul>\n<h3 id=\"常用curl\"><a href=\"#常用curl\" class=\"headerlink\" title=\"常用curl\"></a>常用curl</h3><ul>\n<li><p>集群相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询集群状态</span><br><span class=\"line\">curl -XGET &apos;localhost:9200/_cat/health?v&amp;pretty&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">//获取节点</span><br><span class=\"line\">curl -XGET &apos;localhost:9200/_cat/nodes?v&amp;pretty&apos;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>索引相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//获得所有索引</span><br><span class=\"line\">curl -XGET &apos;localhost:9200/_cat/indices?v&amp;pretty&apos;</span><br><span class=\"line\">//创建索引</span><br><span class=\"line\">curl -XPUT &apos;localhost:9200/customer?pretty&amp;pretty&apos;</span><br><span class=\"line\">//删除索引</span><br><span class=\"line\">curl -XDELETE &apos;localhost:9200/customer?pretty&amp;pretty&apos;</span><br><span class=\"line\">//添加索引文件，当指定了id的时候使用PUT(/customer/external/2)，没指定使用POST</span><br><span class=\"line\">curl -XPOST &apos;localhost:9200/customer/external?pretty&amp;pretty&apos; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;name&quot;: &quot;Jane Doe&quot;</span><br><span class=\"line\">&#125;&apos;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查询相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//使用_search</span><br><span class=\"line\">curl -XGET &apos;localhost:9200/bank/_search?pretty&apos; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&apos;</span><br></pre></td></tr></table></figure>\n\n<p>关于查询和过滤相关的api在隔壁搜索dsl中有详细介绍。</p>\n</li>\n<li><p>analyze 相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//使用索引某字段的分析器分析，可用于查看字段在底层具体结构 uri只能是索引/_analyze,字段加上type</span><br><span class=\"line\">GET /test/_analyze?pretty</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;field&quot;: &quot;analyze.my_text&quot;,</span><br><span class=\"line\">  &quot;text&quot;:  &quot;John Smith&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h3 id=\"索引管理操作\"><a href=\"#索引管理操作\" class=\"headerlink\" title=\"索引管理操作\"></a>索引管理操作</h3><ul>\n<li>关闭/打开索引。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">POST /storm_2017-10-31/_close</span><br><span class=\"line\">curl -XPOST &apos;localhost:9200/storm_2017-10-31/_close&apos;</span><br><span class=\"line\">curl -XPOST &apos;localhost:9200/storm_2017-10-31/_open&apos;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>删除索引。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DELETE /index_name</span><br><span class=\"line\">curl -XDELETE &apos;localhost:9200/index_name?pretty&amp;pretty&apos;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>修改索引副本数, 可以将一些不重要而且比较老的数据设置副本数为0以节省磁盘空间</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -XPUT &apos;localhost:9200/&lt;index_name&gt;/_settings&apos; -d &apos;&#123;&quot;number_of_replicas&quot;: 0&#125;&apos;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"一个相对比较完全查询示例\"><a href=\"#一个相对比较完全查询示例\" class=\"headerlink\" title=\"一个相对比较完全查询示例\"></a>一个相对比较完全查询示例</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\t&#123;</span><br><span class=\"line\">  &quot;query&quot;:&#123;</span><br><span class=\"line\">    &quot;bool&quot;:&#123;</span><br><span class=\"line\">      &quot;must&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;,</span><br><span class=\"line\">      &quot;filter&quot;:[</span><br><span class=\"line\">        &#123;&quot;term&quot;:&#123;&quot;op&quot;: 25677&#125;&#125;,</span><br><span class=\"line\">        &#123;&quot;term&quot;:&#123;&quot;parsed&quot;:true&#125;&#125;,</span><br><span class=\"line\">        &#123;&quot;term&quot;: &#123;&quot;device_addr&quot;: 53784&#125;&#125;,</span><br><span class=\"line\">        &#123;&quot;term&quot;: &#123;&quot;cmd.data.index&quot;: 0&#125;&#125;,</span><br><span class=\"line\">        &#123;&quot;range&quot;:&#123;</span><br><span class=\"line\">          &quot;@timestamp&quot;:&#123;</span><br><span class=\"line\">            &quot;from&quot;:&quot;2017-12-14T07:00:53.000+00:00&quot;,</span><br><span class=\"line\">            &quot;to&quot;:&quot;2017-12-14T10:41:53.000+00:00&quot;</span><br><span class=\"line\">            &#125;&#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;script_fields&quot;: &#123;</span><br><span class=\"line\">    &quot;gm_data_0&quot;: &#123;</span><br><span class=\"line\">      &quot;script&quot;: &quot;if(doc[&apos;op&apos;].value == 25677 &amp;&amp; params[&apos;_source&apos;][&apos;cmd&apos;][&apos;data&apos;] != null) &#123; for(def item : params[&apos;_source&apos;][&apos;cmd&apos;][&apos;data&apos;]) &#123; if(item.index == 0)  return item.data_value;  &#125;&#125; return null;&quot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;size&quot;:50,</span><br><span class=\"line\">  &quot;from&quot;:0,</span><br><span class=\"line\">  &quot;sort&quot;:&#123;&quot;@timestamp&quot;:&quot;desc&quot;&#125;,</span><br><span class=\"line\">  &quot;timeout&quot;:&quot;51s&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"案例\"><a href=\"#案例\" class=\"headerlink\" title=\"案例\"></a>案例</h3><h4 id=\"某一索引为yellow原因及修复方法\"><a href=\"#某一索引为yellow原因及修复方法\" class=\"headerlink\" title=\"某一索引为yellow原因及修复方法\"></a>某一索引为yellow原因及修复方法</h4><p><a href=\"https://www.datadoghq.com/blog/elasticsearch-unassigned-shards/\" target=\"_blank\" rel=\"noopener\">原文连接</a></p>\n<ul>\n<li>查看某一副本分片未分配的原因</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -XGET localhost:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason| grep UNASSIGNED</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>查看节点磁盘占用比例</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -s &apos;localhost:9200/_cat/allocation?v&apos;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>设置当磁盘占用率达到多少时不再分配分片</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -XPUT &apos;localhost:9200/_cluster/settings&apos; -d</span><br><span class=\"line\">                  &apos;&#123;</span><br><span class=\"line\">                           &quot;transient&quot;: &#123;</span><br><span class=\"line\">                             &quot;cluster.routing.allocation.disk.watermark.low&quot;: &quot;90%&quot;</span><br><span class=\"line\">                                &#125;</span><br><span class=\"line\">                       &#125;&apos;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>内存分配问题</li>\n</ul>\n<p>ES为运行在jvm上的java进程,很有可能报OOM,或者查看gc日志时发现回收达到了瓶颈，解决方法是加内存，但给ES加内存是指增加堆内存，但堆内存的分配最好小于机器总内存的一半，并且小于32G。ES使用的大内存除了堆内存外，Lucene使用时会占据文件缓存，故堆内存越大，可用的缓存空间就越小，磁盘换读的频率就越高。堆内存的分配还是小于总内存的一半，给文件缓存留点内存比较合适。</p>\n<p>在查询时，Lucene会将索引部分加载到内存中，这意味着，查询的数据量决定了内存的使用，所以当天数增加，数据量增大的情况下，很容易出现OOM。</p>\n<p>当GC出现瓶颈时，会出现ES无法响应的情况，Kibana也会出现对应提示(Status Red)。</p>\n<p>使用中发现Kibana出现Status Red，首先查询集群状态，看节点是否工作正常，其次查看各节点日志，查看问题。</p>\n<p>另外,swapping的情况对于性能来说是致命的，当内存资源不足时，Linux会将某些内容转移到swapping(硬盘)上，要使用这部分内容的时候，需要先搞到内存中，再使用。所以ES中，最好禁用swapping。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Elasticsearch-v5-6\"><a href=\"#Elasticsearch-v5-6\" class=\"headerlink\" title=\"Elasticsearch - v5.6\"></a>Elasticsearch - v5.6</h2><p>Elasticsearch使用Lucene进行索引和搜索。Lucene，全文检索功能库。</p>\n<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><ul>\n<li><p>Cluster,集群</p>\n</li>\n<li><p>Node,节点</p>\n<p>节点跟集群的确定关系是通过集群的名字cluster.name</p>\n</li>\n<li><p>Index,索引</p>\n</li>\n<li><p>Type,类型</p>\n</li>\n<li><p>Document,文档</p>\n</li>\n<li><p>Shards/Replicas 分片/副本</p>\n<p>⭐️ 分片优势,水平扩容和提高性能和吞吐(分布式+并行)。<br>⭐️ 副本优势，提供高可用性(集群情况下分片和对应的副本决不会在同一个节点上)，扩展搜索量和吞吐。<br>⭐️ 副本的数量在索引建立后可以调整，但分片数量则不能再修改。</p>\n</li>\n</ul>\n<h3 id=\"常用概念\"><a href=\"#常用概念\" class=\"headerlink\" title=\"常用概念\"></a>常用概念</h3><ul>\n<li><p>查询，过滤</p>\n<p>查询和过滤，查询的意思是有多匹配，返回结果包含相关度得分，过滤为匹配否，则不会计算相关度得分</p>\n</li>\n<li><p>analyze</p>\n<p>Lucene的目标是提供一个全文检索的功能库，对字段文本的词会进行分析，建立索引时，Lucene会使用你选择的分析器来处理你的文档内容，查询时，查询的字段同样会被同个分析器进行分析。当然，也可以选择不分析。</p>\n</li>\n<li><p>mapping</p>\n<p>映射定义的过程是一个文档,和它所包含的字段,存储和索引，字段功能上来说，是输入数据到真正存储结构的映射处理，包括字段分析器选择，字段类型等。</p>\n</li>\n</ul>\n<h3 id=\"常用curl\"><a href=\"#常用curl\" class=\"headerlink\" title=\"常用curl\"></a>常用curl</h3><ul>\n<li><p>集群相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询集群状态</span><br><span class=\"line\">curl -XGET &apos;localhost:9200/_cat/health?v&amp;pretty&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">//获取节点</span><br><span class=\"line\">curl -XGET &apos;localhost:9200/_cat/nodes?v&amp;pretty&apos;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>索引相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//获得所有索引</span><br><span class=\"line\">curl -XGET &apos;localhost:9200/_cat/indices?v&amp;pretty&apos;</span><br><span class=\"line\">//创建索引</span><br><span class=\"line\">curl -XPUT &apos;localhost:9200/customer?pretty&amp;pretty&apos;</span><br><span class=\"line\">//删除索引</span><br><span class=\"line\">curl -XDELETE &apos;localhost:9200/customer?pretty&amp;pretty&apos;</span><br><span class=\"line\">//添加索引文件，当指定了id的时候使用PUT(/customer/external/2)，没指定使用POST</span><br><span class=\"line\">curl -XPOST &apos;localhost:9200/customer/external?pretty&amp;pretty&apos; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;name&quot;: &quot;Jane Doe&quot;</span><br><span class=\"line\">&#125;&apos;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查询相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//使用_search</span><br><span class=\"line\">curl -XGET &apos;localhost:9200/bank/_search?pretty&apos; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&apos;</span><br></pre></td></tr></table></figure>\n\n<p>关于查询和过滤相关的api在隔壁搜索dsl中有详细介绍。</p>\n</li>\n<li><p>analyze 相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//使用索引某字段的分析器分析，可用于查看字段在底层具体结构 uri只能是索引/_analyze,字段加上type</span><br><span class=\"line\">GET /test/_analyze?pretty</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;field&quot;: &quot;analyze.my_text&quot;,</span><br><span class=\"line\">  &quot;text&quot;:  &quot;John Smith&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h3 id=\"索引管理操作\"><a href=\"#索引管理操作\" class=\"headerlink\" title=\"索引管理操作\"></a>索引管理操作</h3><ul>\n<li>关闭/打开索引。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">POST /storm_2017-10-31/_close</span><br><span class=\"line\">curl -XPOST &apos;localhost:9200/storm_2017-10-31/_close&apos;</span><br><span class=\"line\">curl -XPOST &apos;localhost:9200/storm_2017-10-31/_open&apos;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>删除索引。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DELETE /index_name</span><br><span class=\"line\">curl -XDELETE &apos;localhost:9200/index_name?pretty&amp;pretty&apos;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>修改索引副本数, 可以将一些不重要而且比较老的数据设置副本数为0以节省磁盘空间</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -XPUT &apos;localhost:9200/&lt;index_name&gt;/_settings&apos; -d &apos;&#123;&quot;number_of_replicas&quot;: 0&#125;&apos;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"一个相对比较完全查询示例\"><a href=\"#一个相对比较完全查询示例\" class=\"headerlink\" title=\"一个相对比较完全查询示例\"></a>一个相对比较完全查询示例</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\t&#123;</span><br><span class=\"line\">  &quot;query&quot;:&#123;</span><br><span class=\"line\">    &quot;bool&quot;:&#123;</span><br><span class=\"line\">      &quot;must&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;,</span><br><span class=\"line\">      &quot;filter&quot;:[</span><br><span class=\"line\">        &#123;&quot;term&quot;:&#123;&quot;op&quot;: 25677&#125;&#125;,</span><br><span class=\"line\">        &#123;&quot;term&quot;:&#123;&quot;parsed&quot;:true&#125;&#125;,</span><br><span class=\"line\">        &#123;&quot;term&quot;: &#123;&quot;device_addr&quot;: 53784&#125;&#125;,</span><br><span class=\"line\">        &#123;&quot;term&quot;: &#123;&quot;cmd.data.index&quot;: 0&#125;&#125;,</span><br><span class=\"line\">        &#123;&quot;range&quot;:&#123;</span><br><span class=\"line\">          &quot;@timestamp&quot;:&#123;</span><br><span class=\"line\">            &quot;from&quot;:&quot;2017-12-14T07:00:53.000+00:00&quot;,</span><br><span class=\"line\">            &quot;to&quot;:&quot;2017-12-14T10:41:53.000+00:00&quot;</span><br><span class=\"line\">            &#125;&#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;script_fields&quot;: &#123;</span><br><span class=\"line\">    &quot;gm_data_0&quot;: &#123;</span><br><span class=\"line\">      &quot;script&quot;: &quot;if(doc[&apos;op&apos;].value == 25677 &amp;&amp; params[&apos;_source&apos;][&apos;cmd&apos;][&apos;data&apos;] != null) &#123; for(def item : params[&apos;_source&apos;][&apos;cmd&apos;][&apos;data&apos;]) &#123; if(item.index == 0)  return item.data_value;  &#125;&#125; return null;&quot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;size&quot;:50,</span><br><span class=\"line\">  &quot;from&quot;:0,</span><br><span class=\"line\">  &quot;sort&quot;:&#123;&quot;@timestamp&quot;:&quot;desc&quot;&#125;,</span><br><span class=\"line\">  &quot;timeout&quot;:&quot;51s&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"案例\"><a href=\"#案例\" class=\"headerlink\" title=\"案例\"></a>案例</h3><h4 id=\"某一索引为yellow原因及修复方法\"><a href=\"#某一索引为yellow原因及修复方法\" class=\"headerlink\" title=\"某一索引为yellow原因及修复方法\"></a>某一索引为yellow原因及修复方法</h4><p><a href=\"https://www.datadoghq.com/blog/elasticsearch-unassigned-shards/\" target=\"_blank\" rel=\"noopener\">原文连接</a></p>\n<ul>\n<li>查看某一副本分片未分配的原因</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -XGET localhost:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason| grep UNASSIGNED</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>查看节点磁盘占用比例</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -s &apos;localhost:9200/_cat/allocation?v&apos;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>设置当磁盘占用率达到多少时不再分配分片</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -XPUT &apos;localhost:9200/_cluster/settings&apos; -d</span><br><span class=\"line\">                  &apos;&#123;</span><br><span class=\"line\">                           &quot;transient&quot;: &#123;</span><br><span class=\"line\">                             &quot;cluster.routing.allocation.disk.watermark.low&quot;: &quot;90%&quot;</span><br><span class=\"line\">                                &#125;</span><br><span class=\"line\">                       &#125;&apos;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>内存分配问题</li>\n</ul>\n<p>ES为运行在jvm上的java进程,很有可能报OOM,或者查看gc日志时发现回收达到了瓶颈，解决方法是加内存，但给ES加内存是指增加堆内存，但堆内存的分配最好小于机器总内存的一半，并且小于32G。ES使用的大内存除了堆内存外，Lucene使用时会占据文件缓存，故堆内存越大，可用的缓存空间就越小，磁盘换读的频率就越高。堆内存的分配还是小于总内存的一半，给文件缓存留点内存比较合适。</p>\n<p>在查询时，Lucene会将索引部分加载到内存中，这意味着，查询的数据量决定了内存的使用，所以当天数增加，数据量增大的情况下，很容易出现OOM。</p>\n<p>当GC出现瓶颈时，会出现ES无法响应的情况，Kibana也会出现对应提示(Status Red)。</p>\n<p>使用中发现Kibana出现Status Red，首先查询集群状态，看节点是否工作正常，其次查看各节点日志，查看问题。</p>\n<p>另外,swapping的情况对于性能来说是致命的，当内存资源不足时，Linux会将某些内容转移到swapping(硬盘)上，要使用这部分内容的时候，需要先搞到内存中，再使用。所以ES中，最好禁用swapping。</p>\n"},{"title":"eth_casper","date":"2019-10-14T06:51:46.000Z","_content":"\n## Casper的基本认识\n\n\n\n#### Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目\n\n- Casper the Friendly Finality Gadget（FFG）\n- Casper the Friendly GHOST: Correct-by-Construction（CBC/TFG）\n\n\n\nPOS算法实现主要可分为两个方向，如下\n\n- 基于链，如 the Friendly GHOST，（理解中基于链意味可是可分叉的）\n- 基于BFT，如Tendermint\n\nCasper TFG是链和BFT二者混合，也是POW+POS混合。其中，POW完成大部分协议，POS定期验证检查点。\n\n\n\n[关于casper分片](https://ethfans.org/posts/Vitalik-on-the-first-test-of-sharding),[casper交联](https://ethresear.ch/t/cross-links-between-main-chain-and-shards/1860),[ppt](https://ethfans.org/posts/you-want-to-be-casper-sharding-validator)\n\n#### Casper vs Tendermint\n\n第一个真正提出将BFT研究应用到PoS公有区块链环境中是Jae Kwon，他在2014年创造了**Tendermint**。\n\n**Tendermint**的设计决策确实是把安全性和不可改变性地位放在了灵活性之上。在现实世界上有相当高的可能性是，系统真的会停止运行，参与者将会需要在协议外组织在某种软件上更新后重启系统。\n\nTendermint的明确属性\n\n可证明的活跃性\n\n安全阈值：1/3的验证者\n\n公有/私有链相容\n\n即时的最终确定性：1-3秒，取决于验证者数量\n\n一致性优先\n\n在弱同步性网络的共识安全\n\n**Casper**的PoS提议机制与Tendermint提议机制最大的区别是相比较伪随机选择领导者，前者的验证者可以基于自己见到的块提出块。\n\n**Casper**提供的一个独特功能是参数化安全阈值。Casper的设计目标是在网络维持PoS低开销的时候能够允许验证者选择自己的容错阈值。\n\n**Casper**对 **Tendermint**的核心优势在于网络随时可以容纳一定数量的验证者。因为Tendermint中的区块在创建的时候需要最终化，所以区块的确认时间应该短一点。为了达到短区块时间，Tendermint PoS能够容纳的验证者数量就需要有个限制。\n\n**Casper**的明确属性\n\n可用性。Casper的节点在它们达成共识之前可以块分杈\n\n异步安全性\n\n生存。Casper的决策可以在部分同步中存活，但是不能在异步中存活\n\n卡特尔阻力。Casper的整个前提是建立在抵制寡头垄断攻击者基础之上，因此不会有任何勾结的验证者可以超越协议\n\n安全性。取决于每个验证者的评估安全阈值\n","source":"_posts/eth-casper.md","raw":"---\ntitle: eth_casper\ncategories:\n  - eth\ndate: 2019-10-14 14:51:46\ntags:\n---\n\n## Casper的基本认识\n\n\n\n#### Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目\n\n- Casper the Friendly Finality Gadget（FFG）\n- Casper the Friendly GHOST: Correct-by-Construction（CBC/TFG）\n\n\n\nPOS算法实现主要可分为两个方向，如下\n\n- 基于链，如 the Friendly GHOST，（理解中基于链意味可是可分叉的）\n- 基于BFT，如Tendermint\n\nCasper TFG是链和BFT二者混合，也是POW+POS混合。其中，POW完成大部分协议，POS定期验证检查点。\n\n\n\n[关于casper分片](https://ethfans.org/posts/Vitalik-on-the-first-test-of-sharding),[casper交联](https://ethresear.ch/t/cross-links-between-main-chain-and-shards/1860),[ppt](https://ethfans.org/posts/you-want-to-be-casper-sharding-validator)\n\n#### Casper vs Tendermint\n\n第一个真正提出将BFT研究应用到PoS公有区块链环境中是Jae Kwon，他在2014年创造了**Tendermint**。\n\n**Tendermint**的设计决策确实是把安全性和不可改变性地位放在了灵活性之上。在现实世界上有相当高的可能性是，系统真的会停止运行，参与者将会需要在协议外组织在某种软件上更新后重启系统。\n\nTendermint的明确属性\n\n可证明的活跃性\n\n安全阈值：1/3的验证者\n\n公有/私有链相容\n\n即时的最终确定性：1-3秒，取决于验证者数量\n\n一致性优先\n\n在弱同步性网络的共识安全\n\n**Casper**的PoS提议机制与Tendermint提议机制最大的区别是相比较伪随机选择领导者，前者的验证者可以基于自己见到的块提出块。\n\n**Casper**提供的一个独特功能是参数化安全阈值。Casper的设计目标是在网络维持PoS低开销的时候能够允许验证者选择自己的容错阈值。\n\n**Casper**对 **Tendermint**的核心优势在于网络随时可以容纳一定数量的验证者。因为Tendermint中的区块在创建的时候需要最终化，所以区块的确认时间应该短一点。为了达到短区块时间，Tendermint PoS能够容纳的验证者数量就需要有个限制。\n\n**Casper**的明确属性\n\n可用性。Casper的节点在它们达成共识之前可以块分杈\n\n异步安全性\n\n生存。Casper的决策可以在部分同步中存活，但是不能在异步中存活\n\n卡特尔阻力。Casper的整个前提是建立在抵制寡头垄断攻击者基础之上，因此不会有任何勾结的验证者可以超越协议\n\n安全性。取决于每个验证者的评估安全阈值\n","slug":"eth-casper","published":1,"updated":"2019-10-14T06:51:53.874Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69ti000mt6xv2flevczd","content":"<h2 id=\"Casper的基本认识\"><a href=\"#Casper的基本认识\" class=\"headerlink\" title=\"Casper的基本认识\"></a>Casper的基本认识</h2><h4 id=\"Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目\"><a href=\"#Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目\" class=\"headerlink\" title=\"Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目\"></a>Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目</h4><ul>\n<li>Casper the Friendly Finality Gadget（FFG）</li>\n<li>Casper the Friendly GHOST: Correct-by-Construction（CBC/TFG）</li>\n</ul>\n<p>POS算法实现主要可分为两个方向，如下</p>\n<ul>\n<li>基于链，如 the Friendly GHOST，（理解中基于链意味可是可分叉的）</li>\n<li>基于BFT，如Tendermint</li>\n</ul>\n<p>Casper TFG是链和BFT二者混合，也是POW+POS混合。其中，POW完成大部分协议，POS定期验证检查点。</p>\n<p><a href=\"https://ethfans.org/posts/Vitalik-on-the-first-test-of-sharding\" target=\"_blank\" rel=\"noopener\">关于casper分片</a>,<a href=\"https://ethresear.ch/t/cross-links-between-main-chain-and-shards/1860\" target=\"_blank\" rel=\"noopener\">casper交联</a>,<a href=\"https://ethfans.org/posts/you-want-to-be-casper-sharding-validator\" target=\"_blank\" rel=\"noopener\">ppt</a></p>\n<h4 id=\"Casper-vs-Tendermint\"><a href=\"#Casper-vs-Tendermint\" class=\"headerlink\" title=\"Casper vs Tendermint\"></a>Casper vs Tendermint</h4><p>第一个真正提出将BFT研究应用到PoS公有区块链环境中是Jae Kwon，他在2014年创造了<strong>Tendermint</strong>。</p>\n<p><strong>Tendermint</strong>的设计决策确实是把安全性和不可改变性地位放在了灵活性之上。在现实世界上有相当高的可能性是，系统真的会停止运行，参与者将会需要在协议外组织在某种软件上更新后重启系统。</p>\n<p>Tendermint的明确属性</p>\n<p>可证明的活跃性</p>\n<p>安全阈值：1/3的验证者</p>\n<p>公有/私有链相容</p>\n<p>即时的最终确定性：1-3秒，取决于验证者数量</p>\n<p>一致性优先</p>\n<p>在弱同步性网络的共识安全</p>\n<p><strong>Casper</strong>的PoS提议机制与Tendermint提议机制最大的区别是相比较伪随机选择领导者，前者的验证者可以基于自己见到的块提出块。</p>\n<p><strong>Casper</strong>提供的一个独特功能是参数化安全阈值。Casper的设计目标是在网络维持PoS低开销的时候能够允许验证者选择自己的容错阈值。</p>\n<p><strong>Casper</strong>对 <strong>Tendermint</strong>的核心优势在于网络随时可以容纳一定数量的验证者。因为Tendermint中的区块在创建的时候需要最终化，所以区块的确认时间应该短一点。为了达到短区块时间，Tendermint PoS能够容纳的验证者数量就需要有个限制。</p>\n<p><strong>Casper</strong>的明确属性</p>\n<p>可用性。Casper的节点在它们达成共识之前可以块分杈</p>\n<p>异步安全性</p>\n<p>生存。Casper的决策可以在部分同步中存活，但是不能在异步中存活</p>\n<p>卡特尔阻力。Casper的整个前提是建立在抵制寡头垄断攻击者基础之上，因此不会有任何勾结的验证者可以超越协议</p>\n<p>安全性。取决于每个验证者的评估安全阈值</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Casper的基本认识\"><a href=\"#Casper的基本认识\" class=\"headerlink\" title=\"Casper的基本认识\"></a>Casper的基本认识</h2><h4 id=\"Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目\"><a href=\"#Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目\" class=\"headerlink\" title=\"Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目\"></a>Casper是以太坊基于POS的研究项目，Casper项目其实包含两个研究项目</h4><ul>\n<li>Casper the Friendly Finality Gadget（FFG）</li>\n<li>Casper the Friendly GHOST: Correct-by-Construction（CBC/TFG）</li>\n</ul>\n<p>POS算法实现主要可分为两个方向，如下</p>\n<ul>\n<li>基于链，如 the Friendly GHOST，（理解中基于链意味可是可分叉的）</li>\n<li>基于BFT，如Tendermint</li>\n</ul>\n<p>Casper TFG是链和BFT二者混合，也是POW+POS混合。其中，POW完成大部分协议，POS定期验证检查点。</p>\n<p><a href=\"https://ethfans.org/posts/Vitalik-on-the-first-test-of-sharding\" target=\"_blank\" rel=\"noopener\">关于casper分片</a>,<a href=\"https://ethresear.ch/t/cross-links-between-main-chain-and-shards/1860\" target=\"_blank\" rel=\"noopener\">casper交联</a>,<a href=\"https://ethfans.org/posts/you-want-to-be-casper-sharding-validator\" target=\"_blank\" rel=\"noopener\">ppt</a></p>\n<h4 id=\"Casper-vs-Tendermint\"><a href=\"#Casper-vs-Tendermint\" class=\"headerlink\" title=\"Casper vs Tendermint\"></a>Casper vs Tendermint</h4><p>第一个真正提出将BFT研究应用到PoS公有区块链环境中是Jae Kwon，他在2014年创造了<strong>Tendermint</strong>。</p>\n<p><strong>Tendermint</strong>的设计决策确实是把安全性和不可改变性地位放在了灵活性之上。在现实世界上有相当高的可能性是，系统真的会停止运行，参与者将会需要在协议外组织在某种软件上更新后重启系统。</p>\n<p>Tendermint的明确属性</p>\n<p>可证明的活跃性</p>\n<p>安全阈值：1/3的验证者</p>\n<p>公有/私有链相容</p>\n<p>即时的最终确定性：1-3秒，取决于验证者数量</p>\n<p>一致性优先</p>\n<p>在弱同步性网络的共识安全</p>\n<p><strong>Casper</strong>的PoS提议机制与Tendermint提议机制最大的区别是相比较伪随机选择领导者，前者的验证者可以基于自己见到的块提出块。</p>\n<p><strong>Casper</strong>提供的一个独特功能是参数化安全阈值。Casper的设计目标是在网络维持PoS低开销的时候能够允许验证者选择自己的容错阈值。</p>\n<p><strong>Casper</strong>对 <strong>Tendermint</strong>的核心优势在于网络随时可以容纳一定数量的验证者。因为Tendermint中的区块在创建的时候需要最终化，所以区块的确认时间应该短一点。为了达到短区块时间，Tendermint PoS能够容纳的验证者数量就需要有个限制。</p>\n<p><strong>Casper</strong>的明确属性</p>\n<p>可用性。Casper的节点在它们达成共识之前可以块分杈</p>\n<p>异步安全性</p>\n<p>生存。Casper的决策可以在部分同步中存活，但是不能在异步中存活</p>\n<p>卡特尔阻力。Casper的整个前提是建立在抵制寡头垄断攻击者基础之上，因此不会有任何勾结的验证者可以超越协议</p>\n<p>安全性。取决于每个验证者的评估安全阈值</p>\n"},{"title":"eos","date":"2019-10-14T06:43:53.000Z","_content":"\n## EOS生态系统介绍\n\n### EOS目标\n\n- EOS能实现每秒百万级的处理量，而目前比特币是每秒7笔，以太坊是30-40笔。\n- EOS将是第一个拥有自己宪法(constitution)的区块链，能实现高度自治。\n- EOS将会成为区块链的操作系统，为开发dApp的开发者提供底层模块，降低开发门槛。会导致开发区块链dApp的大潮。并发处理快，没有手续费，会吸引更多普通用户。\n\n\n\n### EOS App架构\n\n![架构图](https://upload-images.jianshu.io/upload_images/3866441-75058ee05f7b7f8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)\n\n- IPFS存储\n\n  包含文件的存储，和服务器端程序的存储\n\n- 数据库查询服务\n\n​        除了托管文件之外，块生产者还需要运行能够代表应用程序查询区块链数据库状态的API节点\n\n- 资源限制\n\n  应用程序在块链和接口上都占用传输带宽，CPU和存储空间。 **块链生产者**必须设置访问限制规则，以防用户滥用\n\n\n\n### EOS 系统组成\n\n![EOS系统组成](https://github.com/EOSIO/eos/wiki/assets/Single-Host-Testnet-No-keosd.png)\n\n上图为本地单节点组成。\n\n- `keosd`：本地钱包工具。非节点用户存储钱包的进程，可以管理多个含有私钥的钱包并加密。\n- `cleos`:本地的命令行工具，通过命令行与真人用户交互，并与节点（nodeos）的 REST 接口通信。是用户或者开发者与节点进程交互的桥梁。\n- `nodeos`： EOS 系统的核心进程，也就是所谓的“节点”。\n\n\n\n节点运行时可配置相关插件。如\n\n- `producer_plugin`（见证人插件）：见证人必须使用这个插件，普通节点不需要。\n- `wallet_plugin`（钱包插件）：使用这个插件就可以省去 keosd 钱包工具。\n- `wallet_api_plugin`（钱包接口插件）：给钱包插件提供接口。\n- `chain_api_plugin`（区块链接口插件）：提供区块链数据接口。\n- `http_plugin`（http 插件）：提供 http 接口。\n- `account_history_api_plugin`（账户历史接口）：提供账户历史查询接口。\n\n\n\n公共网络下，用户通过 `cleos` 连接到 `nodeos` ， `nodeos` 再连接到区块链网络（其他`nodeos`）。\n\n\n\n### 共识算法(BFT-DPOS)\n\n被投票选出的21个超级节点轮流进行出块，每0.5秒生成一个。任何时刻，只有一个生产者被授权产生区块。如果在计划的某个时间内没有成功出块，则跳过该块。如果有一个或更多的区块被跳过，则在区块链上会有0.5s或者更久的空白。一个生产者一次连续出6个块。那么，区块的产生是以126个区块(每个出块者六个区块，乘以21个出块者)为一个周期。在每个出块周期开始时，会根据通证持有人所投票数选出21个区块生产者。被选中的区块生产者的顺序会根据15个及以上的区块生产者的同意，制定出块顺序的安排。\n\n如果出块者错过了一个块，并且在最近24小时内没有产生任何块，则这个出块者将被剔除在考虑范围之外，直到他们通知区块链可以重新开始产生区块。这确保了网络的顺利运行，把被证明为不可靠的区块生产者排除在出块排程之外，通过这一方式使得错过区块的数量最小化\n\n\n\n**投票**：根据最新规则，投票将会在官方钱包中进行，每隔 63s ，也就是每产生126个区块进行一次。每个EOS拥有 30 票，可以投给不同的候选者。参与投票的代币将会被锁定一段时间，代币持有者可以设置代币锁定期内的候选人账户和投票数量进行投票。\n\n投票结果，EOS 系统会统计各个候选节点获得的代币数量。其中获得代币数量最多的 21 个节点将被选定为超级节点，次多的 100 个节点被选为备用节点。\n\n**超级节点**：收集、验证网络交易信息，打包到区块中，并广播给其他节点。\n\n在正常情况下，DPOS块链不会经历任何分叉，因为区块生产者并非竞争关系，他们合作产生区块。如果有区块分叉，共识将自动切换到最长链。关于不会分叉的验证，见[验证篇](https://steemit.com/dpos/@dantheman/dpos-consensus-algorithm-this-missing-white-paper)\n\n另外，在传统的DPOS算法上增加了拜占庭容错算法(Byzantin Fault Tolerance) ，所有的出块者都要对所有区块签名，以此来确保在同一时间戳或者同一区块高度上，没有区块生产者能够同时在两个区块上签名。一个区块有了15个区块生产者的签名，该区块就被认为是不可逆的。\n\n\n\n### 生态建设\n\nBlock.one和Galaxy Digital将通过资本化一个新的3.25亿美元的[http://EOS.IO](https://link.zhihu.com/?target=http%3A//EOS.IO)生态系统基金（“基金”），为未来的投资部署资金。总之不缺钱，而且目前有大量DAPP已经宣布加入EOS，有易用的通用开发模块，基金投资，人气很不错。\n\n![EOS的Dapp生态图](https://pic2.zhimg.com/80/v2-1b8fb0ef655fcc6e3c70a8da6d3a379d_hd.jpg)\n","source":"_posts/eos.md","raw":"---\ntitle: eos\ncategories:\n  - eos\ndate: 2019-10-14 14:43:53\ntags:\n---\n\n## EOS生态系统介绍\n\n### EOS目标\n\n- EOS能实现每秒百万级的处理量，而目前比特币是每秒7笔，以太坊是30-40笔。\n- EOS将是第一个拥有自己宪法(constitution)的区块链，能实现高度自治。\n- EOS将会成为区块链的操作系统，为开发dApp的开发者提供底层模块，降低开发门槛。会导致开发区块链dApp的大潮。并发处理快，没有手续费，会吸引更多普通用户。\n\n\n\n### EOS App架构\n\n![架构图](https://upload-images.jianshu.io/upload_images/3866441-75058ee05f7b7f8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)\n\n- IPFS存储\n\n  包含文件的存储，和服务器端程序的存储\n\n- 数据库查询服务\n\n​        除了托管文件之外，块生产者还需要运行能够代表应用程序查询区块链数据库状态的API节点\n\n- 资源限制\n\n  应用程序在块链和接口上都占用传输带宽，CPU和存储空间。 **块链生产者**必须设置访问限制规则，以防用户滥用\n\n\n\n### EOS 系统组成\n\n![EOS系统组成](https://github.com/EOSIO/eos/wiki/assets/Single-Host-Testnet-No-keosd.png)\n\n上图为本地单节点组成。\n\n- `keosd`：本地钱包工具。非节点用户存储钱包的进程，可以管理多个含有私钥的钱包并加密。\n- `cleos`:本地的命令行工具，通过命令行与真人用户交互，并与节点（nodeos）的 REST 接口通信。是用户或者开发者与节点进程交互的桥梁。\n- `nodeos`： EOS 系统的核心进程，也就是所谓的“节点”。\n\n\n\n节点运行时可配置相关插件。如\n\n- `producer_plugin`（见证人插件）：见证人必须使用这个插件，普通节点不需要。\n- `wallet_plugin`（钱包插件）：使用这个插件就可以省去 keosd 钱包工具。\n- `wallet_api_plugin`（钱包接口插件）：给钱包插件提供接口。\n- `chain_api_plugin`（区块链接口插件）：提供区块链数据接口。\n- `http_plugin`（http 插件）：提供 http 接口。\n- `account_history_api_plugin`（账户历史接口）：提供账户历史查询接口。\n\n\n\n公共网络下，用户通过 `cleos` 连接到 `nodeos` ， `nodeos` 再连接到区块链网络（其他`nodeos`）。\n\n\n\n### 共识算法(BFT-DPOS)\n\n被投票选出的21个超级节点轮流进行出块，每0.5秒生成一个。任何时刻，只有一个生产者被授权产生区块。如果在计划的某个时间内没有成功出块，则跳过该块。如果有一个或更多的区块被跳过，则在区块链上会有0.5s或者更久的空白。一个生产者一次连续出6个块。那么，区块的产生是以126个区块(每个出块者六个区块，乘以21个出块者)为一个周期。在每个出块周期开始时，会根据通证持有人所投票数选出21个区块生产者。被选中的区块生产者的顺序会根据15个及以上的区块生产者的同意，制定出块顺序的安排。\n\n如果出块者错过了一个块，并且在最近24小时内没有产生任何块，则这个出块者将被剔除在考虑范围之外，直到他们通知区块链可以重新开始产生区块。这确保了网络的顺利运行，把被证明为不可靠的区块生产者排除在出块排程之外，通过这一方式使得错过区块的数量最小化\n\n\n\n**投票**：根据最新规则，投票将会在官方钱包中进行，每隔 63s ，也就是每产生126个区块进行一次。每个EOS拥有 30 票，可以投给不同的候选者。参与投票的代币将会被锁定一段时间，代币持有者可以设置代币锁定期内的候选人账户和投票数量进行投票。\n\n投票结果，EOS 系统会统计各个候选节点获得的代币数量。其中获得代币数量最多的 21 个节点将被选定为超级节点，次多的 100 个节点被选为备用节点。\n\n**超级节点**：收集、验证网络交易信息，打包到区块中，并广播给其他节点。\n\n在正常情况下，DPOS块链不会经历任何分叉，因为区块生产者并非竞争关系，他们合作产生区块。如果有区块分叉，共识将自动切换到最长链。关于不会分叉的验证，见[验证篇](https://steemit.com/dpos/@dantheman/dpos-consensus-algorithm-this-missing-white-paper)\n\n另外，在传统的DPOS算法上增加了拜占庭容错算法(Byzantin Fault Tolerance) ，所有的出块者都要对所有区块签名，以此来确保在同一时间戳或者同一区块高度上，没有区块生产者能够同时在两个区块上签名。一个区块有了15个区块生产者的签名，该区块就被认为是不可逆的。\n\n\n\n### 生态建设\n\nBlock.one和Galaxy Digital将通过资本化一个新的3.25亿美元的[http://EOS.IO](https://link.zhihu.com/?target=http%3A//EOS.IO)生态系统基金（“基金”），为未来的投资部署资金。总之不缺钱，而且目前有大量DAPP已经宣布加入EOS，有易用的通用开发模块，基金投资，人气很不错。\n\n![EOS的Dapp生态图](https://pic2.zhimg.com/80/v2-1b8fb0ef655fcc6e3c70a8da6d3a379d_hd.jpg)\n","slug":"eos","published":1,"updated":"2019-10-14T06:44:23.967Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69tj000nt6xvp9nabogf","content":"<h2 id=\"EOS生态系统介绍\"><a href=\"#EOS生态系统介绍\" class=\"headerlink\" title=\"EOS生态系统介绍\"></a>EOS生态系统介绍</h2><h3 id=\"EOS目标\"><a href=\"#EOS目标\" class=\"headerlink\" title=\"EOS目标\"></a>EOS目标</h3><ul>\n<li>EOS能实现每秒百万级的处理量，而目前比特币是每秒7笔，以太坊是30-40笔。</li>\n<li>EOS将是第一个拥有自己宪法(constitution)的区块链，能实现高度自治。</li>\n<li>EOS将会成为区块链的操作系统，为开发dApp的开发者提供底层模块，降低开发门槛。会导致开发区块链dApp的大潮。并发处理快，没有手续费，会吸引更多普通用户。</li>\n</ul>\n<h3 id=\"EOS-App架构\"><a href=\"#EOS-App架构\" class=\"headerlink\" title=\"EOS App架构\"></a>EOS App架构</h3><p><img src=\"https://upload-images.jianshu.io/upload_images/3866441-75058ee05f7b7f8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700\" alt=\"架构图\"></p>\n<ul>\n<li><p>IPFS存储</p>\n<p>包含文件的存储，和服务器端程序的存储</p>\n</li>\n<li><p>数据库查询服务</p>\n</li>\n</ul>\n<p>​        除了托管文件之外，块生产者还需要运行能够代表应用程序查询区块链数据库状态的API节点</p>\n<ul>\n<li><p>资源限制</p>\n<p>应用程序在块链和接口上都占用传输带宽，CPU和存储空间。 <strong>块链生产者</strong>必须设置访问限制规则，以防用户滥用</p>\n</li>\n</ul>\n<h3 id=\"EOS-系统组成\"><a href=\"#EOS-系统组成\" class=\"headerlink\" title=\"EOS 系统组成\"></a>EOS 系统组成</h3><p><img src=\"https://github.com/EOSIO/eos/wiki/assets/Single-Host-Testnet-No-keosd.png\" alt=\"EOS系统组成\"></p>\n<p>上图为本地单节点组成。</p>\n<ul>\n<li><code>keosd</code>：本地钱包工具。非节点用户存储钱包的进程，可以管理多个含有私钥的钱包并加密。</li>\n<li><code>cleos</code>:本地的命令行工具，通过命令行与真人用户交互，并与节点（nodeos）的 REST 接口通信。是用户或者开发者与节点进程交互的桥梁。</li>\n<li><code>nodeos</code>： EOS 系统的核心进程，也就是所谓的“节点”。</li>\n</ul>\n<p>节点运行时可配置相关插件。如</p>\n<ul>\n<li><code>producer_plugin</code>（见证人插件）：见证人必须使用这个插件，普通节点不需要。</li>\n<li><code>wallet_plugin</code>（钱包插件）：使用这个插件就可以省去 keosd 钱包工具。</li>\n<li><code>wallet_api_plugin</code>（钱包接口插件）：给钱包插件提供接口。</li>\n<li><code>chain_api_plugin</code>（区块链接口插件）：提供区块链数据接口。</li>\n<li><code>http_plugin</code>（http 插件）：提供 http 接口。</li>\n<li><code>account_history_api_plugin</code>（账户历史接口）：提供账户历史查询接口。</li>\n</ul>\n<p>公共网络下，用户通过 <code>cleos</code> 连接到 <code>nodeos</code> ， <code>nodeos</code> 再连接到区块链网络（其他<code>nodeos</code>）。</p>\n<h3 id=\"共识算法-BFT-DPOS\"><a href=\"#共识算法-BFT-DPOS\" class=\"headerlink\" title=\"共识算法(BFT-DPOS)\"></a>共识算法(BFT-DPOS)</h3><p>被投票选出的21个超级节点轮流进行出块，每0.5秒生成一个。任何时刻，只有一个生产者被授权产生区块。如果在计划的某个时间内没有成功出块，则跳过该块。如果有一个或更多的区块被跳过，则在区块链上会有0.5s或者更久的空白。一个生产者一次连续出6个块。那么，区块的产生是以126个区块(每个出块者六个区块，乘以21个出块者)为一个周期。在每个出块周期开始时，会根据通证持有人所投票数选出21个区块生产者。被选中的区块生产者的顺序会根据15个及以上的区块生产者的同意，制定出块顺序的安排。</p>\n<p>如果出块者错过了一个块，并且在最近24小时内没有产生任何块，则这个出块者将被剔除在考虑范围之外，直到他们通知区块链可以重新开始产生区块。这确保了网络的顺利运行，把被证明为不可靠的区块生产者排除在出块排程之外，通过这一方式使得错过区块的数量最小化</p>\n<p><strong>投票</strong>：根据最新规则，投票将会在官方钱包中进行，每隔 63s ，也就是每产生126个区块进行一次。每个EOS拥有 30 票，可以投给不同的候选者。参与投票的代币将会被锁定一段时间，代币持有者可以设置代币锁定期内的候选人账户和投票数量进行投票。</p>\n<p>投票结果，EOS 系统会统计各个候选节点获得的代币数量。其中获得代币数量最多的 21 个节点将被选定为超级节点，次多的 100 个节点被选为备用节点。</p>\n<p><strong>超级节点</strong>：收集、验证网络交易信息，打包到区块中，并广播给其他节点。</p>\n<p>在正常情况下，DPOS块链不会经历任何分叉，因为区块生产者并非竞争关系，他们合作产生区块。如果有区块分叉，共识将自动切换到最长链。关于不会分叉的验证，见<a href=\"https://steemit.com/dpos/@dantheman/dpos-consensus-algorithm-this-missing-white-paper\" target=\"_blank\" rel=\"noopener\">验证篇</a></p>\n<p>另外，在传统的DPOS算法上增加了拜占庭容错算法(Byzantin Fault Tolerance) ，所有的出块者都要对所有区块签名，以此来确保在同一时间戳或者同一区块高度上，没有区块生产者能够同时在两个区块上签名。一个区块有了15个区块生产者的签名，该区块就被认为是不可逆的。</p>\n<h3 id=\"生态建设\"><a href=\"#生态建设\" class=\"headerlink\" title=\"生态建设\"></a>生态建设</h3><p>Block.one和Galaxy Digital将通过资本化一个新的3.25亿美元的<a href=\"https://link.zhihu.com/?target=http%3A//EOS.IO\" target=\"_blank\" rel=\"noopener\">http://EOS.IO</a>生态系统基金（“基金”），为未来的投资部署资金。总之不缺钱，而且目前有大量DAPP已经宣布加入EOS，有易用的通用开发模块，基金投资，人气很不错。</p>\n<p><img src=\"https://pic2.zhimg.com/80/v2-1b8fb0ef655fcc6e3c70a8da6d3a379d_hd.jpg\" alt=\"EOS的Dapp生态图\"></p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"EOS生态系统介绍\"><a href=\"#EOS生态系统介绍\" class=\"headerlink\" title=\"EOS生态系统介绍\"></a>EOS生态系统介绍</h2><h3 id=\"EOS目标\"><a href=\"#EOS目标\" class=\"headerlink\" title=\"EOS目标\"></a>EOS目标</h3><ul>\n<li>EOS能实现每秒百万级的处理量，而目前比特币是每秒7笔，以太坊是30-40笔。</li>\n<li>EOS将是第一个拥有自己宪法(constitution)的区块链，能实现高度自治。</li>\n<li>EOS将会成为区块链的操作系统，为开发dApp的开发者提供底层模块，降低开发门槛。会导致开发区块链dApp的大潮。并发处理快，没有手续费，会吸引更多普通用户。</li>\n</ul>\n<h3 id=\"EOS-App架构\"><a href=\"#EOS-App架构\" class=\"headerlink\" title=\"EOS App架构\"></a>EOS App架构</h3><p><img src=\"https://upload-images.jianshu.io/upload_images/3866441-75058ee05f7b7f8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700\" alt=\"架构图\"></p>\n<ul>\n<li><p>IPFS存储</p>\n<p>包含文件的存储，和服务器端程序的存储</p>\n</li>\n<li><p>数据库查询服务</p>\n</li>\n</ul>\n<p>​        除了托管文件之外，块生产者还需要运行能够代表应用程序查询区块链数据库状态的API节点</p>\n<ul>\n<li><p>资源限制</p>\n<p>应用程序在块链和接口上都占用传输带宽，CPU和存储空间。 <strong>块链生产者</strong>必须设置访问限制规则，以防用户滥用</p>\n</li>\n</ul>\n<h3 id=\"EOS-系统组成\"><a href=\"#EOS-系统组成\" class=\"headerlink\" title=\"EOS 系统组成\"></a>EOS 系统组成</h3><p><img src=\"https://github.com/EOSIO/eos/wiki/assets/Single-Host-Testnet-No-keosd.png\" alt=\"EOS系统组成\"></p>\n<p>上图为本地单节点组成。</p>\n<ul>\n<li><code>keosd</code>：本地钱包工具。非节点用户存储钱包的进程，可以管理多个含有私钥的钱包并加密。</li>\n<li><code>cleos</code>:本地的命令行工具，通过命令行与真人用户交互，并与节点（nodeos）的 REST 接口通信。是用户或者开发者与节点进程交互的桥梁。</li>\n<li><code>nodeos</code>： EOS 系统的核心进程，也就是所谓的“节点”。</li>\n</ul>\n<p>节点运行时可配置相关插件。如</p>\n<ul>\n<li><code>producer_plugin</code>（见证人插件）：见证人必须使用这个插件，普通节点不需要。</li>\n<li><code>wallet_plugin</code>（钱包插件）：使用这个插件就可以省去 keosd 钱包工具。</li>\n<li><code>wallet_api_plugin</code>（钱包接口插件）：给钱包插件提供接口。</li>\n<li><code>chain_api_plugin</code>（区块链接口插件）：提供区块链数据接口。</li>\n<li><code>http_plugin</code>（http 插件）：提供 http 接口。</li>\n<li><code>account_history_api_plugin</code>（账户历史接口）：提供账户历史查询接口。</li>\n</ul>\n<p>公共网络下，用户通过 <code>cleos</code> 连接到 <code>nodeos</code> ， <code>nodeos</code> 再连接到区块链网络（其他<code>nodeos</code>）。</p>\n<h3 id=\"共识算法-BFT-DPOS\"><a href=\"#共识算法-BFT-DPOS\" class=\"headerlink\" title=\"共识算法(BFT-DPOS)\"></a>共识算法(BFT-DPOS)</h3><p>被投票选出的21个超级节点轮流进行出块，每0.5秒生成一个。任何时刻，只有一个生产者被授权产生区块。如果在计划的某个时间内没有成功出块，则跳过该块。如果有一个或更多的区块被跳过，则在区块链上会有0.5s或者更久的空白。一个生产者一次连续出6个块。那么，区块的产生是以126个区块(每个出块者六个区块，乘以21个出块者)为一个周期。在每个出块周期开始时，会根据通证持有人所投票数选出21个区块生产者。被选中的区块生产者的顺序会根据15个及以上的区块生产者的同意，制定出块顺序的安排。</p>\n<p>如果出块者错过了一个块，并且在最近24小时内没有产生任何块，则这个出块者将被剔除在考虑范围之外，直到他们通知区块链可以重新开始产生区块。这确保了网络的顺利运行，把被证明为不可靠的区块生产者排除在出块排程之外，通过这一方式使得错过区块的数量最小化</p>\n<p><strong>投票</strong>：根据最新规则，投票将会在官方钱包中进行，每隔 63s ，也就是每产生126个区块进行一次。每个EOS拥有 30 票，可以投给不同的候选者。参与投票的代币将会被锁定一段时间，代币持有者可以设置代币锁定期内的候选人账户和投票数量进行投票。</p>\n<p>投票结果，EOS 系统会统计各个候选节点获得的代币数量。其中获得代币数量最多的 21 个节点将被选定为超级节点，次多的 100 个节点被选为备用节点。</p>\n<p><strong>超级节点</strong>：收集、验证网络交易信息，打包到区块中，并广播给其他节点。</p>\n<p>在正常情况下，DPOS块链不会经历任何分叉，因为区块生产者并非竞争关系，他们合作产生区块。如果有区块分叉，共识将自动切换到最长链。关于不会分叉的验证，见<a href=\"https://steemit.com/dpos/@dantheman/dpos-consensus-algorithm-this-missing-white-paper\" target=\"_blank\" rel=\"noopener\">验证篇</a></p>\n<p>另外，在传统的DPOS算法上增加了拜占庭容错算法(Byzantin Fault Tolerance) ，所有的出块者都要对所有区块签名，以此来确保在同一时间戳或者同一区块高度上，没有区块生产者能够同时在两个区块上签名。一个区块有了15个区块生产者的签名，该区块就被认为是不可逆的。</p>\n<h3 id=\"生态建设\"><a href=\"#生态建设\" class=\"headerlink\" title=\"生态建设\"></a>生态建设</h3><p>Block.one和Galaxy Digital将通过资本化一个新的3.25亿美元的<a href=\"https://link.zhihu.com/?target=http%3A//EOS.IO\" target=\"_blank\" rel=\"noopener\">http://EOS.IO</a>生态系统基金（“基金”），为未来的投资部署资金。总之不缺钱，而且目前有大量DAPP已经宣布加入EOS，有易用的通用开发模块，基金投资，人气很不错。</p>\n<p><img src=\"https://pic2.zhimg.com/80/v2-1b8fb0ef655fcc6e3c70a8da6d3a379d_hd.jpg\" alt=\"EOS的Dapp生态图\"></p>\n"},{"title":"eth_jsre_api","date":"2019-10-14T06:53:56.000Z","_content":"## jsre中添加api\n\notto包，可以直接在go语言中实现js命令。可以在console这种交互模式或者script这种非交互模式中使用\n\n相关的源码分析就省略了。\n\n\n\n要添加新的api,首先需要在合适的地方定义具体方法。合适地方..例如backend.go的GetAPIs()为api集合，可在相应的namespace对应的Service中定义，例如在PublicEthereumAPI中添加方法test，访问路径为`eth.test()`\n\n```\nfunc (s *PublicBlockChainAPI) Test(ctx context.Context) error {\n   fmt.Println(\"test\")\n   return nil\n}\n\n```\n\n接下来就是要在js中进行注册，才能定向到上面的方法中。\n\njs中注册有两种方式。\n\n第一种是直接在go文件中添加js静态代码。在web3ext.go中对应位置添加，如\n\n```\nconst Eth_JS = `\nweb3._extend({\n\tproperty: 'eth',\n\tmethods: [\n\t\tnew web3._extend.Method({\n\t\t\tname: 'test',\n\t\t\tcall: 'eth_test',\n\t\t\tparams: 0\n\t\t}),\n\t]\n\t...\n\t`\n```\n\n这样添加后，直接重新编译即可`make all`\n\n\n\n第二种是在js文件中添加代码，在web3.js中对应位置添加，如\n\n```\nvar methods = function () {\n    var test = new Method({\n        name: 'test',\n        call: 'eth_test',\n        params: 0\n    });\n    var getStorageAt = new Method({\n        name: 'getStorageAt',\n        call: 'eth_getStorageAt',\n        params: 3,\n        inputFormatter: [null, utils.toHex, formatters.inputDefaultBlockNumberFormatter]\n    });\n\t...\n\t return [\n\t \ttest\n\t ]\n\n}\n```\n\n修改js文件，要进行编译成go（bindata.go）文件才能生效。\n\n编译deps.go中有go:generate语句，用来重新生成bindata.go文件.\n\n生成bindata.go文件，需要安装go-bindata。安装方法如下。\n\n```\ngo get github.com/jteeuwen/go-bindata\ngo install github.com/jteeuwen/go-bindata/go-bindata\n```\n\n安装后生成bindata.go文件，可以在IDE中点击生成，也可以在命令行中执行命令生成。\n\n```\ncd $GOPATH/src/github.com/ethereum/go-ethereum/internal/jsre/deps\ngo-bindata -nometadata -pkg deps -o bindata.go bignumber.js web3.js\ngofmt -w -s bindata.go\n```\n\n最后再进行编译即可`make all`\n\n\n\n\n\n关于输入参数和输出参数，可在js层就输入的参数进行参数的数据类型转换，如上面示例中的getStorageAt的inputFormatter，参数为null的不会进行操作，utils.toHex应该是把参数encode成hex。formatter应该是构造结构体实例，下面放2个具体的formatter的构造\n\n```\nvar inputDefaultBlockNumberFormatter = function (blockNumber) {\n    if (blockNumber === undefined) {\n        return config.defaultBlock;\n    }\n    return inputBlockNumberFormatter(blockNumber);\n};\n\nvar inputTransactionFormatter = function (options){\n\n    options.from = options.from || config.defaultAccount;\n    options.from = inputAddressFormatter(options.from);\n\n    if (options.to) { // it might be contract creation\n        options.to = inputAddressFormatter(options.to);\n    }\n\n    ['gasPrice', 'gas', 'value', 'nonce'].filter(function (key) {\n        return options[key] !== undefined;\n    }).forEach(function(key){\n        options[key] = utils.fromDecimal(options[key]);\n    });\n\n    return options;\n};\n```\n","source":"_posts/eth-jsre-api.md","raw":"---\ntitle: eth_jsre_api\ncategories:\n  - eth\ndate: 2019-10-14 14:53:56\ntags:\n---\n## jsre中添加api\n\notto包，可以直接在go语言中实现js命令。可以在console这种交互模式或者script这种非交互模式中使用\n\n相关的源码分析就省略了。\n\n\n\n要添加新的api,首先需要在合适的地方定义具体方法。合适地方..例如backend.go的GetAPIs()为api集合，可在相应的namespace对应的Service中定义，例如在PublicEthereumAPI中添加方法test，访问路径为`eth.test()`\n\n```\nfunc (s *PublicBlockChainAPI) Test(ctx context.Context) error {\n   fmt.Println(\"test\")\n   return nil\n}\n\n```\n\n接下来就是要在js中进行注册，才能定向到上面的方法中。\n\njs中注册有两种方式。\n\n第一种是直接在go文件中添加js静态代码。在web3ext.go中对应位置添加，如\n\n```\nconst Eth_JS = `\nweb3._extend({\n\tproperty: 'eth',\n\tmethods: [\n\t\tnew web3._extend.Method({\n\t\t\tname: 'test',\n\t\t\tcall: 'eth_test',\n\t\t\tparams: 0\n\t\t}),\n\t]\n\t...\n\t`\n```\n\n这样添加后，直接重新编译即可`make all`\n\n\n\n第二种是在js文件中添加代码，在web3.js中对应位置添加，如\n\n```\nvar methods = function () {\n    var test = new Method({\n        name: 'test',\n        call: 'eth_test',\n        params: 0\n    });\n    var getStorageAt = new Method({\n        name: 'getStorageAt',\n        call: 'eth_getStorageAt',\n        params: 3,\n        inputFormatter: [null, utils.toHex, formatters.inputDefaultBlockNumberFormatter]\n    });\n\t...\n\t return [\n\t \ttest\n\t ]\n\n}\n```\n\n修改js文件，要进行编译成go（bindata.go）文件才能生效。\n\n编译deps.go中有go:generate语句，用来重新生成bindata.go文件.\n\n生成bindata.go文件，需要安装go-bindata。安装方法如下。\n\n```\ngo get github.com/jteeuwen/go-bindata\ngo install github.com/jteeuwen/go-bindata/go-bindata\n```\n\n安装后生成bindata.go文件，可以在IDE中点击生成，也可以在命令行中执行命令生成。\n\n```\ncd $GOPATH/src/github.com/ethereum/go-ethereum/internal/jsre/deps\ngo-bindata -nometadata -pkg deps -o bindata.go bignumber.js web3.js\ngofmt -w -s bindata.go\n```\n\n最后再进行编译即可`make all`\n\n\n\n\n\n关于输入参数和输出参数，可在js层就输入的参数进行参数的数据类型转换，如上面示例中的getStorageAt的inputFormatter，参数为null的不会进行操作，utils.toHex应该是把参数encode成hex。formatter应该是构造结构体实例，下面放2个具体的formatter的构造\n\n```\nvar inputDefaultBlockNumberFormatter = function (blockNumber) {\n    if (blockNumber === undefined) {\n        return config.defaultBlock;\n    }\n    return inputBlockNumberFormatter(blockNumber);\n};\n\nvar inputTransactionFormatter = function (options){\n\n    options.from = options.from || config.defaultAccount;\n    options.from = inputAddressFormatter(options.from);\n\n    if (options.to) { // it might be contract creation\n        options.to = inputAddressFormatter(options.to);\n    }\n\n    ['gasPrice', 'gas', 'value', 'nonce'].filter(function (key) {\n        return options[key] !== undefined;\n    }).forEach(function(key){\n        options[key] = utils.fromDecimal(options[key]);\n    });\n\n    return options;\n};\n```\n","slug":"eth-jsre-api","published":1,"updated":"2019-10-14T06:54:16.741Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69tm000qt6xvso7pmbeq","content":"<h2 id=\"jsre中添加api\"><a href=\"#jsre中添加api\" class=\"headerlink\" title=\"jsre中添加api\"></a>jsre中添加api</h2><p>otto包，可以直接在go语言中实现js命令。可以在console这种交互模式或者script这种非交互模式中使用</p>\n<p>相关的源码分析就省略了。</p>\n<p>要添加新的api,首先需要在合适的地方定义具体方法。合适地方..例如backend.go的GetAPIs()为api集合，可在相应的namespace对应的Service中定义，例如在PublicEthereumAPI中添加方法test，访问路径为<code>eth.test()</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (s *PublicBlockChainAPI) Test(ctx context.Context) error &#123;</span><br><span class=\"line\">   fmt.Println(&quot;test&quot;)</span><br><span class=\"line\">   return nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>接下来就是要在js中进行注册，才能定向到上面的方法中。</p>\n<p>js中注册有两种方式。</p>\n<p>第一种是直接在go文件中添加js静态代码。在web3ext.go中对应位置添加，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">const Eth_JS = `</span><br><span class=\"line\">web3._extend(&#123;</span><br><span class=\"line\">\tproperty: &apos;eth&apos;,</span><br><span class=\"line\">\tmethods: [</span><br><span class=\"line\">\t\tnew web3._extend.Method(&#123;</span><br><span class=\"line\">\t\t\tname: &apos;test&apos;,</span><br><span class=\"line\">\t\t\tcall: &apos;eth_test&apos;,</span><br><span class=\"line\">\t\t\tparams: 0</span><br><span class=\"line\">\t\t&#125;),</span><br><span class=\"line\">\t]</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t`</span><br></pre></td></tr></table></figure>\n\n<p>这样添加后，直接重新编译即可<code>make all</code></p>\n<p>第二种是在js文件中添加代码，在web3.js中对应位置添加，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var methods = function () &#123;</span><br><span class=\"line\">    var test = new Method(&#123;</span><br><span class=\"line\">        name: &apos;test&apos;,</span><br><span class=\"line\">        call: &apos;eth_test&apos;,</span><br><span class=\"line\">        params: 0</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">    var getStorageAt = new Method(&#123;</span><br><span class=\"line\">        name: &apos;getStorageAt&apos;,</span><br><span class=\"line\">        call: &apos;eth_getStorageAt&apos;,</span><br><span class=\"line\">        params: 3,</span><br><span class=\"line\">        inputFormatter: [null, utils.toHex, formatters.inputDefaultBlockNumberFormatter]</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t return [</span><br><span class=\"line\">\t \ttest</span><br><span class=\"line\">\t ]</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>修改js文件，要进行编译成go（bindata.go）文件才能生效。</p>\n<p>编译deps.go中有go:generate语句，用来重新生成bindata.go文件.</p>\n<p>生成bindata.go文件，需要安装go-bindata。安装方法如下。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go get github.com/jteeuwen/go-bindata</span><br><span class=\"line\">go install github.com/jteeuwen/go-bindata/go-bindata</span><br></pre></td></tr></table></figure>\n\n<p>安装后生成bindata.go文件，可以在IDE中点击生成，也可以在命令行中执行命令生成。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd $GOPATH/src/github.com/ethereum/go-ethereum/internal/jsre/deps</span><br><span class=\"line\">go-bindata -nometadata -pkg deps -o bindata.go bignumber.js web3.js</span><br><span class=\"line\">gofmt -w -s bindata.go</span><br></pre></td></tr></table></figure>\n\n<p>最后再进行编译即可<code>make all</code></p>\n<p>关于输入参数和输出参数，可在js层就输入的参数进行参数的数据类型转换，如上面示例中的getStorageAt的inputFormatter，参数为null的不会进行操作，utils.toHex应该是把参数encode成hex。formatter应该是构造结构体实例，下面放2个具体的formatter的构造</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var inputDefaultBlockNumberFormatter = function (blockNumber) &#123;</span><br><span class=\"line\">    if (blockNumber === undefined) &#123;</span><br><span class=\"line\">        return config.defaultBlock;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return inputBlockNumberFormatter(blockNumber);</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">var inputTransactionFormatter = function (options)&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    options.from = options.from || config.defaultAccount;</span><br><span class=\"line\">    options.from = inputAddressFormatter(options.from);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (options.to) &#123; // it might be contract creation</span><br><span class=\"line\">        options.to = inputAddressFormatter(options.to);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    [&apos;gasPrice&apos;, &apos;gas&apos;, &apos;value&apos;, &apos;nonce&apos;].filter(function (key) &#123;</span><br><span class=\"line\">        return options[key] !== undefined;</span><br><span class=\"line\">    &#125;).forEach(function(key)&#123;</span><br><span class=\"line\">        options[key] = utils.fromDecimal(options[key]);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    return options;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"jsre中添加api\"><a href=\"#jsre中添加api\" class=\"headerlink\" title=\"jsre中添加api\"></a>jsre中添加api</h2><p>otto包，可以直接在go语言中实现js命令。可以在console这种交互模式或者script这种非交互模式中使用</p>\n<p>相关的源码分析就省略了。</p>\n<p>要添加新的api,首先需要在合适的地方定义具体方法。合适地方..例如backend.go的GetAPIs()为api集合，可在相应的namespace对应的Service中定义，例如在PublicEthereumAPI中添加方法test，访问路径为<code>eth.test()</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (s *PublicBlockChainAPI) Test(ctx context.Context) error &#123;</span><br><span class=\"line\">   fmt.Println(&quot;test&quot;)</span><br><span class=\"line\">   return nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>接下来就是要在js中进行注册，才能定向到上面的方法中。</p>\n<p>js中注册有两种方式。</p>\n<p>第一种是直接在go文件中添加js静态代码。在web3ext.go中对应位置添加，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">const Eth_JS = `</span><br><span class=\"line\">web3._extend(&#123;</span><br><span class=\"line\">\tproperty: &apos;eth&apos;,</span><br><span class=\"line\">\tmethods: [</span><br><span class=\"line\">\t\tnew web3._extend.Method(&#123;</span><br><span class=\"line\">\t\t\tname: &apos;test&apos;,</span><br><span class=\"line\">\t\t\tcall: &apos;eth_test&apos;,</span><br><span class=\"line\">\t\t\tparams: 0</span><br><span class=\"line\">\t\t&#125;),</span><br><span class=\"line\">\t]</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t`</span><br></pre></td></tr></table></figure>\n\n<p>这样添加后，直接重新编译即可<code>make all</code></p>\n<p>第二种是在js文件中添加代码，在web3.js中对应位置添加，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var methods = function () &#123;</span><br><span class=\"line\">    var test = new Method(&#123;</span><br><span class=\"line\">        name: &apos;test&apos;,</span><br><span class=\"line\">        call: &apos;eth_test&apos;,</span><br><span class=\"line\">        params: 0</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">    var getStorageAt = new Method(&#123;</span><br><span class=\"line\">        name: &apos;getStorageAt&apos;,</span><br><span class=\"line\">        call: &apos;eth_getStorageAt&apos;,</span><br><span class=\"line\">        params: 3,</span><br><span class=\"line\">        inputFormatter: [null, utils.toHex, formatters.inputDefaultBlockNumberFormatter]</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t return [</span><br><span class=\"line\">\t \ttest</span><br><span class=\"line\">\t ]</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>修改js文件，要进行编译成go（bindata.go）文件才能生效。</p>\n<p>编译deps.go中有go:generate语句，用来重新生成bindata.go文件.</p>\n<p>生成bindata.go文件，需要安装go-bindata。安装方法如下。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go get github.com/jteeuwen/go-bindata</span><br><span class=\"line\">go install github.com/jteeuwen/go-bindata/go-bindata</span><br></pre></td></tr></table></figure>\n\n<p>安装后生成bindata.go文件，可以在IDE中点击生成，也可以在命令行中执行命令生成。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd $GOPATH/src/github.com/ethereum/go-ethereum/internal/jsre/deps</span><br><span class=\"line\">go-bindata -nometadata -pkg deps -o bindata.go bignumber.js web3.js</span><br><span class=\"line\">gofmt -w -s bindata.go</span><br></pre></td></tr></table></figure>\n\n<p>最后再进行编译即可<code>make all</code></p>\n<p>关于输入参数和输出参数，可在js层就输入的参数进行参数的数据类型转换，如上面示例中的getStorageAt的inputFormatter，参数为null的不会进行操作，utils.toHex应该是把参数encode成hex。formatter应该是构造结构体实例，下面放2个具体的formatter的构造</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var inputDefaultBlockNumberFormatter = function (blockNumber) &#123;</span><br><span class=\"line\">    if (blockNumber === undefined) &#123;</span><br><span class=\"line\">        return config.defaultBlock;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return inputBlockNumberFormatter(blockNumber);</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">var inputTransactionFormatter = function (options)&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    options.from = options.from || config.defaultAccount;</span><br><span class=\"line\">    options.from = inputAddressFormatter(options.from);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (options.to) &#123; // it might be contract creation</span><br><span class=\"line\">        options.to = inputAddressFormatter(options.to);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    [&apos;gasPrice&apos;, &apos;gas&apos;, &apos;value&apos;, &apos;nonce&apos;].filter(function (key) &#123;</span><br><span class=\"line\">        return options[key] !== undefined;</span><br><span class=\"line\">    &#125;).forEach(function(key)&#123;</span><br><span class=\"line\">        options[key] = utils.fromDecimal(options[key]);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    return options;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"eth_state","date":"2019-10-14T06:54:57.000Z","_content":"\n#### state trie的存储模型\n\n\n\nstate/Trie接口\n\n```\n// Trie is a Ethereum Merkle Trie.\ntype Trie interface {\n\tTryGet(key []byte) ([]byte, error)\n\tTryUpdate(key, value []byte) error\n\tTryDelete(key []byte) error\n\tCommit(onleaf trie.LeafCallback) (common.Hash, error)\n\tHash() common.Hash\n\tNodeIterator(startKey []byte) trie.NodeIterator\n\tGetKey([]byte) []byte // TODO(fjl): remove this when SecureTrie is removed\n\tProve(key []byte, fromLevel uint, proofDb ethdb.Putter) error\n}\n```\n\nTrie接口中定义的方法有Get、Put等操作/查询数据的方法，除此之外，Trie作为数据结构，在进行持久化时需要自定义持久化的数据结构，Commit方法则为进行持久化时的操作。\n\nTrie接口的实现主要是SecureTrie。cachedTrie结构中包含了匿名成员SecureTrie，所以cachedTrie也算Trie接口的实现。SecureTrie位于trie包下，内部是trie/Trie结构体(非接口)的封装，trie/Trie结构体是Trie数据结构的具体实现。\n\n\n\nstate/Database接口\n\n```\n// Database wraps access to tries and contract code.\ntype Database interface {\n\t// OpenTrie opens the main account trie.\n\tOpenTrie(root common.Hash) (Trie, error)\n\n\t// OpenStorageTrie opens the storage trie of an account.\n\tOpenStorageTrie(addrHash, root common.Hash) (Trie, error)\n\n\t// CopyTrie returns an independent copy of the given trie.\n\tCopyTrie(Trie) Trie\n\n\t// ContractCode retrieves a particular contract's code.\n\tContractCode(addrHash, codeHash common.Hash) ([]byte, error)\n\n\t// ContractCodeSize retrieves a particular contracts code's size.\n\tContractCodeSize(addrHash, codeHash common.Hash) (int, error)\n\n\t// TrieDB retrieves the low level trie database used for data storage.\n\tTrieDB() *trie.Database\n}\n```\n\nstate/Database接口，提供了从数据库读出数据一系列方法，主要是读出数据并组成Trie树数据结构。同时还提供了获取db的接口以供直接操作db。\n\ntrie.Database是底层数据库的直接封装实现，增删改查一系列方法。这里使用的是leveldb，leveldb采用key-value的形式，相关知识暂时不展开了。\n\n\n\n\n\ntrie包下的Trie是树的具体实现，Database是数据库的具体实现。\n\nstate包下的Trie接口是接口(= =)..  Database主要是围绕state进行的读取接口。其具体实现也是对trie/Trie和trie/Database的封装。cachingDB另外有一层缓存实现。\n\n\n\n\n\n#### 组织模型\n\nstatedb是key-value结构，value类型为stateObject，最后持久化到数据库的只有stateObject中的data，statedb封装了Database和Trie，可直接进行数据操作。从数据库的key-value来看，存储的value为stateObject中的data(Account类型)，组织trie树的key为addr，从数据操作上来看，state可直接进行账户的操作(setBalance、getBalance等等)，其实操作的都是对应stateObject中的data，最后Commit的时候持久化到数据库。中间还涉及别的很多东西，例如缓存、快照等，以供事务处理。\n\nstatedb内部封装的操作是可以直接存储数据库的，stateObject中data类型为account，内部直接封装了value的序列化和反序列化。如果想存储非account类型的数据呢，statedb也提供了相关方法`SetState`和`GetState`\n\n```\nvar (\n\tstateAddr = common.BytesToAddress([]byte{1, 1, 1, 1, 2})\n\tkey  = common.BytesToHash([]byte(\"names_service\"))\n)\nfunc TestSingleTrie(t *testing.T) {\n\tdb := ethdb.NewMemDatabase()\n\tstate, _ := state.New(common.Hash{}, state.NewDatabase(db))\n\tstate.SetState(stateAddr, key, common.BytesToHash([]byte{0, 0, 0}))\n\tstate.IntermediateRoot(false)\n\thash := state.GetState(stateAddr, key)\n\tif hash != common.BytesToHash([]byte{0, 0, 0}) {\n\t\tt.Error(\"unexpected err\")\n\t}\n}\n```\n\n\n\nsetState的value的类型为hash。也就是说setState只能存储一个哈希值。如果想存储别的东西，可以直接使用trie/database相关接口进行存储，然后将存储的key作为setState的value，查询时先getState获取key，然后再查询value，这样就可以进行索引到存储的value了。如智能合约代码的存储，stateObject.data中只存储了合约代码的hash，合约代码存放在另外的地方。\n\ntrie/Database下提供的直接存储/查询接口为\n\n```\n//查询\nfunc (db *Database) Node(hash common.Hash) ([]byte, error)\n//存储\nfunc (db *Database) InsertBlob(hash common.Hash, blob []byte)\n\n```\n\n\n\n智能合约代码的存储/读取就采用了以上两个方法\n\n```\n// ContractCode retrieves a particular contract's code.\nfunc (db *cachingDB) ContractCode(addrHash, codeHash common.Hash) ([]byte, error) {\n\tcode, err := db.db.Node(codeHash)\n\tif err == nil {\n\t\tdb.codeSizeCache.Add(codeHash, len(code))\n\t}\n\treturn code, err\n}\n\nfunc (s *StateDB) Commit(deleteEmptyObjects bool) (root common.Hash, err error) {\n  ...\n     // Write any contract code associated with the state object\n     if stateObject.code != nil && stateObject.dirtyCode {\n\t\t  s.db.TrieDB().InsertBlob(common.BytesToHash(stateObject.CodeHash()), stateObject.code)\n\t\t  stateObject.dirtyCode = false\n\t  }\n   ...\n}\n```\n\n\n\n以下示例为存储额外的Trie\n\n```\nfunc TestSingleTrie(t *testing.T) {\n\tdb := ethdb.NewMemDatabase()\n\tstate, _ := state.New(common.Hash{}, state.NewDatabase(db))\n\tstate.SetState(stateAddr, key, common.BytesToHash([]byte{0, 0, 0}))\n\tstate.IntermediateRoot(false)\n\thash := state.GetState(stateAddr, key)\n\tif hash != common.BytesToHash([]byte{0, 0, 0}) {\n\t\tt.Error(\"unexpected err\")\n\t}\n\n\n\terr = trie.TryUpdate([]byte(\"anny\"), []byte(\"0xccccc\"))\n\tif err != nil {\n\t\tt.Error(\"update err, \", err)\n\t}\n\tt.Log(trie.Hash())\n\ttrie.Commit(nil)\n\tt.Log(trie.Hash())\n\terr = trie.TryUpdate([]byte(\"anny\"), []byte(\"0xccccb\"))\n\tif err != nil {\n\t\tt.Error(\"update err, \", err)\n\t}\n\terr = trie.TryUpdate([]byte(\"jim\"), []byte(\"0xbbbbbc\"))\n\tif err != nil {\n\t\tt.Error(\"update err, \", err)\n\t}\n\ttrie.Commit(nil)\n\tt.Log(trie.Hash())\n\tstate.SetState(stateAddr, key, trie.Hash())\n\thash = state.GetState(stateAddr, key)\n\tif hash != trie.Hash() {\n\t\tt.Error(\"unexpected err\")\n\t}\n\ttrie1, err := state.Database().OpenStorageTrie(common.Hash{}, hash)\n\tif err != nil {\n\t\tt.Error(\"unexpected err\", err)\n\t}\n\tvalue, err := trie1.TryGet([]byte(\"anny\"))\n\tif err != nil {\n\t\tt.Error(\"unexpected err\", err)\n\t}\n\tif string(value) != \"0xccccb\" {\n\t\tt.Error(\"unexpected err\")\n\t}\n}\n```\n","source":"_posts/eth-state.md","raw":"---\ntitle: eth_state\ncategories:\n  - eth\ndate: 2019-10-14 14:54:57\ntags:\n---\n\n#### state trie的存储模型\n\n\n\nstate/Trie接口\n\n```\n// Trie is a Ethereum Merkle Trie.\ntype Trie interface {\n\tTryGet(key []byte) ([]byte, error)\n\tTryUpdate(key, value []byte) error\n\tTryDelete(key []byte) error\n\tCommit(onleaf trie.LeafCallback) (common.Hash, error)\n\tHash() common.Hash\n\tNodeIterator(startKey []byte) trie.NodeIterator\n\tGetKey([]byte) []byte // TODO(fjl): remove this when SecureTrie is removed\n\tProve(key []byte, fromLevel uint, proofDb ethdb.Putter) error\n}\n```\n\nTrie接口中定义的方法有Get、Put等操作/查询数据的方法，除此之外，Trie作为数据结构，在进行持久化时需要自定义持久化的数据结构，Commit方法则为进行持久化时的操作。\n\nTrie接口的实现主要是SecureTrie。cachedTrie结构中包含了匿名成员SecureTrie，所以cachedTrie也算Trie接口的实现。SecureTrie位于trie包下，内部是trie/Trie结构体(非接口)的封装，trie/Trie结构体是Trie数据结构的具体实现。\n\n\n\nstate/Database接口\n\n```\n// Database wraps access to tries and contract code.\ntype Database interface {\n\t// OpenTrie opens the main account trie.\n\tOpenTrie(root common.Hash) (Trie, error)\n\n\t// OpenStorageTrie opens the storage trie of an account.\n\tOpenStorageTrie(addrHash, root common.Hash) (Trie, error)\n\n\t// CopyTrie returns an independent copy of the given trie.\n\tCopyTrie(Trie) Trie\n\n\t// ContractCode retrieves a particular contract's code.\n\tContractCode(addrHash, codeHash common.Hash) ([]byte, error)\n\n\t// ContractCodeSize retrieves a particular contracts code's size.\n\tContractCodeSize(addrHash, codeHash common.Hash) (int, error)\n\n\t// TrieDB retrieves the low level trie database used for data storage.\n\tTrieDB() *trie.Database\n}\n```\n\nstate/Database接口，提供了从数据库读出数据一系列方法，主要是读出数据并组成Trie树数据结构。同时还提供了获取db的接口以供直接操作db。\n\ntrie.Database是底层数据库的直接封装实现，增删改查一系列方法。这里使用的是leveldb，leveldb采用key-value的形式，相关知识暂时不展开了。\n\n\n\n\n\ntrie包下的Trie是树的具体实现，Database是数据库的具体实现。\n\nstate包下的Trie接口是接口(= =)..  Database主要是围绕state进行的读取接口。其具体实现也是对trie/Trie和trie/Database的封装。cachingDB另外有一层缓存实现。\n\n\n\n\n\n#### 组织模型\n\nstatedb是key-value结构，value类型为stateObject，最后持久化到数据库的只有stateObject中的data，statedb封装了Database和Trie，可直接进行数据操作。从数据库的key-value来看，存储的value为stateObject中的data(Account类型)，组织trie树的key为addr，从数据操作上来看，state可直接进行账户的操作(setBalance、getBalance等等)，其实操作的都是对应stateObject中的data，最后Commit的时候持久化到数据库。中间还涉及别的很多东西，例如缓存、快照等，以供事务处理。\n\nstatedb内部封装的操作是可以直接存储数据库的，stateObject中data类型为account，内部直接封装了value的序列化和反序列化。如果想存储非account类型的数据呢，statedb也提供了相关方法`SetState`和`GetState`\n\n```\nvar (\n\tstateAddr = common.BytesToAddress([]byte{1, 1, 1, 1, 2})\n\tkey  = common.BytesToHash([]byte(\"names_service\"))\n)\nfunc TestSingleTrie(t *testing.T) {\n\tdb := ethdb.NewMemDatabase()\n\tstate, _ := state.New(common.Hash{}, state.NewDatabase(db))\n\tstate.SetState(stateAddr, key, common.BytesToHash([]byte{0, 0, 0}))\n\tstate.IntermediateRoot(false)\n\thash := state.GetState(stateAddr, key)\n\tif hash != common.BytesToHash([]byte{0, 0, 0}) {\n\t\tt.Error(\"unexpected err\")\n\t}\n}\n```\n\n\n\nsetState的value的类型为hash。也就是说setState只能存储一个哈希值。如果想存储别的东西，可以直接使用trie/database相关接口进行存储，然后将存储的key作为setState的value，查询时先getState获取key，然后再查询value，这样就可以进行索引到存储的value了。如智能合约代码的存储，stateObject.data中只存储了合约代码的hash，合约代码存放在另外的地方。\n\ntrie/Database下提供的直接存储/查询接口为\n\n```\n//查询\nfunc (db *Database) Node(hash common.Hash) ([]byte, error)\n//存储\nfunc (db *Database) InsertBlob(hash common.Hash, blob []byte)\n\n```\n\n\n\n智能合约代码的存储/读取就采用了以上两个方法\n\n```\n// ContractCode retrieves a particular contract's code.\nfunc (db *cachingDB) ContractCode(addrHash, codeHash common.Hash) ([]byte, error) {\n\tcode, err := db.db.Node(codeHash)\n\tif err == nil {\n\t\tdb.codeSizeCache.Add(codeHash, len(code))\n\t}\n\treturn code, err\n}\n\nfunc (s *StateDB) Commit(deleteEmptyObjects bool) (root common.Hash, err error) {\n  ...\n     // Write any contract code associated with the state object\n     if stateObject.code != nil && stateObject.dirtyCode {\n\t\t  s.db.TrieDB().InsertBlob(common.BytesToHash(stateObject.CodeHash()), stateObject.code)\n\t\t  stateObject.dirtyCode = false\n\t  }\n   ...\n}\n```\n\n\n\n以下示例为存储额外的Trie\n\n```\nfunc TestSingleTrie(t *testing.T) {\n\tdb := ethdb.NewMemDatabase()\n\tstate, _ := state.New(common.Hash{}, state.NewDatabase(db))\n\tstate.SetState(stateAddr, key, common.BytesToHash([]byte{0, 0, 0}))\n\tstate.IntermediateRoot(false)\n\thash := state.GetState(stateAddr, key)\n\tif hash != common.BytesToHash([]byte{0, 0, 0}) {\n\t\tt.Error(\"unexpected err\")\n\t}\n\n\n\terr = trie.TryUpdate([]byte(\"anny\"), []byte(\"0xccccc\"))\n\tif err != nil {\n\t\tt.Error(\"update err, \", err)\n\t}\n\tt.Log(trie.Hash())\n\ttrie.Commit(nil)\n\tt.Log(trie.Hash())\n\terr = trie.TryUpdate([]byte(\"anny\"), []byte(\"0xccccb\"))\n\tif err != nil {\n\t\tt.Error(\"update err, \", err)\n\t}\n\terr = trie.TryUpdate([]byte(\"jim\"), []byte(\"0xbbbbbc\"))\n\tif err != nil {\n\t\tt.Error(\"update err, \", err)\n\t}\n\ttrie.Commit(nil)\n\tt.Log(trie.Hash())\n\tstate.SetState(stateAddr, key, trie.Hash())\n\thash = state.GetState(stateAddr, key)\n\tif hash != trie.Hash() {\n\t\tt.Error(\"unexpected err\")\n\t}\n\ttrie1, err := state.Database().OpenStorageTrie(common.Hash{}, hash)\n\tif err != nil {\n\t\tt.Error(\"unexpected err\", err)\n\t}\n\tvalue, err := trie1.TryGet([]byte(\"anny\"))\n\tif err != nil {\n\t\tt.Error(\"unexpected err\", err)\n\t}\n\tif string(value) != \"0xccccb\" {\n\t\tt.Error(\"unexpected err\")\n\t}\n}\n```\n","slug":"eth-state","published":1,"updated":"2019-10-14T06:55:20.646Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69to000rt6xvlnk8foeu","content":"<h4 id=\"state-trie的存储模型\"><a href=\"#state-trie的存储模型\" class=\"headerlink\" title=\"state trie的存储模型\"></a>state trie的存储模型</h4><p>state/Trie接口</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Trie is a Ethereum Merkle Trie.</span><br><span class=\"line\">type Trie interface &#123;</span><br><span class=\"line\">\tTryGet(key []byte) ([]byte, error)</span><br><span class=\"line\">\tTryUpdate(key, value []byte) error</span><br><span class=\"line\">\tTryDelete(key []byte) error</span><br><span class=\"line\">\tCommit(onleaf trie.LeafCallback) (common.Hash, error)</span><br><span class=\"line\">\tHash() common.Hash</span><br><span class=\"line\">\tNodeIterator(startKey []byte) trie.NodeIterator</span><br><span class=\"line\">\tGetKey([]byte) []byte // TODO(fjl): remove this when SecureTrie is removed</span><br><span class=\"line\">\tProve(key []byte, fromLevel uint, proofDb ethdb.Putter) error</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Trie接口中定义的方法有Get、Put等操作/查询数据的方法，除此之外，Trie作为数据结构，在进行持久化时需要自定义持久化的数据结构，Commit方法则为进行持久化时的操作。</p>\n<p>Trie接口的实现主要是SecureTrie。cachedTrie结构中包含了匿名成员SecureTrie，所以cachedTrie也算Trie接口的实现。SecureTrie位于trie包下，内部是trie/Trie结构体(非接口)的封装，trie/Trie结构体是Trie数据结构的具体实现。</p>\n<p>state/Database接口</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Database wraps access to tries and contract code.</span><br><span class=\"line\">type Database interface &#123;</span><br><span class=\"line\">\t// OpenTrie opens the main account trie.</span><br><span class=\"line\">\tOpenTrie(root common.Hash) (Trie, error)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// OpenStorageTrie opens the storage trie of an account.</span><br><span class=\"line\">\tOpenStorageTrie(addrHash, root common.Hash) (Trie, error)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// CopyTrie returns an independent copy of the given trie.</span><br><span class=\"line\">\tCopyTrie(Trie) Trie</span><br><span class=\"line\"></span><br><span class=\"line\">\t// ContractCode retrieves a particular contract&apos;s code.</span><br><span class=\"line\">\tContractCode(addrHash, codeHash common.Hash) ([]byte, error)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// ContractCodeSize retrieves a particular contracts code&apos;s size.</span><br><span class=\"line\">\tContractCodeSize(addrHash, codeHash common.Hash) (int, error)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// TrieDB retrieves the low level trie database used for data storage.</span><br><span class=\"line\">\tTrieDB() *trie.Database</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>state/Database接口，提供了从数据库读出数据一系列方法，主要是读出数据并组成Trie树数据结构。同时还提供了获取db的接口以供直接操作db。</p>\n<p>trie.Database是底层数据库的直接封装实现，增删改查一系列方法。这里使用的是leveldb，leveldb采用key-value的形式，相关知识暂时不展开了。</p>\n<p>trie包下的Trie是树的具体实现，Database是数据库的具体实现。</p>\n<p>state包下的Trie接口是接口(= =)..  Database主要是围绕state进行的读取接口。其具体实现也是对trie/Trie和trie/Database的封装。cachingDB另外有一层缓存实现。</p>\n<h4 id=\"组织模型\"><a href=\"#组织模型\" class=\"headerlink\" title=\"组织模型\"></a>组织模型</h4><p>statedb是key-value结构，value类型为stateObject，最后持久化到数据库的只有stateObject中的data，statedb封装了Database和Trie，可直接进行数据操作。从数据库的key-value来看，存储的value为stateObject中的data(Account类型)，组织trie树的key为addr，从数据操作上来看，state可直接进行账户的操作(setBalance、getBalance等等)，其实操作的都是对应stateObject中的data，最后Commit的时候持久化到数据库。中间还涉及别的很多东西，例如缓存、快照等，以供事务处理。</p>\n<p>statedb内部封装的操作是可以直接存储数据库的，stateObject中data类型为account，内部直接封装了value的序列化和反序列化。如果想存储非account类型的数据呢，statedb也提供了相关方法<code>SetState</code>和<code>GetState</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var (</span><br><span class=\"line\">\tstateAddr = common.BytesToAddress([]byte&#123;1, 1, 1, 1, 2&#125;)</span><br><span class=\"line\">\tkey  = common.BytesToHash([]byte(&quot;names_service&quot;))</span><br><span class=\"line\">)</span><br><span class=\"line\">func TestSingleTrie(t *testing.T) &#123;</span><br><span class=\"line\">\tdb := ethdb.NewMemDatabase()</span><br><span class=\"line\">\tstate, _ := state.New(common.Hash&#123;&#125;, state.NewDatabase(db))</span><br><span class=\"line\">\tstate.SetState(stateAddr, key, common.BytesToHash([]byte&#123;0, 0, 0&#125;))</span><br><span class=\"line\">\tstate.IntermediateRoot(false)</span><br><span class=\"line\">\thash := state.GetState(stateAddr, key)</span><br><span class=\"line\">\tif hash != common.BytesToHash([]byte&#123;0, 0, 0&#125;) &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>setState的value的类型为hash。也就是说setState只能存储一个哈希值。如果想存储别的东西，可以直接使用trie/database相关接口进行存储，然后将存储的key作为setState的value，查询时先getState获取key，然后再查询value，这样就可以进行索引到存储的value了。如智能合约代码的存储，stateObject.data中只存储了合约代码的hash，合约代码存放在另外的地方。</p>\n<p>trie/Database下提供的直接存储/查询接口为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询</span><br><span class=\"line\">func (db *Database) Node(hash common.Hash) ([]byte, error)</span><br><span class=\"line\">//存储</span><br><span class=\"line\">func (db *Database) InsertBlob(hash common.Hash, blob []byte)</span><br></pre></td></tr></table></figure>\n\n<p>智能合约代码的存储/读取就采用了以上两个方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// ContractCode retrieves a particular contract&apos;s code.</span><br><span class=\"line\">func (db *cachingDB) ContractCode(addrHash, codeHash common.Hash) ([]byte, error) &#123;</span><br><span class=\"line\">\tcode, err := db.db.Node(codeHash)</span><br><span class=\"line\">\tif err == nil &#123;</span><br><span class=\"line\">\t\tdb.codeSizeCache.Add(codeHash, len(code))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn code, err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (s *StateDB) Commit(deleteEmptyObjects bool) (root common.Hash, err error) &#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">     // Write any contract code associated with the state object</span><br><span class=\"line\">     if stateObject.code != nil &amp;&amp; stateObject.dirtyCode &#123;</span><br><span class=\"line\">\t\t  s.db.TrieDB().InsertBlob(common.BytesToHash(stateObject.CodeHash()), stateObject.code)</span><br><span class=\"line\">\t\t  stateObject.dirtyCode = false</span><br><span class=\"line\">\t  &#125;</span><br><span class=\"line\">   ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>以下示例为存储额外的Trie</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func TestSingleTrie(t *testing.T) &#123;</span><br><span class=\"line\">\tdb := ethdb.NewMemDatabase()</span><br><span class=\"line\">\tstate, _ := state.New(common.Hash&#123;&#125;, state.NewDatabase(db))</span><br><span class=\"line\">\tstate.SetState(stateAddr, key, common.BytesToHash([]byte&#123;0, 0, 0&#125;))</span><br><span class=\"line\">\tstate.IntermediateRoot(false)</span><br><span class=\"line\">\thash := state.GetState(stateAddr, key)</span><br><span class=\"line\">\tif hash != common.BytesToHash([]byte&#123;0, 0, 0&#125;) &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\terr = trie.TryUpdate([]byte(&quot;anny&quot;), []byte(&quot;0xccccc&quot;))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;update err, &quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tt.Log(trie.Hash())</span><br><span class=\"line\">\ttrie.Commit(nil)</span><br><span class=\"line\">\tt.Log(trie.Hash())</span><br><span class=\"line\">\terr = trie.TryUpdate([]byte(&quot;anny&quot;), []byte(&quot;0xccccb&quot;))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;update err, &quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\terr = trie.TryUpdate([]byte(&quot;jim&quot;), []byte(&quot;0xbbbbbc&quot;))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;update err, &quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\ttrie.Commit(nil)</span><br><span class=\"line\">\tt.Log(trie.Hash())</span><br><span class=\"line\">\tstate.SetState(stateAddr, key, trie.Hash())</span><br><span class=\"line\">\thash = state.GetState(stateAddr, key)</span><br><span class=\"line\">\tif hash != trie.Hash() &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\ttrie1, err := state.Database().OpenStorageTrie(common.Hash&#123;&#125;, hash)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tvalue, err := trie1.TryGet([]byte(&quot;anny&quot;))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif string(value) != &quot;0xccccb&quot; &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h4 id=\"state-trie的存储模型\"><a href=\"#state-trie的存储模型\" class=\"headerlink\" title=\"state trie的存储模型\"></a>state trie的存储模型</h4><p>state/Trie接口</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Trie is a Ethereum Merkle Trie.</span><br><span class=\"line\">type Trie interface &#123;</span><br><span class=\"line\">\tTryGet(key []byte) ([]byte, error)</span><br><span class=\"line\">\tTryUpdate(key, value []byte) error</span><br><span class=\"line\">\tTryDelete(key []byte) error</span><br><span class=\"line\">\tCommit(onleaf trie.LeafCallback) (common.Hash, error)</span><br><span class=\"line\">\tHash() common.Hash</span><br><span class=\"line\">\tNodeIterator(startKey []byte) trie.NodeIterator</span><br><span class=\"line\">\tGetKey([]byte) []byte // TODO(fjl): remove this when SecureTrie is removed</span><br><span class=\"line\">\tProve(key []byte, fromLevel uint, proofDb ethdb.Putter) error</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Trie接口中定义的方法有Get、Put等操作/查询数据的方法，除此之外，Trie作为数据结构，在进行持久化时需要自定义持久化的数据结构，Commit方法则为进行持久化时的操作。</p>\n<p>Trie接口的实现主要是SecureTrie。cachedTrie结构中包含了匿名成员SecureTrie，所以cachedTrie也算Trie接口的实现。SecureTrie位于trie包下，内部是trie/Trie结构体(非接口)的封装，trie/Trie结构体是Trie数据结构的具体实现。</p>\n<p>state/Database接口</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Database wraps access to tries and contract code.</span><br><span class=\"line\">type Database interface &#123;</span><br><span class=\"line\">\t// OpenTrie opens the main account trie.</span><br><span class=\"line\">\tOpenTrie(root common.Hash) (Trie, error)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// OpenStorageTrie opens the storage trie of an account.</span><br><span class=\"line\">\tOpenStorageTrie(addrHash, root common.Hash) (Trie, error)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// CopyTrie returns an independent copy of the given trie.</span><br><span class=\"line\">\tCopyTrie(Trie) Trie</span><br><span class=\"line\"></span><br><span class=\"line\">\t// ContractCode retrieves a particular contract&apos;s code.</span><br><span class=\"line\">\tContractCode(addrHash, codeHash common.Hash) ([]byte, error)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// ContractCodeSize retrieves a particular contracts code&apos;s size.</span><br><span class=\"line\">\tContractCodeSize(addrHash, codeHash common.Hash) (int, error)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// TrieDB retrieves the low level trie database used for data storage.</span><br><span class=\"line\">\tTrieDB() *trie.Database</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>state/Database接口，提供了从数据库读出数据一系列方法，主要是读出数据并组成Trie树数据结构。同时还提供了获取db的接口以供直接操作db。</p>\n<p>trie.Database是底层数据库的直接封装实现，增删改查一系列方法。这里使用的是leveldb，leveldb采用key-value的形式，相关知识暂时不展开了。</p>\n<p>trie包下的Trie是树的具体实现，Database是数据库的具体实现。</p>\n<p>state包下的Trie接口是接口(= =)..  Database主要是围绕state进行的读取接口。其具体实现也是对trie/Trie和trie/Database的封装。cachingDB另外有一层缓存实现。</p>\n<h4 id=\"组织模型\"><a href=\"#组织模型\" class=\"headerlink\" title=\"组织模型\"></a>组织模型</h4><p>statedb是key-value结构，value类型为stateObject，最后持久化到数据库的只有stateObject中的data，statedb封装了Database和Trie，可直接进行数据操作。从数据库的key-value来看，存储的value为stateObject中的data(Account类型)，组织trie树的key为addr，从数据操作上来看，state可直接进行账户的操作(setBalance、getBalance等等)，其实操作的都是对应stateObject中的data，最后Commit的时候持久化到数据库。中间还涉及别的很多东西，例如缓存、快照等，以供事务处理。</p>\n<p>statedb内部封装的操作是可以直接存储数据库的，stateObject中data类型为account，内部直接封装了value的序列化和反序列化。如果想存储非account类型的数据呢，statedb也提供了相关方法<code>SetState</code>和<code>GetState</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var (</span><br><span class=\"line\">\tstateAddr = common.BytesToAddress([]byte&#123;1, 1, 1, 1, 2&#125;)</span><br><span class=\"line\">\tkey  = common.BytesToHash([]byte(&quot;names_service&quot;))</span><br><span class=\"line\">)</span><br><span class=\"line\">func TestSingleTrie(t *testing.T) &#123;</span><br><span class=\"line\">\tdb := ethdb.NewMemDatabase()</span><br><span class=\"line\">\tstate, _ := state.New(common.Hash&#123;&#125;, state.NewDatabase(db))</span><br><span class=\"line\">\tstate.SetState(stateAddr, key, common.BytesToHash([]byte&#123;0, 0, 0&#125;))</span><br><span class=\"line\">\tstate.IntermediateRoot(false)</span><br><span class=\"line\">\thash := state.GetState(stateAddr, key)</span><br><span class=\"line\">\tif hash != common.BytesToHash([]byte&#123;0, 0, 0&#125;) &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>setState的value的类型为hash。也就是说setState只能存储一个哈希值。如果想存储别的东西，可以直接使用trie/database相关接口进行存储，然后将存储的key作为setState的value，查询时先getState获取key，然后再查询value，这样就可以进行索引到存储的value了。如智能合约代码的存储，stateObject.data中只存储了合约代码的hash，合约代码存放在另外的地方。</p>\n<p>trie/Database下提供的直接存储/查询接口为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//查询</span><br><span class=\"line\">func (db *Database) Node(hash common.Hash) ([]byte, error)</span><br><span class=\"line\">//存储</span><br><span class=\"line\">func (db *Database) InsertBlob(hash common.Hash, blob []byte)</span><br></pre></td></tr></table></figure>\n\n<p>智能合约代码的存储/读取就采用了以上两个方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// ContractCode retrieves a particular contract&apos;s code.</span><br><span class=\"line\">func (db *cachingDB) ContractCode(addrHash, codeHash common.Hash) ([]byte, error) &#123;</span><br><span class=\"line\">\tcode, err := db.db.Node(codeHash)</span><br><span class=\"line\">\tif err == nil &#123;</span><br><span class=\"line\">\t\tdb.codeSizeCache.Add(codeHash, len(code))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn code, err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (s *StateDB) Commit(deleteEmptyObjects bool) (root common.Hash, err error) &#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">     // Write any contract code associated with the state object</span><br><span class=\"line\">     if stateObject.code != nil &amp;&amp; stateObject.dirtyCode &#123;</span><br><span class=\"line\">\t\t  s.db.TrieDB().InsertBlob(common.BytesToHash(stateObject.CodeHash()), stateObject.code)</span><br><span class=\"line\">\t\t  stateObject.dirtyCode = false</span><br><span class=\"line\">\t  &#125;</span><br><span class=\"line\">   ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>以下示例为存储额外的Trie</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func TestSingleTrie(t *testing.T) &#123;</span><br><span class=\"line\">\tdb := ethdb.NewMemDatabase()</span><br><span class=\"line\">\tstate, _ := state.New(common.Hash&#123;&#125;, state.NewDatabase(db))</span><br><span class=\"line\">\tstate.SetState(stateAddr, key, common.BytesToHash([]byte&#123;0, 0, 0&#125;))</span><br><span class=\"line\">\tstate.IntermediateRoot(false)</span><br><span class=\"line\">\thash := state.GetState(stateAddr, key)</span><br><span class=\"line\">\tif hash != common.BytesToHash([]byte&#123;0, 0, 0&#125;) &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\terr = trie.TryUpdate([]byte(&quot;anny&quot;), []byte(&quot;0xccccc&quot;))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;update err, &quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tt.Log(trie.Hash())</span><br><span class=\"line\">\ttrie.Commit(nil)</span><br><span class=\"line\">\tt.Log(trie.Hash())</span><br><span class=\"line\">\terr = trie.TryUpdate([]byte(&quot;anny&quot;), []byte(&quot;0xccccb&quot;))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;update err, &quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\terr = trie.TryUpdate([]byte(&quot;jim&quot;), []byte(&quot;0xbbbbbc&quot;))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;update err, &quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\ttrie.Commit(nil)</span><br><span class=\"line\">\tt.Log(trie.Hash())</span><br><span class=\"line\">\tstate.SetState(stateAddr, key, trie.Hash())</span><br><span class=\"line\">\thash = state.GetState(stateAddr, key)</span><br><span class=\"line\">\tif hash != trie.Hash() &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\ttrie1, err := state.Database().OpenStorageTrie(common.Hash&#123;&#125;, hash)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tvalue, err := trie1.TryGet([]byte(&quot;anny&quot;))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif string(value) != &quot;0xccccb&quot; &#123;</span><br><span class=\"line\">\t\tt.Error(&quot;unexpected err&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"fabric_pbft","date":"2019-04-14T07:06:52.000Z","_content":"\n#### fabric consensus pbft VS neo dbft\n\n\n\n#### pbft\n\n**pbft分为3个阶段，pre-prepare, prepare, commit**。\n\n一直很好奇为什么是3个阶段，为什么这三个阶段就能保证拜占庭呢？\n\n- 首先， pre-prepare阶段是主节点发给各个从节点的，pre-prepare消息中包括共识消息、序号等\n- 从节点收到pre-prepare消息后，发其他节点广播prepare消息，这是为了告诉别人自己收到的消息是什么\n- 从节点收到有效的prepare消息足够多(f+1)，代表有f+1个节点收到的消息是一样的，故**证明消息的真实可信性**。发出commit，commit为自身签名消息，代表自己同意消息。\n- 只要有1个节点收到的commit消息数量有f+1，则可以确认消息成功。\n\n\n\n#### dbft\n\ndbft中，d是授权的意思，授权拜占庭，这里忽略验证人的选择，仅仅就共识过程进行讨论。\n\n**共识过程只有两个阶段，prepare, prepare-response**\n\n- 首先，prepare阶段，主节点发给各个从节点的，prepare消息中包括共识消息、序号等\n- 从节点收到prepare消息后，就消息进行验证判断，如同意消息，则发送prepare-response消息\n- 从节点收集prepare-response消息，如接收到的消息数量达到阈值，则确认共识成功\n\n\n\n二者对比起来，很明显，neo的dbft缺少了验证消息真实可信性，即无法判断主节点发送给大家的prepare消息是相同的还是不同的。当然，因为回复的response是对消息的签名，是否可以从签名的特性出发，判断对方签名的数据是否与自身签名的数据是相同的。这一点，在代码里来看，暂时还没看到具体解释。\n","source":"_posts/fabric-pbft.md","raw":"---\ntitle: fabric_pbft\ncategories:\n  - fabric\ndate: 2019-4-14 15:06:52\ntags:\n---\n\n#### fabric consensus pbft VS neo dbft\n\n\n\n#### pbft\n\n**pbft分为3个阶段，pre-prepare, prepare, commit**。\n\n一直很好奇为什么是3个阶段，为什么这三个阶段就能保证拜占庭呢？\n\n- 首先， pre-prepare阶段是主节点发给各个从节点的，pre-prepare消息中包括共识消息、序号等\n- 从节点收到pre-prepare消息后，发其他节点广播prepare消息，这是为了告诉别人自己收到的消息是什么\n- 从节点收到有效的prepare消息足够多(f+1)，代表有f+1个节点收到的消息是一样的，故**证明消息的真实可信性**。发出commit，commit为自身签名消息，代表自己同意消息。\n- 只要有1个节点收到的commit消息数量有f+1，则可以确认消息成功。\n\n\n\n#### dbft\n\ndbft中，d是授权的意思，授权拜占庭，这里忽略验证人的选择，仅仅就共识过程进行讨论。\n\n**共识过程只有两个阶段，prepare, prepare-response**\n\n- 首先，prepare阶段，主节点发给各个从节点的，prepare消息中包括共识消息、序号等\n- 从节点收到prepare消息后，就消息进行验证判断，如同意消息，则发送prepare-response消息\n- 从节点收集prepare-response消息，如接收到的消息数量达到阈值，则确认共识成功\n\n\n\n二者对比起来，很明显，neo的dbft缺少了验证消息真实可信性，即无法判断主节点发送给大家的prepare消息是相同的还是不同的。当然，因为回复的response是对消息的签名，是否可以从签名的特性出发，判断对方签名的数据是否与自身签名的数据是相同的。这一点，在代码里来看，暂时还没看到具体解释。\n","slug":"fabric-pbft","published":1,"updated":"2019-10-14T07:09:50.625Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69tt000tt6xvauuq95uf","content":"<h4 id=\"fabric-consensus-pbft-VS-neo-dbft\"><a href=\"#fabric-consensus-pbft-VS-neo-dbft\" class=\"headerlink\" title=\"fabric consensus pbft VS neo dbft\"></a>fabric consensus pbft VS neo dbft</h4><h4 id=\"pbft\"><a href=\"#pbft\" class=\"headerlink\" title=\"pbft\"></a>pbft</h4><p><strong>pbft分为3个阶段，pre-prepare, prepare, commit</strong>。</p>\n<p>一直很好奇为什么是3个阶段，为什么这三个阶段就能保证拜占庭呢？</p>\n<ul>\n<li>首先， pre-prepare阶段是主节点发给各个从节点的，pre-prepare消息中包括共识消息、序号等</li>\n<li>从节点收到pre-prepare消息后，发其他节点广播prepare消息，这是为了告诉别人自己收到的消息是什么</li>\n<li>从节点收到有效的prepare消息足够多(f+1)，代表有f+1个节点收到的消息是一样的，故<strong>证明消息的真实可信性</strong>。发出commit，commit为自身签名消息，代表自己同意消息。</li>\n<li>只要有1个节点收到的commit消息数量有f+1，则可以确认消息成功。</li>\n</ul>\n<h4 id=\"dbft\"><a href=\"#dbft\" class=\"headerlink\" title=\"dbft\"></a>dbft</h4><p>dbft中，d是授权的意思，授权拜占庭，这里忽略验证人的选择，仅仅就共识过程进行讨论。</p>\n<p><strong>共识过程只有两个阶段，prepare, prepare-response</strong></p>\n<ul>\n<li>首先，prepare阶段，主节点发给各个从节点的，prepare消息中包括共识消息、序号等</li>\n<li>从节点收到prepare消息后，就消息进行验证判断，如同意消息，则发送prepare-response消息</li>\n<li>从节点收集prepare-response消息，如接收到的消息数量达到阈值，则确认共识成功</li>\n</ul>\n<p>二者对比起来，很明显，neo的dbft缺少了验证消息真实可信性，即无法判断主节点发送给大家的prepare消息是相同的还是不同的。当然，因为回复的response是对消息的签名，是否可以从签名的特性出发，判断对方签名的数据是否与自身签名的数据是相同的。这一点，在代码里来看，暂时还没看到具体解释。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h4 id=\"fabric-consensus-pbft-VS-neo-dbft\"><a href=\"#fabric-consensus-pbft-VS-neo-dbft\" class=\"headerlink\" title=\"fabric consensus pbft VS neo dbft\"></a>fabric consensus pbft VS neo dbft</h4><h4 id=\"pbft\"><a href=\"#pbft\" class=\"headerlink\" title=\"pbft\"></a>pbft</h4><p><strong>pbft分为3个阶段，pre-prepare, prepare, commit</strong>。</p>\n<p>一直很好奇为什么是3个阶段，为什么这三个阶段就能保证拜占庭呢？</p>\n<ul>\n<li>首先， pre-prepare阶段是主节点发给各个从节点的，pre-prepare消息中包括共识消息、序号等</li>\n<li>从节点收到pre-prepare消息后，发其他节点广播prepare消息，这是为了告诉别人自己收到的消息是什么</li>\n<li>从节点收到有效的prepare消息足够多(f+1)，代表有f+1个节点收到的消息是一样的，故<strong>证明消息的真实可信性</strong>。发出commit，commit为自身签名消息，代表自己同意消息。</li>\n<li>只要有1个节点收到的commit消息数量有f+1，则可以确认消息成功。</li>\n</ul>\n<h4 id=\"dbft\"><a href=\"#dbft\" class=\"headerlink\" title=\"dbft\"></a>dbft</h4><p>dbft中，d是授权的意思，授权拜占庭，这里忽略验证人的选择，仅仅就共识过程进行讨论。</p>\n<p><strong>共识过程只有两个阶段，prepare, prepare-response</strong></p>\n<ul>\n<li>首先，prepare阶段，主节点发给各个从节点的，prepare消息中包括共识消息、序号等</li>\n<li>从节点收到prepare消息后，就消息进行验证判断，如同意消息，则发送prepare-response消息</li>\n<li>从节点收集prepare-response消息，如接收到的消息数量达到阈值，则确认共识成功</li>\n</ul>\n<p>二者对比起来，很明显，neo的dbft缺少了验证消息真实可信性，即无法判断主节点发送给大家的prepare消息是相同的还是不同的。当然，因为回复的response是对消息的签名，是否可以从签名的特性出发，判断对方签名的数据是否与自身签名的数据是相同的。这一点，在代码里来看，暂时还没看到具体解释。</p>\n"},{"title":"fabric_code_consensus_event","date":"2019-04-14T07:07:25.000Z","_content":"\n## fabric consensus event源码解析\n\n代码位置为 fabric/consensus/...\n\n想写pbft的代码解析来着。看到里面的事件流，设计得很赞，学习一下。\n\n\n\n#### Manager 事件管理\n\n主要实现的功能是事件通道的处理，通过相关接口，写入数据到通道中，数据处理方提供处理方法即可，不需关注通道的实现。\n\n```\n//首先，接口事件要做的事主要是，内部提供一个事件通道，暴露出往通道写数据的接口，以及数据处理接收方法，接收方法由Receiver提供，Magager的实现者需要实现数据从通道读出来，回调给接收者的过程。\ntype Manager interface {\n\tInject(Event)         //一个暂时的接口，跳过了通道，直接给到接收者，只限于Manager本线程使用，因为没有了通道做数据保护\n\tQueue() chan<- Event  //提供一个只写通道，用于往通道内写数据\n\tSetReceiver(Receiver) //设置接收者，接收者需要实现接收方法，在Receiver接口中有具体方法定义\n\tStart()               // 启动Manager线程\n\tHalt()                // 停止manager线程\n}\n```\n\n\n\n##### Receiver接口\n\n```\ntype Receiver interface {\n\t//事件处理的地方会调用这个方法传递事件给到Receiver,注意到这个设计的是返回值也是Event事件，这个在之后的地方进行详细解释\n\tProcessEvent(e Event) Event\n}\n```\n\n\n\n##### Manager实现\n\n```\ntype managerImpl struct {\n\tthreaded  //提供一个exit的通道，作为从外面结束线程的信号，包括Halt方法的实现\n\treceiver Receiver  //接收者\n\tevents   chan Event //数据通道\n}\n```\n\n之前说manager是一个事件通道的处理，那么，业务逻辑一定是不断循环，从通道中读出数据，然后调用接收者的方法传递给接收者。所以代码是..\n\n```\nfunc (em *managerImpl) Start() {\n    //开启子线程\n\tgo em.eventLoop()\n}\nfunc (em *managerImpl) eventLoop() {\n\tfor {\n\t\tselect {\n\t\tcase next := <-em.events:\n\t\t\tem.Inject(next)\n\t\tcase <-em.exit:\n\t\t\tlogger.Debug(\"eventLoop told to exit\")\n\t\t\treturn\n\t\t}\n\t}\n}\n//传递Event给receiver\nfunc (em *managerImpl) Inject(event Event) {\n\tif em.receiver != nil {\n\t\tSendEvent(em.receiver, event)\n\t}\n}\n//调用receiver.PeoceesEvent方法将事件传递给接收者\nfunc SendEvent(receiver Receiver, event Event) {\n\tnext := event\n\tfor {\n\t\t// 如果ProcessEvent方法返回值不为空，则作为新的事件，继续处理\n\t\tnext = receiver.ProcessEvent(next)\n\t\tif next == nil {\n\t\t\tbreak\n\t\t}\n\t}\n}\n```\n\nProcessEvent设计为有返回值，且为Event，当返回值不为空，则作为新的事件进行处理，直到返回值为空。当然，因为是同一个receiver，如果设计为返回值为空，然后在ProcessEvent里直接进行递归调用，感觉也是一样的。但这样写的话，在ProcessEvent就会干净很多。\n\n\n\n#### Timer\n\ngo源码包中是有time包的，为什么还要封装一个timer呢，原因是封装的timer一旦被reset或stop，就算倒计时触发事件了，事件也不会传递到事件队列中。\n\n既然提到go中原time包，多嘴一句，time包中的timer也是具体stop和reset方法，但可以看到官方函数解释\n\n> ```\n> Stop does not close the channel, to prevent a read from the channel succeeding incorrectly\n> ```\n\n即stop方法不会关闭通道，一般使用timer的定时器或ticker，都是监听通道是否有值，就意味着即使stop掉定时器，但通道还是在的，监听通道的程序不会退出。\n\n\n\n好了，下面说明event中封装的Timer吧。\n\n直接看实现吧，接口就略过了\n\n```\n// newTimer creates a new instance of timerImpl\nfunc newTimerImpl(manager Manager) Timer {\n\tet := &timerImpl{\n\t\tstartChan: make(chan *timerStart),\n\t\tstopChan:  make(chan struct{}),\n\t\tthreaded:  threaded{make(chan struct{})},\n\t\tmanager:   manager,\n\t}\n\tgo et.loop()\n\treturn et\n}\n```\n\n注意到结构体中有manager的引用，实现的定时器为，当开启定时器时，需要传入定时时间，和event事件，当时间触发时，把event事件传递给manager.receiver，传递方式为manager中的传递方式。故主要代码为\n\n```\nfunc (et *timerImpl) loop() {\n\tvar eventDestChan chan<- Event //内部缓存通道\n\tvar event Event //事件\n\n\tfor {\n\t\tselect {\n\t\tcase start := <-et.startChan:\n\t\t\t//计时开始，时间为start.duration，事件为start.event\n\t\t\tif et.timerChan != nil {\n\t\t\t\tif start.hard {\n\t\t\t\t\tlogger.Debug(\"Resetting a running timer\")\n\t\t\t\t} else {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\tlogger.Debug(\"Starting timer\")\n\t\t\tet.timerChan = time.After(start.duration)\n\t\t\tif eventDestChan != nil {\n\t\t\t\tlogger.Debug(\"Timer cleared pending event\")\n\t\t\t}\n\t\t\tevent = start.event\n\t\t\teventDestChan = nil\n\t\tcase <-et.stopChan:\n\t\t\t//结束计时\n\t\t\tif et.timerChan == nil && eventDestChan == nil {\n\t\t\t\tlogger.Debug(\"Attempting to stop an unfired idle timer\")\n\t\t\t}\n\t\t\tet.timerChan = nil\n\t\t\tlogger.Debug(\"Stopping timer\")\n\t\t\tif eventDestChan != nil {\n\t\t\t\tlogger.Debug(\"Timer cleared pending event\")\n\t\t\t}\n\t\t\teventDestChan = nil\n\t\t\tevent = nil\n\t\tcase <-et.timerChan:\n\t\t\t//倒计时触发，这里好绕，倒计时触发，仅仅只是将事件传递通道的引用缓存下来\n\t\t\tlogger.Debug(\"Event timer fired\")\n\t\t\tet.timerChan = nil\n\t\t\teventDestChan = et.manager.Queue()\n\t\tcase eventDestChan <- event:\n\t\t\t//如果事件传递通道不为空，且event也不为空，则将event传递给事件通道中 eventDestChan <- event这一句话就竟然能实现这么多件事！\n\t\t\tlogger.Debug(\"Timer event delivered\")\n\t\t\teventDestChan = nil\n\t\tcase <-et.exit:\n\t\t\t//退出\n\t\t\tlogger.Debug(\"Halting timer\")\n\t\t\treturn\n\t\t}\n\t}\n\n```\n\n代码看到，倒计时触发的时候，并不是立即直接将event送入通道，而是将通道缓存下来，等到下一次select，再执行将事件送入通道的事。**在nil通道上发送和接受将永远被阻塞，在select中，如果其通道是nil，它将永远不会被选择**。所以，上述eventDestChan如果为nil, case eventDestChan <- event的语句就不会被选择。eventDestChan不为nil时，就能被选择了，select的用法是不是感觉很赞！\n","source":"_posts/fabric-code-consensus-event.md","raw":"---\ntitle: fabric_code_consensus_event\ncategories:\n  - fabric\ndate: 2019-4-14 15:07:25\ntags:\n---\n\n## fabric consensus event源码解析\n\n代码位置为 fabric/consensus/...\n\n想写pbft的代码解析来着。看到里面的事件流，设计得很赞，学习一下。\n\n\n\n#### Manager 事件管理\n\n主要实现的功能是事件通道的处理，通过相关接口，写入数据到通道中，数据处理方提供处理方法即可，不需关注通道的实现。\n\n```\n//首先，接口事件要做的事主要是，内部提供一个事件通道，暴露出往通道写数据的接口，以及数据处理接收方法，接收方法由Receiver提供，Magager的实现者需要实现数据从通道读出来，回调给接收者的过程。\ntype Manager interface {\n\tInject(Event)         //一个暂时的接口，跳过了通道，直接给到接收者，只限于Manager本线程使用，因为没有了通道做数据保护\n\tQueue() chan<- Event  //提供一个只写通道，用于往通道内写数据\n\tSetReceiver(Receiver) //设置接收者，接收者需要实现接收方法，在Receiver接口中有具体方法定义\n\tStart()               // 启动Manager线程\n\tHalt()                // 停止manager线程\n}\n```\n\n\n\n##### Receiver接口\n\n```\ntype Receiver interface {\n\t//事件处理的地方会调用这个方法传递事件给到Receiver,注意到这个设计的是返回值也是Event事件，这个在之后的地方进行详细解释\n\tProcessEvent(e Event) Event\n}\n```\n\n\n\n##### Manager实现\n\n```\ntype managerImpl struct {\n\tthreaded  //提供一个exit的通道，作为从外面结束线程的信号，包括Halt方法的实现\n\treceiver Receiver  //接收者\n\tevents   chan Event //数据通道\n}\n```\n\n之前说manager是一个事件通道的处理，那么，业务逻辑一定是不断循环，从通道中读出数据，然后调用接收者的方法传递给接收者。所以代码是..\n\n```\nfunc (em *managerImpl) Start() {\n    //开启子线程\n\tgo em.eventLoop()\n}\nfunc (em *managerImpl) eventLoop() {\n\tfor {\n\t\tselect {\n\t\tcase next := <-em.events:\n\t\t\tem.Inject(next)\n\t\tcase <-em.exit:\n\t\t\tlogger.Debug(\"eventLoop told to exit\")\n\t\t\treturn\n\t\t}\n\t}\n}\n//传递Event给receiver\nfunc (em *managerImpl) Inject(event Event) {\n\tif em.receiver != nil {\n\t\tSendEvent(em.receiver, event)\n\t}\n}\n//调用receiver.PeoceesEvent方法将事件传递给接收者\nfunc SendEvent(receiver Receiver, event Event) {\n\tnext := event\n\tfor {\n\t\t// 如果ProcessEvent方法返回值不为空，则作为新的事件，继续处理\n\t\tnext = receiver.ProcessEvent(next)\n\t\tif next == nil {\n\t\t\tbreak\n\t\t}\n\t}\n}\n```\n\nProcessEvent设计为有返回值，且为Event，当返回值不为空，则作为新的事件进行处理，直到返回值为空。当然，因为是同一个receiver，如果设计为返回值为空，然后在ProcessEvent里直接进行递归调用，感觉也是一样的。但这样写的话，在ProcessEvent就会干净很多。\n\n\n\n#### Timer\n\ngo源码包中是有time包的，为什么还要封装一个timer呢，原因是封装的timer一旦被reset或stop，就算倒计时触发事件了，事件也不会传递到事件队列中。\n\n既然提到go中原time包，多嘴一句，time包中的timer也是具体stop和reset方法，但可以看到官方函数解释\n\n> ```\n> Stop does not close the channel, to prevent a read from the channel succeeding incorrectly\n> ```\n\n即stop方法不会关闭通道，一般使用timer的定时器或ticker，都是监听通道是否有值，就意味着即使stop掉定时器，但通道还是在的，监听通道的程序不会退出。\n\n\n\n好了，下面说明event中封装的Timer吧。\n\n直接看实现吧，接口就略过了\n\n```\n// newTimer creates a new instance of timerImpl\nfunc newTimerImpl(manager Manager) Timer {\n\tet := &timerImpl{\n\t\tstartChan: make(chan *timerStart),\n\t\tstopChan:  make(chan struct{}),\n\t\tthreaded:  threaded{make(chan struct{})},\n\t\tmanager:   manager,\n\t}\n\tgo et.loop()\n\treturn et\n}\n```\n\n注意到结构体中有manager的引用，实现的定时器为，当开启定时器时，需要传入定时时间，和event事件，当时间触发时，把event事件传递给manager.receiver，传递方式为manager中的传递方式。故主要代码为\n\n```\nfunc (et *timerImpl) loop() {\n\tvar eventDestChan chan<- Event //内部缓存通道\n\tvar event Event //事件\n\n\tfor {\n\t\tselect {\n\t\tcase start := <-et.startChan:\n\t\t\t//计时开始，时间为start.duration，事件为start.event\n\t\t\tif et.timerChan != nil {\n\t\t\t\tif start.hard {\n\t\t\t\t\tlogger.Debug(\"Resetting a running timer\")\n\t\t\t\t} else {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\tlogger.Debug(\"Starting timer\")\n\t\t\tet.timerChan = time.After(start.duration)\n\t\t\tif eventDestChan != nil {\n\t\t\t\tlogger.Debug(\"Timer cleared pending event\")\n\t\t\t}\n\t\t\tevent = start.event\n\t\t\teventDestChan = nil\n\t\tcase <-et.stopChan:\n\t\t\t//结束计时\n\t\t\tif et.timerChan == nil && eventDestChan == nil {\n\t\t\t\tlogger.Debug(\"Attempting to stop an unfired idle timer\")\n\t\t\t}\n\t\t\tet.timerChan = nil\n\t\t\tlogger.Debug(\"Stopping timer\")\n\t\t\tif eventDestChan != nil {\n\t\t\t\tlogger.Debug(\"Timer cleared pending event\")\n\t\t\t}\n\t\t\teventDestChan = nil\n\t\t\tevent = nil\n\t\tcase <-et.timerChan:\n\t\t\t//倒计时触发，这里好绕，倒计时触发，仅仅只是将事件传递通道的引用缓存下来\n\t\t\tlogger.Debug(\"Event timer fired\")\n\t\t\tet.timerChan = nil\n\t\t\teventDestChan = et.manager.Queue()\n\t\tcase eventDestChan <- event:\n\t\t\t//如果事件传递通道不为空，且event也不为空，则将event传递给事件通道中 eventDestChan <- event这一句话就竟然能实现这么多件事！\n\t\t\tlogger.Debug(\"Timer event delivered\")\n\t\t\teventDestChan = nil\n\t\tcase <-et.exit:\n\t\t\t//退出\n\t\t\tlogger.Debug(\"Halting timer\")\n\t\t\treturn\n\t\t}\n\t}\n\n```\n\n代码看到，倒计时触发的时候，并不是立即直接将event送入通道，而是将通道缓存下来，等到下一次select，再执行将事件送入通道的事。**在nil通道上发送和接受将永远被阻塞，在select中，如果其通道是nil，它将永远不会被选择**。所以，上述eventDestChan如果为nil, case eventDestChan <- event的语句就不会被选择。eventDestChan不为nil时，就能被选择了，select的用法是不是感觉很赞！\n","slug":"fabric-code-consensus-event","published":1,"updated":"2019-10-14T07:09:44.048Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69tz000wt6xvsu6r1yui","content":"<h2 id=\"fabric-consensus-event源码解析\"><a href=\"#fabric-consensus-event源码解析\" class=\"headerlink\" title=\"fabric consensus event源码解析\"></a>fabric consensus event源码解析</h2><p>代码位置为 fabric/consensus/…</p>\n<p>想写pbft的代码解析来着。看到里面的事件流，设计得很赞，学习一下。</p>\n<h4 id=\"Manager-事件管理\"><a href=\"#Manager-事件管理\" class=\"headerlink\" title=\"Manager 事件管理\"></a>Manager 事件管理</h4><p>主要实现的功能是事件通道的处理，通过相关接口，写入数据到通道中，数据处理方提供处理方法即可，不需关注通道的实现。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//首先，接口事件要做的事主要是，内部提供一个事件通道，暴露出往通道写数据的接口，以及数据处理接收方法，接收方法由Receiver提供，Magager的实现者需要实现数据从通道读出来，回调给接收者的过程。</span><br><span class=\"line\">type Manager interface &#123;</span><br><span class=\"line\">\tInject(Event)         //一个暂时的接口，跳过了通道，直接给到接收者，只限于Manager本线程使用，因为没有了通道做数据保护</span><br><span class=\"line\">\tQueue() chan&lt;- Event  //提供一个只写通道，用于往通道内写数据</span><br><span class=\"line\">\tSetReceiver(Receiver) //设置接收者，接收者需要实现接收方法，在Receiver接口中有具体方法定义</span><br><span class=\"line\">\tStart()               // 启动Manager线程</span><br><span class=\"line\">\tHalt()                // 停止manager线程</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"Receiver接口\"><a href=\"#Receiver接口\" class=\"headerlink\" title=\"Receiver接口\"></a>Receiver接口</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Receiver interface &#123;</span><br><span class=\"line\">\t//事件处理的地方会调用这个方法传递事件给到Receiver,注意到这个设计的是返回值也是Event事件，这个在之后的地方进行详细解释</span><br><span class=\"line\">\tProcessEvent(e Event) Event</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"Manager实现\"><a href=\"#Manager实现\" class=\"headerlink\" title=\"Manager实现\"></a>Manager实现</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type managerImpl struct &#123;</span><br><span class=\"line\">\tthreaded  //提供一个exit的通道，作为从外面结束线程的信号，包括Halt方法的实现</span><br><span class=\"line\">\treceiver Receiver  //接收者</span><br><span class=\"line\">\tevents   chan Event //数据通道</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>之前说manager是一个事件通道的处理，那么，业务逻辑一定是不断循环，从通道中读出数据，然后调用接收者的方法传递给接收者。所以代码是..</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (em *managerImpl) Start() &#123;</span><br><span class=\"line\">    //开启子线程</span><br><span class=\"line\">\tgo em.eventLoop()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func (em *managerImpl) eventLoop() &#123;</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase next := &lt;-em.events:</span><br><span class=\"line\">\t\t\tem.Inject(next)</span><br><span class=\"line\">\t\tcase &lt;-em.exit:</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;eventLoop told to exit&quot;)</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//传递Event给receiver</span><br><span class=\"line\">func (em *managerImpl) Inject(event Event) &#123;</span><br><span class=\"line\">\tif em.receiver != nil &#123;</span><br><span class=\"line\">\t\tSendEvent(em.receiver, event)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//调用receiver.PeoceesEvent方法将事件传递给接收者</span><br><span class=\"line\">func SendEvent(receiver Receiver, event Event) &#123;</span><br><span class=\"line\">\tnext := event</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\t// 如果ProcessEvent方法返回值不为空，则作为新的事件，继续处理</span><br><span class=\"line\">\t\tnext = receiver.ProcessEvent(next)</span><br><span class=\"line\">\t\tif next == nil &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>ProcessEvent设计为有返回值，且为Event，当返回值不为空，则作为新的事件进行处理，直到返回值为空。当然，因为是同一个receiver，如果设计为返回值为空，然后在ProcessEvent里直接进行递归调用，感觉也是一样的。但这样写的话，在ProcessEvent就会干净很多。</p>\n<h4 id=\"Timer\"><a href=\"#Timer\" class=\"headerlink\" title=\"Timer\"></a>Timer</h4><p>go源码包中是有time包的，为什么还要封装一个timer呢，原因是封装的timer一旦被reset或stop，就算倒计时触发事件了，事件也不会传递到事件队列中。</p>\n<p>既然提到go中原time包，多嘴一句，time包中的timer也是具体stop和reset方法，但可以看到官方函数解释</p>\n<blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; Stop does not close the channel, to prevent a read from the channel succeeding incorrectly</span><br><span class=\"line\">&gt;</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>即stop方法不会关闭通道，一般使用timer的定时器或ticker，都是监听通道是否有值，就意味着即使stop掉定时器，但通道还是在的，监听通道的程序不会退出。</p>\n<p>好了，下面说明event中封装的Timer吧。</p>\n<p>直接看实现吧，接口就略过了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// newTimer creates a new instance of timerImpl</span><br><span class=\"line\">func newTimerImpl(manager Manager) Timer &#123;</span><br><span class=\"line\">\tet := &amp;timerImpl&#123;</span><br><span class=\"line\">\t\tstartChan: make(chan *timerStart),</span><br><span class=\"line\">\t\tstopChan:  make(chan struct&#123;&#125;),</span><br><span class=\"line\">\t\tthreaded:  threaded&#123;make(chan struct&#123;&#125;)&#125;,</span><br><span class=\"line\">\t\tmanager:   manager,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tgo et.loop()</span><br><span class=\"line\">\treturn et</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>注意到结构体中有manager的引用，实现的定时器为，当开启定时器时，需要传入定时时间，和event事件，当时间触发时，把event事件传递给manager.receiver，传递方式为manager中的传递方式。故主要代码为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (et *timerImpl) loop() &#123;</span><br><span class=\"line\">\tvar eventDestChan chan&lt;- Event //内部缓存通道</span><br><span class=\"line\">\tvar event Event //事件</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase start := &lt;-et.startChan:</span><br><span class=\"line\">\t\t\t//计时开始，时间为start.duration，事件为start.event</span><br><span class=\"line\">\t\t\tif et.timerChan != nil &#123;</span><br><span class=\"line\">\t\t\t\tif start.hard &#123;</span><br><span class=\"line\">\t\t\t\t\tlogger.Debug(&quot;Resetting a running timer&quot;)</span><br><span class=\"line\">\t\t\t\t&#125; else &#123;</span><br><span class=\"line\">\t\t\t\t\tcontinue</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Starting timer&quot;)</span><br><span class=\"line\">\t\t\tet.timerChan = time.After(start.duration)</span><br><span class=\"line\">\t\t\tif eventDestChan != nil &#123;</span><br><span class=\"line\">\t\t\t\tlogger.Debug(&quot;Timer cleared pending event&quot;)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tevent = start.event</span><br><span class=\"line\">\t\t\teventDestChan = nil</span><br><span class=\"line\">\t\tcase &lt;-et.stopChan:</span><br><span class=\"line\">\t\t\t//结束计时</span><br><span class=\"line\">\t\t\tif et.timerChan == nil &amp;&amp; eventDestChan == nil &#123;</span><br><span class=\"line\">\t\t\t\tlogger.Debug(&quot;Attempting to stop an unfired idle timer&quot;)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tet.timerChan = nil</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Stopping timer&quot;)</span><br><span class=\"line\">\t\t\tif eventDestChan != nil &#123;</span><br><span class=\"line\">\t\t\t\tlogger.Debug(&quot;Timer cleared pending event&quot;)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\teventDestChan = nil</span><br><span class=\"line\">\t\t\tevent = nil</span><br><span class=\"line\">\t\tcase &lt;-et.timerChan:</span><br><span class=\"line\">\t\t\t//倒计时触发，这里好绕，倒计时触发，仅仅只是将事件传递通道的引用缓存下来</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Event timer fired&quot;)</span><br><span class=\"line\">\t\t\tet.timerChan = nil</span><br><span class=\"line\">\t\t\teventDestChan = et.manager.Queue()</span><br><span class=\"line\">\t\tcase eventDestChan &lt;- event:</span><br><span class=\"line\">\t\t\t//如果事件传递通道不为空，且event也不为空，则将event传递给事件通道中 eventDestChan &lt;- event这一句话就竟然能实现这么多件事！</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Timer event delivered&quot;)</span><br><span class=\"line\">\t\t\teventDestChan = nil</span><br><span class=\"line\">\t\tcase &lt;-et.exit:</span><br><span class=\"line\">\t\t\t//退出</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Halting timer&quot;)</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n\n<p>代码看到，倒计时触发的时候，并不是立即直接将event送入通道，而是将通道缓存下来，等到下一次select，再执行将事件送入通道的事。<strong>在nil通道上发送和接受将永远被阻塞，在select中，如果其通道是nil，它将永远不会被选择</strong>。所以，上述eventDestChan如果为nil, case eventDestChan &lt;- event的语句就不会被选择。eventDestChan不为nil时，就能被选择了，select的用法是不是感觉很赞！</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"fabric-consensus-event源码解析\"><a href=\"#fabric-consensus-event源码解析\" class=\"headerlink\" title=\"fabric consensus event源码解析\"></a>fabric consensus event源码解析</h2><p>代码位置为 fabric/consensus/…</p>\n<p>想写pbft的代码解析来着。看到里面的事件流，设计得很赞，学习一下。</p>\n<h4 id=\"Manager-事件管理\"><a href=\"#Manager-事件管理\" class=\"headerlink\" title=\"Manager 事件管理\"></a>Manager 事件管理</h4><p>主要实现的功能是事件通道的处理，通过相关接口，写入数据到通道中，数据处理方提供处理方法即可，不需关注通道的实现。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//首先，接口事件要做的事主要是，内部提供一个事件通道，暴露出往通道写数据的接口，以及数据处理接收方法，接收方法由Receiver提供，Magager的实现者需要实现数据从通道读出来，回调给接收者的过程。</span><br><span class=\"line\">type Manager interface &#123;</span><br><span class=\"line\">\tInject(Event)         //一个暂时的接口，跳过了通道，直接给到接收者，只限于Manager本线程使用，因为没有了通道做数据保护</span><br><span class=\"line\">\tQueue() chan&lt;- Event  //提供一个只写通道，用于往通道内写数据</span><br><span class=\"line\">\tSetReceiver(Receiver) //设置接收者，接收者需要实现接收方法，在Receiver接口中有具体方法定义</span><br><span class=\"line\">\tStart()               // 启动Manager线程</span><br><span class=\"line\">\tHalt()                // 停止manager线程</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"Receiver接口\"><a href=\"#Receiver接口\" class=\"headerlink\" title=\"Receiver接口\"></a>Receiver接口</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Receiver interface &#123;</span><br><span class=\"line\">\t//事件处理的地方会调用这个方法传递事件给到Receiver,注意到这个设计的是返回值也是Event事件，这个在之后的地方进行详细解释</span><br><span class=\"line\">\tProcessEvent(e Event) Event</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"Manager实现\"><a href=\"#Manager实现\" class=\"headerlink\" title=\"Manager实现\"></a>Manager实现</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type managerImpl struct &#123;</span><br><span class=\"line\">\tthreaded  //提供一个exit的通道，作为从外面结束线程的信号，包括Halt方法的实现</span><br><span class=\"line\">\treceiver Receiver  //接收者</span><br><span class=\"line\">\tevents   chan Event //数据通道</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>之前说manager是一个事件通道的处理，那么，业务逻辑一定是不断循环，从通道中读出数据，然后调用接收者的方法传递给接收者。所以代码是..</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (em *managerImpl) Start() &#123;</span><br><span class=\"line\">    //开启子线程</span><br><span class=\"line\">\tgo em.eventLoop()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func (em *managerImpl) eventLoop() &#123;</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase next := &lt;-em.events:</span><br><span class=\"line\">\t\t\tem.Inject(next)</span><br><span class=\"line\">\t\tcase &lt;-em.exit:</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;eventLoop told to exit&quot;)</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//传递Event给receiver</span><br><span class=\"line\">func (em *managerImpl) Inject(event Event) &#123;</span><br><span class=\"line\">\tif em.receiver != nil &#123;</span><br><span class=\"line\">\t\tSendEvent(em.receiver, event)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//调用receiver.PeoceesEvent方法将事件传递给接收者</span><br><span class=\"line\">func SendEvent(receiver Receiver, event Event) &#123;</span><br><span class=\"line\">\tnext := event</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\t// 如果ProcessEvent方法返回值不为空，则作为新的事件，继续处理</span><br><span class=\"line\">\t\tnext = receiver.ProcessEvent(next)</span><br><span class=\"line\">\t\tif next == nil &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>ProcessEvent设计为有返回值，且为Event，当返回值不为空，则作为新的事件进行处理，直到返回值为空。当然，因为是同一个receiver，如果设计为返回值为空，然后在ProcessEvent里直接进行递归调用，感觉也是一样的。但这样写的话，在ProcessEvent就会干净很多。</p>\n<h4 id=\"Timer\"><a href=\"#Timer\" class=\"headerlink\" title=\"Timer\"></a>Timer</h4><p>go源码包中是有time包的，为什么还要封装一个timer呢，原因是封装的timer一旦被reset或stop，就算倒计时触发事件了，事件也不会传递到事件队列中。</p>\n<p>既然提到go中原time包，多嘴一句，time包中的timer也是具体stop和reset方法，但可以看到官方函数解释</p>\n<blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; Stop does not close the channel, to prevent a read from the channel succeeding incorrectly</span><br><span class=\"line\">&gt;</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>即stop方法不会关闭通道，一般使用timer的定时器或ticker，都是监听通道是否有值，就意味着即使stop掉定时器，但通道还是在的，监听通道的程序不会退出。</p>\n<p>好了，下面说明event中封装的Timer吧。</p>\n<p>直接看实现吧，接口就略过了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// newTimer creates a new instance of timerImpl</span><br><span class=\"line\">func newTimerImpl(manager Manager) Timer &#123;</span><br><span class=\"line\">\tet := &amp;timerImpl&#123;</span><br><span class=\"line\">\t\tstartChan: make(chan *timerStart),</span><br><span class=\"line\">\t\tstopChan:  make(chan struct&#123;&#125;),</span><br><span class=\"line\">\t\tthreaded:  threaded&#123;make(chan struct&#123;&#125;)&#125;,</span><br><span class=\"line\">\t\tmanager:   manager,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tgo et.loop()</span><br><span class=\"line\">\treturn et</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>注意到结构体中有manager的引用，实现的定时器为，当开启定时器时，需要传入定时时间，和event事件，当时间触发时，把event事件传递给manager.receiver，传递方式为manager中的传递方式。故主要代码为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (et *timerImpl) loop() &#123;</span><br><span class=\"line\">\tvar eventDestChan chan&lt;- Event //内部缓存通道</span><br><span class=\"line\">\tvar event Event //事件</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase start := &lt;-et.startChan:</span><br><span class=\"line\">\t\t\t//计时开始，时间为start.duration，事件为start.event</span><br><span class=\"line\">\t\t\tif et.timerChan != nil &#123;</span><br><span class=\"line\">\t\t\t\tif start.hard &#123;</span><br><span class=\"line\">\t\t\t\t\tlogger.Debug(&quot;Resetting a running timer&quot;)</span><br><span class=\"line\">\t\t\t\t&#125; else &#123;</span><br><span class=\"line\">\t\t\t\t\tcontinue</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Starting timer&quot;)</span><br><span class=\"line\">\t\t\tet.timerChan = time.After(start.duration)</span><br><span class=\"line\">\t\t\tif eventDestChan != nil &#123;</span><br><span class=\"line\">\t\t\t\tlogger.Debug(&quot;Timer cleared pending event&quot;)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tevent = start.event</span><br><span class=\"line\">\t\t\teventDestChan = nil</span><br><span class=\"line\">\t\tcase &lt;-et.stopChan:</span><br><span class=\"line\">\t\t\t//结束计时</span><br><span class=\"line\">\t\t\tif et.timerChan == nil &amp;&amp; eventDestChan == nil &#123;</span><br><span class=\"line\">\t\t\t\tlogger.Debug(&quot;Attempting to stop an unfired idle timer&quot;)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tet.timerChan = nil</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Stopping timer&quot;)</span><br><span class=\"line\">\t\t\tif eventDestChan != nil &#123;</span><br><span class=\"line\">\t\t\t\tlogger.Debug(&quot;Timer cleared pending event&quot;)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\teventDestChan = nil</span><br><span class=\"line\">\t\t\tevent = nil</span><br><span class=\"line\">\t\tcase &lt;-et.timerChan:</span><br><span class=\"line\">\t\t\t//倒计时触发，这里好绕，倒计时触发，仅仅只是将事件传递通道的引用缓存下来</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Event timer fired&quot;)</span><br><span class=\"line\">\t\t\tet.timerChan = nil</span><br><span class=\"line\">\t\t\teventDestChan = et.manager.Queue()</span><br><span class=\"line\">\t\tcase eventDestChan &lt;- event:</span><br><span class=\"line\">\t\t\t//如果事件传递通道不为空，且event也不为空，则将event传递给事件通道中 eventDestChan &lt;- event这一句话就竟然能实现这么多件事！</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Timer event delivered&quot;)</span><br><span class=\"line\">\t\t\teventDestChan = nil</span><br><span class=\"line\">\t\tcase &lt;-et.exit:</span><br><span class=\"line\">\t\t\t//退出</span><br><span class=\"line\">\t\t\tlogger.Debug(&quot;Halting timer&quot;)</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n\n<p>代码看到，倒计时触发的时候，并不是立即直接将event送入通道，而是将通道缓存下来，等到下一次select，再执行将事件送入通道的事。<strong>在nil通道上发送和接受将永远被阻塞，在select中，如果其通道是nil，它将永远不会被选择</strong>。所以，上述eventDestChan如果为nil, case eventDestChan &lt;- event的语句就不会被选择。eventDestChan不为nil时，就能被选择了，select的用法是不是感觉很赞！</p>\n"},{"title":"fabric_performance","date":"2019-10-14T07:08:12.000Z","_content":"\n\n\n## 简单性能测试\n\n##### 服务\n\n- order服务: 负责接收背书后的交易放入kafka中，并从kafka中读出交易出块\n- peer服务： 负责背书交易\n- http 客户端测试服务： 向peer发送交易背书后发送到order\n- 1个通道，2个组织\n\n##### 机器\n\n- 1号机，4核8g\n- 2号机，4核8g\n- 3号机，4核8g\n- 云服务kafka\n\n区块配置:  每区块512KB，每条交易2.9KB，每个区块平均包含173个交易\n\n##### 机器使用\n\n| 1号机         | 2号机        | 3号机                   |\n| ------------- | ------------ | ----------------------- |\n| order服务 * 3 | peer服务 * 1 | http 客户端测试服务 * 1 |\n\n性能情况\n\n| 实时出块速度 | 只读出块速度 |\n| ------------ | ------------ |\n| 1400         | -            |\n\n**只读出块速度**： http 客户端发送交易，首先发送到peer背书，随后发送到order节点，order节点收到交易后放入到kafka存储(消息生产过程)，随后order出块(消息消费过程)。当消息生产速度高于消费速度，就会造成消息堆积，**当消息生产速度为0，只消费堆积的消息的速度，称为只读出块速度**。\n\n\n\n#### 第一次更新\n\n增加区块大小\n\n每区块1500KB，每条交易2，9KB，每个区块平均包含500个交易\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 1500         | 1500     | -            |\n\n\n\n#### 第二次更新\n\n增加peer数量\n\n##### 机器使用\n\n| 1号机         | 2号机                      | 3号机                   |\n| ------------- | -------------------------- | ----------------------- |\n| order服务 * 3 | peer服务 * 1；peer服务 * 1 | http 客户端测试服务 * 2 |\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 1000         | 8000*2   | 1800         |\n\n**观察**\n\n增加peer，peer的背书速度稍有提升，但出块速度竟然降低了..\n\n出块的速度小于交易产生速度，当http 客户端停掉之后，出块的速度得到提升并且稍大于单个peer的情况。\n\n\n\n#### 第三次更新\n\n追加服务器，负载均衡\n\n- 4号机，4核8g\n- 5号机，4核8g\n\n##### 机器使用\n\n| 1号机         | 2号机        | 3号机        | 4号机                   | 5号机                   |\n| ------------- | ------------ | ------------ | ----------------------- | ----------------------- |\n| order服务 * 3 | peer服务 * 1 | peer服务 * 1 | http 客户端测试服务 * 1 | http 客户端测试服务 * 1 |\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 1300         | 1400 * 2 | 2200         |\n\n**观察**\n\n负载均衡后，背书的速度得到显著提升！实时出块和只读出块的速度也稍有提升。\n\n但实时出块的速度还是没有只有1个peer的速度...\n\n\n\n#### 第四、五次更新\n\n提升服务器性能，首先将order服务所在的1号机升级为8核16g，实时出块的速度增加到1700，但2个peer的速度还是没有1个peer的速度快..\n\n其次，提升了kafka服务器的性能.. 结果没啥变化\n\n\n\n#### 第六次更新\n\n再次提升服务器性能，这次提升的是peer节点的性能，将peer节点的2号机和3号机升级为8核16g\n\n##### 机器使用\n\n| 1号机8核16g   | 2号机8核16g  | 4号机                   |\n| ------------- | ------------ | ----------------------- |\n| order服务 * 3 | peer服务 * 1 | http 客户端测试服务 * 1 |\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 1800         | 1800     | -            |\n\n##### 机器使用\n\n| 1号机8核16g   | 2号机8核16g  | 3号机8核16g  | 4号机                   | 5号机                   |\n| ------------- | ------------ | ------------ | ----------------------- | ----------------------- |\n| order服务 * 3 | peer服务 * 1 | peer服务 * 1 | http 客户端测试服务 * 1 | http 客户端测试服务 * 1 |\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 2600         | 1700 * 2 | 3500         |\n\n**观察**\n\n1个peer时速度为出块速度为1800\n\n增加1个peer，背书速度提升接近2倍，出块速度增加至2600，当停掉http客户端后，只读出块速度增加至3500\n\n\n\n### 结论\n\n(在一定条件下)增加peer的数量，能增加tps。在本例中，8核16g的peer下，增加一个peer的tps由1800增加至2600。\n\n所谓一定条件，例如peer服务对于服务器性能(内存等)要求挺高的。\n","source":"_posts/fabric-performance.md","raw":"---\ntitle: fabric_performance\ncategories:\n  - fabric\ndate: 2019-10-14 15:08:12\ntags:\n---\n\n\n\n## 简单性能测试\n\n##### 服务\n\n- order服务: 负责接收背书后的交易放入kafka中，并从kafka中读出交易出块\n- peer服务： 负责背书交易\n- http 客户端测试服务： 向peer发送交易背书后发送到order\n- 1个通道，2个组织\n\n##### 机器\n\n- 1号机，4核8g\n- 2号机，4核8g\n- 3号机，4核8g\n- 云服务kafka\n\n区块配置:  每区块512KB，每条交易2.9KB，每个区块平均包含173个交易\n\n##### 机器使用\n\n| 1号机         | 2号机        | 3号机                   |\n| ------------- | ------------ | ----------------------- |\n| order服务 * 3 | peer服务 * 1 | http 客户端测试服务 * 1 |\n\n性能情况\n\n| 实时出块速度 | 只读出块速度 |\n| ------------ | ------------ |\n| 1400         | -            |\n\n**只读出块速度**： http 客户端发送交易，首先发送到peer背书，随后发送到order节点，order节点收到交易后放入到kafka存储(消息生产过程)，随后order出块(消息消费过程)。当消息生产速度高于消费速度，就会造成消息堆积，**当消息生产速度为0，只消费堆积的消息的速度，称为只读出块速度**。\n\n\n\n#### 第一次更新\n\n增加区块大小\n\n每区块1500KB，每条交易2，9KB，每个区块平均包含500个交易\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 1500         | 1500     | -            |\n\n\n\n#### 第二次更新\n\n增加peer数量\n\n##### 机器使用\n\n| 1号机         | 2号机                      | 3号机                   |\n| ------------- | -------------------------- | ----------------------- |\n| order服务 * 3 | peer服务 * 1；peer服务 * 1 | http 客户端测试服务 * 2 |\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 1000         | 8000*2   | 1800         |\n\n**观察**\n\n增加peer，peer的背书速度稍有提升，但出块速度竟然降低了..\n\n出块的速度小于交易产生速度，当http 客户端停掉之后，出块的速度得到提升并且稍大于单个peer的情况。\n\n\n\n#### 第三次更新\n\n追加服务器，负载均衡\n\n- 4号机，4核8g\n- 5号机，4核8g\n\n##### 机器使用\n\n| 1号机         | 2号机        | 3号机        | 4号机                   | 5号机                   |\n| ------------- | ------------ | ------------ | ----------------------- | ----------------------- |\n| order服务 * 3 | peer服务 * 1 | peer服务 * 1 | http 客户端测试服务 * 1 | http 客户端测试服务 * 1 |\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 1300         | 1400 * 2 | 2200         |\n\n**观察**\n\n负载均衡后，背书的速度得到显著提升！实时出块和只读出块的速度也稍有提升。\n\n但实时出块的速度还是没有只有1个peer的速度...\n\n\n\n#### 第四、五次更新\n\n提升服务器性能，首先将order服务所在的1号机升级为8核16g，实时出块的速度增加到1700，但2个peer的速度还是没有1个peer的速度快..\n\n其次，提升了kafka服务器的性能.. 结果没啥变化\n\n\n\n#### 第六次更新\n\n再次提升服务器性能，这次提升的是peer节点的性能，将peer节点的2号机和3号机升级为8核16g\n\n##### 机器使用\n\n| 1号机8核16g   | 2号机8核16g  | 4号机                   |\n| ------------- | ------------ | ----------------------- |\n| order服务 * 3 | peer服务 * 1 | http 客户端测试服务 * 1 |\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 1800         | 1800     | -            |\n\n##### 机器使用\n\n| 1号机8核16g   | 2号机8核16g  | 3号机8核16g  | 4号机                   | 5号机                   |\n| ------------- | ------------ | ------------ | ----------------------- | ----------------------- |\n| order服务 * 3 | peer服务 * 1 | peer服务 * 1 | http 客户端测试服务 * 1 | http 客户端测试服务 * 1 |\n\n性能情况\n\n| 实时出块速度 | 背书速度 | 只读出块速度 |\n| ------------ | -------- | ------------ |\n| 2600         | 1700 * 2 | 3500         |\n\n**观察**\n\n1个peer时速度为出块速度为1800\n\n增加1个peer，背书速度提升接近2倍，出块速度增加至2600，当停掉http客户端后，只读出块速度增加至3500\n\n\n\n### 结论\n\n(在一定条件下)增加peer的数量，能增加tps。在本例中，8核16g的peer下，增加一个peer的tps由1800增加至2600。\n\n所谓一定条件，例如peer服务对于服务器性能(内存等)要求挺高的。\n","slug":"fabric-performance","published":1,"updated":"2019-10-14T07:08:27.722Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69u3000yt6xvl3p0o8tn","content":"<h2 id=\"简单性能测试\"><a href=\"#简单性能测试\" class=\"headerlink\" title=\"简单性能测试\"></a>简单性能测试</h2><h5 id=\"服务\"><a href=\"#服务\" class=\"headerlink\" title=\"服务\"></a>服务</h5><ul>\n<li>order服务: 负责接收背书后的交易放入kafka中，并从kafka中读出交易出块</li>\n<li>peer服务： 负责背书交易</li>\n<li>http 客户端测试服务： 向peer发送交易背书后发送到order</li>\n<li>1个通道，2个组织</li>\n</ul>\n<h5 id=\"机器\"><a href=\"#机器\" class=\"headerlink\" title=\"机器\"></a>机器</h5><ul>\n<li>1号机，4核8g</li>\n<li>2号机，4核8g</li>\n<li>3号机，4核8g</li>\n<li>云服务kafka</li>\n</ul>\n<p>区块配置:  每区块512KB，每条交易2.9KB，每个区块平均包含173个交易</p>\n<h5 id=\"机器使用\"><a href=\"#机器使用\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机</th>\n<th>2号机</th>\n<th>3号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1400</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<p><strong>只读出块速度</strong>： http 客户端发送交易，首先发送到peer背书，随后发送到order节点，order节点收到交易后放入到kafka存储(消息生产过程)，随后order出块(消息消费过程)。当消息生产速度高于消费速度，就会造成消息堆积，<strong>当消息生产速度为0，只消费堆积的消息的速度，称为只读出块速度</strong>。</p>\n<h4 id=\"第一次更新\"><a href=\"#第一次更新\" class=\"headerlink\" title=\"第一次更新\"></a>第一次更新</h4><p>增加区块大小</p>\n<p>每区块1500KB，每条交易2，9KB，每个区块平均包含500个交易</p>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1500</td>\n<td>1500</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<h4 id=\"第二次更新\"><a href=\"#第二次更新\" class=\"headerlink\" title=\"第二次更新\"></a>第二次更新</h4><p>增加peer数量</p>\n<h5 id=\"机器使用-1\"><a href=\"#机器使用-1\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机</th>\n<th>2号机</th>\n<th>3号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1；peer服务 * 1</td>\n<td>http 客户端测试服务 * 2</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1000</td>\n<td>8000*2</td>\n<td>1800</td>\n</tr>\n</tbody></table>\n<p><strong>观察</strong></p>\n<p>增加peer，peer的背书速度稍有提升，但出块速度竟然降低了..</p>\n<p>出块的速度小于交易产生速度，当http 客户端停掉之后，出块的速度得到提升并且稍大于单个peer的情况。</p>\n<h4 id=\"第三次更新\"><a href=\"#第三次更新\" class=\"headerlink\" title=\"第三次更新\"></a>第三次更新</h4><p>追加服务器，负载均衡</p>\n<ul>\n<li>4号机，4核8g</li>\n<li>5号机，4核8g</li>\n</ul>\n<h5 id=\"机器使用-2\"><a href=\"#机器使用-2\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机</th>\n<th>2号机</th>\n<th>3号机</th>\n<th>4号机</th>\n<th>5号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1</td>\n<td>peer服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1300</td>\n<td>1400 * 2</td>\n<td>2200</td>\n</tr>\n</tbody></table>\n<p><strong>观察</strong></p>\n<p>负载均衡后，背书的速度得到显著提升！实时出块和只读出块的速度也稍有提升。</p>\n<p>但实时出块的速度还是没有只有1个peer的速度…</p>\n<h4 id=\"第四、五次更新\"><a href=\"#第四、五次更新\" class=\"headerlink\" title=\"第四、五次更新\"></a>第四、五次更新</h4><p>提升服务器性能，首先将order服务所在的1号机升级为8核16g，实时出块的速度增加到1700，但2个peer的速度还是没有1个peer的速度快..</p>\n<p>其次，提升了kafka服务器的性能.. 结果没啥变化</p>\n<h4 id=\"第六次更新\"><a href=\"#第六次更新\" class=\"headerlink\" title=\"第六次更新\"></a>第六次更新</h4><p>再次提升服务器性能，这次提升的是peer节点的性能，将peer节点的2号机和3号机升级为8核16g</p>\n<h5 id=\"机器使用-3\"><a href=\"#机器使用-3\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机8核16g</th>\n<th>2号机8核16g</th>\n<th>4号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1800</td>\n<td>1800</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<h5 id=\"机器使用-4\"><a href=\"#机器使用-4\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机8核16g</th>\n<th>2号机8核16g</th>\n<th>3号机8核16g</th>\n<th>4号机</th>\n<th>5号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1</td>\n<td>peer服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2600</td>\n<td>1700 * 2</td>\n<td>3500</td>\n</tr>\n</tbody></table>\n<p><strong>观察</strong></p>\n<p>1个peer时速度为出块速度为1800</p>\n<p>增加1个peer，背书速度提升接近2倍，出块速度增加至2600，当停掉http客户端后，只读出块速度增加至3500</p>\n<h3 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h3><p>(在一定条件下)增加peer的数量，能增加tps。在本例中，8核16g的peer下，增加一个peer的tps由1800增加至2600。</p>\n<p>所谓一定条件，例如peer服务对于服务器性能(内存等)要求挺高的。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"简单性能测试\"><a href=\"#简单性能测试\" class=\"headerlink\" title=\"简单性能测试\"></a>简单性能测试</h2><h5 id=\"服务\"><a href=\"#服务\" class=\"headerlink\" title=\"服务\"></a>服务</h5><ul>\n<li>order服务: 负责接收背书后的交易放入kafka中，并从kafka中读出交易出块</li>\n<li>peer服务： 负责背书交易</li>\n<li>http 客户端测试服务： 向peer发送交易背书后发送到order</li>\n<li>1个通道，2个组织</li>\n</ul>\n<h5 id=\"机器\"><a href=\"#机器\" class=\"headerlink\" title=\"机器\"></a>机器</h5><ul>\n<li>1号机，4核8g</li>\n<li>2号机，4核8g</li>\n<li>3号机，4核8g</li>\n<li>云服务kafka</li>\n</ul>\n<p>区块配置:  每区块512KB，每条交易2.9KB，每个区块平均包含173个交易</p>\n<h5 id=\"机器使用\"><a href=\"#机器使用\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机</th>\n<th>2号机</th>\n<th>3号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1400</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<p><strong>只读出块速度</strong>： http 客户端发送交易，首先发送到peer背书，随后发送到order节点，order节点收到交易后放入到kafka存储(消息生产过程)，随后order出块(消息消费过程)。当消息生产速度高于消费速度，就会造成消息堆积，<strong>当消息生产速度为0，只消费堆积的消息的速度，称为只读出块速度</strong>。</p>\n<h4 id=\"第一次更新\"><a href=\"#第一次更新\" class=\"headerlink\" title=\"第一次更新\"></a>第一次更新</h4><p>增加区块大小</p>\n<p>每区块1500KB，每条交易2，9KB，每个区块平均包含500个交易</p>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1500</td>\n<td>1500</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<h4 id=\"第二次更新\"><a href=\"#第二次更新\" class=\"headerlink\" title=\"第二次更新\"></a>第二次更新</h4><p>增加peer数量</p>\n<h5 id=\"机器使用-1\"><a href=\"#机器使用-1\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机</th>\n<th>2号机</th>\n<th>3号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1；peer服务 * 1</td>\n<td>http 客户端测试服务 * 2</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1000</td>\n<td>8000*2</td>\n<td>1800</td>\n</tr>\n</tbody></table>\n<p><strong>观察</strong></p>\n<p>增加peer，peer的背书速度稍有提升，但出块速度竟然降低了..</p>\n<p>出块的速度小于交易产生速度，当http 客户端停掉之后，出块的速度得到提升并且稍大于单个peer的情况。</p>\n<h4 id=\"第三次更新\"><a href=\"#第三次更新\" class=\"headerlink\" title=\"第三次更新\"></a>第三次更新</h4><p>追加服务器，负载均衡</p>\n<ul>\n<li>4号机，4核8g</li>\n<li>5号机，4核8g</li>\n</ul>\n<h5 id=\"机器使用-2\"><a href=\"#机器使用-2\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机</th>\n<th>2号机</th>\n<th>3号机</th>\n<th>4号机</th>\n<th>5号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1</td>\n<td>peer服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1300</td>\n<td>1400 * 2</td>\n<td>2200</td>\n</tr>\n</tbody></table>\n<p><strong>观察</strong></p>\n<p>负载均衡后，背书的速度得到显著提升！实时出块和只读出块的速度也稍有提升。</p>\n<p>但实时出块的速度还是没有只有1个peer的速度…</p>\n<h4 id=\"第四、五次更新\"><a href=\"#第四、五次更新\" class=\"headerlink\" title=\"第四、五次更新\"></a>第四、五次更新</h4><p>提升服务器性能，首先将order服务所在的1号机升级为8核16g，实时出块的速度增加到1700，但2个peer的速度还是没有1个peer的速度快..</p>\n<p>其次，提升了kafka服务器的性能.. 结果没啥变化</p>\n<h4 id=\"第六次更新\"><a href=\"#第六次更新\" class=\"headerlink\" title=\"第六次更新\"></a>第六次更新</h4><p>再次提升服务器性能，这次提升的是peer节点的性能，将peer节点的2号机和3号机升级为8核16g</p>\n<h5 id=\"机器使用-3\"><a href=\"#机器使用-3\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机8核16g</th>\n<th>2号机8核16g</th>\n<th>4号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1800</td>\n<td>1800</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<h5 id=\"机器使用-4\"><a href=\"#机器使用-4\" class=\"headerlink\" title=\"机器使用\"></a>机器使用</h5><table>\n<thead>\n<tr>\n<th>1号机8核16g</th>\n<th>2号机8核16g</th>\n<th>3号机8核16g</th>\n<th>4号机</th>\n<th>5号机</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>order服务 * 3</td>\n<td>peer服务 * 1</td>\n<td>peer服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n<td>http 客户端测试服务 * 1</td>\n</tr>\n</tbody></table>\n<p>性能情况</p>\n<table>\n<thead>\n<tr>\n<th>实时出块速度</th>\n<th>背书速度</th>\n<th>只读出块速度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2600</td>\n<td>1700 * 2</td>\n<td>3500</td>\n</tr>\n</tbody></table>\n<p><strong>观察</strong></p>\n<p>1个peer时速度为出块速度为1800</p>\n<p>增加1个peer，背书速度提升接近2倍，出块速度增加至2600，当停掉http客户端后，只读出块速度增加至3500</p>\n<h3 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h3><p>(在一定条件下)增加peer的数量，能增加tps。在本例中，8核16g的peer下，增加一个peer的tps由1800增加至2600。</p>\n<p>所谓一定条件，例如peer服务对于服务器性能(内存等)要求挺高的。</p>\n"},{"title":"floodlight_sdn","date":"2017-10-14T05:56:22.000Z","_content":"\n## SDN基本架构\n\n- 控制层\n- 转发层\n- 应用层\n- 南向接口\n- 北向接口\n\n基本含义借\"SDN核心技术剖析和实战指南\"书的例子来说：\n\n> SDN的架构可以与人的身体做类比：控制层就是人的大脑，负责对人身体的总体管控；转发层的设备是人的四肢，在大脑的控制下进行各种活动；应用层对应的是各种创新的想法，大脑在它们的驱动下对四肢进行指挥以达到其所需的效果；南向接口和北向接口则分别相当于人体内的神经和脑电波，负责各种信号的上传下达\n\n故由上到下的顺序是 应用层 -> 控制层 -> 转发层，南北也因此命名，北向接口为控制层提供给应用层的接口，南向接口为控制层提供给转发层的接口。\n\n#### SDN 交换机\n\n交换机属于转发层，负责具体数据转发处理的设备。\n\n> 其工作原理都是在收到数据包时，将数据包中的某些特征域与设备自身存储的一些表项进行比对，当发现匹配时则按照表项的要求进行相应处理。\n\n言而言之交换机的工作就是对数据包进行匹配和处理，但匹配和处理的定义并非在交换机中实现，而是由控制器统一下发，统称**流表**。简要介绍一下OpenFlow流表的组成: 包头域 + 计数器 + 动作，包头域包括一系列进行匹配的参数，如入端口、源MAC地址，目的MAC地址等，计数器则用于统计数据流量的相关信息，动作用于指示交换机经匹配后的数据包如何处理，如转发。\n\n#### 南向接口\n\n> SDN交换机需要在远程控制器的管控下工作，与之相关的设备状态和控制指令都需要经由SDN的南向接口传达。当前，最知名的南向接口莫过于ONF倡导的OpenFlow协议。\n\n#### 北向接口\n\n> SDN北向接口是通过控制器向上层业务应用开放的接口，其目标是使得业务应用能够便利地调用底层的网络资源和能力。\n\n> 例如REST API就是上层业务应用的开发者比较喜欢的接口形式\n\n上面的概念下面将进一步讨论，但主要记录的是Builder设计模式的易用性和不可变对象的production(Buidler和production都是设计模式），production的对象的使用，代替了强制类型安全编码的原始类型，并且产生的是更多的可读性代码，内置的通配形式，以及最后没有必要去处理消息的长度。(这段话的对比是Pre-v1.0和Floodlight v1.0, v1.1, v1.2，可见readme中这段话的前面代码对比)\n\n所有的连接到Floodloght的switches都包含一个switch描述Openflow版本的工厂。可以有多种switch,所有都是不同版本的Openflow，在那些swicth中，controller会幕后处理低级协议差异。从模块和应用开发人员的角度来看，switch是暴露出来的IOFSwitch, IOFSwitch的方法之一getOFFactory能返回OpenFlowJ-Loxi工厂，适合switch描述的OpenFlow版本。一旦你有了正确的工厂，你就可以通过公共的OpenFlowJ-Loxi暴露的API创建OpenFlow类型和概念。\n\n因此，你在编写FlowMods和其他类型的时候不需要切换Api。例如，假设你想构建一个FlowMod，发送到一个switch上，OFSwitchManager已知的每一个switch都有一个相同版本的OpenFlow工厂的引用。这个引用在于协商switch和controller之间最初的握手。故上述整体过程是，从你的switch引用工厂，创建buidler，构建FlowMod, 并写到switch.忽略OpenFlow版本的话，所有OpenFlow对象的构造器是相同的API，但是你需要知道你可以使用的每一个OpenFlow版本，否则，例如你告诉一个OpenFlow1.0的switch去执行一些类似添加组的操作，而这个操作在1.0中并不支持，OpenFlowJ-Loxi库会使用一个UnsupportedOperationException友好提醒你。\n\n介绍其他一些微妙的为了变得很好变化。例如，许多常见的类型，如交换机交换机datapath ids, openflow ports, ip mac 地址被定义到OpenFlowJ-Loxi库中，通过DatapathId, OFPort, IPv4Address/IPv6Address, and MacAddress。你可以搜索org.projectfloodlight.openflow.types，能发现很多常见的可以被定义到单一位置的类型，像上面的buidlers中的produced对象，所有的类型都是不可变的。\n\n更多新的API在Floodlight v1.2中，参阅OpenFlowJ-Loxi文档和例子\n","source":"_posts/floodlight-sdn.md","raw":"---\ntitle: floodlight_sdn\ndate: 2017-10-14 13:56:22\ncategories:\n- enjoy\n---\n\n## SDN基本架构\n\n- 控制层\n- 转发层\n- 应用层\n- 南向接口\n- 北向接口\n\n基本含义借\"SDN核心技术剖析和实战指南\"书的例子来说：\n\n> SDN的架构可以与人的身体做类比：控制层就是人的大脑，负责对人身体的总体管控；转发层的设备是人的四肢，在大脑的控制下进行各种活动；应用层对应的是各种创新的想法，大脑在它们的驱动下对四肢进行指挥以达到其所需的效果；南向接口和北向接口则分别相当于人体内的神经和脑电波，负责各种信号的上传下达\n\n故由上到下的顺序是 应用层 -> 控制层 -> 转发层，南北也因此命名，北向接口为控制层提供给应用层的接口，南向接口为控制层提供给转发层的接口。\n\n#### SDN 交换机\n\n交换机属于转发层，负责具体数据转发处理的设备。\n\n> 其工作原理都是在收到数据包时，将数据包中的某些特征域与设备自身存储的一些表项进行比对，当发现匹配时则按照表项的要求进行相应处理。\n\n言而言之交换机的工作就是对数据包进行匹配和处理，但匹配和处理的定义并非在交换机中实现，而是由控制器统一下发，统称**流表**。简要介绍一下OpenFlow流表的组成: 包头域 + 计数器 + 动作，包头域包括一系列进行匹配的参数，如入端口、源MAC地址，目的MAC地址等，计数器则用于统计数据流量的相关信息，动作用于指示交换机经匹配后的数据包如何处理，如转发。\n\n#### 南向接口\n\n> SDN交换机需要在远程控制器的管控下工作，与之相关的设备状态和控制指令都需要经由SDN的南向接口传达。当前，最知名的南向接口莫过于ONF倡导的OpenFlow协议。\n\n#### 北向接口\n\n> SDN北向接口是通过控制器向上层业务应用开放的接口，其目标是使得业务应用能够便利地调用底层的网络资源和能力。\n\n> 例如REST API就是上层业务应用的开发者比较喜欢的接口形式\n\n上面的概念下面将进一步讨论，但主要记录的是Builder设计模式的易用性和不可变对象的production(Buidler和production都是设计模式），production的对象的使用，代替了强制类型安全编码的原始类型，并且产生的是更多的可读性代码，内置的通配形式，以及最后没有必要去处理消息的长度。(这段话的对比是Pre-v1.0和Floodlight v1.0, v1.1, v1.2，可见readme中这段话的前面代码对比)\n\n所有的连接到Floodloght的switches都包含一个switch描述Openflow版本的工厂。可以有多种switch,所有都是不同版本的Openflow，在那些swicth中，controller会幕后处理低级协议差异。从模块和应用开发人员的角度来看，switch是暴露出来的IOFSwitch, IOFSwitch的方法之一getOFFactory能返回OpenFlowJ-Loxi工厂，适合switch描述的OpenFlow版本。一旦你有了正确的工厂，你就可以通过公共的OpenFlowJ-Loxi暴露的API创建OpenFlow类型和概念。\n\n因此，你在编写FlowMods和其他类型的时候不需要切换Api。例如，假设你想构建一个FlowMod，发送到一个switch上，OFSwitchManager已知的每一个switch都有一个相同版本的OpenFlow工厂的引用。这个引用在于协商switch和controller之间最初的握手。故上述整体过程是，从你的switch引用工厂，创建buidler，构建FlowMod, 并写到switch.忽略OpenFlow版本的话，所有OpenFlow对象的构造器是相同的API，但是你需要知道你可以使用的每一个OpenFlow版本，否则，例如你告诉一个OpenFlow1.0的switch去执行一些类似添加组的操作，而这个操作在1.0中并不支持，OpenFlowJ-Loxi库会使用一个UnsupportedOperationException友好提醒你。\n\n介绍其他一些微妙的为了变得很好变化。例如，许多常见的类型，如交换机交换机datapath ids, openflow ports, ip mac 地址被定义到OpenFlowJ-Loxi库中，通过DatapathId, OFPort, IPv4Address/IPv6Address, and MacAddress。你可以搜索org.projectfloodlight.openflow.types，能发现很多常见的可以被定义到单一位置的类型，像上面的buidlers中的produced对象，所有的类型都是不可变的。\n\n更多新的API在Floodlight v1.2中，参阅OpenFlowJ-Loxi文档和例子\n","slug":"floodlight-sdn","published":1,"updated":"2019-10-14T06:21:47.845Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69u50011t6xvixx4owv1","content":"<h2 id=\"SDN基本架构\"><a href=\"#SDN基本架构\" class=\"headerlink\" title=\"SDN基本架构\"></a>SDN基本架构</h2><ul>\n<li>控制层</li>\n<li>转发层</li>\n<li>应用层</li>\n<li>南向接口</li>\n<li>北向接口</li>\n</ul>\n<p>基本含义借”SDN核心技术剖析和实战指南”书的例子来说：</p>\n<blockquote>\n<p>SDN的架构可以与人的身体做类比：控制层就是人的大脑，负责对人身体的总体管控；转发层的设备是人的四肢，在大脑的控制下进行各种活动；应用层对应的是各种创新的想法，大脑在它们的驱动下对四肢进行指挥以达到其所需的效果；南向接口和北向接口则分别相当于人体内的神经和脑电波，负责各种信号的上传下达</p>\n</blockquote>\n<p>故由上到下的顺序是 应用层 -&gt; 控制层 -&gt; 转发层，南北也因此命名，北向接口为控制层提供给应用层的接口，南向接口为控制层提供给转发层的接口。</p>\n<h4 id=\"SDN-交换机\"><a href=\"#SDN-交换机\" class=\"headerlink\" title=\"SDN 交换机\"></a>SDN 交换机</h4><p>交换机属于转发层，负责具体数据转发处理的设备。</p>\n<blockquote>\n<p>其工作原理都是在收到数据包时，将数据包中的某些特征域与设备自身存储的一些表项进行比对，当发现匹配时则按照表项的要求进行相应处理。</p>\n</blockquote>\n<p>言而言之交换机的工作就是对数据包进行匹配和处理，但匹配和处理的定义并非在交换机中实现，而是由控制器统一下发，统称<strong>流表</strong>。简要介绍一下OpenFlow流表的组成: 包头域 + 计数器 + 动作，包头域包括一系列进行匹配的参数，如入端口、源MAC地址，目的MAC地址等，计数器则用于统计数据流量的相关信息，动作用于指示交换机经匹配后的数据包如何处理，如转发。</p>\n<h4 id=\"南向接口\"><a href=\"#南向接口\" class=\"headerlink\" title=\"南向接口\"></a>南向接口</h4><blockquote>\n<p>SDN交换机需要在远程控制器的管控下工作，与之相关的设备状态和控制指令都需要经由SDN的南向接口传达。当前，最知名的南向接口莫过于ONF倡导的OpenFlow协议。</p>\n</blockquote>\n<h4 id=\"北向接口\"><a href=\"#北向接口\" class=\"headerlink\" title=\"北向接口\"></a>北向接口</h4><blockquote>\n<p>SDN北向接口是通过控制器向上层业务应用开放的接口，其目标是使得业务应用能够便利地调用底层的网络资源和能力。</p>\n</blockquote>\n<blockquote>\n<p>例如REST API就是上层业务应用的开发者比较喜欢的接口形式</p>\n</blockquote>\n<p>上面的概念下面将进一步讨论，但主要记录的是Builder设计模式的易用性和不可变对象的production(Buidler和production都是设计模式），production的对象的使用，代替了强制类型安全编码的原始类型，并且产生的是更多的可读性代码，内置的通配形式，以及最后没有必要去处理消息的长度。(这段话的对比是Pre-v1.0和Floodlight v1.0, v1.1, v1.2，可见readme中这段话的前面代码对比)</p>\n<p>所有的连接到Floodloght的switches都包含一个switch描述Openflow版本的工厂。可以有多种switch,所有都是不同版本的Openflow，在那些swicth中，controller会幕后处理低级协议差异。从模块和应用开发人员的角度来看，switch是暴露出来的IOFSwitch, IOFSwitch的方法之一getOFFactory能返回OpenFlowJ-Loxi工厂，适合switch描述的OpenFlow版本。一旦你有了正确的工厂，你就可以通过公共的OpenFlowJ-Loxi暴露的API创建OpenFlow类型和概念。</p>\n<p>因此，你在编写FlowMods和其他类型的时候不需要切换Api。例如，假设你想构建一个FlowMod，发送到一个switch上，OFSwitchManager已知的每一个switch都有一个相同版本的OpenFlow工厂的引用。这个引用在于协商switch和controller之间最初的握手。故上述整体过程是，从你的switch引用工厂，创建buidler，构建FlowMod, 并写到switch.忽略OpenFlow版本的话，所有OpenFlow对象的构造器是相同的API，但是你需要知道你可以使用的每一个OpenFlow版本，否则，例如你告诉一个OpenFlow1.0的switch去执行一些类似添加组的操作，而这个操作在1.0中并不支持，OpenFlowJ-Loxi库会使用一个UnsupportedOperationException友好提醒你。</p>\n<p>介绍其他一些微妙的为了变得很好变化。例如，许多常见的类型，如交换机交换机datapath ids, openflow ports, ip mac 地址被定义到OpenFlowJ-Loxi库中，通过DatapathId, OFPort, IPv4Address/IPv6Address, and MacAddress。你可以搜索org.projectfloodlight.openflow.types，能发现很多常见的可以被定义到单一位置的类型，像上面的buidlers中的produced对象，所有的类型都是不可变的。</p>\n<p>更多新的API在Floodlight v1.2中，参阅OpenFlowJ-Loxi文档和例子</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"SDN基本架构\"><a href=\"#SDN基本架构\" class=\"headerlink\" title=\"SDN基本架构\"></a>SDN基本架构</h2><ul>\n<li>控制层</li>\n<li>转发层</li>\n<li>应用层</li>\n<li>南向接口</li>\n<li>北向接口</li>\n</ul>\n<p>基本含义借”SDN核心技术剖析和实战指南”书的例子来说：</p>\n<blockquote>\n<p>SDN的架构可以与人的身体做类比：控制层就是人的大脑，负责对人身体的总体管控；转发层的设备是人的四肢，在大脑的控制下进行各种活动；应用层对应的是各种创新的想法，大脑在它们的驱动下对四肢进行指挥以达到其所需的效果；南向接口和北向接口则分别相当于人体内的神经和脑电波，负责各种信号的上传下达</p>\n</blockquote>\n<p>故由上到下的顺序是 应用层 -&gt; 控制层 -&gt; 转发层，南北也因此命名，北向接口为控制层提供给应用层的接口，南向接口为控制层提供给转发层的接口。</p>\n<h4 id=\"SDN-交换机\"><a href=\"#SDN-交换机\" class=\"headerlink\" title=\"SDN 交换机\"></a>SDN 交换机</h4><p>交换机属于转发层，负责具体数据转发处理的设备。</p>\n<blockquote>\n<p>其工作原理都是在收到数据包时，将数据包中的某些特征域与设备自身存储的一些表项进行比对，当发现匹配时则按照表项的要求进行相应处理。</p>\n</blockquote>\n<p>言而言之交换机的工作就是对数据包进行匹配和处理，但匹配和处理的定义并非在交换机中实现，而是由控制器统一下发，统称<strong>流表</strong>。简要介绍一下OpenFlow流表的组成: 包头域 + 计数器 + 动作，包头域包括一系列进行匹配的参数，如入端口、源MAC地址，目的MAC地址等，计数器则用于统计数据流量的相关信息，动作用于指示交换机经匹配后的数据包如何处理，如转发。</p>\n<h4 id=\"南向接口\"><a href=\"#南向接口\" class=\"headerlink\" title=\"南向接口\"></a>南向接口</h4><blockquote>\n<p>SDN交换机需要在远程控制器的管控下工作，与之相关的设备状态和控制指令都需要经由SDN的南向接口传达。当前，最知名的南向接口莫过于ONF倡导的OpenFlow协议。</p>\n</blockquote>\n<h4 id=\"北向接口\"><a href=\"#北向接口\" class=\"headerlink\" title=\"北向接口\"></a>北向接口</h4><blockquote>\n<p>SDN北向接口是通过控制器向上层业务应用开放的接口，其目标是使得业务应用能够便利地调用底层的网络资源和能力。</p>\n</blockquote>\n<blockquote>\n<p>例如REST API就是上层业务应用的开发者比较喜欢的接口形式</p>\n</blockquote>\n<p>上面的概念下面将进一步讨论，但主要记录的是Builder设计模式的易用性和不可变对象的production(Buidler和production都是设计模式），production的对象的使用，代替了强制类型安全编码的原始类型，并且产生的是更多的可读性代码，内置的通配形式，以及最后没有必要去处理消息的长度。(这段话的对比是Pre-v1.0和Floodlight v1.0, v1.1, v1.2，可见readme中这段话的前面代码对比)</p>\n<p>所有的连接到Floodloght的switches都包含一个switch描述Openflow版本的工厂。可以有多种switch,所有都是不同版本的Openflow，在那些swicth中，controller会幕后处理低级协议差异。从模块和应用开发人员的角度来看，switch是暴露出来的IOFSwitch, IOFSwitch的方法之一getOFFactory能返回OpenFlowJ-Loxi工厂，适合switch描述的OpenFlow版本。一旦你有了正确的工厂，你就可以通过公共的OpenFlowJ-Loxi暴露的API创建OpenFlow类型和概念。</p>\n<p>因此，你在编写FlowMods和其他类型的时候不需要切换Api。例如，假设你想构建一个FlowMod，发送到一个switch上，OFSwitchManager已知的每一个switch都有一个相同版本的OpenFlow工厂的引用。这个引用在于协商switch和controller之间最初的握手。故上述整体过程是，从你的switch引用工厂，创建buidler，构建FlowMod, 并写到switch.忽略OpenFlow版本的话，所有OpenFlow对象的构造器是相同的API，但是你需要知道你可以使用的每一个OpenFlow版本，否则，例如你告诉一个OpenFlow1.0的switch去执行一些类似添加组的操作，而这个操作在1.0中并不支持，OpenFlowJ-Loxi库会使用一个UnsupportedOperationException友好提醒你。</p>\n<p>介绍其他一些微妙的为了变得很好变化。例如，许多常见的类型，如交换机交换机datapath ids, openflow ports, ip mac 地址被定义到OpenFlowJ-Loxi库中，通过DatapathId, OFPort, IPv4Address/IPv6Address, and MacAddress。你可以搜索org.projectfloodlight.openflow.types，能发现很多常见的可以被定义到单一位置的类型，像上面的buidlers中的produced对象，所有的类型都是不可变的。</p>\n<p>更多新的API在Floodlight v1.2中，参阅OpenFlowJ-Loxi文档和例子</p>\n"},{"title":"how to set up a blog","date":"2019-10-12T03:32:16.000Z","_content":"## 博客搭建\n\n<font size=\"1\">哈哈哈哈哈哈哈哈，继我工作3年后，终于搭建了博客了。(虽然迟到了这么久…但还是哈哈哈哈哈哈好开心啊)</font>\n\n### 方案\n\nGithub Pages + Travis + Hexo\n\n\n\n### Hexo\n\nHexo呢，是基于Node.js的静态博客框架。反正就是，可以减小那些别的操作，让写博客的人更专注于写博客内容。 \n\n##### 安装和使用\n\n前提条件，已安装git、nodejs。\n\n```\nnpm install -g hexo-cli \n```\n\n安装完hexo-cli工具后，就可以使用hexo命令进行操作了。\n\n```\nhexo init [dir]\n```\n\n初始化博客。\n\n完成之后，会产生几个文件夹，如下。\n\n```\n.\n├── _config.yml\n├── package.json\n├── scaffolds   //模板，用于创建博文等\n├── source   //博文等具体位置\n└── themes  //主题\n```\n\n关于hexo的操作命令如下\n\n```\nhexo --help\nUsage: hexo <command>\n\nCommands:\n  clean     Remove generated files and cache.\n  config    Get or set configurations.\n  deploy    Deploy your website.\n  generate  Generate static files.\n  help      Get help on a command.\n  init      Create a new Hexo folder.\n  list      List the information of the site\n  migrate   Migrate your site from other system to Hexo.\n  new       Create a new post.\n  publish   Moves a draft post from _drafts to _posts folder.\n  render    Render files with renderer plugins.\n  server    Start the server.\n```\n\n使用generate可产生静态文件夹`public`，使用server命令即可在本地启动node服务，使用浏览器即可查看到效果。\n\n如果 hexo没有server的话，是因为版本的不同，将server独立出去了，需要单独安装` npm install hexo-server --save`\n\n关于主题的话，如果选择开源主题，可直接下载到theme文件夹即可使用。我这里使用的是[cactus](https://github.com/probberechts/hexo-theme-cactus)\n\n\n\n### Github Pages\n\n> [GitHub Pages](https://pages.github.com/) is designed to host your personal, organization, or project pages from a GitHub repository.\n>\n>  Your site is published at https://xiaoxuez.github.io/\n\n就是github提供的服务，将github仓库部署到`https://username.github.io`这样的域名下。\n\n<font size=2>这样就不用自己买服务器，自己部署服务了。</font>\n\n使用方式呢，就是创建一个仓库，然后从仓库setting页，即可看到Github Pages设置项，可选择要部署的分支和选择主题。这里要选择一个主题。然后如果使用username.github.io命名的仓库的话，只能部署master分支，不能修改。\n\n\n\n### Travis\n\n[travis]([https://travis-ci.com](https://travis-ci.com/))自动化部署\n\n首先要理解的是，博客，其实是有两套代码的，一套是源代码，一套是生成的`public`。我们可以选择将源代码放到一个分支上，`public`提交到另一个分支上。然后Github Pages部署的分支选择`public`所在的分支即可。\n\n那么，travis可以帮助的事呢，就是当我将源代码push到远程仓库后，做一些事，比如执行`hexo generate`脚本生成`public`文件夹并push到对应分支上。这样就很完美了。\n\n关于travis的具体使用，可见[详细文档](https://docs.travis-ci.com/)\n\n首先，要添加`.travis.yaml`配置文件到仓库代码里。\n\n```\nsudo: false\nlanguage: node_js\nnode_js:\n  - 10 # use nodejs v10 LTS\ncache: npm\nbranches:\n  only:\n    - resource # build master branch only\nscript:\n  - hexo generate # generate static files\ndeploy:\n  provider: pages\n  skip-cleanup: true\n  github-token: $GH_TOKEN\n  keep-history: true\n  on:\n    branch: resource  //构建resource分支\n  local-dir: public\n  target_branch: master  //发布到master分支\n\n```\n\ntarget_branch默认呢是`gh-pages`。然后因为我的仓库名为`xiaoxuez.github.io`，上文提到了我需要将静态文件提交到master分支，所以我将`hexo generate`之后的`public`文件夹发布到mster分支上了。关于deploy各字段的介绍，可见[文档](https://docs.travis-ci.com/user/deployment/pages/)\n\n最后，就是要github授权给travis，文档在[这里](https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line)。Token的存放可以选择在本地，或者配置到[travis](https://docs.travis-ci.com/user/environment-variables#defining-variables-in-repository-settings)上。\n\n这样，就可以使用啦。\n\n还有就是在github上的personal settings里的Applicaitons会安装travis插件，可以控制travis的权限。\n\n\n","source":"_posts/how-to-set-up-a-blog.md","raw":"---\ntitle: how to set up a blog\ndate: 2019-10-12 11:32:16\ntags:\ncategories:\n- enjoyment\n---\n## 博客搭建\n\n<font size=\"1\">哈哈哈哈哈哈哈哈，继我工作3年后，终于搭建了博客了。(虽然迟到了这么久…但还是哈哈哈哈哈哈好开心啊)</font>\n\n### 方案\n\nGithub Pages + Travis + Hexo\n\n\n\n### Hexo\n\nHexo呢，是基于Node.js的静态博客框架。反正就是，可以减小那些别的操作，让写博客的人更专注于写博客内容。 \n\n##### 安装和使用\n\n前提条件，已安装git、nodejs。\n\n```\nnpm install -g hexo-cli \n```\n\n安装完hexo-cli工具后，就可以使用hexo命令进行操作了。\n\n```\nhexo init [dir]\n```\n\n初始化博客。\n\n完成之后，会产生几个文件夹，如下。\n\n```\n.\n├── _config.yml\n├── package.json\n├── scaffolds   //模板，用于创建博文等\n├── source   //博文等具体位置\n└── themes  //主题\n```\n\n关于hexo的操作命令如下\n\n```\nhexo --help\nUsage: hexo <command>\n\nCommands:\n  clean     Remove generated files and cache.\n  config    Get or set configurations.\n  deploy    Deploy your website.\n  generate  Generate static files.\n  help      Get help on a command.\n  init      Create a new Hexo folder.\n  list      List the information of the site\n  migrate   Migrate your site from other system to Hexo.\n  new       Create a new post.\n  publish   Moves a draft post from _drafts to _posts folder.\n  render    Render files with renderer plugins.\n  server    Start the server.\n```\n\n使用generate可产生静态文件夹`public`，使用server命令即可在本地启动node服务，使用浏览器即可查看到效果。\n\n如果 hexo没有server的话，是因为版本的不同，将server独立出去了，需要单独安装` npm install hexo-server --save`\n\n关于主题的话，如果选择开源主题，可直接下载到theme文件夹即可使用。我这里使用的是[cactus](https://github.com/probberechts/hexo-theme-cactus)\n\n\n\n### Github Pages\n\n> [GitHub Pages](https://pages.github.com/) is designed to host your personal, organization, or project pages from a GitHub repository.\n>\n>  Your site is published at https://xiaoxuez.github.io/\n\n就是github提供的服务，将github仓库部署到`https://username.github.io`这样的域名下。\n\n<font size=2>这样就不用自己买服务器，自己部署服务了。</font>\n\n使用方式呢，就是创建一个仓库，然后从仓库setting页，即可看到Github Pages设置项，可选择要部署的分支和选择主题。这里要选择一个主题。然后如果使用username.github.io命名的仓库的话，只能部署master分支，不能修改。\n\n\n\n### Travis\n\n[travis]([https://travis-ci.com](https://travis-ci.com/))自动化部署\n\n首先要理解的是，博客，其实是有两套代码的，一套是源代码，一套是生成的`public`。我们可以选择将源代码放到一个分支上，`public`提交到另一个分支上。然后Github Pages部署的分支选择`public`所在的分支即可。\n\n那么，travis可以帮助的事呢，就是当我将源代码push到远程仓库后，做一些事，比如执行`hexo generate`脚本生成`public`文件夹并push到对应分支上。这样就很完美了。\n\n关于travis的具体使用，可见[详细文档](https://docs.travis-ci.com/)\n\n首先，要添加`.travis.yaml`配置文件到仓库代码里。\n\n```\nsudo: false\nlanguage: node_js\nnode_js:\n  - 10 # use nodejs v10 LTS\ncache: npm\nbranches:\n  only:\n    - resource # build master branch only\nscript:\n  - hexo generate # generate static files\ndeploy:\n  provider: pages\n  skip-cleanup: true\n  github-token: $GH_TOKEN\n  keep-history: true\n  on:\n    branch: resource  //构建resource分支\n  local-dir: public\n  target_branch: master  //发布到master分支\n\n```\n\ntarget_branch默认呢是`gh-pages`。然后因为我的仓库名为`xiaoxuez.github.io`，上文提到了我需要将静态文件提交到master分支，所以我将`hexo generate`之后的`public`文件夹发布到mster分支上了。关于deploy各字段的介绍，可见[文档](https://docs.travis-ci.com/user/deployment/pages/)\n\n最后，就是要github授权给travis，文档在[这里](https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line)。Token的存放可以选择在本地，或者配置到[travis](https://docs.travis-ci.com/user/environment-variables#defining-variables-in-repository-settings)上。\n\n这样，就可以使用啦。\n\n还有就是在github上的personal settings里的Applicaitons会安装travis插件，可以控制travis的权限。\n\n\n","slug":"how-to-set-up-a-blog","published":1,"updated":"2019-10-14T02:31:17.620Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69u70013t6xv76lf3sqm","content":"<h2 id=\"博客搭建\"><a href=\"#博客搭建\" class=\"headerlink\" title=\"博客搭建\"></a>博客搭建</h2><p><font size=\"1\">哈哈哈哈哈哈哈哈，继我工作3年后，终于搭建了博客了。(虽然迟到了这么久…但还是哈哈哈哈哈哈好开心啊)</font></p>\n<h3 id=\"方案\"><a href=\"#方案\" class=\"headerlink\" title=\"方案\"></a>方案</h3><p>Github Pages + Travis + Hexo</p>\n<h3 id=\"Hexo\"><a href=\"#Hexo\" class=\"headerlink\" title=\"Hexo\"></a>Hexo</h3><p>Hexo呢，是基于Node.js的静态博客框架。反正就是，可以减小那些别的操作，让写博客的人更专注于写博客内容。 </p>\n<h5 id=\"安装和使用\"><a href=\"#安装和使用\" class=\"headerlink\" title=\"安装和使用\"></a>安装和使用</h5><p>前提条件，已安装git、nodejs。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>\n\n<p>安装完hexo-cli工具后，就可以使用hexo命令进行操作了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo init [dir]</span><br></pre></td></tr></table></figure>\n\n<p>初始化博客。</p>\n<p>完成之后，会产生几个文件夹，如下。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.</span><br><span class=\"line\">├── _config.yml</span><br><span class=\"line\">├── package.json</span><br><span class=\"line\">├── scaffolds   //模板，用于创建博文等</span><br><span class=\"line\">├── source   //博文等具体位置</span><br><span class=\"line\">└── themes  //主题</span><br></pre></td></tr></table></figure>\n\n<p>关于hexo的操作命令如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo --help</span><br><span class=\"line\">Usage: hexo &lt;command&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">Commands:</span><br><span class=\"line\">  clean     Remove generated files and cache.</span><br><span class=\"line\">  config    Get or set configurations.</span><br><span class=\"line\">  deploy    Deploy your website.</span><br><span class=\"line\">  generate  Generate static files.</span><br><span class=\"line\">  help      Get help on a command.</span><br><span class=\"line\">  init      Create a new Hexo folder.</span><br><span class=\"line\">  list      List the information of the site</span><br><span class=\"line\">  migrate   Migrate your site from other system to Hexo.</span><br><span class=\"line\">  new       Create a new post.</span><br><span class=\"line\">  publish   Moves a draft post from _drafts to _posts folder.</span><br><span class=\"line\">  render    Render files with renderer plugins.</span><br><span class=\"line\">  server    Start the server.</span><br></pre></td></tr></table></figure>\n\n<p>使用generate可产生静态文件夹<code>public</code>，使用server命令即可在本地启动node服务，使用浏览器即可查看到效果。</p>\n<p>如果 hexo没有server的话，是因为版本的不同，将server独立出去了，需要单独安装<code>npm install hexo-server --save</code></p>\n<p>关于主题的话，如果选择开源主题，可直接下载到theme文件夹即可使用。我这里使用的是<a href=\"https://github.com/probberechts/hexo-theme-cactus\">cactus</a></p>\n<h3 id=\"Github-Pages\"><a href=\"#Github-Pages\" class=\"headerlink\" title=\"Github Pages\"></a>Github Pages</h3><blockquote>\n<p><a href=\"https://pages.github.com/\" target=\"_blank\" rel=\"noopener\">GitHub Pages</a> is designed to host your personal, organization, or project pages from a GitHub repository.</p>\n<p> Your site is published at <a href=\"https://xiaoxuez.github.io/\" target=\"_blank\" rel=\"noopener\">https://xiaoxuez.github.io/</a></p>\n</blockquote>\n<p>就是github提供的服务，将github仓库部署到<code>https://username.github.io</code>这样的域名下。</p>\n<p><font size=\"2\">这样就不用自己买服务器，自己部署服务了。</font></p>\n<p>使用方式呢，就是创建一个仓库，然后从仓库setting页，即可看到Github Pages设置项，可选择要部署的分支和选择主题。这里要选择一个主题。然后如果使用username.github.io命名的仓库的话，只能部署master分支，不能修改。</p>\n<h3 id=\"Travis\"><a href=\"#Travis\" class=\"headerlink\" title=\"Travis\"></a>Travis</h3><p><a href=\"[https://travis-ci.com](https://travis-ci.com/)\">travis</a>自动化部署</p>\n<p>首先要理解的是，博客，其实是有两套代码的，一套是源代码，一套是生成的<code>public</code>。我们可以选择将源代码放到一个分支上，<code>public</code>提交到另一个分支上。然后Github Pages部署的分支选择<code>public</code>所在的分支即可。</p>\n<p>那么，travis可以帮助的事呢，就是当我将源代码push到远程仓库后，做一些事，比如执行<code>hexo generate</code>脚本生成<code>public</code>文件夹并push到对应分支上。这样就很完美了。</p>\n<p>关于travis的具体使用，可见<a href=\"https://docs.travis-ci.com/\" target=\"_blank\" rel=\"noopener\">详细文档</a></p>\n<p>首先，要添加<code>.travis.yaml</code>配置文件到仓库代码里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo: false</span><br><span class=\"line\">language: node_js</span><br><span class=\"line\">node_js:</span><br><span class=\"line\">  - 10 # use nodejs v10 LTS</span><br><span class=\"line\">cache: npm</span><br><span class=\"line\">branches:</span><br><span class=\"line\">  only:</span><br><span class=\"line\">    - resource # build master branch only</span><br><span class=\"line\">script:</span><br><span class=\"line\">  - hexo generate # generate static files</span><br><span class=\"line\">deploy:</span><br><span class=\"line\">  provider: pages</span><br><span class=\"line\">  skip-cleanup: true</span><br><span class=\"line\">  github-token: $GH_TOKEN</span><br><span class=\"line\">  keep-history: true</span><br><span class=\"line\">  on:</span><br><span class=\"line\">    branch: resource  //构建resource分支</span><br><span class=\"line\">  local-dir: public</span><br><span class=\"line\">  target_branch: master  //发布到master分支</span><br></pre></td></tr></table></figure>\n\n<p>target_branch默认呢是<code>gh-pages</code>。然后因为我的仓库名为<code>xiaoxuez.github.io</code>，上文提到了我需要将静态文件提交到master分支，所以我将<code>hexo generate</code>之后的<code>public</code>文件夹发布到mster分支上了。关于deploy各字段的介绍，可见<a href=\"https://docs.travis-ci.com/user/deployment/pages/\" target=\"_blank\" rel=\"noopener\">文档</a></p>\n<p>最后，就是要github授权给travis，文档在<a href=\"https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line\" target=\"_blank\" rel=\"noopener\">这里</a>。Token的存放可以选择在本地，或者配置到<a href=\"https://docs.travis-ci.com/user/environment-variables#defining-variables-in-repository-settings\" target=\"_blank\" rel=\"noopener\">travis</a>上。</p>\n<p>这样，就可以使用啦。</p>\n<p>还有就是在github上的personal settings里的Applicaitons会安装travis插件，可以控制travis的权限。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"博客搭建\"><a href=\"#博客搭建\" class=\"headerlink\" title=\"博客搭建\"></a>博客搭建</h2><p><font size=\"1\">哈哈哈哈哈哈哈哈，继我工作3年后，终于搭建了博客了。(虽然迟到了这么久…但还是哈哈哈哈哈哈好开心啊)</font></p>\n<h3 id=\"方案\"><a href=\"#方案\" class=\"headerlink\" title=\"方案\"></a>方案</h3><p>Github Pages + Travis + Hexo</p>\n<h3 id=\"Hexo\"><a href=\"#Hexo\" class=\"headerlink\" title=\"Hexo\"></a>Hexo</h3><p>Hexo呢，是基于Node.js的静态博客框架。反正就是，可以减小那些别的操作，让写博客的人更专注于写博客内容。 </p>\n<h5 id=\"安装和使用\"><a href=\"#安装和使用\" class=\"headerlink\" title=\"安装和使用\"></a>安装和使用</h5><p>前提条件，已安装git、nodejs。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>\n\n<p>安装完hexo-cli工具后，就可以使用hexo命令进行操作了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo init [dir]</span><br></pre></td></tr></table></figure>\n\n<p>初始化博客。</p>\n<p>完成之后，会产生几个文件夹，如下。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.</span><br><span class=\"line\">├── _config.yml</span><br><span class=\"line\">├── package.json</span><br><span class=\"line\">├── scaffolds   //模板，用于创建博文等</span><br><span class=\"line\">├── source   //博文等具体位置</span><br><span class=\"line\">└── themes  //主题</span><br></pre></td></tr></table></figure>\n\n<p>关于hexo的操作命令如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo --help</span><br><span class=\"line\">Usage: hexo &lt;command&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">Commands:</span><br><span class=\"line\">  clean     Remove generated files and cache.</span><br><span class=\"line\">  config    Get or set configurations.</span><br><span class=\"line\">  deploy    Deploy your website.</span><br><span class=\"line\">  generate  Generate static files.</span><br><span class=\"line\">  help      Get help on a command.</span><br><span class=\"line\">  init      Create a new Hexo folder.</span><br><span class=\"line\">  list      List the information of the site</span><br><span class=\"line\">  migrate   Migrate your site from other system to Hexo.</span><br><span class=\"line\">  new       Create a new post.</span><br><span class=\"line\">  publish   Moves a draft post from _drafts to _posts folder.</span><br><span class=\"line\">  render    Render files with renderer plugins.</span><br><span class=\"line\">  server    Start the server.</span><br></pre></td></tr></table></figure>\n\n<p>使用generate可产生静态文件夹<code>public</code>，使用server命令即可在本地启动node服务，使用浏览器即可查看到效果。</p>\n<p>如果 hexo没有server的话，是因为版本的不同，将server独立出去了，需要单独安装<code>npm install hexo-server --save</code></p>\n<p>关于主题的话，如果选择开源主题，可直接下载到theme文件夹即可使用。我这里使用的是<a href=\"https://github.com/probberechts/hexo-theme-cactus\">cactus</a></p>\n<h3 id=\"Github-Pages\"><a href=\"#Github-Pages\" class=\"headerlink\" title=\"Github Pages\"></a>Github Pages</h3><blockquote>\n<p><a href=\"https://pages.github.com/\" target=\"_blank\" rel=\"noopener\">GitHub Pages</a> is designed to host your personal, organization, or project pages from a GitHub repository.</p>\n<p> Your site is published at <a href=\"https://xiaoxuez.github.io/\" target=\"_blank\" rel=\"noopener\">https://xiaoxuez.github.io/</a></p>\n</blockquote>\n<p>就是github提供的服务，将github仓库部署到<code>https://username.github.io</code>这样的域名下。</p>\n<p><font size=\"2\">这样就不用自己买服务器，自己部署服务了。</font></p>\n<p>使用方式呢，就是创建一个仓库，然后从仓库setting页，即可看到Github Pages设置项，可选择要部署的分支和选择主题。这里要选择一个主题。然后如果使用username.github.io命名的仓库的话，只能部署master分支，不能修改。</p>\n<h3 id=\"Travis\"><a href=\"#Travis\" class=\"headerlink\" title=\"Travis\"></a>Travis</h3><p><a href=\"[https://travis-ci.com](https://travis-ci.com/)\">travis</a>自动化部署</p>\n<p>首先要理解的是，博客，其实是有两套代码的，一套是源代码，一套是生成的<code>public</code>。我们可以选择将源代码放到一个分支上，<code>public</code>提交到另一个分支上。然后Github Pages部署的分支选择<code>public</code>所在的分支即可。</p>\n<p>那么，travis可以帮助的事呢，就是当我将源代码push到远程仓库后，做一些事，比如执行<code>hexo generate</code>脚本生成<code>public</code>文件夹并push到对应分支上。这样就很完美了。</p>\n<p>关于travis的具体使用，可见<a href=\"https://docs.travis-ci.com/\" target=\"_blank\" rel=\"noopener\">详细文档</a></p>\n<p>首先，要添加<code>.travis.yaml</code>配置文件到仓库代码里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo: false</span><br><span class=\"line\">language: node_js</span><br><span class=\"line\">node_js:</span><br><span class=\"line\">  - 10 # use nodejs v10 LTS</span><br><span class=\"line\">cache: npm</span><br><span class=\"line\">branches:</span><br><span class=\"line\">  only:</span><br><span class=\"line\">    - resource # build master branch only</span><br><span class=\"line\">script:</span><br><span class=\"line\">  - hexo generate # generate static files</span><br><span class=\"line\">deploy:</span><br><span class=\"line\">  provider: pages</span><br><span class=\"line\">  skip-cleanup: true</span><br><span class=\"line\">  github-token: $GH_TOKEN</span><br><span class=\"line\">  keep-history: true</span><br><span class=\"line\">  on:</span><br><span class=\"line\">    branch: resource  //构建resource分支</span><br><span class=\"line\">  local-dir: public</span><br><span class=\"line\">  target_branch: master  //发布到master分支</span><br></pre></td></tr></table></figure>\n\n<p>target_branch默认呢是<code>gh-pages</code>。然后因为我的仓库名为<code>xiaoxuez.github.io</code>，上文提到了我需要将静态文件提交到master分支，所以我将<code>hexo generate</code>之后的<code>public</code>文件夹发布到mster分支上了。关于deploy各字段的介绍，可见<a href=\"https://docs.travis-ci.com/user/deployment/pages/\" target=\"_blank\" rel=\"noopener\">文档</a></p>\n<p>最后，就是要github授权给travis，文档在<a href=\"https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line\" target=\"_blank\" rel=\"noopener\">这里</a>。Token的存放可以选择在本地，或者配置到<a href=\"https://docs.travis-ci.com/user/environment-variables#defining-variables-in-repository-settings\" target=\"_blank\" rel=\"noopener\">travis</a>上。</p>\n<p>这样，就可以使用啦。</p>\n<p>还有就是在github上的personal settings里的Applicaitons会安装travis插件，可以控制travis的权限。</p>\n"},{"title":"kibana_plugin_development","date":"2017-10-14T05:55:13.000Z","_content":"## Kibana插件开发指南\n\n本文档参考自以下资源\n\n- [trumandu-tutorial](https://trumandu.gitbooks.io/kibana-plugin-development-tutorial/content/)\n- [timroes.de](https://www.timroes.de/2015/12/02/writing-kibana-4-plugins-basics/)\n\n### Kibana开发环境搭建\n\n- github上下载kibana的源代码，切换到对应版本，kibana的版本很重要，kibana在升级的过程中api有可能会变化，所以插件的开发需要针对特定的版本，kibana多版本的话，插件也需要多版本。（本文全局变量kibana是5.3.4版本）。\n\n- npm install安装依赖。\n\n  - 如果公司防火墙限制从github下载依赖的话，git下载的方式将ssh替换成http\n\n    ```\n    git config --global url.\"https://\".insteadOf \"git://\"\n    //或者在.gitconfig文件中添加\n    [url \"https://\"]\n    insteadOf = git://\n    ```\n\n  - 安装过程中，可能会有依赖下载失败，或欠缺依赖，有提示的话，按照提示来单独下载就好了，没提示的话，愿谷歌保佑你。\n\n- npm start, 默认dev 启动方式会使用ssl,所以是https,如果需要修改的话，可以修改\\kibana\\src\\cli\\serve\\serve.js文件。修改位置如下：\n\n  ```\n  if (opts.dev) {\n      set('env', 'development');\n      set('optimize.lazy', true);\n\n      // if (opts.ssl) {\n      //   set('server.ssl.enabled', true);\n      // }\n\n      // if (opts.ssl && !has('server.ssl.certificate') && !has('server.ssl.key')) {\n      //   set('server.ssl.certificate', DEV_SSL_CERT_PATH);\n      //   set('server.ssl.key', DEV_SSL_KEY_PATH);\n      // }\n    }\n  ```\n\n### 加入插件\n\n将代码放在kibana的plugins文件夹下，Kibana会自动watch这些文件的changes。(只能直接把代码/文件夹放过来，并不能用软连接)。\n\n当你修改了代码，kibana会自动重新打包，会需要点时间，在命令行的console上能够看到如下提示\n\n```\nrestarting server due to changes in\n - \"installedPlugins/tr-k4p-clock/index.js\"\nserver log [21:49:59.323] [info][status][plugin:tr-k4p-clock] Status changed from uninitialized to green - Ready\n[...]\nserver log [21:49:59.421] [info][listening] Server running at http://0.0.0.0:5601\noptmzr log [21:50:07.177] [info][optimize] Lazy optimization started\noptmzr log [21:50:13.834] [info][optimize] Lazy optimization success in 6.66 seconds\n```\n\n重新打包后，刷新浏览器就可以看到你的修改了(小吐槽，刷新kibana是个最耗费时间的操作)。\n\n#### 基本插件\n\n每个插件都是一个npm module,所以至少需要两个文件，package.json和index.js。\n\n一个package.json的示例如下, 最好的话，文件夹名称，name保持一致，如下可以通过plugins/kibana\\_gm\\_cal\\_vis/进入文件夹,具体可见index示例,\n\n```\n{\n  \"name\": \"kibana_gm_cal_vis\",\n  \"version\": \"0.1.0\",\n  \"kibana\": {\n    \"version\": \"5.3.4\"\n  }\n}\n```\n\n一个index.js的示例如下\n\n```\nmodule.exports = function(kibana) {\n  return new kibana.Plugin({\n    uiExports: {\n      visTypes: ['plugins/kibana_gm_cal_vis/gm_cal']\n    }\n  });\n};\n```\n\n#### 插件的安装\n\n在Kibana上安装插件\n\n```\nbin/kibana plugin --install plugin-name -u https://url.to/plugin\n```\n\n如果是文件夹，直接放在plugins文件夹下就好了。\n\nkibana-docker的话，可以把文件夹挂载到/usr/share/kibana/plugins/plugin-name，但插件更新的话需要重新run重新挂载，不知道是不是我操作有问题..\n","source":"_posts/kibana-plugin-development.md","raw":"---\ntitle: kibana_plugin_development\ndate: 2017-10-14 13:55:13\ncategories:\n- elk\n---\n## Kibana插件开发指南\n\n本文档参考自以下资源\n\n- [trumandu-tutorial](https://trumandu.gitbooks.io/kibana-plugin-development-tutorial/content/)\n- [timroes.de](https://www.timroes.de/2015/12/02/writing-kibana-4-plugins-basics/)\n\n### Kibana开发环境搭建\n\n- github上下载kibana的源代码，切换到对应版本，kibana的版本很重要，kibana在升级的过程中api有可能会变化，所以插件的开发需要针对特定的版本，kibana多版本的话，插件也需要多版本。（本文全局变量kibana是5.3.4版本）。\n\n- npm install安装依赖。\n\n  - 如果公司防火墙限制从github下载依赖的话，git下载的方式将ssh替换成http\n\n    ```\n    git config --global url.\"https://\".insteadOf \"git://\"\n    //或者在.gitconfig文件中添加\n    [url \"https://\"]\n    insteadOf = git://\n    ```\n\n  - 安装过程中，可能会有依赖下载失败，或欠缺依赖，有提示的话，按照提示来单独下载就好了，没提示的话，愿谷歌保佑你。\n\n- npm start, 默认dev 启动方式会使用ssl,所以是https,如果需要修改的话，可以修改\\kibana\\src\\cli\\serve\\serve.js文件。修改位置如下：\n\n  ```\n  if (opts.dev) {\n      set('env', 'development');\n      set('optimize.lazy', true);\n\n      // if (opts.ssl) {\n      //   set('server.ssl.enabled', true);\n      // }\n\n      // if (opts.ssl && !has('server.ssl.certificate') && !has('server.ssl.key')) {\n      //   set('server.ssl.certificate', DEV_SSL_CERT_PATH);\n      //   set('server.ssl.key', DEV_SSL_KEY_PATH);\n      // }\n    }\n  ```\n\n### 加入插件\n\n将代码放在kibana的plugins文件夹下，Kibana会自动watch这些文件的changes。(只能直接把代码/文件夹放过来，并不能用软连接)。\n\n当你修改了代码，kibana会自动重新打包，会需要点时间，在命令行的console上能够看到如下提示\n\n```\nrestarting server due to changes in\n - \"installedPlugins/tr-k4p-clock/index.js\"\nserver log [21:49:59.323] [info][status][plugin:tr-k4p-clock] Status changed from uninitialized to green - Ready\n[...]\nserver log [21:49:59.421] [info][listening] Server running at http://0.0.0.0:5601\noptmzr log [21:50:07.177] [info][optimize] Lazy optimization started\noptmzr log [21:50:13.834] [info][optimize] Lazy optimization success in 6.66 seconds\n```\n\n重新打包后，刷新浏览器就可以看到你的修改了(小吐槽，刷新kibana是个最耗费时间的操作)。\n\n#### 基本插件\n\n每个插件都是一个npm module,所以至少需要两个文件，package.json和index.js。\n\n一个package.json的示例如下, 最好的话，文件夹名称，name保持一致，如下可以通过plugins/kibana\\_gm\\_cal\\_vis/进入文件夹,具体可见index示例,\n\n```\n{\n  \"name\": \"kibana_gm_cal_vis\",\n  \"version\": \"0.1.0\",\n  \"kibana\": {\n    \"version\": \"5.3.4\"\n  }\n}\n```\n\n一个index.js的示例如下\n\n```\nmodule.exports = function(kibana) {\n  return new kibana.Plugin({\n    uiExports: {\n      visTypes: ['plugins/kibana_gm_cal_vis/gm_cal']\n    }\n  });\n};\n```\n\n#### 插件的安装\n\n在Kibana上安装插件\n\n```\nbin/kibana plugin --install plugin-name -u https://url.to/plugin\n```\n\n如果是文件夹，直接放在plugins文件夹下就好了。\n\nkibana-docker的话，可以把文件夹挂载到/usr/share/kibana/plugins/plugin-name，但插件更新的话需要重新run重新挂载，不知道是不是我操作有问题..\n","slug":"kibana-plugin-development","published":1,"updated":"2019-10-14T06:21:57.352Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69ua0016t6xvqq43x12d","content":"<h2 id=\"Kibana插件开发指南\"><a href=\"#Kibana插件开发指南\" class=\"headerlink\" title=\"Kibana插件开发指南\"></a>Kibana插件开发指南</h2><p>本文档参考自以下资源</p>\n<ul>\n<li><a href=\"https://trumandu.gitbooks.io/kibana-plugin-development-tutorial/content/\" target=\"_blank\" rel=\"noopener\">trumandu-tutorial</a></li>\n<li><a href=\"https://www.timroes.de/2015/12/02/writing-kibana-4-plugins-basics/\" target=\"_blank\" rel=\"noopener\">timroes.de</a></li>\n</ul>\n<h3 id=\"Kibana开发环境搭建\"><a href=\"#Kibana开发环境搭建\" class=\"headerlink\" title=\"Kibana开发环境搭建\"></a>Kibana开发环境搭建</h3><ul>\n<li><p>github上下载kibana的源代码，切换到对应版本，kibana的版本很重要，kibana在升级的过程中api有可能会变化，所以插件的开发需要针对特定的版本，kibana多版本的话，插件也需要多版本。（本文全局变量kibana是5.3.4版本）。</p>\n</li>\n<li><p>npm install安装依赖。</p>\n<ul>\n<li><p>如果公司防火墙限制从github下载依赖的话，git下载的方式将ssh替换成http</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global url.&quot;https://&quot;.insteadOf &quot;git://&quot;</span><br><span class=\"line\">//或者在.gitconfig文件中添加</span><br><span class=\"line\">[url &quot;https://&quot;]</span><br><span class=\"line\">insteadOf = git://</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装过程中，可能会有依赖下载失败，或欠缺依赖，有提示的话，按照提示来单独下载就好了，没提示的话，愿谷歌保佑你。</p>\n</li>\n</ul>\n</li>\n<li><p>npm start, 默认dev 启动方式会使用ssl,所以是https,如果需要修改的话，可以修改\\kibana\\src\\cli\\serve\\serve.js文件。修改位置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (opts.dev) &#123;</span><br><span class=\"line\">    set(&apos;env&apos;, &apos;development&apos;);</span><br><span class=\"line\">    set(&apos;optimize.lazy&apos;, true);</span><br><span class=\"line\"></span><br><span class=\"line\">    // if (opts.ssl) &#123;</span><br><span class=\"line\">    //   set(&apos;server.ssl.enabled&apos;, true);</span><br><span class=\"line\">    // &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // if (opts.ssl &amp;&amp; !has(&apos;server.ssl.certificate&apos;) &amp;&amp; !has(&apos;server.ssl.key&apos;)) &#123;</span><br><span class=\"line\">    //   set(&apos;server.ssl.certificate&apos;, DEV_SSL_CERT_PATH);</span><br><span class=\"line\">    //   set(&apos;server.ssl.key&apos;, DEV_SSL_KEY_PATH);</span><br><span class=\"line\">    // &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h3 id=\"加入插件\"><a href=\"#加入插件\" class=\"headerlink\" title=\"加入插件\"></a>加入插件</h3><p>将代码放在kibana的plugins文件夹下，Kibana会自动watch这些文件的changes。(只能直接把代码/文件夹放过来，并不能用软连接)。</p>\n<p>当你修改了代码，kibana会自动重新打包，会需要点时间，在命令行的console上能够看到如下提示</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restarting server due to changes in</span><br><span class=\"line\"> - &quot;installedPlugins/tr-k4p-clock/index.js&quot;</span><br><span class=\"line\">server log [21:49:59.323] [info][status][plugin:tr-k4p-clock] Status changed from uninitialized to green - Ready</span><br><span class=\"line\">[...]</span><br><span class=\"line\">server log [21:49:59.421] [info][listening] Server running at http://0.0.0.0:5601</span><br><span class=\"line\">optmzr log [21:50:07.177] [info][optimize] Lazy optimization started</span><br><span class=\"line\">optmzr log [21:50:13.834] [info][optimize] Lazy optimization success in 6.66 seconds</span><br></pre></td></tr></table></figure>\n\n<p>重新打包后，刷新浏览器就可以看到你的修改了(小吐槽，刷新kibana是个最耗费时间的操作)。</p>\n<h4 id=\"基本插件\"><a href=\"#基本插件\" class=\"headerlink\" title=\"基本插件\"></a>基本插件</h4><p>每个插件都是一个npm module,所以至少需要两个文件，package.json和index.js。</p>\n<p>一个package.json的示例如下, 最好的话，文件夹名称，name保持一致，如下可以通过plugins/kibana_gm_cal_vis/进入文件夹,具体可见index示例,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;name&quot;: &quot;kibana_gm_cal_vis&quot;,</span><br><span class=\"line\">  &quot;version&quot;: &quot;0.1.0&quot;,</span><br><span class=\"line\">  &quot;kibana&quot;: &#123;</span><br><span class=\"line\">    &quot;version&quot;: &quot;5.3.4&quot;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>一个index.js的示例如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">module.exports = function(kibana) &#123;</span><br><span class=\"line\">  return new kibana.Plugin(&#123;</span><br><span class=\"line\">    uiExports: &#123;</span><br><span class=\"line\">      visTypes: [&apos;plugins/kibana_gm_cal_vis/gm_cal&apos;]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"插件的安装\"><a href=\"#插件的安装\" class=\"headerlink\" title=\"插件的安装\"></a>插件的安装</h4><p>在Kibana上安装插件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kibana plugin --install plugin-name -u https://url.to/plugin</span><br></pre></td></tr></table></figure>\n\n<p>如果是文件夹，直接放在plugins文件夹下就好了。</p>\n<p>kibana-docker的话，可以把文件夹挂载到/usr/share/kibana/plugins/plugin-name，但插件更新的话需要重新run重新挂载，不知道是不是我操作有问题..</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Kibana插件开发指南\"><a href=\"#Kibana插件开发指南\" class=\"headerlink\" title=\"Kibana插件开发指南\"></a>Kibana插件开发指南</h2><p>本文档参考自以下资源</p>\n<ul>\n<li><a href=\"https://trumandu.gitbooks.io/kibana-plugin-development-tutorial/content/\" target=\"_blank\" rel=\"noopener\">trumandu-tutorial</a></li>\n<li><a href=\"https://www.timroes.de/2015/12/02/writing-kibana-4-plugins-basics/\" target=\"_blank\" rel=\"noopener\">timroes.de</a></li>\n</ul>\n<h3 id=\"Kibana开发环境搭建\"><a href=\"#Kibana开发环境搭建\" class=\"headerlink\" title=\"Kibana开发环境搭建\"></a>Kibana开发环境搭建</h3><ul>\n<li><p>github上下载kibana的源代码，切换到对应版本，kibana的版本很重要，kibana在升级的过程中api有可能会变化，所以插件的开发需要针对特定的版本，kibana多版本的话，插件也需要多版本。（本文全局变量kibana是5.3.4版本）。</p>\n</li>\n<li><p>npm install安装依赖。</p>\n<ul>\n<li><p>如果公司防火墙限制从github下载依赖的话，git下载的方式将ssh替换成http</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global url.&quot;https://&quot;.insteadOf &quot;git://&quot;</span><br><span class=\"line\">//或者在.gitconfig文件中添加</span><br><span class=\"line\">[url &quot;https://&quot;]</span><br><span class=\"line\">insteadOf = git://</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装过程中，可能会有依赖下载失败，或欠缺依赖，有提示的话，按照提示来单独下载就好了，没提示的话，愿谷歌保佑你。</p>\n</li>\n</ul>\n</li>\n<li><p>npm start, 默认dev 启动方式会使用ssl,所以是https,如果需要修改的话，可以修改\\kibana\\src\\cli\\serve\\serve.js文件。修改位置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (opts.dev) &#123;</span><br><span class=\"line\">    set(&apos;env&apos;, &apos;development&apos;);</span><br><span class=\"line\">    set(&apos;optimize.lazy&apos;, true);</span><br><span class=\"line\"></span><br><span class=\"line\">    // if (opts.ssl) &#123;</span><br><span class=\"line\">    //   set(&apos;server.ssl.enabled&apos;, true);</span><br><span class=\"line\">    // &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // if (opts.ssl &amp;&amp; !has(&apos;server.ssl.certificate&apos;) &amp;&amp; !has(&apos;server.ssl.key&apos;)) &#123;</span><br><span class=\"line\">    //   set(&apos;server.ssl.certificate&apos;, DEV_SSL_CERT_PATH);</span><br><span class=\"line\">    //   set(&apos;server.ssl.key&apos;, DEV_SSL_KEY_PATH);</span><br><span class=\"line\">    // &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h3 id=\"加入插件\"><a href=\"#加入插件\" class=\"headerlink\" title=\"加入插件\"></a>加入插件</h3><p>将代码放在kibana的plugins文件夹下，Kibana会自动watch这些文件的changes。(只能直接把代码/文件夹放过来，并不能用软连接)。</p>\n<p>当你修改了代码，kibana会自动重新打包，会需要点时间，在命令行的console上能够看到如下提示</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restarting server due to changes in</span><br><span class=\"line\"> - &quot;installedPlugins/tr-k4p-clock/index.js&quot;</span><br><span class=\"line\">server log [21:49:59.323] [info][status][plugin:tr-k4p-clock] Status changed from uninitialized to green - Ready</span><br><span class=\"line\">[...]</span><br><span class=\"line\">server log [21:49:59.421] [info][listening] Server running at http://0.0.0.0:5601</span><br><span class=\"line\">optmzr log [21:50:07.177] [info][optimize] Lazy optimization started</span><br><span class=\"line\">optmzr log [21:50:13.834] [info][optimize] Lazy optimization success in 6.66 seconds</span><br></pre></td></tr></table></figure>\n\n<p>重新打包后，刷新浏览器就可以看到你的修改了(小吐槽，刷新kibana是个最耗费时间的操作)。</p>\n<h4 id=\"基本插件\"><a href=\"#基本插件\" class=\"headerlink\" title=\"基本插件\"></a>基本插件</h4><p>每个插件都是一个npm module,所以至少需要两个文件，package.json和index.js。</p>\n<p>一个package.json的示例如下, 最好的话，文件夹名称，name保持一致，如下可以通过plugins/kibana_gm_cal_vis/进入文件夹,具体可见index示例,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;name&quot;: &quot;kibana_gm_cal_vis&quot;,</span><br><span class=\"line\">  &quot;version&quot;: &quot;0.1.0&quot;,</span><br><span class=\"line\">  &quot;kibana&quot;: &#123;</span><br><span class=\"line\">    &quot;version&quot;: &quot;5.3.4&quot;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>一个index.js的示例如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">module.exports = function(kibana) &#123;</span><br><span class=\"line\">  return new kibana.Plugin(&#123;</span><br><span class=\"line\">    uiExports: &#123;</span><br><span class=\"line\">      visTypes: [&apos;plugins/kibana_gm_cal_vis/gm_cal&apos;]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"插件的安装\"><a href=\"#插件的安装\" class=\"headerlink\" title=\"插件的安装\"></a>插件的安装</h4><p>在Kibana上安装插件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kibana plugin --install plugin-name -u https://url.to/plugin</span><br></pre></td></tr></table></figure>\n\n<p>如果是文件夹，直接放在plugins文件夹下就好了。</p>\n<p>kibana-docker的话，可以把文件夹挂载到/usr/share/kibana/plugins/plugin-name，但插件更新的话需要重新run重新挂载，不知道是不是我操作有问题..</p>\n"},{"title":"kibana-timeline","date":"2017-10-14T05:54:37.000Z","_content":"在路径..kibana-5.4.2/src/core_plugins/timelion下为timeline的源码。\n\n### fit-functitons\n\nfit方法有average,carry,nearest,scale几种。\n\n#### average\n\naverage的方法参数有2，dataTuples, targetTuples。前者为数据数据，后者为目标数据，数据结构都为[[time,value],[..]],目标数据的设定为以时间分的桶，传入时数据为[time,null]..\n\n方法作用一，遍历时间桶，取数据中有在当前桶时间的范围内的数据，求平均值，若桶内无数据，则记为NaN,结果记为resultValues，随后再进行NaN处理，将resultValues中所有NaN的值都取代为值，取值的函数为\t取前一次有值的数，与当前的数的差值 除以 连续NaN的个数+1，得出这期间的增长率，再依次给其中连续的nan的值赋值为前一次值+增长率。最后resultValues与目标数据中取出来的时间桶组成返回值。\n\n求平均值部分的代码如\n\n```\n  while (i < dataTuplesQueue.length && dataTuplesQueue[i][0] <= time) {\n      avgSet.push(dataTuplesQueue[i][1]);\n      i++;\n    }\n    dataTuplesQueue.splice(0, i);\n\n    const sum = _lodash2.default.reduce(avgSet, function (sum, num) {\n      return sum + num;\n    }, 0);\n    return avgSet.length ? sum / avgSet.length : NaN;\n```\n\n#### carry\n\n方法参数有2，dataTuples, targetTuples。要求dataTuples的长度大于targetTuples的，即原本数据的时间桶分布密集。作用是在targetTuples时间桶间，返回dataTuples时间桶中的值。targetTuples的长度是小于dataTuples的，从算法上来看dataTuples多出去了的就没了...\n\n#### nearest\n\n时间桶间隔，取离自己最近的一个桶的值为值。\n\n#### 结论\n\n通过上述代码可见，fit方法提供的主要是对已分好的数据桶进行再加工，传入参数为原有数据桶，和 目标桶，目标桶提供了新的时间桶。\n\n#### 测试新方法\n\n在fit中添加一个新方法，为某个时间桶无值，则保持上一次的值。\n\n```\n'use strict';\n\nvar _lodash = require('lodash');\n\nvar _lodash2 = _interopRequireDefault(_lodash);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// bug: 没考虑没值的情况，就是dataTuples为[].\nmodule.exports = function (dataTuples, targetTuples) {\n  return _lodash2.default.map(targetTuples, function (bucket) {\n    const time = bucket[0];\n    let i = 0;\n    while (i < dataTuples.length - 1 && dataTuples[i + 1][0] < time) {\n        i++;\n    }\n    const closest = dataTuples[i];\n    dataTuples.splice(0, i);\n    return [bucket[0], closest[1]];\n  });\n};\n```\n\n目前是添加到源码的fit_functions文件夹下，重启服务即可生效。\n\n#### Question\n\n以fit为例，timeline提供的其余处理数据的方法，如，mutilply等都是在原有数据桶进行操作，原有数据桶是通过.es生成，如何能控制原有数据桶呢？\n\n### Timeline\n\n- 创建一条曲线。\n\n```\n.es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct')\n\n```\n\n- 绘两条曲线，offset代表时间间隔,offset=-1h为前一个小时\n\n```\n.es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct'), .es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct')\n\n```\n\n- .label()为曲线添加描述，如两条曲线可分别添加增加可视化。\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour'), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour')\n\n```\n\n- title()方法为时序图添加标题。使用方法为添加到最后\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour'), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour').title('CPU usage over time')\n```\n\n- .lines为曲线设置appearance，.lines(fill=1,width=0.5)为填充1，宽度为1。默认曲线为填充0宽1\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour').lines(fill=1,width=0.5), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour').title('CPU usage over time')\n\n```\n\n- .color()为曲线设置颜色，包括其label,如color(gray)，也可直接使用颜色值color(#1E90FF)\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour').lines(fill=1,width=0.5).color(gray), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour').title('CPU usage over time').color(#1E90FF)\n```\n\n- .legend()设置位置和图例的样式。\n\n> For this example, place the legend in the north west position of the visualization with two columns by appending .legend(columns=2, position=nw)\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour').lines(fill=1,width=0.5).color(gray), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour').title('CPU usage over time').color(#1E90FF).legend(columns=2, position=nw)\n\n```\n\n- 使用数学计算\n\n- max 取最大值, 使用在metric中，如metric=max:system.network.in.bytes\n- derivative 取导数， .es返回对象的方法\n- multiply 乘法， 前面的应该为数字序列\n- divide 除法，前面的应该为数字序列\n\n```\n .es(index=metricbeat*, timefield=@timestamp, metric=max:system.network.in.bytes).derivative().divide(1048576).lines(fill=2, width=1).color(green).label(\"Inbound traffic\").title(\"Network traffic (MB/s)\"), .es(index=metricbeat*, timefield=@timestamp, metric=max:system.network.out.bytes).derivative().multiply(-1).divide(1048576).lines(fill=2, width=1).color(blue).label(\"Outbound traffic\").legend(columns=2, position=nw)\n\n```\n\n //这个示例，是绘制出入网流，关心的是变化率，所以取导数，bytes to megabytes单位换算所以除以1024*1024，再则，出相对于入，在一副图中显示为增强视图感，便一个的值>0,一个<0来表示，故出的线乘-1\n\n- 使用条件 if ()， 参数为(eq/ne.. , value, then do, else do)//then do、else do没有的就写null\n\n- eq ==\n- ne !=\n- lt <\n- lte <=\n- gt >\n- gte >=\n\n```\n .es(index=metricbeat-*, timefield='@timestamp', metric='max:system.memory.actual.used.bytes'), .es(index=metricbeat-*, timefield='@timestamp', metric='max:system.memory.actual.used.bytes').if(gt,12500000000,.es(index=metricbeat-*, timefield='@timestamp', metric='max:system.memory.actual.used.bytes'),null).label('warning').color('#FFCC11'), .es(index=metricbeat-*, timefield='@timestamp', metric='max:system.memory.actual.used.bytes').if(gt,15000000000,.es(index=metricbeat-*, timefield='@timestamp', ='max:system.memory.actual.used.bytes'),null).label('severe').color('red')\n```\n\n //这个示例呢，是大于12500000000的绘制一种，大于15000000000绘制一种，看得出来if必须作为.es返回对象的方法，故有两种不同判断就得写两个相同的.es。\n\n- 趋势，取数据个数的窗口的平均值连线。对于消除时间连续来说是极好的选择\n\n```\n.es().if(lt, 500, null).if(gte, 500, 1000)\n.es().if(lt, 500, 0, 1000)\n```\n\n```\n- mvavg()，如mvavg（10）\n```\n\n\n\n- .bars, .lines, .point改变展现形式的，.point是圆形\n","source":"_posts/kibana-timeline.md","raw":"---\ntitle: kibana-timeline\ndate: 2017-10-14 13:54:37\ncategories:\n- elk\n---\n在路径..kibana-5.4.2/src/core_plugins/timelion下为timeline的源码。\n\n### fit-functitons\n\nfit方法有average,carry,nearest,scale几种。\n\n#### average\n\naverage的方法参数有2，dataTuples, targetTuples。前者为数据数据，后者为目标数据，数据结构都为[[time,value],[..]],目标数据的设定为以时间分的桶，传入时数据为[time,null]..\n\n方法作用一，遍历时间桶，取数据中有在当前桶时间的范围内的数据，求平均值，若桶内无数据，则记为NaN,结果记为resultValues，随后再进行NaN处理，将resultValues中所有NaN的值都取代为值，取值的函数为\t取前一次有值的数，与当前的数的差值 除以 连续NaN的个数+1，得出这期间的增长率，再依次给其中连续的nan的值赋值为前一次值+增长率。最后resultValues与目标数据中取出来的时间桶组成返回值。\n\n求平均值部分的代码如\n\n```\n  while (i < dataTuplesQueue.length && dataTuplesQueue[i][0] <= time) {\n      avgSet.push(dataTuplesQueue[i][1]);\n      i++;\n    }\n    dataTuplesQueue.splice(0, i);\n\n    const sum = _lodash2.default.reduce(avgSet, function (sum, num) {\n      return sum + num;\n    }, 0);\n    return avgSet.length ? sum / avgSet.length : NaN;\n```\n\n#### carry\n\n方法参数有2，dataTuples, targetTuples。要求dataTuples的长度大于targetTuples的，即原本数据的时间桶分布密集。作用是在targetTuples时间桶间，返回dataTuples时间桶中的值。targetTuples的长度是小于dataTuples的，从算法上来看dataTuples多出去了的就没了...\n\n#### nearest\n\n时间桶间隔，取离自己最近的一个桶的值为值。\n\n#### 结论\n\n通过上述代码可见，fit方法提供的主要是对已分好的数据桶进行再加工，传入参数为原有数据桶，和 目标桶，目标桶提供了新的时间桶。\n\n#### 测试新方法\n\n在fit中添加一个新方法，为某个时间桶无值，则保持上一次的值。\n\n```\n'use strict';\n\nvar _lodash = require('lodash');\n\nvar _lodash2 = _interopRequireDefault(_lodash);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// bug: 没考虑没值的情况，就是dataTuples为[].\nmodule.exports = function (dataTuples, targetTuples) {\n  return _lodash2.default.map(targetTuples, function (bucket) {\n    const time = bucket[0];\n    let i = 0;\n    while (i < dataTuples.length - 1 && dataTuples[i + 1][0] < time) {\n        i++;\n    }\n    const closest = dataTuples[i];\n    dataTuples.splice(0, i);\n    return [bucket[0], closest[1]];\n  });\n};\n```\n\n目前是添加到源码的fit_functions文件夹下，重启服务即可生效。\n\n#### Question\n\n以fit为例，timeline提供的其余处理数据的方法，如，mutilply等都是在原有数据桶进行操作，原有数据桶是通过.es生成，如何能控制原有数据桶呢？\n\n### Timeline\n\n- 创建一条曲线。\n\n```\n.es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct')\n\n```\n\n- 绘两条曲线，offset代表时间间隔,offset=-1h为前一个小时\n\n```\n.es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct'), .es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct')\n\n```\n\n- .label()为曲线添加描述，如两条曲线可分别添加增加可视化。\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour'), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour')\n\n```\n\n- title()方法为时序图添加标题。使用方法为添加到最后\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour'), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour').title('CPU usage over time')\n```\n\n- .lines为曲线设置appearance，.lines(fill=1,width=0.5)为填充1，宽度为1。默认曲线为填充0宽1\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour').lines(fill=1,width=0.5), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour').title('CPU usage over time')\n\n```\n\n- .color()为曲线设置颜色，包括其label,如color(gray)，也可直接使用颜色值color(#1E90FF)\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour').lines(fill=1,width=0.5).color(gray), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour').title('CPU usage over time').color(#1E90FF)\n```\n\n- .legend()设置位置和图例的样式。\n\n> For this example, place the legend in the north west position of the visualization with two columns by appending .legend(columns=2, position=nw)\n\n```\n.es(offset=-1h,index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('last hour').lines(fill=1,width=0.5).color(gray), .es(index=metricbeat-*, timefield='@timestamp', metric='avg:system.cpu.user.pct').label('current hour').title('CPU usage over time').color(#1E90FF).legend(columns=2, position=nw)\n\n```\n\n- 使用数学计算\n\n- max 取最大值, 使用在metric中，如metric=max:system.network.in.bytes\n- derivative 取导数， .es返回对象的方法\n- multiply 乘法， 前面的应该为数字序列\n- divide 除法，前面的应该为数字序列\n\n```\n .es(index=metricbeat*, timefield=@timestamp, metric=max:system.network.in.bytes).derivative().divide(1048576).lines(fill=2, width=1).color(green).label(\"Inbound traffic\").title(\"Network traffic (MB/s)\"), .es(index=metricbeat*, timefield=@timestamp, metric=max:system.network.out.bytes).derivative().multiply(-1).divide(1048576).lines(fill=2, width=1).color(blue).label(\"Outbound traffic\").legend(columns=2, position=nw)\n\n```\n\n //这个示例，是绘制出入网流，关心的是变化率，所以取导数，bytes to megabytes单位换算所以除以1024*1024，再则，出相对于入，在一副图中显示为增强视图感，便一个的值>0,一个<0来表示，故出的线乘-1\n\n- 使用条件 if ()， 参数为(eq/ne.. , value, then do, else do)//then do、else do没有的就写null\n\n- eq ==\n- ne !=\n- lt <\n- lte <=\n- gt >\n- gte >=\n\n```\n .es(index=metricbeat-*, timefield='@timestamp', metric='max:system.memory.actual.used.bytes'), .es(index=metricbeat-*, timefield='@timestamp', metric='max:system.memory.actual.used.bytes').if(gt,12500000000,.es(index=metricbeat-*, timefield='@timestamp', metric='max:system.memory.actual.used.bytes'),null).label('warning').color('#FFCC11'), .es(index=metricbeat-*, timefield='@timestamp', metric='max:system.memory.actual.used.bytes').if(gt,15000000000,.es(index=metricbeat-*, timefield='@timestamp', ='max:system.memory.actual.used.bytes'),null).label('severe').color('red')\n```\n\n //这个示例呢，是大于12500000000的绘制一种，大于15000000000绘制一种，看得出来if必须作为.es返回对象的方法，故有两种不同判断就得写两个相同的.es。\n\n- 趋势，取数据个数的窗口的平均值连线。对于消除时间连续来说是极好的选择\n\n```\n.es().if(lt, 500, null).if(gte, 500, 1000)\n.es().if(lt, 500, 0, 1000)\n```\n\n```\n- mvavg()，如mvavg（10）\n```\n\n\n\n- .bars, .lines, .point改变展现形式的，.point是圆形\n","slug":"kibana-timeline","published":1,"updated":"2019-10-14T06:22:10.627Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69uf0017t6xvmp2qho78","content":"<p>在路径..kibana-5.4.2/src/core_plugins/timelion下为timeline的源码。</p>\n<h3 id=\"fit-functitons\"><a href=\"#fit-functitons\" class=\"headerlink\" title=\"fit-functitons\"></a>fit-functitons</h3><p>fit方法有average,carry,nearest,scale几种。</p>\n<h4 id=\"average\"><a href=\"#average\" class=\"headerlink\" title=\"average\"></a>average</h4><p>average的方法参数有2，dataTuples, targetTuples。前者为数据数据，后者为目标数据，数据结构都为[[time,value],[..]],目标数据的设定为以时间分的桶，传入时数据为[time,null]..</p>\n<p>方法作用一，遍历时间桶，取数据中有在当前桶时间的范围内的数据，求平均值，若桶内无数据，则记为NaN,结果记为resultValues，随后再进行NaN处理，将resultValues中所有NaN的值都取代为值，取值的函数为    取前一次有值的数，与当前的数的差值 除以 连续NaN的个数+1，得出这期间的增长率，再依次给其中连续的nan的值赋值为前一次值+增长率。最后resultValues与目标数据中取出来的时间桶组成返回值。</p>\n<p>求平均值部分的代码如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while (i &lt; dataTuplesQueue.length &amp;&amp; dataTuplesQueue[i][0] &lt;= time) &#123;</span><br><span class=\"line\">    avgSet.push(dataTuplesQueue[i][1]);</span><br><span class=\"line\">    i++;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  dataTuplesQueue.splice(0, i);</span><br><span class=\"line\"></span><br><span class=\"line\">  const sum = _lodash2.default.reduce(avgSet, function (sum, num) &#123;</span><br><span class=\"line\">    return sum + num;</span><br><span class=\"line\">  &#125;, 0);</span><br><span class=\"line\">  return avgSet.length ? sum / avgSet.length : NaN;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"carry\"><a href=\"#carry\" class=\"headerlink\" title=\"carry\"></a>carry</h4><p>方法参数有2，dataTuples, targetTuples。要求dataTuples的长度大于targetTuples的，即原本数据的时间桶分布密集。作用是在targetTuples时间桶间，返回dataTuples时间桶中的值。targetTuples的长度是小于dataTuples的，从算法上来看dataTuples多出去了的就没了…</p>\n<h4 id=\"nearest\"><a href=\"#nearest\" class=\"headerlink\" title=\"nearest\"></a>nearest</h4><p>时间桶间隔，取离自己最近的一个桶的值为值。</p>\n<h4 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h4><p>通过上述代码可见，fit方法提供的主要是对已分好的数据桶进行再加工，传入参数为原有数据桶，和 目标桶，目标桶提供了新的时间桶。</p>\n<h4 id=\"测试新方法\"><a href=\"#测试新方法\" class=\"headerlink\" title=\"测试新方法\"></a>测试新方法</h4><p>在fit中添加一个新方法，为某个时间桶无值，则保持上一次的值。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&apos;use strict&apos;;</span><br><span class=\"line\"></span><br><span class=\"line\">var _lodash = require(&apos;lodash&apos;);</span><br><span class=\"line\"></span><br><span class=\"line\">var _lodash2 = _interopRequireDefault(_lodash);</span><br><span class=\"line\"></span><br><span class=\"line\">function _interopRequireDefault(obj) &#123; return obj &amp;&amp; obj.__esModule ? obj : &#123; default: obj &#125;; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// bug: 没考虑没值的情况，就是dataTuples为[].</span><br><span class=\"line\">module.exports = function (dataTuples, targetTuples) &#123;</span><br><span class=\"line\">  return _lodash2.default.map(targetTuples, function (bucket) &#123;</span><br><span class=\"line\">    const time = bucket[0];</span><br><span class=\"line\">    let i = 0;</span><br><span class=\"line\">    while (i &lt; dataTuples.length - 1 &amp;&amp; dataTuples[i + 1][0] &lt; time) &#123;</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    const closest = dataTuples[i];</span><br><span class=\"line\">    dataTuples.splice(0, i);</span><br><span class=\"line\">    return [bucket[0], closest[1]];</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>目前是添加到源码的fit_functions文件夹下，重启服务即可生效。</p>\n<h4 id=\"Question\"><a href=\"#Question\" class=\"headerlink\" title=\"Question\"></a>Question</h4><p>以fit为例，timeline提供的其余处理数据的方法，如，mutilply等都是在原有数据桶进行操作，原有数据桶是通过.es生成，如何能控制原有数据桶呢？</p>\n<h3 id=\"Timeline\"><a href=\"#Timeline\" class=\"headerlink\" title=\"Timeline\"></a>Timeline</h3><ul>\n<li>创建一条曲线。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>绘两条曲线，offset代表时间间隔,offset=-1h为前一个小时</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;), .es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.label()为曲线添加描述，如两条曲线可分别添加增加可视化。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>title()方法为时序图添加标题。使用方法为添加到最后</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;).title(&apos;CPU usage over time&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.lines为曲线设置appearance，.lines(fill=1,width=0.5)为填充1，宽度为1。默认曲线为填充0宽1</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;).lines(fill=1,width=0.5), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;).title(&apos;CPU usage over time&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.color()为曲线设置颜色，包括其label,如color(gray)，也可直接使用颜色值color(#1E90FF)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;).lines(fill=1,width=0.5).color(gray), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;).title(&apos;CPU usage over time&apos;).color(#1E90FF)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.legend()设置位置和图例的样式。</li>\n</ul>\n<blockquote>\n<p>For this example, place the legend in the north west position of the visualization with two columns by appending .legend(columns=2, position=nw)</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;).lines(fill=1,width=0.5).color(gray), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;).title(&apos;CPU usage over time&apos;).color(#1E90FF).legend(columns=2, position=nw)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>使用数学计算</p>\n</li>\n<li><p>max 取最大值, 使用在metric中，如metric=max:system.network.in.bytes</p>\n</li>\n<li><p>derivative 取导数， .es返回对象的方法</p>\n</li>\n<li><p>multiply 乘法， 前面的应该为数字序列</p>\n</li>\n<li><p>divide 除法，前面的应该为数字序列</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(index=metricbeat*, timefield=@timestamp, metric=max:system.network.in.bytes).derivative().divide(1048576).lines(fill=2, width=1).color(green).label(&quot;Inbound traffic&quot;).title(&quot;Network traffic (MB/s)&quot;), .es(index=metricbeat*, timefield=@timestamp, metric=max:system.network.out.bytes).derivative().multiply(-1).divide(1048576).lines(fill=2, width=1).color(blue).label(&quot;Outbound traffic&quot;).legend(columns=2, position=nw)</span><br></pre></td></tr></table></figure>\n\n<p> //这个示例，是绘制出入网流，关心的是变化率，所以取导数，bytes to megabytes单位换算所以除以1024*1024，再则，出相对于入，在一副图中显示为增强视图感，便一个的值&gt;0,一个&lt;0来表示，故出的线乘-1</p>\n<ul>\n<li><p>使用条件 if ()， 参数为(eq/ne.. , value, then do, else do)//then do、else do没有的就写null</p>\n</li>\n<li><p>eq ==</p>\n</li>\n<li><p>ne !=</p>\n</li>\n<li><p>lt &lt;</p>\n</li>\n<li><p>lte &lt;=</p>\n</li>\n<li><p>gt &gt;</p>\n</li>\n<li><p>gte &gt;=</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;max:system.memory.actual.used.bytes&apos;), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;max:system.memory.actual.used.bytes&apos;).if(gt,12500000000,.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;max:system.memory.actual.used.bytes&apos;),null).label(&apos;warning&apos;).color(&apos;#FFCC11&apos;), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;max:system.memory.actual.used.bytes&apos;).if(gt,15000000000,.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, =&apos;max:system.memory.actual.used.bytes&apos;),null).label(&apos;severe&apos;).color(&apos;red&apos;)</span><br></pre></td></tr></table></figure>\n\n<p> //这个示例呢，是大于12500000000的绘制一种，大于15000000000绘制一种，看得出来if必须作为.es返回对象的方法，故有两种不同判断就得写两个相同的.es。</p>\n<ul>\n<li>趋势，取数据个数的窗口的平均值连线。对于消除时间连续来说是极好的选择</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es().if(lt, 500, null).if(gte, 500, 1000)</span><br><span class=\"line\">.es().if(lt, 500, 0, 1000)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- mvavg()，如mvavg（10）</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.bars, .lines, .point改变展现形式的，.point是圆形</li>\n</ul>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<p>在路径..kibana-5.4.2/src/core_plugins/timelion下为timeline的源码。</p>\n<h3 id=\"fit-functitons\"><a href=\"#fit-functitons\" class=\"headerlink\" title=\"fit-functitons\"></a>fit-functitons</h3><p>fit方法有average,carry,nearest,scale几种。</p>\n<h4 id=\"average\"><a href=\"#average\" class=\"headerlink\" title=\"average\"></a>average</h4><p>average的方法参数有2，dataTuples, targetTuples。前者为数据数据，后者为目标数据，数据结构都为[[time,value],[..]],目标数据的设定为以时间分的桶，传入时数据为[time,null]..</p>\n<p>方法作用一，遍历时间桶，取数据中有在当前桶时间的范围内的数据，求平均值，若桶内无数据，则记为NaN,结果记为resultValues，随后再进行NaN处理，将resultValues中所有NaN的值都取代为值，取值的函数为    取前一次有值的数，与当前的数的差值 除以 连续NaN的个数+1，得出这期间的增长率，再依次给其中连续的nan的值赋值为前一次值+增长率。最后resultValues与目标数据中取出来的时间桶组成返回值。</p>\n<p>求平均值部分的代码如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while (i &lt; dataTuplesQueue.length &amp;&amp; dataTuplesQueue[i][0] &lt;= time) &#123;</span><br><span class=\"line\">    avgSet.push(dataTuplesQueue[i][1]);</span><br><span class=\"line\">    i++;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  dataTuplesQueue.splice(0, i);</span><br><span class=\"line\"></span><br><span class=\"line\">  const sum = _lodash2.default.reduce(avgSet, function (sum, num) &#123;</span><br><span class=\"line\">    return sum + num;</span><br><span class=\"line\">  &#125;, 0);</span><br><span class=\"line\">  return avgSet.length ? sum / avgSet.length : NaN;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"carry\"><a href=\"#carry\" class=\"headerlink\" title=\"carry\"></a>carry</h4><p>方法参数有2，dataTuples, targetTuples。要求dataTuples的长度大于targetTuples的，即原本数据的时间桶分布密集。作用是在targetTuples时间桶间，返回dataTuples时间桶中的值。targetTuples的长度是小于dataTuples的，从算法上来看dataTuples多出去了的就没了…</p>\n<h4 id=\"nearest\"><a href=\"#nearest\" class=\"headerlink\" title=\"nearest\"></a>nearest</h4><p>时间桶间隔，取离自己最近的一个桶的值为值。</p>\n<h4 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h4><p>通过上述代码可见，fit方法提供的主要是对已分好的数据桶进行再加工，传入参数为原有数据桶，和 目标桶，目标桶提供了新的时间桶。</p>\n<h4 id=\"测试新方法\"><a href=\"#测试新方法\" class=\"headerlink\" title=\"测试新方法\"></a>测试新方法</h4><p>在fit中添加一个新方法，为某个时间桶无值，则保持上一次的值。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&apos;use strict&apos;;</span><br><span class=\"line\"></span><br><span class=\"line\">var _lodash = require(&apos;lodash&apos;);</span><br><span class=\"line\"></span><br><span class=\"line\">var _lodash2 = _interopRequireDefault(_lodash);</span><br><span class=\"line\"></span><br><span class=\"line\">function _interopRequireDefault(obj) &#123; return obj &amp;&amp; obj.__esModule ? obj : &#123; default: obj &#125;; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// bug: 没考虑没值的情况，就是dataTuples为[].</span><br><span class=\"line\">module.exports = function (dataTuples, targetTuples) &#123;</span><br><span class=\"line\">  return _lodash2.default.map(targetTuples, function (bucket) &#123;</span><br><span class=\"line\">    const time = bucket[0];</span><br><span class=\"line\">    let i = 0;</span><br><span class=\"line\">    while (i &lt; dataTuples.length - 1 &amp;&amp; dataTuples[i + 1][0] &lt; time) &#123;</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    const closest = dataTuples[i];</span><br><span class=\"line\">    dataTuples.splice(0, i);</span><br><span class=\"line\">    return [bucket[0], closest[1]];</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>目前是添加到源码的fit_functions文件夹下，重启服务即可生效。</p>\n<h4 id=\"Question\"><a href=\"#Question\" class=\"headerlink\" title=\"Question\"></a>Question</h4><p>以fit为例，timeline提供的其余处理数据的方法，如，mutilply等都是在原有数据桶进行操作，原有数据桶是通过.es生成，如何能控制原有数据桶呢？</p>\n<h3 id=\"Timeline\"><a href=\"#Timeline\" class=\"headerlink\" title=\"Timeline\"></a>Timeline</h3><ul>\n<li>创建一条曲线。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>绘两条曲线，offset代表时间间隔,offset=-1h为前一个小时</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;), .es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.label()为曲线添加描述，如两条曲线可分别添加增加可视化。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>title()方法为时序图添加标题。使用方法为添加到最后</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;).title(&apos;CPU usage over time&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.lines为曲线设置appearance，.lines(fill=1,width=0.5)为填充1，宽度为1。默认曲线为填充0宽1</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;).lines(fill=1,width=0.5), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;).title(&apos;CPU usage over time&apos;)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.color()为曲线设置颜色，包括其label,如color(gray)，也可直接使用颜色值color(#1E90FF)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;).lines(fill=1,width=0.5).color(gray), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;).title(&apos;CPU usage over time&apos;).color(#1E90FF)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.legend()设置位置和图例的样式。</li>\n</ul>\n<blockquote>\n<p>For this example, place the legend in the north west position of the visualization with two columns by appending .legend(columns=2, position=nw)</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(offset=-1h,index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;last hour&apos;).lines(fill=1,width=0.5).color(gray), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;avg:system.cpu.user.pct&apos;).label(&apos;current hour&apos;).title(&apos;CPU usage over time&apos;).color(#1E90FF).legend(columns=2, position=nw)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>使用数学计算</p>\n</li>\n<li><p>max 取最大值, 使用在metric中，如metric=max:system.network.in.bytes</p>\n</li>\n<li><p>derivative 取导数， .es返回对象的方法</p>\n</li>\n<li><p>multiply 乘法， 前面的应该为数字序列</p>\n</li>\n<li><p>divide 除法，前面的应该为数字序列</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(index=metricbeat*, timefield=@timestamp, metric=max:system.network.in.bytes).derivative().divide(1048576).lines(fill=2, width=1).color(green).label(&quot;Inbound traffic&quot;).title(&quot;Network traffic (MB/s)&quot;), .es(index=metricbeat*, timefield=@timestamp, metric=max:system.network.out.bytes).derivative().multiply(-1).divide(1048576).lines(fill=2, width=1).color(blue).label(&quot;Outbound traffic&quot;).legend(columns=2, position=nw)</span><br></pre></td></tr></table></figure>\n\n<p> //这个示例，是绘制出入网流，关心的是变化率，所以取导数，bytes to megabytes单位换算所以除以1024*1024，再则，出相对于入，在一副图中显示为增强视图感，便一个的值&gt;0,一个&lt;0来表示，故出的线乘-1</p>\n<ul>\n<li><p>使用条件 if ()， 参数为(eq/ne.. , value, then do, else do)//then do、else do没有的就写null</p>\n</li>\n<li><p>eq ==</p>\n</li>\n<li><p>ne !=</p>\n</li>\n<li><p>lt &lt;</p>\n</li>\n<li><p>lte &lt;=</p>\n</li>\n<li><p>gt &gt;</p>\n</li>\n<li><p>gte &gt;=</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;max:system.memory.actual.used.bytes&apos;), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;max:system.memory.actual.used.bytes&apos;).if(gt,12500000000,.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;max:system.memory.actual.used.bytes&apos;),null).label(&apos;warning&apos;).color(&apos;#FFCC11&apos;), .es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, metric=&apos;max:system.memory.actual.used.bytes&apos;).if(gt,15000000000,.es(index=metricbeat-*, timefield=&apos;@timestamp&apos;, =&apos;max:system.memory.actual.used.bytes&apos;),null).label(&apos;severe&apos;).color(&apos;red&apos;)</span><br></pre></td></tr></table></figure>\n\n<p> //这个示例呢，是大于12500000000的绘制一种，大于15000000000绘制一种，看得出来if必须作为.es返回对象的方法，故有两种不同判断就得写两个相同的.es。</p>\n<ul>\n<li>趋势，取数据个数的窗口的平均值连线。对于消除时间连续来说是极好的选择</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.es().if(lt, 500, null).if(gte, 500, 1000)</span><br><span class=\"line\">.es().if(lt, 500, 0, 1000)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- mvavg()，如mvavg（10）</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>.bars, .lines, .point改变展现形式的，.point是圆形</li>\n</ul>\n"},{"title":"web3j","date":"2019-10-14T06:55:36.000Z","_content":"## web3j的使用\n\n\n\n#### 特性\n\n- 通过Java类型的JSON-RPC与Ethereum客户端进行交互\n- 支持所有的JSON-RPC方法类型\n- 支持所有Geth和Parity方法，用于管理账户和签署交易\n- 同步或异步的发送客户端请求\n- 可从Solidity ABI文件自动生成Java只能合约功能包\n\n\n\n重点是交互的手段是JSON-RPC！\n\nweb3j可以监听事件、发送交易等等，发送交易时上链后方才返回结果。即内部也有监听事件。一直很好奇监听事件是怎么做的，实时推送？\n\n简单翻了下源码，并不是推送，而是轮询。\n\n因为是从智能合约接手入web3j，故从合约生成的java类入手，发现需要上链的方法返回的都是TransactionReceipt类型，例如\n\n```\n    public RemoteCall<TransactionReceipt> addUser(byte[] name, String addr, byte[] pk_pre, byte[] pk_bk) {\n        final Function function = new Function(\n                FUNC_ADDUSER,\n                Arrays.<Type>asList(new org.web3j.abi.datatypes.generated.Bytes32(name),\n                        new org.web3j.abi.datatypes.Address(addr),\n                        new org.web3j.abi.datatypes.generated.Bytes32(pk_pre),\n                        new org.web3j.abi.datatypes.generated.Bytes32(pk_bk)),\n                Collections.<TypeReference<?>>emptyList());\n        return executeRemoteCallTransaction(function);\n    }\n```\n\n从executeRemoteCallTransaction入手，跟踪进去。看到\n\n```\n    TransactionReceipt executeTransaction(String data, BigInteger weiValue, String funcName) throws TransactionException, IOException {\n        TransactionReceipt receipt = this.send(this.contractAddress, data, weiValue, this.gasProvider.getGasPrice(funcName), this.gasProvider.getGasLimit(funcName));\n        if (!receipt.isStatusOK()) {\n            throw new TransactionException(String.format(\"Transaction has failed with status: %s. Gas used: %d. (not-enough gas?)\", receipt.getStatus(), receipt.getGasUsed()));\n        } else {\n            return receipt;\n        }\n    }\n```\n\n原来交易失败，总是抛出not-enough gas异常是在这里抛出的，根据返回receipt的status判断。\n\n再跟着send方法进去，终于进入到transactionManager，离真相很近了。\n\n然后找到\n\n```\n   protected TransactionReceipt executeTransaction(BigInteger gasPrice, BigInteger gasLimit, String to, String data, BigInteger value) throws IOException, TransactionException {\n        EthSendTransaction ethSendTransaction = this.sendTransaction(gasPrice, gasLimit, to, data, value);\n        return this.processResponse(ethSendTransaction);\n    }\n```\n\nprocessResponse肯定就是等待返回结果的地方了。然后内部是调用this.transactionReceiptProcessor.waitForTransactionReceipt，再进去就是个抽象类了。找了一下，在TransactionManager中，实现的具体类是PollingTransactionReceiptProcessor。所以..答案就在这里了\n\n```\n private TransactionReceipt getTransactionReceipt(String transactionHash, long sleepDuration, int attempts) throws IOException, TransactionException {\n        Optional<TransactionReceipt> receiptOptional = this.sendTransactionReceiptRequest(transactionHash);\n\n        for(int i = 0; i < attempts; ++i) {\n            if (receiptOptional.isPresent()) {\n                return (TransactionReceipt)receiptOptional.get();\n            }\n\n            try {\n                Thread.sleep(sleepDuration);\n            } catch (InterruptedException var8) {\n                throw new TransactionException(var8);\n            }\n\n            receiptOptional = this.sendTransactionReceiptRequest(transactionHash);\n        }\n\n        throw new TransactionException(\"Transaction receipt was not generated after \" + sleepDuration * (long)attempts / 1000L + \" seconds for transaction: \" + transactionHash);\n    }\n```\n\n**这里可以看到，是每隔sleepDuration就轮询查询一次。sleepDuration的值默认为15s, 查询次数默认最多为40。**\n","source":"_posts/web3j.md","raw":"---\ntitle: web3j\ncategories:\n  - eth\ndate: 2019-10-14 14:55:36\ntags:\n---\n## web3j的使用\n\n\n\n#### 特性\n\n- 通过Java类型的JSON-RPC与Ethereum客户端进行交互\n- 支持所有的JSON-RPC方法类型\n- 支持所有Geth和Parity方法，用于管理账户和签署交易\n- 同步或异步的发送客户端请求\n- 可从Solidity ABI文件自动生成Java只能合约功能包\n\n\n\n重点是交互的手段是JSON-RPC！\n\nweb3j可以监听事件、发送交易等等，发送交易时上链后方才返回结果。即内部也有监听事件。一直很好奇监听事件是怎么做的，实时推送？\n\n简单翻了下源码，并不是推送，而是轮询。\n\n因为是从智能合约接手入web3j，故从合约生成的java类入手，发现需要上链的方法返回的都是TransactionReceipt类型，例如\n\n```\n    public RemoteCall<TransactionReceipt> addUser(byte[] name, String addr, byte[] pk_pre, byte[] pk_bk) {\n        final Function function = new Function(\n                FUNC_ADDUSER,\n                Arrays.<Type>asList(new org.web3j.abi.datatypes.generated.Bytes32(name),\n                        new org.web3j.abi.datatypes.Address(addr),\n                        new org.web3j.abi.datatypes.generated.Bytes32(pk_pre),\n                        new org.web3j.abi.datatypes.generated.Bytes32(pk_bk)),\n                Collections.<TypeReference<?>>emptyList());\n        return executeRemoteCallTransaction(function);\n    }\n```\n\n从executeRemoteCallTransaction入手，跟踪进去。看到\n\n```\n    TransactionReceipt executeTransaction(String data, BigInteger weiValue, String funcName) throws TransactionException, IOException {\n        TransactionReceipt receipt = this.send(this.contractAddress, data, weiValue, this.gasProvider.getGasPrice(funcName), this.gasProvider.getGasLimit(funcName));\n        if (!receipt.isStatusOK()) {\n            throw new TransactionException(String.format(\"Transaction has failed with status: %s. Gas used: %d. (not-enough gas?)\", receipt.getStatus(), receipt.getGasUsed()));\n        } else {\n            return receipt;\n        }\n    }\n```\n\n原来交易失败，总是抛出not-enough gas异常是在这里抛出的，根据返回receipt的status判断。\n\n再跟着send方法进去，终于进入到transactionManager，离真相很近了。\n\n然后找到\n\n```\n   protected TransactionReceipt executeTransaction(BigInteger gasPrice, BigInteger gasLimit, String to, String data, BigInteger value) throws IOException, TransactionException {\n        EthSendTransaction ethSendTransaction = this.sendTransaction(gasPrice, gasLimit, to, data, value);\n        return this.processResponse(ethSendTransaction);\n    }\n```\n\nprocessResponse肯定就是等待返回结果的地方了。然后内部是调用this.transactionReceiptProcessor.waitForTransactionReceipt，再进去就是个抽象类了。找了一下，在TransactionManager中，实现的具体类是PollingTransactionReceiptProcessor。所以..答案就在这里了\n\n```\n private TransactionReceipt getTransactionReceipt(String transactionHash, long sleepDuration, int attempts) throws IOException, TransactionException {\n        Optional<TransactionReceipt> receiptOptional = this.sendTransactionReceiptRequest(transactionHash);\n\n        for(int i = 0; i < attempts; ++i) {\n            if (receiptOptional.isPresent()) {\n                return (TransactionReceipt)receiptOptional.get();\n            }\n\n            try {\n                Thread.sleep(sleepDuration);\n            } catch (InterruptedException var8) {\n                throw new TransactionException(var8);\n            }\n\n            receiptOptional = this.sendTransactionReceiptRequest(transactionHash);\n        }\n\n        throw new TransactionException(\"Transaction receipt was not generated after \" + sleepDuration * (long)attempts / 1000L + \" seconds for transaction: \" + transactionHash);\n    }\n```\n\n**这里可以看到，是每隔sleepDuration就轮询查询一次。sleepDuration的值默认为15s, 查询次数默认最多为40。**\n","slug":"web3j","published":1,"updated":"2019-10-14T06:55:54.674Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69uk001at6xvky7tryyj","content":"<h2 id=\"web3j的使用\"><a href=\"#web3j的使用\" class=\"headerlink\" title=\"web3j的使用\"></a>web3j的使用</h2><h4 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li>通过Java类型的JSON-RPC与Ethereum客户端进行交互</li>\n<li>支持所有的JSON-RPC方法类型</li>\n<li>支持所有Geth和Parity方法，用于管理账户和签署交易</li>\n<li>同步或异步的发送客户端请求</li>\n<li>可从Solidity ABI文件自动生成Java只能合约功能包</li>\n</ul>\n<p>重点是交互的手段是JSON-RPC！</p>\n<p>web3j可以监听事件、发送交易等等，发送交易时上链后方才返回结果。即内部也有监听事件。一直很好奇监听事件是怎么做的，实时推送？</p>\n<p>简单翻了下源码，并不是推送，而是轮询。</p>\n<p>因为是从智能合约接手入web3j，故从合约生成的java类入手，发现需要上链的方法返回的都是TransactionReceipt类型，例如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public RemoteCall&lt;TransactionReceipt&gt; addUser(byte[] name, String addr, byte[] pk_pre, byte[] pk_bk) &#123;</span><br><span class=\"line\">    final Function function = new Function(</span><br><span class=\"line\">            FUNC_ADDUSER,</span><br><span class=\"line\">            Arrays.&lt;Type&gt;asList(new org.web3j.abi.datatypes.generated.Bytes32(name),</span><br><span class=\"line\">                    new org.web3j.abi.datatypes.Address(addr),</span><br><span class=\"line\">                    new org.web3j.abi.datatypes.generated.Bytes32(pk_pre),</span><br><span class=\"line\">                    new org.web3j.abi.datatypes.generated.Bytes32(pk_bk)),</span><br><span class=\"line\">            Collections.&lt;TypeReference&lt;?&gt;&gt;emptyList());</span><br><span class=\"line\">    return executeRemoteCallTransaction(function);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从executeRemoteCallTransaction入手，跟踪进去。看到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TransactionReceipt executeTransaction(String data, BigInteger weiValue, String funcName) throws TransactionException, IOException &#123;</span><br><span class=\"line\">    TransactionReceipt receipt = this.send(this.contractAddress, data, weiValue, this.gasProvider.getGasPrice(funcName), this.gasProvider.getGasLimit(funcName));</span><br><span class=\"line\">    if (!receipt.isStatusOK()) &#123;</span><br><span class=\"line\">        throw new TransactionException(String.format(&quot;Transaction has failed with status: %s. Gas used: %d. (not-enough gas?)&quot;, receipt.getStatus(), receipt.getGasUsed()));</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        return receipt;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>原来交易失败，总是抛出not-enough gas异常是在这里抛出的，根据返回receipt的status判断。</p>\n<p>再跟着send方法进去，终于进入到transactionManager，离真相很近了。</p>\n<p>然后找到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected TransactionReceipt executeTransaction(BigInteger gasPrice, BigInteger gasLimit, String to, String data, BigInteger value) throws IOException, TransactionException &#123;</span><br><span class=\"line\">     EthSendTransaction ethSendTransaction = this.sendTransaction(gasPrice, gasLimit, to, data, value);</span><br><span class=\"line\">     return this.processResponse(ethSendTransaction);</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n\n<p>processResponse肯定就是等待返回结果的地方了。然后内部是调用this.transactionReceiptProcessor.waitForTransactionReceipt，再进去就是个抽象类了。找了一下，在TransactionManager中，实现的具体类是PollingTransactionReceiptProcessor。所以..答案就在这里了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private TransactionReceipt getTransactionReceipt(String transactionHash, long sleepDuration, int attempts) throws IOException, TransactionException &#123;</span><br><span class=\"line\">       Optional&lt;TransactionReceipt&gt; receiptOptional = this.sendTransactionReceiptRequest(transactionHash);</span><br><span class=\"line\"></span><br><span class=\"line\">       for(int i = 0; i &lt; attempts; ++i) &#123;</span><br><span class=\"line\">           if (receiptOptional.isPresent()) &#123;</span><br><span class=\"line\">               return (TransactionReceipt)receiptOptional.get();</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">           try &#123;</span><br><span class=\"line\">               Thread.sleep(sleepDuration);</span><br><span class=\"line\">           &#125; catch (InterruptedException var8) &#123;</span><br><span class=\"line\">               throw new TransactionException(var8);</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">           receiptOptional = this.sendTransactionReceiptRequest(transactionHash);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       throw new TransactionException(&quot;Transaction receipt was not generated after &quot; + sleepDuration * (long)attempts / 1000L + &quot; seconds for transaction: &quot; + transactionHash);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>这里可以看到，是每隔sleepDuration就轮询查询一次。sleepDuration的值默认为15s, 查询次数默认最多为40。</strong></p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"web3j的使用\"><a href=\"#web3j的使用\" class=\"headerlink\" title=\"web3j的使用\"></a>web3j的使用</h2><h4 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li>通过Java类型的JSON-RPC与Ethereum客户端进行交互</li>\n<li>支持所有的JSON-RPC方法类型</li>\n<li>支持所有Geth和Parity方法，用于管理账户和签署交易</li>\n<li>同步或异步的发送客户端请求</li>\n<li>可从Solidity ABI文件自动生成Java只能合约功能包</li>\n</ul>\n<p>重点是交互的手段是JSON-RPC！</p>\n<p>web3j可以监听事件、发送交易等等，发送交易时上链后方才返回结果。即内部也有监听事件。一直很好奇监听事件是怎么做的，实时推送？</p>\n<p>简单翻了下源码，并不是推送，而是轮询。</p>\n<p>因为是从智能合约接手入web3j，故从合约生成的java类入手，发现需要上链的方法返回的都是TransactionReceipt类型，例如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public RemoteCall&lt;TransactionReceipt&gt; addUser(byte[] name, String addr, byte[] pk_pre, byte[] pk_bk) &#123;</span><br><span class=\"line\">    final Function function = new Function(</span><br><span class=\"line\">            FUNC_ADDUSER,</span><br><span class=\"line\">            Arrays.&lt;Type&gt;asList(new org.web3j.abi.datatypes.generated.Bytes32(name),</span><br><span class=\"line\">                    new org.web3j.abi.datatypes.Address(addr),</span><br><span class=\"line\">                    new org.web3j.abi.datatypes.generated.Bytes32(pk_pre),</span><br><span class=\"line\">                    new org.web3j.abi.datatypes.generated.Bytes32(pk_bk)),</span><br><span class=\"line\">            Collections.&lt;TypeReference&lt;?&gt;&gt;emptyList());</span><br><span class=\"line\">    return executeRemoteCallTransaction(function);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从executeRemoteCallTransaction入手，跟踪进去。看到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TransactionReceipt executeTransaction(String data, BigInteger weiValue, String funcName) throws TransactionException, IOException &#123;</span><br><span class=\"line\">    TransactionReceipt receipt = this.send(this.contractAddress, data, weiValue, this.gasProvider.getGasPrice(funcName), this.gasProvider.getGasLimit(funcName));</span><br><span class=\"line\">    if (!receipt.isStatusOK()) &#123;</span><br><span class=\"line\">        throw new TransactionException(String.format(&quot;Transaction has failed with status: %s. Gas used: %d. (not-enough gas?)&quot;, receipt.getStatus(), receipt.getGasUsed()));</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        return receipt;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>原来交易失败，总是抛出not-enough gas异常是在这里抛出的，根据返回receipt的status判断。</p>\n<p>再跟着send方法进去，终于进入到transactionManager，离真相很近了。</p>\n<p>然后找到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected TransactionReceipt executeTransaction(BigInteger gasPrice, BigInteger gasLimit, String to, String data, BigInteger value) throws IOException, TransactionException &#123;</span><br><span class=\"line\">     EthSendTransaction ethSendTransaction = this.sendTransaction(gasPrice, gasLimit, to, data, value);</span><br><span class=\"line\">     return this.processResponse(ethSendTransaction);</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n\n<p>processResponse肯定就是等待返回结果的地方了。然后内部是调用this.transactionReceiptProcessor.waitForTransactionReceipt，再进去就是个抽象类了。找了一下，在TransactionManager中，实现的具体类是PollingTransactionReceiptProcessor。所以..答案就在这里了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private TransactionReceipt getTransactionReceipt(String transactionHash, long sleepDuration, int attempts) throws IOException, TransactionException &#123;</span><br><span class=\"line\">       Optional&lt;TransactionReceipt&gt; receiptOptional = this.sendTransactionReceiptRequest(transactionHash);</span><br><span class=\"line\"></span><br><span class=\"line\">       for(int i = 0; i &lt; attempts; ++i) &#123;</span><br><span class=\"line\">           if (receiptOptional.isPresent()) &#123;</span><br><span class=\"line\">               return (TransactionReceipt)receiptOptional.get();</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">           try &#123;</span><br><span class=\"line\">               Thread.sleep(sleepDuration);</span><br><span class=\"line\">           &#125; catch (InterruptedException var8) &#123;</span><br><span class=\"line\">               throw new TransactionException(var8);</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">           receiptOptional = this.sendTransactionReceiptRequest(transactionHash);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       throw new TransactionException(&quot;Transaction receipt was not generated after &quot; + sleepDuration * (long)attempts / 1000L + &quot; seconds for transaction: &quot; + transactionHash);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>这里可以看到，是每隔sleepDuration就轮询查询一次。sleepDuration的值默认为15s, 查询次数默认最多为40。</strong></p>\n"},{"title":"wallet_connection","date":"2019-10-14T06:31:54.000Z","_content":"\n## wallet connection\n\n练习使用的库是kotlin的<https://github.com/WalletConnect/kotlin-walletconnect-lib>\n\n然后下载下来，导入到as中...曲折而又艰辛。\n\n- 什么gradle和kotlin版本问题\n\n  ```\n    classpath 'com.android.tools.build:gradle:3.4.1'\n  ```\n\n  在项目build.gradle中加入\n\n- sample:app不是module\n\n  在settings.gradle中修改\n\n  ```\n  include ':lib' , ':sample:app'\n  ```\n\n- 云镜像\n\n  ```\n  allprojects {\n      repositories {\n          mavenLocal()\n          maven { url 'http://maven.aliyun.com/nexus/content/repositories/central' }\n          maven { url 'http://maven.aliyun.com/nexus/content/groups/public' }\n          maven { url 'http://maven.aliyun.com/nexus/content/repositories/google' }\n          maven { url 'http://maven.aliyun.com/nexus/content/repositories/gradle-plugin' }\n          maven { url \"https://maven.google.com\" }\n          /**不需要fabric就不需要此项*/\n          maven { url 'http://s3.amazonaws.com/fabric-artifacts/public' }\n      }\n  }\n  ~\n  ```\n\n   init.gradle为上述内容，添加到~/.gradle目录下\n\n- 正常情况下就能编译好了，如果出现代码版本不兼容的问题，就根据代码提示修改下\n\n\n\n然后就能正常运行和编译啦。\n\n粘贴一个test\n\n```\nclass WalletConnectBridgeRepositoryIntegrationTest {\n\n\n    /**\n     * Integration test that can be used with the wallet connect example dapp\n     */\n    @Test\n    fun approveSession() {\n        val client = OkHttpClient.Builder().pingInterval(1000, TimeUnit.MILLISECONDS).build()\n        val moshi = Moshi.Builder().build()\n        val sessionDir = File(\"build/tmp/\").apply { mkdirs() }\n        val sessionStore = FileWCSessionStore(File(sessionDir, \"test_store.json\").apply { createNewFile() }, moshi)\n        //wc:33...为扫码扫出来的结果\n        val config = Session.Config.fromWCUri(\"wc:79870fae-c04f-479e-8241-085e96603f2b@1?bridge=http%3A%2F%2F192.168.20.18%3A8000%2Fapi%2Fv1%2Fws&key=db8147b92d96a62cb1a2181dd3f9076cfd8eceaeba01feb8becfb965754e6f3e\")\n        val session = WCSession(\n            config,\n            MoshiPayloadAdapter(moshi),\n            sessionStore,\n            OkHttpTransport.Builder(client, moshi),\n            Session.PeerMeta(name = \"WC Unit Test\")\n        )\n        session.addCallback(object : Session.Callback {\n            //相关的状态会回调，如建立连接，连接断掉\n            override fun onStatus(status: Session.Status) {\n                System.out.println(\"onStatus: $status\")\n            }\n            //网页有请求，会接收到回调\n            override fun onMethodCall(call: Session.MethodCall) {\n\n                if (call is Session.MethodCall.SessionRequest) {\n                    //Session.MethodCall.SessionRequest授权请求\n                    //回复账户地址，代表授权此账户地址\n                    session.approve(listOf(\"0x32C772DCCF8DCddd3e271B213a0027c22C98Fd1e\"), 1L)\n                } else if (call is Session.MethodCall.SendTransaction) {\n                    //Session.MethodCall.SessionRequest发送交易请求\n                    // 可拿到call.to, call.from, call.data 等信息，后进行签名交易，并发送，然后回复处理成功\n                    session.approveRequest(call.id, \"ok\")\n                } else if(call is Session.MethodCall.Custom) {\n                    //自定义方法和参数\n                    //根据call.params call.method进行处理后签名交易，并发送，然后回复处理成功\n                    session.approveRequest(call.id, \"ok\")\n                }\n            }\n        })\n        //创建连接\n        session.init()\n        Thread.sleep(2000000)\n    }\n\n\n    @Test\n    fun approveSession1() {\n        val client = OkHttpClient.Builder().pingInterval(1000, TimeUnit.MILLISECONDS).build()\n        val moshi = Moshi.Builder().build()\n        val sessionDir = File(\"build/tmp/\").apply { mkdirs() }\n        val sessionStore = FileWCSessionStore(File(sessionDir, \"test_store.json\").apply { createNewFile() }, moshi)\n        val key = ByteArray(32).also { Random().nextBytes(it) }.toNoPrefixHexString()\n        val topic  = ByteArray(32).also { Random().nextBytes(it) }.toNoPrefixHexString()\n        println(\"topic: \" + topic)\n        println(\"key : $key\")\n        val config = Session.Config(topic, \"http://192.168.20.18:5000\", key)\n        val session = WCSession(\n                config,\n                MoshiPayloadAdapter(moshi),\n                sessionStore,\n                OkHttpTransport.Builder(client, moshi),\n                Session.PeerMeta(name = \"WC Unit Test\")\n        )\n        session.addCallback(object : Session.Callback {\n            override fun onStatus(status: Session.Status) {\n                System.out.println(\"onStatus: $status\")\n            }\n\n            override fun onMethodCall(call: Session.MethodCall) {\n                System.out.println(\"onMethodCall: $call\")\n            }\n        })\n        session.offer()\n        Thread.sleep(5000)\n        println(\"==========================\")\n        val id = Random().nextLong()\n        println(\"id: \"+ id)\n        val p = session.performMethodCall(Session.MethodCall.Custom(id, \"tttt\",  listOf(1,2,\"3\",4,\"5\")), callback = { resp ->\n            println(resp)\n        })\n        println(p)\n        Thread.sleep(100000)\n        session.kill()\n        Thread.sleep(200000)\n    }\n\n}\n\n```\n","source":"_posts/wallet-connection.md","raw":"---\ntitle: wallet_connection\ndate: 2019-10-14 14:31:54\ntags:\ncategories:\n- blockchain\n---\n\n## wallet connection\n\n练习使用的库是kotlin的<https://github.com/WalletConnect/kotlin-walletconnect-lib>\n\n然后下载下来，导入到as中...曲折而又艰辛。\n\n- 什么gradle和kotlin版本问题\n\n  ```\n    classpath 'com.android.tools.build:gradle:3.4.1'\n  ```\n\n  在项目build.gradle中加入\n\n- sample:app不是module\n\n  在settings.gradle中修改\n\n  ```\n  include ':lib' , ':sample:app'\n  ```\n\n- 云镜像\n\n  ```\n  allprojects {\n      repositories {\n          mavenLocal()\n          maven { url 'http://maven.aliyun.com/nexus/content/repositories/central' }\n          maven { url 'http://maven.aliyun.com/nexus/content/groups/public' }\n          maven { url 'http://maven.aliyun.com/nexus/content/repositories/google' }\n          maven { url 'http://maven.aliyun.com/nexus/content/repositories/gradle-plugin' }\n          maven { url \"https://maven.google.com\" }\n          /**不需要fabric就不需要此项*/\n          maven { url 'http://s3.amazonaws.com/fabric-artifacts/public' }\n      }\n  }\n  ~\n  ```\n\n   init.gradle为上述内容，添加到~/.gradle目录下\n\n- 正常情况下就能编译好了，如果出现代码版本不兼容的问题，就根据代码提示修改下\n\n\n\n然后就能正常运行和编译啦。\n\n粘贴一个test\n\n```\nclass WalletConnectBridgeRepositoryIntegrationTest {\n\n\n    /**\n     * Integration test that can be used with the wallet connect example dapp\n     */\n    @Test\n    fun approveSession() {\n        val client = OkHttpClient.Builder().pingInterval(1000, TimeUnit.MILLISECONDS).build()\n        val moshi = Moshi.Builder().build()\n        val sessionDir = File(\"build/tmp/\").apply { mkdirs() }\n        val sessionStore = FileWCSessionStore(File(sessionDir, \"test_store.json\").apply { createNewFile() }, moshi)\n        //wc:33...为扫码扫出来的结果\n        val config = Session.Config.fromWCUri(\"wc:79870fae-c04f-479e-8241-085e96603f2b@1?bridge=http%3A%2F%2F192.168.20.18%3A8000%2Fapi%2Fv1%2Fws&key=db8147b92d96a62cb1a2181dd3f9076cfd8eceaeba01feb8becfb965754e6f3e\")\n        val session = WCSession(\n            config,\n            MoshiPayloadAdapter(moshi),\n            sessionStore,\n            OkHttpTransport.Builder(client, moshi),\n            Session.PeerMeta(name = \"WC Unit Test\")\n        )\n        session.addCallback(object : Session.Callback {\n            //相关的状态会回调，如建立连接，连接断掉\n            override fun onStatus(status: Session.Status) {\n                System.out.println(\"onStatus: $status\")\n            }\n            //网页有请求，会接收到回调\n            override fun onMethodCall(call: Session.MethodCall) {\n\n                if (call is Session.MethodCall.SessionRequest) {\n                    //Session.MethodCall.SessionRequest授权请求\n                    //回复账户地址，代表授权此账户地址\n                    session.approve(listOf(\"0x32C772DCCF8DCddd3e271B213a0027c22C98Fd1e\"), 1L)\n                } else if (call is Session.MethodCall.SendTransaction) {\n                    //Session.MethodCall.SessionRequest发送交易请求\n                    // 可拿到call.to, call.from, call.data 等信息，后进行签名交易，并发送，然后回复处理成功\n                    session.approveRequest(call.id, \"ok\")\n                } else if(call is Session.MethodCall.Custom) {\n                    //自定义方法和参数\n                    //根据call.params call.method进行处理后签名交易，并发送，然后回复处理成功\n                    session.approveRequest(call.id, \"ok\")\n                }\n            }\n        })\n        //创建连接\n        session.init()\n        Thread.sleep(2000000)\n    }\n\n\n    @Test\n    fun approveSession1() {\n        val client = OkHttpClient.Builder().pingInterval(1000, TimeUnit.MILLISECONDS).build()\n        val moshi = Moshi.Builder().build()\n        val sessionDir = File(\"build/tmp/\").apply { mkdirs() }\n        val sessionStore = FileWCSessionStore(File(sessionDir, \"test_store.json\").apply { createNewFile() }, moshi)\n        val key = ByteArray(32).also { Random().nextBytes(it) }.toNoPrefixHexString()\n        val topic  = ByteArray(32).also { Random().nextBytes(it) }.toNoPrefixHexString()\n        println(\"topic: \" + topic)\n        println(\"key : $key\")\n        val config = Session.Config(topic, \"http://192.168.20.18:5000\", key)\n        val session = WCSession(\n                config,\n                MoshiPayloadAdapter(moshi),\n                sessionStore,\n                OkHttpTransport.Builder(client, moshi),\n                Session.PeerMeta(name = \"WC Unit Test\")\n        )\n        session.addCallback(object : Session.Callback {\n            override fun onStatus(status: Session.Status) {\n                System.out.println(\"onStatus: $status\")\n            }\n\n            override fun onMethodCall(call: Session.MethodCall) {\n                System.out.println(\"onMethodCall: $call\")\n            }\n        })\n        session.offer()\n        Thread.sleep(5000)\n        println(\"==========================\")\n        val id = Random().nextLong()\n        println(\"id: \"+ id)\n        val p = session.performMethodCall(Session.MethodCall.Custom(id, \"tttt\",  listOf(1,2,\"3\",4,\"5\")), callback = { resp ->\n            println(resp)\n        })\n        println(p)\n        Thread.sleep(100000)\n        session.kill()\n        Thread.sleep(200000)\n    }\n\n}\n\n```\n","slug":"wallet-connection","published":1,"updated":"2019-10-14T06:34:33.925Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69um001bt6xveobfk3fd","content":"<h2 id=\"wallet-connection\"><a href=\"#wallet-connection\" class=\"headerlink\" title=\"wallet connection\"></a>wallet connection</h2><p>练习使用的库是kotlin的<a href=\"https://github.com/WalletConnect/kotlin-walletconnect-lib\">https://github.com/WalletConnect/kotlin-walletconnect-lib</a></p>\n<p>然后下载下来，导入到as中…曲折而又艰辛。</p>\n<ul>\n<li><p>什么gradle和kotlin版本问题</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">classpath &apos;com.android.tools.build:gradle:3.4.1&apos;</span><br></pre></td></tr></table></figure>\n\n<p>在项目build.gradle中加入</p>\n</li>\n<li><p>sample:app不是module</p>\n<p>在settings.gradle中修改</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include &apos;:lib&apos; , &apos;:sample:app&apos;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>云镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">allprojects &#123;</span><br><span class=\"line\">    repositories &#123;</span><br><span class=\"line\">        mavenLocal()</span><br><span class=\"line\">        maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/central&apos; &#125;</span><br><span class=\"line\">        maven &#123; url &apos;http://maven.aliyun.com/nexus/content/groups/public&apos; &#125;</span><br><span class=\"line\">        maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/google&apos; &#125;</span><br><span class=\"line\">        maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/gradle-plugin&apos; &#125;</span><br><span class=\"line\">        maven &#123; url &quot;https://maven.google.com&quot; &#125;</span><br><span class=\"line\">        /**不需要fabric就不需要此项*/</span><br><span class=\"line\">        maven &#123; url &apos;http://s3.amazonaws.com/fabric-artifacts/public&apos; &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">~</span><br></pre></td></tr></table></figure>\n\n<p> init.gradle为上述内容，添加到~/.gradle目录下</p>\n</li>\n<li><p>正常情况下就能编译好了，如果出现代码版本不兼容的问题，就根据代码提示修改下</p>\n</li>\n</ul>\n<p>然后就能正常运行和编译啦。</p>\n<p>粘贴一个test</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class WalletConnectBridgeRepositoryIntegrationTest &#123;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * Integration test that can be used with the wallet connect example dapp</span><br><span class=\"line\">     */</span><br><span class=\"line\">    @Test</span><br><span class=\"line\">    fun approveSession() &#123;</span><br><span class=\"line\">        val client = OkHttpClient.Builder().pingInterval(1000, TimeUnit.MILLISECONDS).build()</span><br><span class=\"line\">        val moshi = Moshi.Builder().build()</span><br><span class=\"line\">        val sessionDir = File(&quot;build/tmp/&quot;).apply &#123; mkdirs() &#125;</span><br><span class=\"line\">        val sessionStore = FileWCSessionStore(File(sessionDir, &quot;test_store.json&quot;).apply &#123; createNewFile() &#125;, moshi)</span><br><span class=\"line\">        //wc:33...为扫码扫出来的结果</span><br><span class=\"line\">        val config = Session.Config.fromWCUri(&quot;wc:79870fae-c04f-479e-8241-085e96603f2b@1?bridge=http%3A%2F%2F192.168.20.18%3A8000%2Fapi%2Fv1%2Fws&amp;key=db8147b92d96a62cb1a2181dd3f9076cfd8eceaeba01feb8becfb965754e6f3e&quot;)</span><br><span class=\"line\">        val session = WCSession(</span><br><span class=\"line\">            config,</span><br><span class=\"line\">            MoshiPayloadAdapter(moshi),</span><br><span class=\"line\">            sessionStore,</span><br><span class=\"line\">            OkHttpTransport.Builder(client, moshi),</span><br><span class=\"line\">            Session.PeerMeta(name = &quot;WC Unit Test&quot;)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        session.addCallback(object : Session.Callback &#123;</span><br><span class=\"line\">            //相关的状态会回调，如建立连接，连接断掉</span><br><span class=\"line\">            override fun onStatus(status: Session.Status) &#123;</span><br><span class=\"line\">                System.out.println(&quot;onStatus: $status&quot;)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            //网页有请求，会接收到回调</span><br><span class=\"line\">            override fun onMethodCall(call: Session.MethodCall) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">                if (call is Session.MethodCall.SessionRequest) &#123;</span><br><span class=\"line\">                    //Session.MethodCall.SessionRequest授权请求</span><br><span class=\"line\">                    //回复账户地址，代表授权此账户地址</span><br><span class=\"line\">                    session.approve(listOf(&quot;0x32C772DCCF8DCddd3e271B213a0027c22C98Fd1e&quot;), 1L)</span><br><span class=\"line\">                &#125; else if (call is Session.MethodCall.SendTransaction) &#123;</span><br><span class=\"line\">                    //Session.MethodCall.SessionRequest发送交易请求</span><br><span class=\"line\">                    // 可拿到call.to, call.from, call.data 等信息，后进行签名交易，并发送，然后回复处理成功</span><br><span class=\"line\">                    session.approveRequest(call.id, &quot;ok&quot;)</span><br><span class=\"line\">                &#125; else if(call is Session.MethodCall.Custom) &#123;</span><br><span class=\"line\">                    //自定义方法和参数</span><br><span class=\"line\">                    //根据call.params call.method进行处理后签名交易，并发送，然后回复处理成功</span><br><span class=\"line\">                    session.approveRequest(call.id, &quot;ok&quot;)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">        //创建连接</span><br><span class=\"line\">        session.init()</span><br><span class=\"line\">        Thread.sleep(2000000)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    @Test</span><br><span class=\"line\">    fun approveSession1() &#123;</span><br><span class=\"line\">        val client = OkHttpClient.Builder().pingInterval(1000, TimeUnit.MILLISECONDS).build()</span><br><span class=\"line\">        val moshi = Moshi.Builder().build()</span><br><span class=\"line\">        val sessionDir = File(&quot;build/tmp/&quot;).apply &#123; mkdirs() &#125;</span><br><span class=\"line\">        val sessionStore = FileWCSessionStore(File(sessionDir, &quot;test_store.json&quot;).apply &#123; createNewFile() &#125;, moshi)</span><br><span class=\"line\">        val key = ByteArray(32).also &#123; Random().nextBytes(it) &#125;.toNoPrefixHexString()</span><br><span class=\"line\">        val topic  = ByteArray(32).also &#123; Random().nextBytes(it) &#125;.toNoPrefixHexString()</span><br><span class=\"line\">        println(&quot;topic: &quot; + topic)</span><br><span class=\"line\">        println(&quot;key : $key&quot;)</span><br><span class=\"line\">        val config = Session.Config(topic, &quot;http://192.168.20.18:5000&quot;, key)</span><br><span class=\"line\">        val session = WCSession(</span><br><span class=\"line\">                config,</span><br><span class=\"line\">                MoshiPayloadAdapter(moshi),</span><br><span class=\"line\">                sessionStore,</span><br><span class=\"line\">                OkHttpTransport.Builder(client, moshi),</span><br><span class=\"line\">                Session.PeerMeta(name = &quot;WC Unit Test&quot;)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        session.addCallback(object : Session.Callback &#123;</span><br><span class=\"line\">            override fun onStatus(status: Session.Status) &#123;</span><br><span class=\"line\">                System.out.println(&quot;onStatus: $status&quot;)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            override fun onMethodCall(call: Session.MethodCall) &#123;</span><br><span class=\"line\">                System.out.println(&quot;onMethodCall: $call&quot;)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">        session.offer()</span><br><span class=\"line\">        Thread.sleep(5000)</span><br><span class=\"line\">        println(&quot;==========================&quot;)</span><br><span class=\"line\">        val id = Random().nextLong()</span><br><span class=\"line\">        println(&quot;id: &quot;+ id)</span><br><span class=\"line\">        val p = session.performMethodCall(Session.MethodCall.Custom(id, &quot;tttt&quot;,  listOf(1,2,&quot;3&quot;,4,&quot;5&quot;)), callback = &#123; resp -&gt;</span><br><span class=\"line\">            println(resp)</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">        println(p)</span><br><span class=\"line\">        Thread.sleep(100000)</span><br><span class=\"line\">        session.kill()</span><br><span class=\"line\">        Thread.sleep(200000)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"wallet-connection\"><a href=\"#wallet-connection\" class=\"headerlink\" title=\"wallet connection\"></a>wallet connection</h2><p>练习使用的库是kotlin的<a href=\"https://github.com/WalletConnect/kotlin-walletconnect-lib\">https://github.com/WalletConnect/kotlin-walletconnect-lib</a></p>\n<p>然后下载下来，导入到as中…曲折而又艰辛。</p>\n<ul>\n<li><p>什么gradle和kotlin版本问题</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">classpath &apos;com.android.tools.build:gradle:3.4.1&apos;</span><br></pre></td></tr></table></figure>\n\n<p>在项目build.gradle中加入</p>\n</li>\n<li><p>sample:app不是module</p>\n<p>在settings.gradle中修改</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include &apos;:lib&apos; , &apos;:sample:app&apos;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>云镜像</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">allprojects &#123;</span><br><span class=\"line\">    repositories &#123;</span><br><span class=\"line\">        mavenLocal()</span><br><span class=\"line\">        maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/central&apos; &#125;</span><br><span class=\"line\">        maven &#123; url &apos;http://maven.aliyun.com/nexus/content/groups/public&apos; &#125;</span><br><span class=\"line\">        maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/google&apos; &#125;</span><br><span class=\"line\">        maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/gradle-plugin&apos; &#125;</span><br><span class=\"line\">        maven &#123; url &quot;https://maven.google.com&quot; &#125;</span><br><span class=\"line\">        /**不需要fabric就不需要此项*/</span><br><span class=\"line\">        maven &#123; url &apos;http://s3.amazonaws.com/fabric-artifacts/public&apos; &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">~</span><br></pre></td></tr></table></figure>\n\n<p> init.gradle为上述内容，添加到~/.gradle目录下</p>\n</li>\n<li><p>正常情况下就能编译好了，如果出现代码版本不兼容的问题，就根据代码提示修改下</p>\n</li>\n</ul>\n<p>然后就能正常运行和编译啦。</p>\n<p>粘贴一个test</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class WalletConnectBridgeRepositoryIntegrationTest &#123;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * Integration test that can be used with the wallet connect example dapp</span><br><span class=\"line\">     */</span><br><span class=\"line\">    @Test</span><br><span class=\"line\">    fun approveSession() &#123;</span><br><span class=\"line\">        val client = OkHttpClient.Builder().pingInterval(1000, TimeUnit.MILLISECONDS).build()</span><br><span class=\"line\">        val moshi = Moshi.Builder().build()</span><br><span class=\"line\">        val sessionDir = File(&quot;build/tmp/&quot;).apply &#123; mkdirs() &#125;</span><br><span class=\"line\">        val sessionStore = FileWCSessionStore(File(sessionDir, &quot;test_store.json&quot;).apply &#123; createNewFile() &#125;, moshi)</span><br><span class=\"line\">        //wc:33...为扫码扫出来的结果</span><br><span class=\"line\">        val config = Session.Config.fromWCUri(&quot;wc:79870fae-c04f-479e-8241-085e96603f2b@1?bridge=http%3A%2F%2F192.168.20.18%3A8000%2Fapi%2Fv1%2Fws&amp;key=db8147b92d96a62cb1a2181dd3f9076cfd8eceaeba01feb8becfb965754e6f3e&quot;)</span><br><span class=\"line\">        val session = WCSession(</span><br><span class=\"line\">            config,</span><br><span class=\"line\">            MoshiPayloadAdapter(moshi),</span><br><span class=\"line\">            sessionStore,</span><br><span class=\"line\">            OkHttpTransport.Builder(client, moshi),</span><br><span class=\"line\">            Session.PeerMeta(name = &quot;WC Unit Test&quot;)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        session.addCallback(object : Session.Callback &#123;</span><br><span class=\"line\">            //相关的状态会回调，如建立连接，连接断掉</span><br><span class=\"line\">            override fun onStatus(status: Session.Status) &#123;</span><br><span class=\"line\">                System.out.println(&quot;onStatus: $status&quot;)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            //网页有请求，会接收到回调</span><br><span class=\"line\">            override fun onMethodCall(call: Session.MethodCall) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">                if (call is Session.MethodCall.SessionRequest) &#123;</span><br><span class=\"line\">                    //Session.MethodCall.SessionRequest授权请求</span><br><span class=\"line\">                    //回复账户地址，代表授权此账户地址</span><br><span class=\"line\">                    session.approve(listOf(&quot;0x32C772DCCF8DCddd3e271B213a0027c22C98Fd1e&quot;), 1L)</span><br><span class=\"line\">                &#125; else if (call is Session.MethodCall.SendTransaction) &#123;</span><br><span class=\"line\">                    //Session.MethodCall.SessionRequest发送交易请求</span><br><span class=\"line\">                    // 可拿到call.to, call.from, call.data 等信息，后进行签名交易，并发送，然后回复处理成功</span><br><span class=\"line\">                    session.approveRequest(call.id, &quot;ok&quot;)</span><br><span class=\"line\">                &#125; else if(call is Session.MethodCall.Custom) &#123;</span><br><span class=\"line\">                    //自定义方法和参数</span><br><span class=\"line\">                    //根据call.params call.method进行处理后签名交易，并发送，然后回复处理成功</span><br><span class=\"line\">                    session.approveRequest(call.id, &quot;ok&quot;)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">        //创建连接</span><br><span class=\"line\">        session.init()</span><br><span class=\"line\">        Thread.sleep(2000000)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    @Test</span><br><span class=\"line\">    fun approveSession1() &#123;</span><br><span class=\"line\">        val client = OkHttpClient.Builder().pingInterval(1000, TimeUnit.MILLISECONDS).build()</span><br><span class=\"line\">        val moshi = Moshi.Builder().build()</span><br><span class=\"line\">        val sessionDir = File(&quot;build/tmp/&quot;).apply &#123; mkdirs() &#125;</span><br><span class=\"line\">        val sessionStore = FileWCSessionStore(File(sessionDir, &quot;test_store.json&quot;).apply &#123; createNewFile() &#125;, moshi)</span><br><span class=\"line\">        val key = ByteArray(32).also &#123; Random().nextBytes(it) &#125;.toNoPrefixHexString()</span><br><span class=\"line\">        val topic  = ByteArray(32).also &#123; Random().nextBytes(it) &#125;.toNoPrefixHexString()</span><br><span class=\"line\">        println(&quot;topic: &quot; + topic)</span><br><span class=\"line\">        println(&quot;key : $key&quot;)</span><br><span class=\"line\">        val config = Session.Config(topic, &quot;http://192.168.20.18:5000&quot;, key)</span><br><span class=\"line\">        val session = WCSession(</span><br><span class=\"line\">                config,</span><br><span class=\"line\">                MoshiPayloadAdapter(moshi),</span><br><span class=\"line\">                sessionStore,</span><br><span class=\"line\">                OkHttpTransport.Builder(client, moshi),</span><br><span class=\"line\">                Session.PeerMeta(name = &quot;WC Unit Test&quot;)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        session.addCallback(object : Session.Callback &#123;</span><br><span class=\"line\">            override fun onStatus(status: Session.Status) &#123;</span><br><span class=\"line\">                System.out.println(&quot;onStatus: $status&quot;)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            override fun onMethodCall(call: Session.MethodCall) &#123;</span><br><span class=\"line\">                System.out.println(&quot;onMethodCall: $call&quot;)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">        session.offer()</span><br><span class=\"line\">        Thread.sleep(5000)</span><br><span class=\"line\">        println(&quot;==========================&quot;)</span><br><span class=\"line\">        val id = Random().nextLong()</span><br><span class=\"line\">        println(&quot;id: &quot;+ id)</span><br><span class=\"line\">        val p = session.performMethodCall(Session.MethodCall.Custom(id, &quot;tttt&quot;,  listOf(1,2,&quot;3&quot;,4,&quot;5&quot;)), callback = &#123; resp -&gt;</span><br><span class=\"line\">            println(resp)</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">        println(p)</span><br><span class=\"line\">        Thread.sleep(100000)</span><br><span class=\"line\">        session.kill()</span><br><span class=\"line\">        Thread.sleep(200000)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"maven","date":"2017-10-14T05:52:37.000Z","_content":"\n## Maven\n\n### 坐标\n\nmaven 的所有构件均通过坐标进行组织和管理。maven 的坐标通过 5 个元素进行定义，其中 groupId、artifactId、version 是必须的，packaging 是可选的（默认为jar），classifier 是不能直接定义的。\n\n- groupId：定义当前 Maven 项目所属的实际项目，跟 Java 包名类似，通常与域名反向一一对应。\n- artifactId：定义当前 Maven 项目的一个模块，默认情况下，Maven 生成的构件，其文件名会以 artifactId 开头，如 hibernate-core-3.6.5.Final.jar。\n- version：定义项目版本。\n- packaging：定义项目打包方式，如 jar，war，pom，zip ……，默认为 jar。\n- classifier：定义项目的附属构件，如 hibernate-core-3.6.6.Final-sources.jar，hibernate-core-3.6.6.Final-javadoc.jar，其中 sources 和 javadoc 就是这两个附属构件的 classifier。classifier 不能直接定义，通常由附加的插件帮助生成。\n\n### Maven提供的一些管理依赖功能\n\n- Dependency mediation: 当出现依赖项目为多个版本时，决定使用哪个版本。如果两个版本在依赖树上处于相同深度时，先定义的依赖版本将会被使用。\n- Dependency management: 依赖传递时，会使用直接指定的版本。例如，B < C, 在C中定义依赖时在它的dependencyManagement部分直接指定B的版本，在C被依赖时，将会使用对应B的版本。\n- Dependency scope: 按构建阶段包含依赖\n- Excluded dependencies: 传递依赖时可在“exclusion”元素中排除依赖。例如，B是A的依赖，C是B的依赖，A可以排除C作为依赖\n- Optional dependencies: 依赖传递时，可使用\"optional\"将依赖标记为可选项。例如，B是A的依赖，C是B的依赖，然后B标记C是可选项的，那么A将不会使用C。\n\n粘贴一下别人的大白话：\n\n#### 依赖冲突\n\n通常我们不需要关心传递性依赖，当多个传递性依赖中有对同一构件不同版本的依赖时，如何解决呢？\n\n- 短路径优先：假如有以下依赖：A -> B -> C ->X(版本 1.0) 和 A -> D -> X(版本 2.0)，则优先解析较短路径的 X(版本 2.0)；\n- 先声明优先：若路径长度相同，则谁先声明，谁被解析。\n\n#### 依赖排除\n\n针对依赖冲突中的“短路径优先”，如果我们想使用长路径的依赖怎么办呢？这时可以使用依赖排除 <exclusions> 元素，显示排除短路径依赖。在非冲突的情况下，这种方法同样有效。\n\n#### 依赖归类\n\n通常在项目中，我们会同时依赖同一个构件的不同模块，如 spring-orm-3.2.0，spring-context-3.2.0，且多个模块版本相同，为了维护和升级方便，我们可以对其同一管理，这时可以使用到 Maven 属性，类似于变量的概念。\n\n```\n <properties>\n     <springframework.version>3.2.0.RELEASE</springframework.version>\n  </properties>\n\n  <dependencies>\n      <dependency>\n          <groupId>org.springframework</groupId>\n          <artifactId>spring-orm</artifactId>\n          <version>${springframework.version}</version>\n     </dependency>\n     <dependency>\n         <groupId>org.springframework</groupId>\n         <artifactId>spring-context</artifactId>\n         <version>${springframework.version}</version>\n     </dependency>\n </dependencies>\n\n```\n\n--\n\n## Maven Test\n\n1. 新建测试类，new JUnit Case Test\n\n2. 新建类时选择的几个方法的解释。    \n\n   - setUp： 测试前的初始化工作\n   - tearDown: 测试完成后垃圾回收工作\n   - constructor: 构造方法\n\n3. 几种标注的介绍。\n\n   - @Test,表示这个是测试方法\n   - @Before,这个方法会在每个测试方法前都执行一次\n   - @After,这个方法会在每个测试方法后都执行一次\n   - @Ignore, 表示这个方法在测试的时候会被忽略\n   - @BeforeClass, 只在测试用例初始化时执行\n   - @AfterClass,，当所有测试执行完毕之后进行收尾工作\n   - 每个测试类只能有一个方法被标注为 @BeforeClass 或 @AfterClass ，并且该方法必须是 Public 和 Static 的。\n   - @Test(timeout  =   1000 )  限时测试\n   - @Test(expected  =  ArithmeticException. class ) 异常测试\n   - 参数化测试，这个以代码来解释怎么用。下面的测试数据是3组，会有3次结果。\n\n   ```\n   \tpublic class SquareTest {\n\n   \t\tprivate static Calculator calculator = new Calculator();\n   \t\tprivate int param;\n   \t\tprivate int result;\n\n   \t\t@Parameters\n   \t      public   static  Collection data()  {\n   \t          return  Arrays.asList( new  Object[][] {\n   \t                  { 2 ,  4 } ,\n   \t                  { 0 ,  0 } ,\n   \t                  {－ 3 ,  9 } ,\n   \t         } );\n   \t     }\n\n   \t\t// 构造函数，对变量进行初始化\n   \t\tpublic SquareTest(int param, int result) {\n   \t\t\tthis.param = param;\n   \t\t\tthis.result = result;\n   \t\t}\n\n   \t\t@Test\n   \t\tpublic void square() {\n   \t\t\tcalculator.square(param);\n   \t\t\tassertEquals(result, calculator.getResult());\n   \t\t}\n\n   \t}\n   ```\n\n4. 使用mvn test进行测试\n","source":"_posts/maven.md","raw":"---\ntitle: maven\ndate: 2017-10-14 13:52:37\ncategories:\n- java\n---\n\n## Maven\n\n### 坐标\n\nmaven 的所有构件均通过坐标进行组织和管理。maven 的坐标通过 5 个元素进行定义，其中 groupId、artifactId、version 是必须的，packaging 是可选的（默认为jar），classifier 是不能直接定义的。\n\n- groupId：定义当前 Maven 项目所属的实际项目，跟 Java 包名类似，通常与域名反向一一对应。\n- artifactId：定义当前 Maven 项目的一个模块，默认情况下，Maven 生成的构件，其文件名会以 artifactId 开头，如 hibernate-core-3.6.5.Final.jar。\n- version：定义项目版本。\n- packaging：定义项目打包方式，如 jar，war，pom，zip ……，默认为 jar。\n- classifier：定义项目的附属构件，如 hibernate-core-3.6.6.Final-sources.jar，hibernate-core-3.6.6.Final-javadoc.jar，其中 sources 和 javadoc 就是这两个附属构件的 classifier。classifier 不能直接定义，通常由附加的插件帮助生成。\n\n### Maven提供的一些管理依赖功能\n\n- Dependency mediation: 当出现依赖项目为多个版本时，决定使用哪个版本。如果两个版本在依赖树上处于相同深度时，先定义的依赖版本将会被使用。\n- Dependency management: 依赖传递时，会使用直接指定的版本。例如，B < C, 在C中定义依赖时在它的dependencyManagement部分直接指定B的版本，在C被依赖时，将会使用对应B的版本。\n- Dependency scope: 按构建阶段包含依赖\n- Excluded dependencies: 传递依赖时可在“exclusion”元素中排除依赖。例如，B是A的依赖，C是B的依赖，A可以排除C作为依赖\n- Optional dependencies: 依赖传递时，可使用\"optional\"将依赖标记为可选项。例如，B是A的依赖，C是B的依赖，然后B标记C是可选项的，那么A将不会使用C。\n\n粘贴一下别人的大白话：\n\n#### 依赖冲突\n\n通常我们不需要关心传递性依赖，当多个传递性依赖中有对同一构件不同版本的依赖时，如何解决呢？\n\n- 短路径优先：假如有以下依赖：A -> B -> C ->X(版本 1.0) 和 A -> D -> X(版本 2.0)，则优先解析较短路径的 X(版本 2.0)；\n- 先声明优先：若路径长度相同，则谁先声明，谁被解析。\n\n#### 依赖排除\n\n针对依赖冲突中的“短路径优先”，如果我们想使用长路径的依赖怎么办呢？这时可以使用依赖排除 <exclusions> 元素，显示排除短路径依赖。在非冲突的情况下，这种方法同样有效。\n\n#### 依赖归类\n\n通常在项目中，我们会同时依赖同一个构件的不同模块，如 spring-orm-3.2.0，spring-context-3.2.0，且多个模块版本相同，为了维护和升级方便，我们可以对其同一管理，这时可以使用到 Maven 属性，类似于变量的概念。\n\n```\n <properties>\n     <springframework.version>3.2.0.RELEASE</springframework.version>\n  </properties>\n\n  <dependencies>\n      <dependency>\n          <groupId>org.springframework</groupId>\n          <artifactId>spring-orm</artifactId>\n          <version>${springframework.version}</version>\n     </dependency>\n     <dependency>\n         <groupId>org.springframework</groupId>\n         <artifactId>spring-context</artifactId>\n         <version>${springframework.version}</version>\n     </dependency>\n </dependencies>\n\n```\n\n--\n\n## Maven Test\n\n1. 新建测试类，new JUnit Case Test\n\n2. 新建类时选择的几个方法的解释。    \n\n   - setUp： 测试前的初始化工作\n   - tearDown: 测试完成后垃圾回收工作\n   - constructor: 构造方法\n\n3. 几种标注的介绍。\n\n   - @Test,表示这个是测试方法\n   - @Before,这个方法会在每个测试方法前都执行一次\n   - @After,这个方法会在每个测试方法后都执行一次\n   - @Ignore, 表示这个方法在测试的时候会被忽略\n   - @BeforeClass, 只在测试用例初始化时执行\n   - @AfterClass,，当所有测试执行完毕之后进行收尾工作\n   - 每个测试类只能有一个方法被标注为 @BeforeClass 或 @AfterClass ，并且该方法必须是 Public 和 Static 的。\n   - @Test(timeout  =   1000 )  限时测试\n   - @Test(expected  =  ArithmeticException. class ) 异常测试\n   - 参数化测试，这个以代码来解释怎么用。下面的测试数据是3组，会有3次结果。\n\n   ```\n   \tpublic class SquareTest {\n\n   \t\tprivate static Calculator calculator = new Calculator();\n   \t\tprivate int param;\n   \t\tprivate int result;\n\n   \t\t@Parameters\n   \t      public   static  Collection data()  {\n   \t          return  Arrays.asList( new  Object[][] {\n   \t                  { 2 ,  4 } ,\n   \t                  { 0 ,  0 } ,\n   \t                  {－ 3 ,  9 } ,\n   \t         } );\n   \t     }\n\n   \t\t// 构造函数，对变量进行初始化\n   \t\tpublic SquareTest(int param, int result) {\n   \t\t\tthis.param = param;\n   \t\t\tthis.result = result;\n   \t\t}\n\n   \t\t@Test\n   \t\tpublic void square() {\n   \t\t\tcalculator.square(param);\n   \t\t\tassertEquals(result, calculator.getResult());\n   \t\t}\n\n   \t}\n   ```\n\n4. 使用mvn test进行测试\n","slug":"maven","published":1,"updated":"2019-10-14T06:22:57.697Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69up001et6xvze4lg28j","content":"<h2 id=\"Maven\"><a href=\"#Maven\" class=\"headerlink\" title=\"Maven\"></a>Maven</h2><h3 id=\"坐标\"><a href=\"#坐标\" class=\"headerlink\" title=\"坐标\"></a>坐标</h3><p>maven 的所有构件均通过坐标进行组织和管理。maven 的坐标通过 5 个元素进行定义，其中 groupId、artifactId、version 是必须的，packaging 是可选的（默认为jar），classifier 是不能直接定义的。</p>\n<ul>\n<li>groupId：定义当前 Maven 项目所属的实际项目，跟 Java 包名类似，通常与域名反向一一对应。</li>\n<li>artifactId：定义当前 Maven 项目的一个模块，默认情况下，Maven 生成的构件，其文件名会以 artifactId 开头，如 hibernate-core-3.6.5.Final.jar。</li>\n<li>version：定义项目版本。</li>\n<li>packaging：定义项目打包方式，如 jar，war，pom，zip ……，默认为 jar。</li>\n<li>classifier：定义项目的附属构件，如 hibernate-core-3.6.6.Final-sources.jar，hibernate-core-3.6.6.Final-javadoc.jar，其中 sources 和 javadoc 就是这两个附属构件的 classifier。classifier 不能直接定义，通常由附加的插件帮助生成。</li>\n</ul>\n<h3 id=\"Maven提供的一些管理依赖功能\"><a href=\"#Maven提供的一些管理依赖功能\" class=\"headerlink\" title=\"Maven提供的一些管理依赖功能\"></a>Maven提供的一些管理依赖功能</h3><ul>\n<li>Dependency mediation: 当出现依赖项目为多个版本时，决定使用哪个版本。如果两个版本在依赖树上处于相同深度时，先定义的依赖版本将会被使用。</li>\n<li>Dependency management: 依赖传递时，会使用直接指定的版本。例如，B &lt; C, 在C中定义依赖时在它的dependencyManagement部分直接指定B的版本，在C被依赖时，将会使用对应B的版本。</li>\n<li>Dependency scope: 按构建阶段包含依赖</li>\n<li>Excluded dependencies: 传递依赖时可在“exclusion”元素中排除依赖。例如，B是A的依赖，C是B的依赖，A可以排除C作为依赖</li>\n<li>Optional dependencies: 依赖传递时，可使用”optional”将依赖标记为可选项。例如，B是A的依赖，C是B的依赖，然后B标记C是可选项的，那么A将不会使用C。</li>\n</ul>\n<p>粘贴一下别人的大白话：</p>\n<h4 id=\"依赖冲突\"><a href=\"#依赖冲突\" class=\"headerlink\" title=\"依赖冲突\"></a>依赖冲突</h4><p>通常我们不需要关心传递性依赖，当多个传递性依赖中有对同一构件不同版本的依赖时，如何解决呢？</p>\n<ul>\n<li>短路径优先：假如有以下依赖：A -&gt; B -&gt; C -&gt;X(版本 1.0) 和 A -&gt; D -&gt; X(版本 2.0)，则优先解析较短路径的 X(版本 2.0)；</li>\n<li>先声明优先：若路径长度相同，则谁先声明，谁被解析。</li>\n</ul>\n<h4 id=\"依赖排除\"><a href=\"#依赖排除\" class=\"headerlink\" title=\"依赖排除\"></a>依赖排除</h4><p>针对依赖冲突中的“短路径优先”，如果我们想使用长路径的依赖怎么办呢？这时可以使用依赖排除 <exclusions> 元素，显示排除短路径依赖。在非冲突的情况下，这种方法同样有效。</exclusions></p>\n<h4 id=\"依赖归类\"><a href=\"#依赖归类\" class=\"headerlink\" title=\"依赖归类\"></a>依赖归类</h4><p>通常在项目中，我们会同时依赖同一个构件的不同模块，如 spring-orm-3.2.0，spring-context-3.2.0，且多个模块版本相同，为了维护和升级方便，我们可以对其同一管理，这时可以使用到 Maven 属性，类似于变量的概念。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;properties&gt;</span><br><span class=\"line\">    &lt;springframework.version&gt;3.2.0.RELEASE&lt;/springframework.version&gt;</span><br><span class=\"line\"> &lt;/properties&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"> &lt;dependencies&gt;</span><br><span class=\"line\">     &lt;dependency&gt;</span><br><span class=\"line\">         &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class=\"line\">         &lt;artifactId&gt;spring-orm&lt;/artifactId&gt;</span><br><span class=\"line\">         &lt;version&gt;$&#123;springframework.version&#125;&lt;/version&gt;</span><br><span class=\"line\">    &lt;/dependency&gt;</span><br><span class=\"line\">    &lt;dependency&gt;</span><br><span class=\"line\">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class=\"line\">        &lt;artifactId&gt;spring-context&lt;/artifactId&gt;</span><br><span class=\"line\">        &lt;version&gt;$&#123;springframework.version&#125;&lt;/version&gt;</span><br><span class=\"line\">    &lt;/dependency&gt;</span><br><span class=\"line\">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure>\n\n<p>–</p>\n<h2 id=\"Maven-Test\"><a href=\"#Maven-Test\" class=\"headerlink\" title=\"Maven Test\"></a>Maven Test</h2><ol>\n<li><p>新建测试类，new JUnit Case Test</p>\n</li>\n<li><p>新建类时选择的几个方法的解释。    </p>\n<ul>\n<li>setUp： 测试前的初始化工作</li>\n<li>tearDown: 测试完成后垃圾回收工作</li>\n<li>constructor: 构造方法</li>\n</ul>\n</li>\n<li><p>几种标注的介绍。</p>\n<ul>\n<li>@Test,表示这个是测试方法</li>\n<li>@Before,这个方法会在每个测试方法前都执行一次</li>\n<li>@After,这个方法会在每个测试方法后都执行一次</li>\n<li>@Ignore, 表示这个方法在测试的时候会被忽略</li>\n<li>@BeforeClass, 只在测试用例初始化时执行</li>\n<li>@AfterClass,，当所有测试执行完毕之后进行收尾工作</li>\n<li>每个测试类只能有一个方法被标注为 @BeforeClass 或 @AfterClass ，并且该方法必须是 Public 和 Static 的。</li>\n<li>@Test(timeout  =   1000 )  限时测试</li>\n<li>@Test(expected  =  ArithmeticException. class ) 异常测试</li>\n<li>参数化测试，这个以代码来解释怎么用。下面的测试数据是3组，会有3次结果。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class SquareTest &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\tprivate static Calculator calculator = new Calculator();</span><br><span class=\"line\">\tprivate int param;</span><br><span class=\"line\">\tprivate int result;</span><br><span class=\"line\"></span><br><span class=\"line\">\t@Parameters</span><br><span class=\"line\">      public   static  Collection data()  &#123;</span><br><span class=\"line\">          return  Arrays.asList( new  Object[][] &#123;</span><br><span class=\"line\">                  &#123; 2 ,  4 &#125; ,</span><br><span class=\"line\">                  &#123; 0 ,  0 &#125; ,</span><br><span class=\"line\">                  &#123;－ 3 ,  9 &#125; ,</span><br><span class=\"line\">         &#125; );</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 构造函数，对变量进行初始化</span><br><span class=\"line\">\tpublic SquareTest(int param, int result) &#123;</span><br><span class=\"line\">\t\tthis.param = param;</span><br><span class=\"line\">\t\tthis.result = result;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t@Test</span><br><span class=\"line\">\tpublic void square() &#123;</span><br><span class=\"line\">\t\tcalculator.square(param);</span><br><span class=\"line\">\t\tassertEquals(result, calculator.getResult());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用mvn test进行测试</p>\n</li>\n</ol>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Maven\"><a href=\"#Maven\" class=\"headerlink\" title=\"Maven\"></a>Maven</h2><h3 id=\"坐标\"><a href=\"#坐标\" class=\"headerlink\" title=\"坐标\"></a>坐标</h3><p>maven 的所有构件均通过坐标进行组织和管理。maven 的坐标通过 5 个元素进行定义，其中 groupId、artifactId、version 是必须的，packaging 是可选的（默认为jar），classifier 是不能直接定义的。</p>\n<ul>\n<li>groupId：定义当前 Maven 项目所属的实际项目，跟 Java 包名类似，通常与域名反向一一对应。</li>\n<li>artifactId：定义当前 Maven 项目的一个模块，默认情况下，Maven 生成的构件，其文件名会以 artifactId 开头，如 hibernate-core-3.6.5.Final.jar。</li>\n<li>version：定义项目版本。</li>\n<li>packaging：定义项目打包方式，如 jar，war，pom，zip ……，默认为 jar。</li>\n<li>classifier：定义项目的附属构件，如 hibernate-core-3.6.6.Final-sources.jar，hibernate-core-3.6.6.Final-javadoc.jar，其中 sources 和 javadoc 就是这两个附属构件的 classifier。classifier 不能直接定义，通常由附加的插件帮助生成。</li>\n</ul>\n<h3 id=\"Maven提供的一些管理依赖功能\"><a href=\"#Maven提供的一些管理依赖功能\" class=\"headerlink\" title=\"Maven提供的一些管理依赖功能\"></a>Maven提供的一些管理依赖功能</h3><ul>\n<li>Dependency mediation: 当出现依赖项目为多个版本时，决定使用哪个版本。如果两个版本在依赖树上处于相同深度时，先定义的依赖版本将会被使用。</li>\n<li>Dependency management: 依赖传递时，会使用直接指定的版本。例如，B &lt; C, 在C中定义依赖时在它的dependencyManagement部分直接指定B的版本，在C被依赖时，将会使用对应B的版本。</li>\n<li>Dependency scope: 按构建阶段包含依赖</li>\n<li>Excluded dependencies: 传递依赖时可在“exclusion”元素中排除依赖。例如，B是A的依赖，C是B的依赖，A可以排除C作为依赖</li>\n<li>Optional dependencies: 依赖传递时，可使用”optional”将依赖标记为可选项。例如，B是A的依赖，C是B的依赖，然后B标记C是可选项的，那么A将不会使用C。</li>\n</ul>\n<p>粘贴一下别人的大白话：</p>\n<h4 id=\"依赖冲突\"><a href=\"#依赖冲突\" class=\"headerlink\" title=\"依赖冲突\"></a>依赖冲突</h4><p>通常我们不需要关心传递性依赖，当多个传递性依赖中有对同一构件不同版本的依赖时，如何解决呢？</p>\n<ul>\n<li>短路径优先：假如有以下依赖：A -&gt; B -&gt; C -&gt;X(版本 1.0) 和 A -&gt; D -&gt; X(版本 2.0)，则优先解析较短路径的 X(版本 2.0)；</li>\n<li>先声明优先：若路径长度相同，则谁先声明，谁被解析。</li>\n</ul>\n<h4 id=\"依赖排除\"><a href=\"#依赖排除\" class=\"headerlink\" title=\"依赖排除\"></a>依赖排除</h4><p>针对依赖冲突中的“短路径优先”，如果我们想使用长路径的依赖怎么办呢？这时可以使用依赖排除 <exclusions> 元素，显示排除短路径依赖。在非冲突的情况下，这种方法同样有效。</exclusions></p>\n<h4 id=\"依赖归类\"><a href=\"#依赖归类\" class=\"headerlink\" title=\"依赖归类\"></a>依赖归类</h4><p>通常在项目中，我们会同时依赖同一个构件的不同模块，如 spring-orm-3.2.0，spring-context-3.2.0，且多个模块版本相同，为了维护和升级方便，我们可以对其同一管理，这时可以使用到 Maven 属性，类似于变量的概念。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;properties&gt;</span><br><span class=\"line\">    &lt;springframework.version&gt;3.2.0.RELEASE&lt;/springframework.version&gt;</span><br><span class=\"line\"> &lt;/properties&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"> &lt;dependencies&gt;</span><br><span class=\"line\">     &lt;dependency&gt;</span><br><span class=\"line\">         &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class=\"line\">         &lt;artifactId&gt;spring-orm&lt;/artifactId&gt;</span><br><span class=\"line\">         &lt;version&gt;$&#123;springframework.version&#125;&lt;/version&gt;</span><br><span class=\"line\">    &lt;/dependency&gt;</span><br><span class=\"line\">    &lt;dependency&gt;</span><br><span class=\"line\">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class=\"line\">        &lt;artifactId&gt;spring-context&lt;/artifactId&gt;</span><br><span class=\"line\">        &lt;version&gt;$&#123;springframework.version&#125;&lt;/version&gt;</span><br><span class=\"line\">    &lt;/dependency&gt;</span><br><span class=\"line\">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure>\n\n<p>–</p>\n<h2 id=\"Maven-Test\"><a href=\"#Maven-Test\" class=\"headerlink\" title=\"Maven Test\"></a>Maven Test</h2><ol>\n<li><p>新建测试类，new JUnit Case Test</p>\n</li>\n<li><p>新建类时选择的几个方法的解释。    </p>\n<ul>\n<li>setUp： 测试前的初始化工作</li>\n<li>tearDown: 测试完成后垃圾回收工作</li>\n<li>constructor: 构造方法</li>\n</ul>\n</li>\n<li><p>几种标注的介绍。</p>\n<ul>\n<li>@Test,表示这个是测试方法</li>\n<li>@Before,这个方法会在每个测试方法前都执行一次</li>\n<li>@After,这个方法会在每个测试方法后都执行一次</li>\n<li>@Ignore, 表示这个方法在测试的时候会被忽略</li>\n<li>@BeforeClass, 只在测试用例初始化时执行</li>\n<li>@AfterClass,，当所有测试执行完毕之后进行收尾工作</li>\n<li>每个测试类只能有一个方法被标注为 @BeforeClass 或 @AfterClass ，并且该方法必须是 Public 和 Static 的。</li>\n<li>@Test(timeout  =   1000 )  限时测试</li>\n<li>@Test(expected  =  ArithmeticException. class ) 异常测试</li>\n<li>参数化测试，这个以代码来解释怎么用。下面的测试数据是3组，会有3次结果。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class SquareTest &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\tprivate static Calculator calculator = new Calculator();</span><br><span class=\"line\">\tprivate int param;</span><br><span class=\"line\">\tprivate int result;</span><br><span class=\"line\"></span><br><span class=\"line\">\t@Parameters</span><br><span class=\"line\">      public   static  Collection data()  &#123;</span><br><span class=\"line\">          return  Arrays.asList( new  Object[][] &#123;</span><br><span class=\"line\">                  &#123; 2 ,  4 &#125; ,</span><br><span class=\"line\">                  &#123; 0 ,  0 &#125; ,</span><br><span class=\"line\">                  &#123;－ 3 ,  9 &#125; ,</span><br><span class=\"line\">         &#125; );</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 构造函数，对变量进行初始化</span><br><span class=\"line\">\tpublic SquareTest(int param, int result) &#123;</span><br><span class=\"line\">\t\tthis.param = param;</span><br><span class=\"line\">\t\tthis.result = result;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t@Test</span><br><span class=\"line\">\tpublic void square() &#123;</span><br><span class=\"line\">\t\tcalculator.square(param);</span><br><span class=\"line\">\t\tassertEquals(result, calculator.getResult());</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用mvn test进行测试</p>\n</li>\n</ol>\n"},{"title":"blockchain","date":"2019-10-14T06:36:24.000Z","_content":"\n## 区块链\n\n区块链的本质，是去中心化的分布式的数据库系统，实现了数据公开、透明、可追溯。\n\n区块链技术，广义上来说，区块链技术是实现了数据公开透明可追溯的产品的架构涉及方法，必须包含点对点网络设计、加密技术应用、分布式算法的实现、数据存储技术的使用等4方面，可能还涉及到分布式存储，机器学习，VR，物联网，大数据等；狭义上来说，区块链是指类似比特币的数据存储方式或数据库实现，仅仅涉及到数据存储技术，数据库或文件操作等。\n\n从架构上来说，区块链由下到上可以简单的分为三个层次，**协议层**、**扩展层**和**应用层**。最底层的协议层分为存储层和网络层，存储层存储各个区块，组成区块链，存储层的上方是网络层，网络层的主要工作是通过挖矿投票等共识算法保障节点安全，网络层再向上，便是扩展层了，扩展层中含有的扩展例如智能合约、各种侧链应用，或者文档、图书电子书视频等用户数据文件存储或分享等..应用层就要就是可视化操作等..\n\n**协议层**涉及的技术主要是，网络编程，加密签名，分布算法，数据存储。总的看来，网络的实现和并发处理是开发的难点，故开发语言选择优先选择网络编程能力强，并发处理简单的语言，例如Nodejs,Go。\n\n**扩展层**的编程语言与协议层的编程语言可以不用，因为二者交互是通过http/rpc或json/rpc实现，二者基本完全分类，二者除了在交易时发生交互之外，其他时候尽量不要混在一起。扩展层与应用层更加接近，也可以理解位B/S架构的产品中的服务端（Server）。\n\n\n\n#### 共识机制\n\n区块链是去中心化的，去中心化的基础就是节点众多，那么如何吸引用户加入网络成为节点，有哪些激励机制？同时，开发的重点是让多个节点维护一个数据库，那么如何决定哪个节点写入？何时写入？一旦写入，又怎么保证不被其他的节点更改（不可逆）？这些问题的答案，就是共识机制。共识机制可防双花\n\n- POW， 工作量证明，引入了对一个特定值的计算工作，比特币采用的共识算法就是POW\n- POS，权益证明，简单说来，这种机制通过计算你持有占总币数的百分比，包括你占有币数的时间来决定记账权。因此在PoS中，一个账户的余额越多，在同等算力下，就越容易发现下一个区块。\n- DPOS，  委托权益证明\n- PBFT， 实用拜占庭容错\n\n\n\n#### 智能合约\n\n智能合约就是可编程合约，或者叫做合约智能化，其中的\"智能\"是执行上的智能，也就是说达到某个条件，合约自动执行，比如自动转移证券、自动付款等\n\n\n\n#### 加密货币\n\n生活中接触到的数字货币很多，像Q币等的平台内币，这些用“代币”来称呼更为适合。那么加密货币和这些“代币”又有什么区别呢？加密货币定义如下：\n\n> 加密货币，是一种基于点对点网络（P2P网络)、没有发行机构、总量基本固定的加密电子通货。\n\n1. P2P网络：这个不是什么新鲜玩意，最早我们使用的BT(BitTorrent)下载，就是基于P2P网络的，现在很多下载工具都支持。它的好处就是“去中心化”，也就是没有中央服务器，要下载的文件都在用户自己电脑上，而且下载速度更快;\n2. 没有发行机构：就是说，不是那个公司、银行或国家控制发行的。要做到这一点，同时防止通货膨胀等因素，需要在编程中使用非常复杂的机制和规则来实现。\n3. 总量基本固定：这是保证加密货币价值的一种策略，“物以稀为贵”，任何东西没有上限就会失去它的吸引力。这一点，区别于很多网络社区使用的积分，比如：A币、C币、Q币、S币等。\n4. 加密：这里说的加密，不是用户使用的输入用户名、密码那种简单的权限控制，而是对每一个产生的电子货币本身的交易与传输的加密。密码学本身很复杂，但是使用它并不复杂，明白这个就足够了。\n5. 电子通货：也就是说加密货币就是货币，跟法币一样，可以自由交易，只不过是一种电子（数字）形式而已。\n\n\n\n#### 吞吐量\n\n区块链每秒交易量。吞吐量对于区块链项目来说，还算是一个比较重要的点。共识算法中，采用POW/POS的区块链的吞吐量就受到了极大的限制，吞吐量不超过100tx/s，例如比特币和以太坊。原因在于单纯的提高区块大小或者减少区块生成之间的时间解决不了问题，因为区块需要时间传输验证，如果区块太大，那么就会造成网络节点的不一致性加重（分叉变多），从而严重影响可靠性。DPOS通过缩小参与核心共识过程的节点数量，提高共识效率。PBFT对于节点数量少(小于100)的情况下，交易量大概还能有1000tx/s这样。\n\n\n\n#### Token\n\n代币。\n\n- ICO： 当某方以某个价格向投资者提供一些新的加密货币（即代币）时，可以与其他加密货币（即代币）进行交换。 这个想法是投资者购买这些代币，代币可以进行互换和转移。销售代币筹资的概念称作Initial Coin Offer或ICO\n\n\n\n#### 硬分叉/软分叉\n\n**比特币交易其中一个含义指的是我们发送比特币统一使用的数据结构**，这是一套规则，我们所有人发送比特币，不论你使用什么钱包软件都得遵守这一套规则。\n\n硬分叉定义\n\n> 硬分叉是指比特币区块格式或交易格式（这就是广泛流传的“共识”）发生改变时，未升级的节点拒绝验证已经升级的节点生产出的区块，不过已经升级的节点可以验证未升级节点生产出的区块，然后大家各自延续自己认为正确的链，所以分成两条链。\n\n软分叉定义\n\n> 软分叉是指比特币交易的数据结构（这就是被广泛流传的“共识”）发生改变时，未升级的节点可以验证已经升级的节点生产出的区块，而且已经升级的节点也可以验证未升级的节点生产出的区块。\n\n硬分叉不向前兼容，旧版本不会接受新版本创建的区块。要实现硬分叉所有用户都需要切换到新版本协议上。\n\n软分叉向前兼容，旧的版本会接受新版本创建的区块，在软分叉中只需要矿工升级到新版本即可，用户可以继续使用旧版本的协议，他们仍然会接受新版本协议创建的区块。如果有至少51%的矿工的算力转向的新版本，那么网络自动完成软分叉：一开始旧版本创建的区块在新协议下被认为是不合法的，这时会出现一个短暂的分叉，但最终新版本的分叉会赶超旧版本的分叉成为最长链。因为在旧版本上的算力是小于新版本的。\n\n#### 石墨烯技术\n\n[github地址](https://github.com/cryptonomex/graphene)\n\n\n\n### bft\n\n\n\n本文提出了Zyzzyva1，一种使用推测来降低成本并简化BFT状态机复制设计的新协议[18,34]。与传统的状态机复制协议[9,32,40]一样，主要提出了客户端对其他副本的请求的顺序。在Zyzzyva中，与传统协议不同，复制品推测性地执行请求，而不运行昂贵的协议协议来确定订单。因此，正确的副本状态可能会有所不同，并且副本可能会向客户端发送不同的响应。尽管如此，客户端的应用程序观察到复制状态机的传统和强大的抽象，它以可线性化[13]的顺序执行请求，因为答复带有足够的历史信息给客户端以确定答复和历史记录是否稳定并最终保证最终承诺。如果推测回复和历史记录稳定，则客户端使用回复。否则，客户端会等待系统收敛于稳定的回复和历史记录。\n\n\n\nZyzzyva面临的挑战是确保对正确客户的响应变得稳定。 最终，副本负责确保来自正确客户端的所有请求最终完成，但等待回复并且历史稳定的客户端可以通过提供将导致请求在当前视图内快速稳定的信息来加速进程 或触发视图更改。 请注意，由于客户不需要提交请求，而只是为了保持稳定，因此客户可以按照一到两个阶段而不是惯常的三个请求行事[9,32,40]。\n\n\n\n鉴于BFT复制协议已经在客户端上实施的职责[3,9,10,21,32,40]，将输出提交完全移交给客户端并不是一个很大的步骤，但这一小步骤带来了巨大的收益。首先，Zyzzyva利用推测执行 - 复制品在订单完全建立之前执行请求。其次，Zyzzyva利用快速协议协议[11,20,24]在少至三个消息延迟的情况下建立请求排序。第三，一旦客户知道请求的顺序，协议子协议就停止处理请求，从而避免在副本上建立这些知识所需的工作。\n\n这些选择导致设计Zyzzyva时遇到两个关键挑战。首先，我们必须仔细地指定请求在客户端完成的条件，并定义协议，检查点和视图变更子协议，以保留请求在单个正确的状态机上执行的抽象。直接地，当正确的客户端可以安全地处理对该请求的回复。为了帮助客户确定何时适合回复，Zyzzyva会将历史信息附加到客户收到的回复中，以便客户可以判断回复是否基于相同的请求顺序。\n\n\n\n#### 协议概述\n\n3f+1个节点replicas执行，由一系列views组成，在一个view内，一个单点的节点replica被指定为主要负责子协议共识的leader。\n\n客户端发送一个请求给到leader, leader转发给其余replicas, 收到请求的replicas执行请求并将结果返回给客户端，客户端完成1个请求有两种方式，首先，如果客户端收到3f+1相互一致的响应结果（包括history和application-level的回复），然后客户端便认为请求完成并执行之。其次，如果客户端收到再2f+1 ~ 3f之间个数的一致的结果，客户端将手机2f+1的结果然后分发commit certificate给replicas，一旦2f+1的replicas确认收到commit certificate，客户端将会认为请求完成并且执行响应的回复。\n\n如果有足够的replicas认为leader故障，然后view将会进行更换，一个新的leader将会产生。\n\n在本节的其余部分中，我们描述基本协议并概述其正确性的证明[16]。 在§4中，我们描述了一些优化，这些优化全部在我们的原型中实现，通过用消息认证码（MAC）代替公钥签名来降低加密成本，通过批量请求提高吞吐量，通过缓存out-of 通过优化只读请求来提高读取性能，通过使大多数副本发送散列而不是完整回复来减少带宽，通过仅为首选法定数包括MAC来减少开销，并且通过包括额外的附加功能来提高存在故障节点的性能 证人副本。\n\n\n\n#### 节点状态和检查点协议\n\n为了明确地讨论我们的讨论，我们首先讨论由每个副本维护的状态，如图2所总结的。每个副本i维护它已执行的请求的有序历史记录，以及最大提交证书副本，提交证书（定义如下）由我看到，涵盖了我存储历史的最大前缀。这个提交证书覆盖的序列号最高的请求的历史记录是承诺的历史记录，以下的历史记录是推测历史记录。如果n是提交历史记录中的任何请求的最高序列号，我们说一个提交证书的序列号为n。\n\n每个CP INTERVAL请求都会创建一个检查点。副本维护一个稳定的检查点和一个相应的稳定应用程序状态快照，并且它可以存储多达一个暂定检查点和相应的暂定应用程序状态快照。尝试性检查点和应用程序状态提交的过程与早期BFT协议所使用的过程类似[9,10,17,32,40]，因此我们将详细讨论推迟到我们的扩展技术报告[16]。但是，简要总结一下：当正确的副本生成临时检查点时，它会向所有副本发送签名检查点消息。该消息包含检查点中包含的任何请求的最高序列号以及对应的试验性检查点和应用程序快照的摘要。当收集由不同副本签名的f + 1匹配检查点消息时，正确的Zyzzyva副本会将检查点和相应的应用程序快照视为稳定。为了限制历史的大小，副本（1）在提交的检查点之前截断历史记录，（2）在处理自上次提交的检查点以来的2×CP INTERVAL请求之后阻止处理新的请求。最后，每个副本维护一个响应缓存，其中包含每个客户端的最新订购请求的副本以及相应的响应。\n\n\n### IPFS\n\nIPFS是一个分布式文件系统，它综合了以前的对等系统的成功想法，包括DHT，BitTorrent，Git和SFS（SFS文件系统的名字认证了它的服务，用户可以通过服务提供的公钥来验证，协商一个共享的私钥，保证所有的通信。所有的SFS实例都共享了一个全局的命名空间，这个命名空间的名称分配是加密的，不被任何中心化的body控制）。\n\n IPFS的贡献是简化，发展和将成熟的技术连接成一个单一的内聚系统，大于其部分的总和。 IPFS提供了编写和部署应用程序的新平台，以及一个新的分发系统版本化大数据。 IPFS甚至可以演进网络本身。\n\nIPFS是点对点的;没有节点是特权的。 IPFS节点将IPFS对象存储在本地存储中。节点彼此连接并传输对象。这些对象表示文件和其他数据结构。 IPFS协议分为一组负责不同功能的子协议：\n\n- 身份\n  管理节点身份生成和验证。\n- 网络\n  管理与其他对等体的连接，使用各种底层网络协议。可配置的。\n- 路由\n  维护信息以定位特定的对等体和对象。响应本地和远程查询。默认为DHT，但可更换。\n- 对象\n  具有链接的内容寻址不可更改对象的Merkle DAG。用于表示任意数据结构，例如文件层次和通信系统。\n- 交换\n  一种支持有效块分配的新型块交换协议（BitSwap）。模拟市场，弱化数据复制。贸易策略可替换。\n- 文件\n  由Git启发的版本化文件系统层次结构。\n- 命名\n  自我认证的可变名称系统。这些子系统不是独立的;它们是集成在一起，互相利用各自的属性。但是，分开描述它们是有用的，从下到上构建协议栈。符号：Go语言中指定了以下数据结构和功能\n\n\n\n一步步来学习IPFS。\n\n### P2P\n\nP2P网络结构可分为结构化和非结构化，非结构化组建方便，多个peer同时加入或下线离开，整个网络也会很稳定，结构化网络数据查询效率高，但当大量peer同时加入或离开时网络稳定性差，性能受影响。\n\n结构化网络与纯分布式网络不同的是，所有节点按照某种结构有序组织，比如形成环状网络，或树状网络。DHT提出了一种网络模型，基于DHT，实现结构化网络的算法如Chord、Pastry、Kad等\n\nDHT的核心为，资源空间和节点空间都进行编号，资源空间的编号可映射到对应节点空间。节点路由的普遍实现为trie树，形成K桶。资源的实现的话，邻近节点可存储冗余，对于热点信息，查询周围可缓存，Kad算法本身并未实现资源的冗余存储，主要是K桶的实现，逻辑的距离为节点Id的异或。\n\nK桶一般为定时刷新，以自己为中心，查询距离自己最近的节点组成K桶，以太坊的Kad算法不太一样的是查询的是某个随机ID作为刷新基点，所查找的节点均在距离上向随机生成的TargetId收敛。\n\n\n#### 示例\n\n可查看[以太坊P2P解析](http://qjpcpu.github.io/blog/2018/01/30/shen-ru-ethereumyuan-ma-p2pmo-kuai-jie-dian-fa-xian-ji-zhi/)进一步理解。\n\n[DHT的实现，BT种子嗅探器](https://github.com/shiyanhui/dht)\n\n\n\n\n\n\n\n参考自\n\n1. https://github.com/imfly/bitcoin-on-nodejs/blob/master/\n","source":"_posts/blockchain.md","raw":"---\ntitle: blockchain\ncategories:\n  - blockchain\ndate: 2019-10-14 14:36:24\ntags:\n---\n\n## 区块链\n\n区块链的本质，是去中心化的分布式的数据库系统，实现了数据公开、透明、可追溯。\n\n区块链技术，广义上来说，区块链技术是实现了数据公开透明可追溯的产品的架构涉及方法，必须包含点对点网络设计、加密技术应用、分布式算法的实现、数据存储技术的使用等4方面，可能还涉及到分布式存储，机器学习，VR，物联网，大数据等；狭义上来说，区块链是指类似比特币的数据存储方式或数据库实现，仅仅涉及到数据存储技术，数据库或文件操作等。\n\n从架构上来说，区块链由下到上可以简单的分为三个层次，**协议层**、**扩展层**和**应用层**。最底层的协议层分为存储层和网络层，存储层存储各个区块，组成区块链，存储层的上方是网络层，网络层的主要工作是通过挖矿投票等共识算法保障节点安全，网络层再向上，便是扩展层了，扩展层中含有的扩展例如智能合约、各种侧链应用，或者文档、图书电子书视频等用户数据文件存储或分享等..应用层就要就是可视化操作等..\n\n**协议层**涉及的技术主要是，网络编程，加密签名，分布算法，数据存储。总的看来，网络的实现和并发处理是开发的难点，故开发语言选择优先选择网络编程能力强，并发处理简单的语言，例如Nodejs,Go。\n\n**扩展层**的编程语言与协议层的编程语言可以不用，因为二者交互是通过http/rpc或json/rpc实现，二者基本完全分类，二者除了在交易时发生交互之外，其他时候尽量不要混在一起。扩展层与应用层更加接近，也可以理解位B/S架构的产品中的服务端（Server）。\n\n\n\n#### 共识机制\n\n区块链是去中心化的，去中心化的基础就是节点众多，那么如何吸引用户加入网络成为节点，有哪些激励机制？同时，开发的重点是让多个节点维护一个数据库，那么如何决定哪个节点写入？何时写入？一旦写入，又怎么保证不被其他的节点更改（不可逆）？这些问题的答案，就是共识机制。共识机制可防双花\n\n- POW， 工作量证明，引入了对一个特定值的计算工作，比特币采用的共识算法就是POW\n- POS，权益证明，简单说来，这种机制通过计算你持有占总币数的百分比，包括你占有币数的时间来决定记账权。因此在PoS中，一个账户的余额越多，在同等算力下，就越容易发现下一个区块。\n- DPOS，  委托权益证明\n- PBFT， 实用拜占庭容错\n\n\n\n#### 智能合约\n\n智能合约就是可编程合约，或者叫做合约智能化，其中的\"智能\"是执行上的智能，也就是说达到某个条件，合约自动执行，比如自动转移证券、自动付款等\n\n\n\n#### 加密货币\n\n生活中接触到的数字货币很多，像Q币等的平台内币，这些用“代币”来称呼更为适合。那么加密货币和这些“代币”又有什么区别呢？加密货币定义如下：\n\n> 加密货币，是一种基于点对点网络（P2P网络)、没有发行机构、总量基本固定的加密电子通货。\n\n1. P2P网络：这个不是什么新鲜玩意，最早我们使用的BT(BitTorrent)下载，就是基于P2P网络的，现在很多下载工具都支持。它的好处就是“去中心化”，也就是没有中央服务器，要下载的文件都在用户自己电脑上，而且下载速度更快;\n2. 没有发行机构：就是说，不是那个公司、银行或国家控制发行的。要做到这一点，同时防止通货膨胀等因素，需要在编程中使用非常复杂的机制和规则来实现。\n3. 总量基本固定：这是保证加密货币价值的一种策略，“物以稀为贵”，任何东西没有上限就会失去它的吸引力。这一点，区别于很多网络社区使用的积分，比如：A币、C币、Q币、S币等。\n4. 加密：这里说的加密，不是用户使用的输入用户名、密码那种简单的权限控制，而是对每一个产生的电子货币本身的交易与传输的加密。密码学本身很复杂，但是使用它并不复杂，明白这个就足够了。\n5. 电子通货：也就是说加密货币就是货币，跟法币一样，可以自由交易，只不过是一种电子（数字）形式而已。\n\n\n\n#### 吞吐量\n\n区块链每秒交易量。吞吐量对于区块链项目来说，还算是一个比较重要的点。共识算法中，采用POW/POS的区块链的吞吐量就受到了极大的限制，吞吐量不超过100tx/s，例如比特币和以太坊。原因在于单纯的提高区块大小或者减少区块生成之间的时间解决不了问题，因为区块需要时间传输验证，如果区块太大，那么就会造成网络节点的不一致性加重（分叉变多），从而严重影响可靠性。DPOS通过缩小参与核心共识过程的节点数量，提高共识效率。PBFT对于节点数量少(小于100)的情况下，交易量大概还能有1000tx/s这样。\n\n\n\n#### Token\n\n代币。\n\n- ICO： 当某方以某个价格向投资者提供一些新的加密货币（即代币）时，可以与其他加密货币（即代币）进行交换。 这个想法是投资者购买这些代币，代币可以进行互换和转移。销售代币筹资的概念称作Initial Coin Offer或ICO\n\n\n\n#### 硬分叉/软分叉\n\n**比特币交易其中一个含义指的是我们发送比特币统一使用的数据结构**，这是一套规则，我们所有人发送比特币，不论你使用什么钱包软件都得遵守这一套规则。\n\n硬分叉定义\n\n> 硬分叉是指比特币区块格式或交易格式（这就是广泛流传的“共识”）发生改变时，未升级的节点拒绝验证已经升级的节点生产出的区块，不过已经升级的节点可以验证未升级节点生产出的区块，然后大家各自延续自己认为正确的链，所以分成两条链。\n\n软分叉定义\n\n> 软分叉是指比特币交易的数据结构（这就是被广泛流传的“共识”）发生改变时，未升级的节点可以验证已经升级的节点生产出的区块，而且已经升级的节点也可以验证未升级的节点生产出的区块。\n\n硬分叉不向前兼容，旧版本不会接受新版本创建的区块。要实现硬分叉所有用户都需要切换到新版本协议上。\n\n软分叉向前兼容，旧的版本会接受新版本创建的区块，在软分叉中只需要矿工升级到新版本即可，用户可以继续使用旧版本的协议，他们仍然会接受新版本协议创建的区块。如果有至少51%的矿工的算力转向的新版本，那么网络自动完成软分叉：一开始旧版本创建的区块在新协议下被认为是不合法的，这时会出现一个短暂的分叉，但最终新版本的分叉会赶超旧版本的分叉成为最长链。因为在旧版本上的算力是小于新版本的。\n\n#### 石墨烯技术\n\n[github地址](https://github.com/cryptonomex/graphene)\n\n\n\n### bft\n\n\n\n本文提出了Zyzzyva1，一种使用推测来降低成本并简化BFT状态机复制设计的新协议[18,34]。与传统的状态机复制协议[9,32,40]一样，主要提出了客户端对其他副本的请求的顺序。在Zyzzyva中，与传统协议不同，复制品推测性地执行请求，而不运行昂贵的协议协议来确定订单。因此，正确的副本状态可能会有所不同，并且副本可能会向客户端发送不同的响应。尽管如此，客户端的应用程序观察到复制状态机的传统和强大的抽象，它以可线性化[13]的顺序执行请求，因为答复带有足够的历史信息给客户端以确定答复和历史记录是否稳定并最终保证最终承诺。如果推测回复和历史记录稳定，则客户端使用回复。否则，客户端会等待系统收敛于稳定的回复和历史记录。\n\n\n\nZyzzyva面临的挑战是确保对正确客户的响应变得稳定。 最终，副本负责确保来自正确客户端的所有请求最终完成，但等待回复并且历史稳定的客户端可以通过提供将导致请求在当前视图内快速稳定的信息来加速进程 或触发视图更改。 请注意，由于客户不需要提交请求，而只是为了保持稳定，因此客户可以按照一到两个阶段而不是惯常的三个请求行事[9,32,40]。\n\n\n\n鉴于BFT复制协议已经在客户端上实施的职责[3,9,10,21,32,40]，将输出提交完全移交给客户端并不是一个很大的步骤，但这一小步骤带来了巨大的收益。首先，Zyzzyva利用推测执行 - 复制品在订单完全建立之前执行请求。其次，Zyzzyva利用快速协议协议[11,20,24]在少至三个消息延迟的情况下建立请求排序。第三，一旦客户知道请求的顺序，协议子协议就停止处理请求，从而避免在副本上建立这些知识所需的工作。\n\n这些选择导致设计Zyzzyva时遇到两个关键挑战。首先，我们必须仔细地指定请求在客户端完成的条件，并定义协议，检查点和视图变更子协议，以保留请求在单个正确的状态机上执行的抽象。直接地，当正确的客户端可以安全地处理对该请求的回复。为了帮助客户确定何时适合回复，Zyzzyva会将历史信息附加到客户收到的回复中，以便客户可以判断回复是否基于相同的请求顺序。\n\n\n\n#### 协议概述\n\n3f+1个节点replicas执行，由一系列views组成，在一个view内，一个单点的节点replica被指定为主要负责子协议共识的leader。\n\n客户端发送一个请求给到leader, leader转发给其余replicas, 收到请求的replicas执行请求并将结果返回给客户端，客户端完成1个请求有两种方式，首先，如果客户端收到3f+1相互一致的响应结果（包括history和application-level的回复），然后客户端便认为请求完成并执行之。其次，如果客户端收到再2f+1 ~ 3f之间个数的一致的结果，客户端将手机2f+1的结果然后分发commit certificate给replicas，一旦2f+1的replicas确认收到commit certificate，客户端将会认为请求完成并且执行响应的回复。\n\n如果有足够的replicas认为leader故障，然后view将会进行更换，一个新的leader将会产生。\n\n在本节的其余部分中，我们描述基本协议并概述其正确性的证明[16]。 在§4中，我们描述了一些优化，这些优化全部在我们的原型中实现，通过用消息认证码（MAC）代替公钥签名来降低加密成本，通过批量请求提高吞吐量，通过缓存out-of 通过优化只读请求来提高读取性能，通过使大多数副本发送散列而不是完整回复来减少带宽，通过仅为首选法定数包括MAC来减少开销，并且通过包括额外的附加功能来提高存在故障节点的性能 证人副本。\n\n\n\n#### 节点状态和检查点协议\n\n为了明确地讨论我们的讨论，我们首先讨论由每个副本维护的状态，如图2所总结的。每个副本i维护它已执行的请求的有序历史记录，以及最大提交证书副本，提交证书（定义如下）由我看到，涵盖了我存储历史的最大前缀。这个提交证书覆盖的序列号最高的请求的历史记录是承诺的历史记录，以下的历史记录是推测历史记录。如果n是提交历史记录中的任何请求的最高序列号，我们说一个提交证书的序列号为n。\n\n每个CP INTERVAL请求都会创建一个检查点。副本维护一个稳定的检查点和一个相应的稳定应用程序状态快照，并且它可以存储多达一个暂定检查点和相应的暂定应用程序状态快照。尝试性检查点和应用程序状态提交的过程与早期BFT协议所使用的过程类似[9,10,17,32,40]，因此我们将详细讨论推迟到我们的扩展技术报告[16]。但是，简要总结一下：当正确的副本生成临时检查点时，它会向所有副本发送签名检查点消息。该消息包含检查点中包含的任何请求的最高序列号以及对应的试验性检查点和应用程序快照的摘要。当收集由不同副本签名的f + 1匹配检查点消息时，正确的Zyzzyva副本会将检查点和相应的应用程序快照视为稳定。为了限制历史的大小，副本（1）在提交的检查点之前截断历史记录，（2）在处理自上次提交的检查点以来的2×CP INTERVAL请求之后阻止处理新的请求。最后，每个副本维护一个响应缓存，其中包含每个客户端的最新订购请求的副本以及相应的响应。\n\n\n### IPFS\n\nIPFS是一个分布式文件系统，它综合了以前的对等系统的成功想法，包括DHT，BitTorrent，Git和SFS（SFS文件系统的名字认证了它的服务，用户可以通过服务提供的公钥来验证，协商一个共享的私钥，保证所有的通信。所有的SFS实例都共享了一个全局的命名空间，这个命名空间的名称分配是加密的，不被任何中心化的body控制）。\n\n IPFS的贡献是简化，发展和将成熟的技术连接成一个单一的内聚系统，大于其部分的总和。 IPFS提供了编写和部署应用程序的新平台，以及一个新的分发系统版本化大数据。 IPFS甚至可以演进网络本身。\n\nIPFS是点对点的;没有节点是特权的。 IPFS节点将IPFS对象存储在本地存储中。节点彼此连接并传输对象。这些对象表示文件和其他数据结构。 IPFS协议分为一组负责不同功能的子协议：\n\n- 身份\n  管理节点身份生成和验证。\n- 网络\n  管理与其他对等体的连接，使用各种底层网络协议。可配置的。\n- 路由\n  维护信息以定位特定的对等体和对象。响应本地和远程查询。默认为DHT，但可更换。\n- 对象\n  具有链接的内容寻址不可更改对象的Merkle DAG。用于表示任意数据结构，例如文件层次和通信系统。\n- 交换\n  一种支持有效块分配的新型块交换协议（BitSwap）。模拟市场，弱化数据复制。贸易策略可替换。\n- 文件\n  由Git启发的版本化文件系统层次结构。\n- 命名\n  自我认证的可变名称系统。这些子系统不是独立的;它们是集成在一起，互相利用各自的属性。但是，分开描述它们是有用的，从下到上构建协议栈。符号：Go语言中指定了以下数据结构和功能\n\n\n\n一步步来学习IPFS。\n\n### P2P\n\nP2P网络结构可分为结构化和非结构化，非结构化组建方便，多个peer同时加入或下线离开，整个网络也会很稳定，结构化网络数据查询效率高，但当大量peer同时加入或离开时网络稳定性差，性能受影响。\n\n结构化网络与纯分布式网络不同的是，所有节点按照某种结构有序组织，比如形成环状网络，或树状网络。DHT提出了一种网络模型，基于DHT，实现结构化网络的算法如Chord、Pastry、Kad等\n\nDHT的核心为，资源空间和节点空间都进行编号，资源空间的编号可映射到对应节点空间。节点路由的普遍实现为trie树，形成K桶。资源的实现的话，邻近节点可存储冗余，对于热点信息，查询周围可缓存，Kad算法本身并未实现资源的冗余存储，主要是K桶的实现，逻辑的距离为节点Id的异或。\n\nK桶一般为定时刷新，以自己为中心，查询距离自己最近的节点组成K桶，以太坊的Kad算法不太一样的是查询的是某个随机ID作为刷新基点，所查找的节点均在距离上向随机生成的TargetId收敛。\n\n\n#### 示例\n\n可查看[以太坊P2P解析](http://qjpcpu.github.io/blog/2018/01/30/shen-ru-ethereumyuan-ma-p2pmo-kuai-jie-dian-fa-xian-ji-zhi/)进一步理解。\n\n[DHT的实现，BT种子嗅探器](https://github.com/shiyanhui/dht)\n\n\n\n\n\n\n\n参考自\n\n1. https://github.com/imfly/bitcoin-on-nodejs/blob/master/\n","slug":"blockchain","published":1,"updated":"2019-10-14T06:39:21.716Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69wr001zt6xv3i73t48z","content":"<h2 id=\"区块链\"><a href=\"#区块链\" class=\"headerlink\" title=\"区块链\"></a>区块链</h2><p>区块链的本质，是去中心化的分布式的数据库系统，实现了数据公开、透明、可追溯。</p>\n<p>区块链技术，广义上来说，区块链技术是实现了数据公开透明可追溯的产品的架构涉及方法，必须包含点对点网络设计、加密技术应用、分布式算法的实现、数据存储技术的使用等4方面，可能还涉及到分布式存储，机器学习，VR，物联网，大数据等；狭义上来说，区块链是指类似比特币的数据存储方式或数据库实现，仅仅涉及到数据存储技术，数据库或文件操作等。</p>\n<p>从架构上来说，区块链由下到上可以简单的分为三个层次，<strong>协议层</strong>、<strong>扩展层</strong>和<strong>应用层</strong>。最底层的协议层分为存储层和网络层，存储层存储各个区块，组成区块链，存储层的上方是网络层，网络层的主要工作是通过挖矿投票等共识算法保障节点安全，网络层再向上，便是扩展层了，扩展层中含有的扩展例如智能合约、各种侧链应用，或者文档、图书电子书视频等用户数据文件存储或分享等..应用层就要就是可视化操作等..</p>\n<p><strong>协议层</strong>涉及的技术主要是，网络编程，加密签名，分布算法，数据存储。总的看来，网络的实现和并发处理是开发的难点，故开发语言选择优先选择网络编程能力强，并发处理简单的语言，例如Nodejs,Go。</p>\n<p><strong>扩展层</strong>的编程语言与协议层的编程语言可以不用，因为二者交互是通过http/rpc或json/rpc实现，二者基本完全分类，二者除了在交易时发生交互之外，其他时候尽量不要混在一起。扩展层与应用层更加接近，也可以理解位B/S架构的产品中的服务端（Server）。</p>\n<h4 id=\"共识机制\"><a href=\"#共识机制\" class=\"headerlink\" title=\"共识机制\"></a>共识机制</h4><p>区块链是去中心化的，去中心化的基础就是节点众多，那么如何吸引用户加入网络成为节点，有哪些激励机制？同时，开发的重点是让多个节点维护一个数据库，那么如何决定哪个节点写入？何时写入？一旦写入，又怎么保证不被其他的节点更改（不可逆）？这些问题的答案，就是共识机制。共识机制可防双花</p>\n<ul>\n<li>POW， 工作量证明，引入了对一个特定值的计算工作，比特币采用的共识算法就是POW</li>\n<li>POS，权益证明，简单说来，这种机制通过计算你持有占总币数的百分比，包括你占有币数的时间来决定记账权。因此在PoS中，一个账户的余额越多，在同等算力下，就越容易发现下一个区块。</li>\n<li>DPOS，  委托权益证明</li>\n<li>PBFT， 实用拜占庭容错</li>\n</ul>\n<h4 id=\"智能合约\"><a href=\"#智能合约\" class=\"headerlink\" title=\"智能合约\"></a>智能合约</h4><p>智能合约就是可编程合约，或者叫做合约智能化，其中的”智能”是执行上的智能，也就是说达到某个条件，合约自动执行，比如自动转移证券、自动付款等</p>\n<h4 id=\"加密货币\"><a href=\"#加密货币\" class=\"headerlink\" title=\"加密货币\"></a>加密货币</h4><p>生活中接触到的数字货币很多，像Q币等的平台内币，这些用“代币”来称呼更为适合。那么加密货币和这些“代币”又有什么区别呢？加密货币定义如下：</p>\n<blockquote>\n<p>加密货币，是一种基于点对点网络（P2P网络)、没有发行机构、总量基本固定的加密电子通货。</p>\n</blockquote>\n<ol>\n<li>P2P网络：这个不是什么新鲜玩意，最早我们使用的BT(BitTorrent)下载，就是基于P2P网络的，现在很多下载工具都支持。它的好处就是“去中心化”，也就是没有中央服务器，要下载的文件都在用户自己电脑上，而且下载速度更快;</li>\n<li>没有发行机构：就是说，不是那个公司、银行或国家控制发行的。要做到这一点，同时防止通货膨胀等因素，需要在编程中使用非常复杂的机制和规则来实现。</li>\n<li>总量基本固定：这是保证加密货币价值的一种策略，“物以稀为贵”，任何东西没有上限就会失去它的吸引力。这一点，区别于很多网络社区使用的积分，比如：A币、C币、Q币、S币等。</li>\n<li>加密：这里说的加密，不是用户使用的输入用户名、密码那种简单的权限控制，而是对每一个产生的电子货币本身的交易与传输的加密。密码学本身很复杂，但是使用它并不复杂，明白这个就足够了。</li>\n<li>电子通货：也就是说加密货币就是货币，跟法币一样，可以自由交易，只不过是一种电子（数字）形式而已。</li>\n</ol>\n<h4 id=\"吞吐量\"><a href=\"#吞吐量\" class=\"headerlink\" title=\"吞吐量\"></a>吞吐量</h4><p>区块链每秒交易量。吞吐量对于区块链项目来说，还算是一个比较重要的点。共识算法中，采用POW/POS的区块链的吞吐量就受到了极大的限制，吞吐量不超过100tx/s，例如比特币和以太坊。原因在于单纯的提高区块大小或者减少区块生成之间的时间解决不了问题，因为区块需要时间传输验证，如果区块太大，那么就会造成网络节点的不一致性加重（分叉变多），从而严重影响可靠性。DPOS通过缩小参与核心共识过程的节点数量，提高共识效率。PBFT对于节点数量少(小于100)的情况下，交易量大概还能有1000tx/s这样。</p>\n<h4 id=\"Token\"><a href=\"#Token\" class=\"headerlink\" title=\"Token\"></a>Token</h4><p>代币。</p>\n<ul>\n<li>ICO： 当某方以某个价格向投资者提供一些新的加密货币（即代币）时，可以与其他加密货币（即代币）进行交换。 这个想法是投资者购买这些代币，代币可以进行互换和转移。销售代币筹资的概念称作Initial Coin Offer或ICO</li>\n</ul>\n<h4 id=\"硬分叉-软分叉\"><a href=\"#硬分叉-软分叉\" class=\"headerlink\" title=\"硬分叉/软分叉\"></a>硬分叉/软分叉</h4><p><strong>比特币交易其中一个含义指的是我们发送比特币统一使用的数据结构</strong>，这是一套规则，我们所有人发送比特币，不论你使用什么钱包软件都得遵守这一套规则。</p>\n<p>硬分叉定义</p>\n<blockquote>\n<p>硬分叉是指比特币区块格式或交易格式（这就是广泛流传的“共识”）发生改变时，未升级的节点拒绝验证已经升级的节点生产出的区块，不过已经升级的节点可以验证未升级节点生产出的区块，然后大家各自延续自己认为正确的链，所以分成两条链。</p>\n</blockquote>\n<p>软分叉定义</p>\n<blockquote>\n<p>软分叉是指比特币交易的数据结构（这就是被广泛流传的“共识”）发生改变时，未升级的节点可以验证已经升级的节点生产出的区块，而且已经升级的节点也可以验证未升级的节点生产出的区块。</p>\n</blockquote>\n<p>硬分叉不向前兼容，旧版本不会接受新版本创建的区块。要实现硬分叉所有用户都需要切换到新版本协议上。</p>\n<p>软分叉向前兼容，旧的版本会接受新版本创建的区块，在软分叉中只需要矿工升级到新版本即可，用户可以继续使用旧版本的协议，他们仍然会接受新版本协议创建的区块。如果有至少51%的矿工的算力转向的新版本，那么网络自动完成软分叉：一开始旧版本创建的区块在新协议下被认为是不合法的，这时会出现一个短暂的分叉，但最终新版本的分叉会赶超旧版本的分叉成为最长链。因为在旧版本上的算力是小于新版本的。</p>\n<h4 id=\"石墨烯技术\"><a href=\"#石墨烯技术\" class=\"headerlink\" title=\"石墨烯技术\"></a>石墨烯技术</h4><p><a href=\"https://github.com/cryptonomex/graphene\">github地址</a></p>\n<h3 id=\"bft\"><a href=\"#bft\" class=\"headerlink\" title=\"bft\"></a>bft</h3><p>本文提出了Zyzzyva1，一种使用推测来降低成本并简化BFT状态机复制设计的新协议[18,34]。与传统的状态机复制协议[9,32,40]一样，主要提出了客户端对其他副本的请求的顺序。在Zyzzyva中，与传统协议不同，复制品推测性地执行请求，而不运行昂贵的协议协议来确定订单。因此，正确的副本状态可能会有所不同，并且副本可能会向客户端发送不同的响应。尽管如此，客户端的应用程序观察到复制状态机的传统和强大的抽象，它以可线性化[13]的顺序执行请求，因为答复带有足够的历史信息给客户端以确定答复和历史记录是否稳定并最终保证最终承诺。如果推测回复和历史记录稳定，则客户端使用回复。否则，客户端会等待系统收敛于稳定的回复和历史记录。</p>\n<p>Zyzzyva面临的挑战是确保对正确客户的响应变得稳定。 最终，副本负责确保来自正确客户端的所有请求最终完成，但等待回复并且历史稳定的客户端可以通过提供将导致请求在当前视图内快速稳定的信息来加速进程 或触发视图更改。 请注意，由于客户不需要提交请求，而只是为了保持稳定，因此客户可以按照一到两个阶段而不是惯常的三个请求行事[9,32,40]。</p>\n<p>鉴于BFT复制协议已经在客户端上实施的职责[3,9,10,21,32,40]，将输出提交完全移交给客户端并不是一个很大的步骤，但这一小步骤带来了巨大的收益。首先，Zyzzyva利用推测执行 - 复制品在订单完全建立之前执行请求。其次，Zyzzyva利用快速协议协议[11,20,24]在少至三个消息延迟的情况下建立请求排序。第三，一旦客户知道请求的顺序，协议子协议就停止处理请求，从而避免在副本上建立这些知识所需的工作。</p>\n<p>这些选择导致设计Zyzzyva时遇到两个关键挑战。首先，我们必须仔细地指定请求在客户端完成的条件，并定义协议，检查点和视图变更子协议，以保留请求在单个正确的状态机上执行的抽象。直接地，当正确的客户端可以安全地处理对该请求的回复。为了帮助客户确定何时适合回复，Zyzzyva会将历史信息附加到客户收到的回复中，以便客户可以判断回复是否基于相同的请求顺序。</p>\n<h4 id=\"协议概述\"><a href=\"#协议概述\" class=\"headerlink\" title=\"协议概述\"></a>协议概述</h4><p>3f+1个节点replicas执行，由一系列views组成，在一个view内，一个单点的节点replica被指定为主要负责子协议共识的leader。</p>\n<p>客户端发送一个请求给到leader, leader转发给其余replicas, 收到请求的replicas执行请求并将结果返回给客户端，客户端完成1个请求有两种方式，首先，如果客户端收到3f+1相互一致的响应结果（包括history和application-level的回复），然后客户端便认为请求完成并执行之。其次，如果客户端收到再2f+1 ~ 3f之间个数的一致的结果，客户端将手机2f+1的结果然后分发commit certificate给replicas，一旦2f+1的replicas确认收到commit certificate，客户端将会认为请求完成并且执行响应的回复。</p>\n<p>如果有足够的replicas认为leader故障，然后view将会进行更换，一个新的leader将会产生。</p>\n<p>在本节的其余部分中，我们描述基本协议并概述其正确性的证明[16]。 在§4中，我们描述了一些优化，这些优化全部在我们的原型中实现，通过用消息认证码（MAC）代替公钥签名来降低加密成本，通过批量请求提高吞吐量，通过缓存out-of 通过优化只读请求来提高读取性能，通过使大多数副本发送散列而不是完整回复来减少带宽，通过仅为首选法定数包括MAC来减少开销，并且通过包括额外的附加功能来提高存在故障节点的性能 证人副本。</p>\n<h4 id=\"节点状态和检查点协议\"><a href=\"#节点状态和检查点协议\" class=\"headerlink\" title=\"节点状态和检查点协议\"></a>节点状态和检查点协议</h4><p>为了明确地讨论我们的讨论，我们首先讨论由每个副本维护的状态，如图2所总结的。每个副本i维护它已执行的请求的有序历史记录，以及最大提交证书副本，提交证书（定义如下）由我看到，涵盖了我存储历史的最大前缀。这个提交证书覆盖的序列号最高的请求的历史记录是承诺的历史记录，以下的历史记录是推测历史记录。如果n是提交历史记录中的任何请求的最高序列号，我们说一个提交证书的序列号为n。</p>\n<p>每个CP INTERVAL请求都会创建一个检查点。副本维护一个稳定的检查点和一个相应的稳定应用程序状态快照，并且它可以存储多达一个暂定检查点和相应的暂定应用程序状态快照。尝试性检查点和应用程序状态提交的过程与早期BFT协议所使用的过程类似[9,10,17,32,40]，因此我们将详细讨论推迟到我们的扩展技术报告[16]。但是，简要总结一下：当正确的副本生成临时检查点时，它会向所有副本发送签名检查点消息。该消息包含检查点中包含的任何请求的最高序列号以及对应的试验性检查点和应用程序快照的摘要。当收集由不同副本签名的f + 1匹配检查点消息时，正确的Zyzzyva副本会将检查点和相应的应用程序快照视为稳定。为了限制历史的大小，副本（1）在提交的检查点之前截断历史记录，（2）在处理自上次提交的检查点以来的2×CP INTERVAL请求之后阻止处理新的请求。最后，每个副本维护一个响应缓存，其中包含每个客户端的最新订购请求的副本以及相应的响应。</p>\n<h3 id=\"IPFS\"><a href=\"#IPFS\" class=\"headerlink\" title=\"IPFS\"></a>IPFS</h3><p>IPFS是一个分布式文件系统，它综合了以前的对等系统的成功想法，包括DHT，BitTorrent，Git和SFS（SFS文件系统的名字认证了它的服务，用户可以通过服务提供的公钥来验证，协商一个共享的私钥，保证所有的通信。所有的SFS实例都共享了一个全局的命名空间，这个命名空间的名称分配是加密的，不被任何中心化的body控制）。</p>\n<p> IPFS的贡献是简化，发展和将成熟的技术连接成一个单一的内聚系统，大于其部分的总和。 IPFS提供了编写和部署应用程序的新平台，以及一个新的分发系统版本化大数据。 IPFS甚至可以演进网络本身。</p>\n<p>IPFS是点对点的;没有节点是特权的。 IPFS节点将IPFS对象存储在本地存储中。节点彼此连接并传输对象。这些对象表示文件和其他数据结构。 IPFS协议分为一组负责不同功能的子协议：</p>\n<ul>\n<li>身份<br>管理节点身份生成和验证。</li>\n<li>网络<br>管理与其他对等体的连接，使用各种底层网络协议。可配置的。</li>\n<li>路由<br>维护信息以定位特定的对等体和对象。响应本地和远程查询。默认为DHT，但可更换。</li>\n<li>对象<br>具有链接的内容寻址不可更改对象的Merkle DAG。用于表示任意数据结构，例如文件层次和通信系统。</li>\n<li>交换<br>一种支持有效块分配的新型块交换协议（BitSwap）。模拟市场，弱化数据复制。贸易策略可替换。</li>\n<li>文件<br>由Git启发的版本化文件系统层次结构。</li>\n<li>命名<br>自我认证的可变名称系统。这些子系统不是独立的;它们是集成在一起，互相利用各自的属性。但是，分开描述它们是有用的，从下到上构建协议栈。符号：Go语言中指定了以下数据结构和功能</li>\n</ul>\n<p>一步步来学习IPFS。</p>\n<h3 id=\"P2P\"><a href=\"#P2P\" class=\"headerlink\" title=\"P2P\"></a>P2P</h3><p>P2P网络结构可分为结构化和非结构化，非结构化组建方便，多个peer同时加入或下线离开，整个网络也会很稳定，结构化网络数据查询效率高，但当大量peer同时加入或离开时网络稳定性差，性能受影响。</p>\n<p>结构化网络与纯分布式网络不同的是，所有节点按照某种结构有序组织，比如形成环状网络，或树状网络。DHT提出了一种网络模型，基于DHT，实现结构化网络的算法如Chord、Pastry、Kad等</p>\n<p>DHT的核心为，资源空间和节点空间都进行编号，资源空间的编号可映射到对应节点空间。节点路由的普遍实现为trie树，形成K桶。资源的实现的话，邻近节点可存储冗余，对于热点信息，查询周围可缓存，Kad算法本身并未实现资源的冗余存储，主要是K桶的实现，逻辑的距离为节点Id的异或。</p>\n<p>K桶一般为定时刷新，以自己为中心，查询距离自己最近的节点组成K桶，以太坊的Kad算法不太一样的是查询的是某个随机ID作为刷新基点，所查找的节点均在距离上向随机生成的TargetId收敛。</p>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h4><p>可查看<a href=\"http://qjpcpu.github.io/blog/2018/01/30/shen-ru-ethereumyuan-ma-p2pmo-kuai-jie-dian-fa-xian-ji-zhi/\" target=\"_blank\" rel=\"noopener\">以太坊P2P解析</a>进一步理解。</p>\n<p><a href=\"https://github.com/shiyanhui/dht\">DHT的实现，BT种子嗅探器</a></p>\n<p>参考自</p>\n<ol>\n<li><a href=\"https://github.com/imfly/bitcoin-on-nodejs/blob/master/\">https://github.com/imfly/bitcoin-on-nodejs/blob/master/</a></li>\n</ol>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"区块链\"><a href=\"#区块链\" class=\"headerlink\" title=\"区块链\"></a>区块链</h2><p>区块链的本质，是去中心化的分布式的数据库系统，实现了数据公开、透明、可追溯。</p>\n<p>区块链技术，广义上来说，区块链技术是实现了数据公开透明可追溯的产品的架构涉及方法，必须包含点对点网络设计、加密技术应用、分布式算法的实现、数据存储技术的使用等4方面，可能还涉及到分布式存储，机器学习，VR，物联网，大数据等；狭义上来说，区块链是指类似比特币的数据存储方式或数据库实现，仅仅涉及到数据存储技术，数据库或文件操作等。</p>\n<p>从架构上来说，区块链由下到上可以简单的分为三个层次，<strong>协议层</strong>、<strong>扩展层</strong>和<strong>应用层</strong>。最底层的协议层分为存储层和网络层，存储层存储各个区块，组成区块链，存储层的上方是网络层，网络层的主要工作是通过挖矿投票等共识算法保障节点安全，网络层再向上，便是扩展层了，扩展层中含有的扩展例如智能合约、各种侧链应用，或者文档、图书电子书视频等用户数据文件存储或分享等..应用层就要就是可视化操作等..</p>\n<p><strong>协议层</strong>涉及的技术主要是，网络编程，加密签名，分布算法，数据存储。总的看来，网络的实现和并发处理是开发的难点，故开发语言选择优先选择网络编程能力强，并发处理简单的语言，例如Nodejs,Go。</p>\n<p><strong>扩展层</strong>的编程语言与协议层的编程语言可以不用，因为二者交互是通过http/rpc或json/rpc实现，二者基本完全分类，二者除了在交易时发生交互之外，其他时候尽量不要混在一起。扩展层与应用层更加接近，也可以理解位B/S架构的产品中的服务端（Server）。</p>\n<h4 id=\"共识机制\"><a href=\"#共识机制\" class=\"headerlink\" title=\"共识机制\"></a>共识机制</h4><p>区块链是去中心化的，去中心化的基础就是节点众多，那么如何吸引用户加入网络成为节点，有哪些激励机制？同时，开发的重点是让多个节点维护一个数据库，那么如何决定哪个节点写入？何时写入？一旦写入，又怎么保证不被其他的节点更改（不可逆）？这些问题的答案，就是共识机制。共识机制可防双花</p>\n<ul>\n<li>POW， 工作量证明，引入了对一个特定值的计算工作，比特币采用的共识算法就是POW</li>\n<li>POS，权益证明，简单说来，这种机制通过计算你持有占总币数的百分比，包括你占有币数的时间来决定记账权。因此在PoS中，一个账户的余额越多，在同等算力下，就越容易发现下一个区块。</li>\n<li>DPOS，  委托权益证明</li>\n<li>PBFT， 实用拜占庭容错</li>\n</ul>\n<h4 id=\"智能合约\"><a href=\"#智能合约\" class=\"headerlink\" title=\"智能合约\"></a>智能合约</h4><p>智能合约就是可编程合约，或者叫做合约智能化，其中的”智能”是执行上的智能，也就是说达到某个条件，合约自动执行，比如自动转移证券、自动付款等</p>\n<h4 id=\"加密货币\"><a href=\"#加密货币\" class=\"headerlink\" title=\"加密货币\"></a>加密货币</h4><p>生活中接触到的数字货币很多，像Q币等的平台内币，这些用“代币”来称呼更为适合。那么加密货币和这些“代币”又有什么区别呢？加密货币定义如下：</p>\n<blockquote>\n<p>加密货币，是一种基于点对点网络（P2P网络)、没有发行机构、总量基本固定的加密电子通货。</p>\n</blockquote>\n<ol>\n<li>P2P网络：这个不是什么新鲜玩意，最早我们使用的BT(BitTorrent)下载，就是基于P2P网络的，现在很多下载工具都支持。它的好处就是“去中心化”，也就是没有中央服务器，要下载的文件都在用户自己电脑上，而且下载速度更快;</li>\n<li>没有发行机构：就是说，不是那个公司、银行或国家控制发行的。要做到这一点，同时防止通货膨胀等因素，需要在编程中使用非常复杂的机制和规则来实现。</li>\n<li>总量基本固定：这是保证加密货币价值的一种策略，“物以稀为贵”，任何东西没有上限就会失去它的吸引力。这一点，区别于很多网络社区使用的积分，比如：A币、C币、Q币、S币等。</li>\n<li>加密：这里说的加密，不是用户使用的输入用户名、密码那种简单的权限控制，而是对每一个产生的电子货币本身的交易与传输的加密。密码学本身很复杂，但是使用它并不复杂，明白这个就足够了。</li>\n<li>电子通货：也就是说加密货币就是货币，跟法币一样，可以自由交易，只不过是一种电子（数字）形式而已。</li>\n</ol>\n<h4 id=\"吞吐量\"><a href=\"#吞吐量\" class=\"headerlink\" title=\"吞吐量\"></a>吞吐量</h4><p>区块链每秒交易量。吞吐量对于区块链项目来说，还算是一个比较重要的点。共识算法中，采用POW/POS的区块链的吞吐量就受到了极大的限制，吞吐量不超过100tx/s，例如比特币和以太坊。原因在于单纯的提高区块大小或者减少区块生成之间的时间解决不了问题，因为区块需要时间传输验证，如果区块太大，那么就会造成网络节点的不一致性加重（分叉变多），从而严重影响可靠性。DPOS通过缩小参与核心共识过程的节点数量，提高共识效率。PBFT对于节点数量少(小于100)的情况下，交易量大概还能有1000tx/s这样。</p>\n<h4 id=\"Token\"><a href=\"#Token\" class=\"headerlink\" title=\"Token\"></a>Token</h4><p>代币。</p>\n<ul>\n<li>ICO： 当某方以某个价格向投资者提供一些新的加密货币（即代币）时，可以与其他加密货币（即代币）进行交换。 这个想法是投资者购买这些代币，代币可以进行互换和转移。销售代币筹资的概念称作Initial Coin Offer或ICO</li>\n</ul>\n<h4 id=\"硬分叉-软分叉\"><a href=\"#硬分叉-软分叉\" class=\"headerlink\" title=\"硬分叉/软分叉\"></a>硬分叉/软分叉</h4><p><strong>比特币交易其中一个含义指的是我们发送比特币统一使用的数据结构</strong>，这是一套规则，我们所有人发送比特币，不论你使用什么钱包软件都得遵守这一套规则。</p>\n<p>硬分叉定义</p>\n<blockquote>\n<p>硬分叉是指比特币区块格式或交易格式（这就是广泛流传的“共识”）发生改变时，未升级的节点拒绝验证已经升级的节点生产出的区块，不过已经升级的节点可以验证未升级节点生产出的区块，然后大家各自延续自己认为正确的链，所以分成两条链。</p>\n</blockquote>\n<p>软分叉定义</p>\n<blockquote>\n<p>软分叉是指比特币交易的数据结构（这就是被广泛流传的“共识”）发生改变时，未升级的节点可以验证已经升级的节点生产出的区块，而且已经升级的节点也可以验证未升级的节点生产出的区块。</p>\n</blockquote>\n<p>硬分叉不向前兼容，旧版本不会接受新版本创建的区块。要实现硬分叉所有用户都需要切换到新版本协议上。</p>\n<p>软分叉向前兼容，旧的版本会接受新版本创建的区块，在软分叉中只需要矿工升级到新版本即可，用户可以继续使用旧版本的协议，他们仍然会接受新版本协议创建的区块。如果有至少51%的矿工的算力转向的新版本，那么网络自动完成软分叉：一开始旧版本创建的区块在新协议下被认为是不合法的，这时会出现一个短暂的分叉，但最终新版本的分叉会赶超旧版本的分叉成为最长链。因为在旧版本上的算力是小于新版本的。</p>\n<h4 id=\"石墨烯技术\"><a href=\"#石墨烯技术\" class=\"headerlink\" title=\"石墨烯技术\"></a>石墨烯技术</h4><p><a href=\"https://github.com/cryptonomex/graphene\">github地址</a></p>\n<h3 id=\"bft\"><a href=\"#bft\" class=\"headerlink\" title=\"bft\"></a>bft</h3><p>本文提出了Zyzzyva1，一种使用推测来降低成本并简化BFT状态机复制设计的新协议[18,34]。与传统的状态机复制协议[9,32,40]一样，主要提出了客户端对其他副本的请求的顺序。在Zyzzyva中，与传统协议不同，复制品推测性地执行请求，而不运行昂贵的协议协议来确定订单。因此，正确的副本状态可能会有所不同，并且副本可能会向客户端发送不同的响应。尽管如此，客户端的应用程序观察到复制状态机的传统和强大的抽象，它以可线性化[13]的顺序执行请求，因为答复带有足够的历史信息给客户端以确定答复和历史记录是否稳定并最终保证最终承诺。如果推测回复和历史记录稳定，则客户端使用回复。否则，客户端会等待系统收敛于稳定的回复和历史记录。</p>\n<p>Zyzzyva面临的挑战是确保对正确客户的响应变得稳定。 最终，副本负责确保来自正确客户端的所有请求最终完成，但等待回复并且历史稳定的客户端可以通过提供将导致请求在当前视图内快速稳定的信息来加速进程 或触发视图更改。 请注意，由于客户不需要提交请求，而只是为了保持稳定，因此客户可以按照一到两个阶段而不是惯常的三个请求行事[9,32,40]。</p>\n<p>鉴于BFT复制协议已经在客户端上实施的职责[3,9,10,21,32,40]，将输出提交完全移交给客户端并不是一个很大的步骤，但这一小步骤带来了巨大的收益。首先，Zyzzyva利用推测执行 - 复制品在订单完全建立之前执行请求。其次，Zyzzyva利用快速协议协议[11,20,24]在少至三个消息延迟的情况下建立请求排序。第三，一旦客户知道请求的顺序，协议子协议就停止处理请求，从而避免在副本上建立这些知识所需的工作。</p>\n<p>这些选择导致设计Zyzzyva时遇到两个关键挑战。首先，我们必须仔细地指定请求在客户端完成的条件，并定义协议，检查点和视图变更子协议，以保留请求在单个正确的状态机上执行的抽象。直接地，当正确的客户端可以安全地处理对该请求的回复。为了帮助客户确定何时适合回复，Zyzzyva会将历史信息附加到客户收到的回复中，以便客户可以判断回复是否基于相同的请求顺序。</p>\n<h4 id=\"协议概述\"><a href=\"#协议概述\" class=\"headerlink\" title=\"协议概述\"></a>协议概述</h4><p>3f+1个节点replicas执行，由一系列views组成，在一个view内，一个单点的节点replica被指定为主要负责子协议共识的leader。</p>\n<p>客户端发送一个请求给到leader, leader转发给其余replicas, 收到请求的replicas执行请求并将结果返回给客户端，客户端完成1个请求有两种方式，首先，如果客户端收到3f+1相互一致的响应结果（包括history和application-level的回复），然后客户端便认为请求完成并执行之。其次，如果客户端收到再2f+1 ~ 3f之间个数的一致的结果，客户端将手机2f+1的结果然后分发commit certificate给replicas，一旦2f+1的replicas确认收到commit certificate，客户端将会认为请求完成并且执行响应的回复。</p>\n<p>如果有足够的replicas认为leader故障，然后view将会进行更换，一个新的leader将会产生。</p>\n<p>在本节的其余部分中，我们描述基本协议并概述其正确性的证明[16]。 在§4中，我们描述了一些优化，这些优化全部在我们的原型中实现，通过用消息认证码（MAC）代替公钥签名来降低加密成本，通过批量请求提高吞吐量，通过缓存out-of 通过优化只读请求来提高读取性能，通过使大多数副本发送散列而不是完整回复来减少带宽，通过仅为首选法定数包括MAC来减少开销，并且通过包括额外的附加功能来提高存在故障节点的性能 证人副本。</p>\n<h4 id=\"节点状态和检查点协议\"><a href=\"#节点状态和检查点协议\" class=\"headerlink\" title=\"节点状态和检查点协议\"></a>节点状态和检查点协议</h4><p>为了明确地讨论我们的讨论，我们首先讨论由每个副本维护的状态，如图2所总结的。每个副本i维护它已执行的请求的有序历史记录，以及最大提交证书副本，提交证书（定义如下）由我看到，涵盖了我存储历史的最大前缀。这个提交证书覆盖的序列号最高的请求的历史记录是承诺的历史记录，以下的历史记录是推测历史记录。如果n是提交历史记录中的任何请求的最高序列号，我们说一个提交证书的序列号为n。</p>\n<p>每个CP INTERVAL请求都会创建一个检查点。副本维护一个稳定的检查点和一个相应的稳定应用程序状态快照，并且它可以存储多达一个暂定检查点和相应的暂定应用程序状态快照。尝试性检查点和应用程序状态提交的过程与早期BFT协议所使用的过程类似[9,10,17,32,40]，因此我们将详细讨论推迟到我们的扩展技术报告[16]。但是，简要总结一下：当正确的副本生成临时检查点时，它会向所有副本发送签名检查点消息。该消息包含检查点中包含的任何请求的最高序列号以及对应的试验性检查点和应用程序快照的摘要。当收集由不同副本签名的f + 1匹配检查点消息时，正确的Zyzzyva副本会将检查点和相应的应用程序快照视为稳定。为了限制历史的大小，副本（1）在提交的检查点之前截断历史记录，（2）在处理自上次提交的检查点以来的2×CP INTERVAL请求之后阻止处理新的请求。最后，每个副本维护一个响应缓存，其中包含每个客户端的最新订购请求的副本以及相应的响应。</p>\n<h3 id=\"IPFS\"><a href=\"#IPFS\" class=\"headerlink\" title=\"IPFS\"></a>IPFS</h3><p>IPFS是一个分布式文件系统，它综合了以前的对等系统的成功想法，包括DHT，BitTorrent，Git和SFS（SFS文件系统的名字认证了它的服务，用户可以通过服务提供的公钥来验证，协商一个共享的私钥，保证所有的通信。所有的SFS实例都共享了一个全局的命名空间，这个命名空间的名称分配是加密的，不被任何中心化的body控制）。</p>\n<p> IPFS的贡献是简化，发展和将成熟的技术连接成一个单一的内聚系统，大于其部分的总和。 IPFS提供了编写和部署应用程序的新平台，以及一个新的分发系统版本化大数据。 IPFS甚至可以演进网络本身。</p>\n<p>IPFS是点对点的;没有节点是特权的。 IPFS节点将IPFS对象存储在本地存储中。节点彼此连接并传输对象。这些对象表示文件和其他数据结构。 IPFS协议分为一组负责不同功能的子协议：</p>\n<ul>\n<li>身份<br>管理节点身份生成和验证。</li>\n<li>网络<br>管理与其他对等体的连接，使用各种底层网络协议。可配置的。</li>\n<li>路由<br>维护信息以定位特定的对等体和对象。响应本地和远程查询。默认为DHT，但可更换。</li>\n<li>对象<br>具有链接的内容寻址不可更改对象的Merkle DAG。用于表示任意数据结构，例如文件层次和通信系统。</li>\n<li>交换<br>一种支持有效块分配的新型块交换协议（BitSwap）。模拟市场，弱化数据复制。贸易策略可替换。</li>\n<li>文件<br>由Git启发的版本化文件系统层次结构。</li>\n<li>命名<br>自我认证的可变名称系统。这些子系统不是独立的;它们是集成在一起，互相利用各自的属性。但是，分开描述它们是有用的，从下到上构建协议栈。符号：Go语言中指定了以下数据结构和功能</li>\n</ul>\n<p>一步步来学习IPFS。</p>\n<h3 id=\"P2P\"><a href=\"#P2P\" class=\"headerlink\" title=\"P2P\"></a>P2P</h3><p>P2P网络结构可分为结构化和非结构化，非结构化组建方便，多个peer同时加入或下线离开，整个网络也会很稳定，结构化网络数据查询效率高，但当大量peer同时加入或离开时网络稳定性差，性能受影响。</p>\n<p>结构化网络与纯分布式网络不同的是，所有节点按照某种结构有序组织，比如形成环状网络，或树状网络。DHT提出了一种网络模型，基于DHT，实现结构化网络的算法如Chord、Pastry、Kad等</p>\n<p>DHT的核心为，资源空间和节点空间都进行编号，资源空间的编号可映射到对应节点空间。节点路由的普遍实现为trie树，形成K桶。资源的实现的话，邻近节点可存储冗余，对于热点信息，查询周围可缓存，Kad算法本身并未实现资源的冗余存储，主要是K桶的实现，逻辑的距离为节点Id的异或。</p>\n<p>K桶一般为定时刷新，以自己为中心，查询距离自己最近的节点组成K桶，以太坊的Kad算法不太一样的是查询的是某个随机ID作为刷新基点，所查找的节点均在距离上向随机生成的TargetId收敛。</p>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h4><p>可查看<a href=\"http://qjpcpu.github.io/blog/2018/01/30/shen-ru-ethereumyuan-ma-p2pmo-kuai-jie-dian-fa-xian-ji-zhi/\" target=\"_blank\" rel=\"noopener\">以太坊P2P解析</a>进一步理解。</p>\n<p><a href=\"https://github.com/shiyanhui/dht\">DHT的实现，BT种子嗅探器</a></p>\n<p>参考自</p>\n<ol>\n<li><a href=\"https://github.com/imfly/bitcoin-on-nodejs/blob/master/\">https://github.com/imfly/bitcoin-on-nodejs/blob/master/</a></li>\n</ol>\n"},{"title":"btc_data_dat","date":"2019-04-14T07:16:51.000Z","_content":"\n\n\n## btc dat数据重组\n\nBitcoin core同步的数据是dat文件和index文件夹，index文件夹里是ldb \n\ndat是向各个节点同步的数据，各个区块之间不保证有序。ldb里保存了如何去dat文件里查询区块/交易等的信息。 \n\n\n\n具体维基解释 https://en.bitcoin.it/wiki/Bitcoin_Core_0.11_(ch_2):_Data_Storage \n\n\n\n其中ldb中区块信息为 \n\n ```\n  'b' + 32-byte block hash -> block index record. Each record stores: \n\n       * The block header \n\n       * The height. \n\n       * The number of transactions. \n\n       * To what extent this block is validated. \n\n       * In which file, and where in that file, the block data is stored. \n\n       * In which file, and where in that file, the undo data is stored. \n\n ```\n\n实现，重组为有序的dat文件 \n\n```\n/*\n@Time : 2019/4/4 下午6:57\n@Author : xiaoxuez\n*/\n\npackage main\n\nimport (\n   \"encoding/binary\"\n   \"encoding/hex\"\n   \"errors\"\n   \"flag\"\n   \"fmt\"\n   \"io\"\n   \"os\"\n   \"path\"\n   \"sync\"\n\n   \"git.wokoworks.com/blockchain/btc-explorer/db\"\n   \"git.wokoworks.com/blockchain/btc-explorer/log\"\n)\n\ntype readBlockChain struct {\n   height    uint64\n   blockHash [32]byte\n}\n\nvar indexLDB *db.LDBDatabase\nvar blSourceDir string\nvar blDirtyDir string\n\nfunc main() {\n   log.InitHandler(log.Root(), log.LvlTrace, \"logs/reorder.log\")\n   var err error\n   flag.StringVar(&blSourceDir, \"old\", \"/Users/xiaoxuez/btc_test_db/mainnet/\", \"xx\")\n   flag.StringVar(&blDirtyDir, \"new\", \"/Users/xiaoxuez/btc_test_db/reorder\", \"xx\")\n   flag.Parse()\n   //bmdb, err = db.NewLDBDatabase(\"/Users/xiaoxuez/btc_test_db/mainnet/index\", 0, 0)\n   indexLDB, err = db.NewLDBDatabase(path.Join(blSourceDir, \"index\"), 0, 0)\n   if err != nil {\n      panic(err)\n   }\n   //len must < 24\n   var data = []readBlockChain{\n      {\n         height:    0,\n         blockHash: hexToHash(\"00000000000003a20def7a05a77361b9657ff954b2f2080e135ea6f5970da215\"), // 20万-1\n      },\n      {\n         height:    20 * 10000,\n         blockHash: hexToHash(\"0000000000000009c2e82d884ec07b4aafb64ca3ef83baca2b6b0b5eb72c8f02\"), // 25万-1\n      },\n      //{\n      // height:    25 * 10000,\n      // blockHash: hexToHash(\"000000000000000067ecc744b5ae34eebbde14d21ca4db51652e4d67e155f07e\"), // 30-1\n      //},\n      //{\n      // height:    30 * 10000,\n      // blockHash: hexToHash(\"000000000000000002045664f89a1077d0c6c0aaa6dd89b485208cf92d6bbd30\"), // 35-1\n      //},\n      //{\n      // height:    35 * 10000,\n      // blockHash: hexToHash(\"0000000000000000030034b661aed920a9bdf6bbfa6d2e7a021f78481882fa39\"), // 40-1\n      //},\n      //{\n      // height:    40 * 10000,\n      // blockHash: hexToHash(\"0000000000000000024c4a35f0485bab79ce341cdd5cc6b15186d9b5b57bf3da\"), // 45-1\n      //},\n      //{\n      // height:    45 * 10000,\n      // blockHash: hexToHash(\"0000000000000000007962066dcd6675830883516bcf40047d42740a85eb2919\"), // 50\n      //},\n      //{\n      // height:    50 * 10000,\n      // blockHash: hexToHash(\"00000000000000000013dad60a42a3401a8f37ca02f1c00ac5923e674566a3ae\"), // 55\n      //},\n   }\n   if len(data) > 24 {\n      log.Error(\"parallel number must < 24\", \"actual \", len(data))\n      return\n   }\n   var wg sync.WaitGroup\n   for index, v := range data {\n      wg.Add(1)\n      go func(index int, v readBlockChain) {\n         rwBlocks(v.blockHash[:], v.height, fmt.Sprint(index), func() { wg.Done() })\n      }(index, v)\n   }\n   wg.Wait()\n}\n\nfunc rwBlocks(startBlock []byte, endHeight uint64, prefix string, callback func()) {\n   defer callback()\n   fileCache := make(map[uint64]*os.File, 0)\n   blockHash := startBlock\n   reverWriter := NewReverseWriter(blDirtyDir, 138*1024*1024, prefix)\n   defer reverWriter.Flush()\n   count := 0\n   for {\n      content, height, err := rwBlock(fileCache, blockHash)\n      if err != nil {\n         log.Error(\"rw block\", \"err\", err.Error())\n         return\n      }\n      blockHash = content[12:44]\n      err = reverWriter.Insert(content)\n      if err != nil {\n         fmt.Println(\"writer err\", err)\n         return\n      }\n      if height == endHeight {\n         log.Info(\"finish to save block height\", \"height\", height)\n         return\n      }\n      if height%3000 == 0 {\n         log.Trace(\"====>\", \"height\", height, \"parent block hash\", hashToHex(blockHash))\n      }\n      count++\n   }\n   log.Info(\"write file end\", \"count\", count)\n}\n\nfunc rwBlock(fileCache map[uint64]*os.File, block []byte) ([]byte, uint64, error) {\n   value, err := indexLDB.Get(append([]byte(\"b\"), block...))\n   if err != nil {\n      return []byte{}, 0, errors.New(fmt.Sprintf(\"%s%s\", err.Error(), hashToHex(block)))\n   }\n   bm := parseBlockMeta(value)\n   file, ok := fileCache[bm.file]\n   if !ok {\n      file, err = os.Open(idx2fname(blSourceDir, uint32(bm.file)))\n      if err != nil {\n         return []byte{}, 0, err\n      }\n      fileCache[bm.file] = file\n   }\n   file.Seek(int64(bm.dataPos-8), io.SeekStart)\n   res, err := readBlockFromFile(file)\n\n   if err != nil {\n      return []byte{}, 0, err\n   }\n   binary.LittleEndian.PutUint32(res[:4], uint32(bm.height))\n   return res, bm.height, err\n}\n\nfunc readBlockFromFile(f *os.File) (res []byte, e error) {\n   var buf [4]byte\n   _, e = f.Read(buf[:])\n   _, e = f.Read(buf[:])\n   if e != nil {\n      return\n   }\n   le := uint32(lsb2uint(buf[:]))\n   if le < 81 {\n      e = errors.New(fmt.Sprintf(\"Incorrect block size %d\", le))\n      return\n   }\n\n   res = make([]byte, le+8)\n   copy(res[4:8], buf[:])\n   _, e = f.Read(res[8:])\n   if e != nil {\n      return\n   }\n   return\n}\nfunc idx2fname(dir string, fidx uint32) (s string) {\n   if fidx == 0xffffffff {\n      return \"blk99999.dat\"\n   }\n   return fmt.Sprintf(\"%s/blk%05d.dat\", dir, fidx)\n}\nfunc lsb2uint(lt []byte) (res uint64) {\n   for i := 0; i < len(lt); i++ {\n      res |= uint64(lt[i]) << uint(i*8)\n   }\n   return\n}\n\ntype blockMeta struct {\n   version uint64\n   height  uint64\n   status  uint64\n   nTx     uint64\n   file    uint64\n   dataPos uint64\n   undoPos uint64\n}\n\nfunc parseBlockMeta(raw []byte) (bm blockMeta) {\n   var pos uint64\n   var i uint64\n   bm.version, i = readRawData(raw[pos:])\n   pos += i\n   bm.height, i = readRawData(raw[pos:])\n   pos += i\n   bm.status, i = readRawData(raw[pos:])\n   pos += i\n   bm.nTx, i = readRawData(raw[pos:])\n   pos += i\n   bm.file, i = readRawData(raw[pos:])\n   pos += i\n   bm.dataPos, i = readRawData(raw[pos:])\n   pos += i\n   bm.undoPos, i = readRawData(raw[pos:])\n   return\n}\n\nfunc readRawData(raw []byte) (uint64, uint64) {\n   var n uint64\n   var pos uint64\n   for {\n      data := raw[pos]\n      pos += 1\n      n = (n << 7) | (uint64(data) & 0x7f)\n      if data&0x80 == 0 {\n         return n, pos\n      }\n      n += 1\n   }\n}\n\nfunc hashToHex(hash []byte) (s string) {\n   for i := 0; i < 32; i++ {\n      s += fmt.Sprintf(\"%02x\", hash[31-i])\n   }\n   return\n}\n\nfunc hexToHash(s string) (res [32]byte) {\n   d, e := hex.DecodeString(s)\n   if e != nil {\n      return\n   }\n   if len(d) != 32 {\n      return\n   }\n   for i := 0; i < 32; i++ {\n      res[31-i] = d[i]\n   }\n   return\n}\n\ntype ReverseWriter struct {\n   Dir          string\n   CacheMaxSize int\n   len          int\n   cache        []byte\n   seek         int\n   index        int\n   Prefix       string\n}\n\nfunc NewReverseWriter(dir string, cacheSize int, prefix string) *ReverseWriter {\n   rw := &ReverseWriter{Dir: dir, CacheMaxSize: cacheSize, Prefix: prefix}\n   rw.init()\n   return rw\n}\n\nfunc (rw *ReverseWriter) init() {\n   rw.len = 0\n   rw.cache = make([]byte, rw.CacheMaxSize)\n   rw.seek = rw.CacheMaxSize\n}\n\nfunc (rw *ReverseWriter) Insert(content []byte) error {\n   if rw.len+len(content) > rw.CacheMaxSize {\n      err := rw.writeToFile()\n      if err != nil {\n         return err\n      }\n      rw.index++\n      rw.init()\n   }\n   copy(rw.cache[rw.seek-len(content):rw.seek], content)\n   rw.seek = rw.seek - len(content)\n   rw.len += len(content)\n   return nil\n}\n\nfunc (rw *ReverseWriter) writeToFile() error {\n   if rw.len == 0 {\n      return nil\n   }\n   writer, err := os.OpenFile(fmt.Sprintf(\"%s/%sblk%05d.dat\", rw.Dir, rw.Prefix, rw.index), os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0666)\n   if err != nil {\n      return err\n   }\n   _, err = writer.Write(rw.cache[rw.seek:])\n   return err\n}\n\nfunc (rw *ReverseWriter) Flush() error {\n   err := rw.writeToFile()\n   rw.index++\n   rw.init()\n   return err\n}\n\n\n重组完成之后，进行更名操作\n#!/usr/bin/env bash\n\n# shell is funny\n\nread -p \"Are you sure:(y/n) \" an\nif [[ ${an} != \"y\" ]]; then exit; fi\n\ncd /Users/woko/bitcoin\n\nfunction rename_2() {\n    index=0\n    for name in $(ls | grep .dat) ; do\n        if [[ -f ${name} ]]; then\n            rename=$(echo ${index}|awk '{printf(\"blk%05d.dat\",$0)}')\n            echo ${name} \" ==> \" ${rename}\n            mv ${name} ${rename}\n            ((index=index+1))\n        fi\n    done\n}\n\nfunction rename_1() {\n    count=0\n    for (( i = 0; i < 10; ++i )); do\n        index=$(ls ${count}*.dat | wc -l)\n        for name in $(ls ${count}*.dat) ; do\n            if [[ -f ${name} ]]; then\n                ((index=index-1))\n                rename=$(echo \"${count} ${index}\"|awk '{printf(\"%02dblk%05d.dat\",$1,$2)}')\n                echo ${name} \" ==> \" ${rename}\n                mv ${name} ${rename}\n            fi\n        done\n        ((count=count+1))\n        echo \"--------------\"\n    done\n}\n\nrename_1\necho \"==============\"\nrename_2\n\n```\n\n","source":"_posts/btc-data-dat.md","raw":"---\ntitle: btc_data_dat\ncategories:\n  - btc\ndate: 2019-4-14 15:16:51\ntags:\n---\n\n\n\n## btc dat数据重组\n\nBitcoin core同步的数据是dat文件和index文件夹，index文件夹里是ldb \n\ndat是向各个节点同步的数据，各个区块之间不保证有序。ldb里保存了如何去dat文件里查询区块/交易等的信息。 \n\n\n\n具体维基解释 https://en.bitcoin.it/wiki/Bitcoin_Core_0.11_(ch_2):_Data_Storage \n\n\n\n其中ldb中区块信息为 \n\n ```\n  'b' + 32-byte block hash -> block index record. Each record stores: \n\n       * The block header \n\n       * The height. \n\n       * The number of transactions. \n\n       * To what extent this block is validated. \n\n       * In which file, and where in that file, the block data is stored. \n\n       * In which file, and where in that file, the undo data is stored. \n\n ```\n\n实现，重组为有序的dat文件 \n\n```\n/*\n@Time : 2019/4/4 下午6:57\n@Author : xiaoxuez\n*/\n\npackage main\n\nimport (\n   \"encoding/binary\"\n   \"encoding/hex\"\n   \"errors\"\n   \"flag\"\n   \"fmt\"\n   \"io\"\n   \"os\"\n   \"path\"\n   \"sync\"\n\n   \"git.wokoworks.com/blockchain/btc-explorer/db\"\n   \"git.wokoworks.com/blockchain/btc-explorer/log\"\n)\n\ntype readBlockChain struct {\n   height    uint64\n   blockHash [32]byte\n}\n\nvar indexLDB *db.LDBDatabase\nvar blSourceDir string\nvar blDirtyDir string\n\nfunc main() {\n   log.InitHandler(log.Root(), log.LvlTrace, \"logs/reorder.log\")\n   var err error\n   flag.StringVar(&blSourceDir, \"old\", \"/Users/xiaoxuez/btc_test_db/mainnet/\", \"xx\")\n   flag.StringVar(&blDirtyDir, \"new\", \"/Users/xiaoxuez/btc_test_db/reorder\", \"xx\")\n   flag.Parse()\n   //bmdb, err = db.NewLDBDatabase(\"/Users/xiaoxuez/btc_test_db/mainnet/index\", 0, 0)\n   indexLDB, err = db.NewLDBDatabase(path.Join(blSourceDir, \"index\"), 0, 0)\n   if err != nil {\n      panic(err)\n   }\n   //len must < 24\n   var data = []readBlockChain{\n      {\n         height:    0,\n         blockHash: hexToHash(\"00000000000003a20def7a05a77361b9657ff954b2f2080e135ea6f5970da215\"), // 20万-1\n      },\n      {\n         height:    20 * 10000,\n         blockHash: hexToHash(\"0000000000000009c2e82d884ec07b4aafb64ca3ef83baca2b6b0b5eb72c8f02\"), // 25万-1\n      },\n      //{\n      // height:    25 * 10000,\n      // blockHash: hexToHash(\"000000000000000067ecc744b5ae34eebbde14d21ca4db51652e4d67e155f07e\"), // 30-1\n      //},\n      //{\n      // height:    30 * 10000,\n      // blockHash: hexToHash(\"000000000000000002045664f89a1077d0c6c0aaa6dd89b485208cf92d6bbd30\"), // 35-1\n      //},\n      //{\n      // height:    35 * 10000,\n      // blockHash: hexToHash(\"0000000000000000030034b661aed920a9bdf6bbfa6d2e7a021f78481882fa39\"), // 40-1\n      //},\n      //{\n      // height:    40 * 10000,\n      // blockHash: hexToHash(\"0000000000000000024c4a35f0485bab79ce341cdd5cc6b15186d9b5b57bf3da\"), // 45-1\n      //},\n      //{\n      // height:    45 * 10000,\n      // blockHash: hexToHash(\"0000000000000000007962066dcd6675830883516bcf40047d42740a85eb2919\"), // 50\n      //},\n      //{\n      // height:    50 * 10000,\n      // blockHash: hexToHash(\"00000000000000000013dad60a42a3401a8f37ca02f1c00ac5923e674566a3ae\"), // 55\n      //},\n   }\n   if len(data) > 24 {\n      log.Error(\"parallel number must < 24\", \"actual \", len(data))\n      return\n   }\n   var wg sync.WaitGroup\n   for index, v := range data {\n      wg.Add(1)\n      go func(index int, v readBlockChain) {\n         rwBlocks(v.blockHash[:], v.height, fmt.Sprint(index), func() { wg.Done() })\n      }(index, v)\n   }\n   wg.Wait()\n}\n\nfunc rwBlocks(startBlock []byte, endHeight uint64, prefix string, callback func()) {\n   defer callback()\n   fileCache := make(map[uint64]*os.File, 0)\n   blockHash := startBlock\n   reverWriter := NewReverseWriter(blDirtyDir, 138*1024*1024, prefix)\n   defer reverWriter.Flush()\n   count := 0\n   for {\n      content, height, err := rwBlock(fileCache, blockHash)\n      if err != nil {\n         log.Error(\"rw block\", \"err\", err.Error())\n         return\n      }\n      blockHash = content[12:44]\n      err = reverWriter.Insert(content)\n      if err != nil {\n         fmt.Println(\"writer err\", err)\n         return\n      }\n      if height == endHeight {\n         log.Info(\"finish to save block height\", \"height\", height)\n         return\n      }\n      if height%3000 == 0 {\n         log.Trace(\"====>\", \"height\", height, \"parent block hash\", hashToHex(blockHash))\n      }\n      count++\n   }\n   log.Info(\"write file end\", \"count\", count)\n}\n\nfunc rwBlock(fileCache map[uint64]*os.File, block []byte) ([]byte, uint64, error) {\n   value, err := indexLDB.Get(append([]byte(\"b\"), block...))\n   if err != nil {\n      return []byte{}, 0, errors.New(fmt.Sprintf(\"%s%s\", err.Error(), hashToHex(block)))\n   }\n   bm := parseBlockMeta(value)\n   file, ok := fileCache[bm.file]\n   if !ok {\n      file, err = os.Open(idx2fname(blSourceDir, uint32(bm.file)))\n      if err != nil {\n         return []byte{}, 0, err\n      }\n      fileCache[bm.file] = file\n   }\n   file.Seek(int64(bm.dataPos-8), io.SeekStart)\n   res, err := readBlockFromFile(file)\n\n   if err != nil {\n      return []byte{}, 0, err\n   }\n   binary.LittleEndian.PutUint32(res[:4], uint32(bm.height))\n   return res, bm.height, err\n}\n\nfunc readBlockFromFile(f *os.File) (res []byte, e error) {\n   var buf [4]byte\n   _, e = f.Read(buf[:])\n   _, e = f.Read(buf[:])\n   if e != nil {\n      return\n   }\n   le := uint32(lsb2uint(buf[:]))\n   if le < 81 {\n      e = errors.New(fmt.Sprintf(\"Incorrect block size %d\", le))\n      return\n   }\n\n   res = make([]byte, le+8)\n   copy(res[4:8], buf[:])\n   _, e = f.Read(res[8:])\n   if e != nil {\n      return\n   }\n   return\n}\nfunc idx2fname(dir string, fidx uint32) (s string) {\n   if fidx == 0xffffffff {\n      return \"blk99999.dat\"\n   }\n   return fmt.Sprintf(\"%s/blk%05d.dat\", dir, fidx)\n}\nfunc lsb2uint(lt []byte) (res uint64) {\n   for i := 0; i < len(lt); i++ {\n      res |= uint64(lt[i]) << uint(i*8)\n   }\n   return\n}\n\ntype blockMeta struct {\n   version uint64\n   height  uint64\n   status  uint64\n   nTx     uint64\n   file    uint64\n   dataPos uint64\n   undoPos uint64\n}\n\nfunc parseBlockMeta(raw []byte) (bm blockMeta) {\n   var pos uint64\n   var i uint64\n   bm.version, i = readRawData(raw[pos:])\n   pos += i\n   bm.height, i = readRawData(raw[pos:])\n   pos += i\n   bm.status, i = readRawData(raw[pos:])\n   pos += i\n   bm.nTx, i = readRawData(raw[pos:])\n   pos += i\n   bm.file, i = readRawData(raw[pos:])\n   pos += i\n   bm.dataPos, i = readRawData(raw[pos:])\n   pos += i\n   bm.undoPos, i = readRawData(raw[pos:])\n   return\n}\n\nfunc readRawData(raw []byte) (uint64, uint64) {\n   var n uint64\n   var pos uint64\n   for {\n      data := raw[pos]\n      pos += 1\n      n = (n << 7) | (uint64(data) & 0x7f)\n      if data&0x80 == 0 {\n         return n, pos\n      }\n      n += 1\n   }\n}\n\nfunc hashToHex(hash []byte) (s string) {\n   for i := 0; i < 32; i++ {\n      s += fmt.Sprintf(\"%02x\", hash[31-i])\n   }\n   return\n}\n\nfunc hexToHash(s string) (res [32]byte) {\n   d, e := hex.DecodeString(s)\n   if e != nil {\n      return\n   }\n   if len(d) != 32 {\n      return\n   }\n   for i := 0; i < 32; i++ {\n      res[31-i] = d[i]\n   }\n   return\n}\n\ntype ReverseWriter struct {\n   Dir          string\n   CacheMaxSize int\n   len          int\n   cache        []byte\n   seek         int\n   index        int\n   Prefix       string\n}\n\nfunc NewReverseWriter(dir string, cacheSize int, prefix string) *ReverseWriter {\n   rw := &ReverseWriter{Dir: dir, CacheMaxSize: cacheSize, Prefix: prefix}\n   rw.init()\n   return rw\n}\n\nfunc (rw *ReverseWriter) init() {\n   rw.len = 0\n   rw.cache = make([]byte, rw.CacheMaxSize)\n   rw.seek = rw.CacheMaxSize\n}\n\nfunc (rw *ReverseWriter) Insert(content []byte) error {\n   if rw.len+len(content) > rw.CacheMaxSize {\n      err := rw.writeToFile()\n      if err != nil {\n         return err\n      }\n      rw.index++\n      rw.init()\n   }\n   copy(rw.cache[rw.seek-len(content):rw.seek], content)\n   rw.seek = rw.seek - len(content)\n   rw.len += len(content)\n   return nil\n}\n\nfunc (rw *ReverseWriter) writeToFile() error {\n   if rw.len == 0 {\n      return nil\n   }\n   writer, err := os.OpenFile(fmt.Sprintf(\"%s/%sblk%05d.dat\", rw.Dir, rw.Prefix, rw.index), os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0666)\n   if err != nil {\n      return err\n   }\n   _, err = writer.Write(rw.cache[rw.seek:])\n   return err\n}\n\nfunc (rw *ReverseWriter) Flush() error {\n   err := rw.writeToFile()\n   rw.index++\n   rw.init()\n   return err\n}\n\n\n重组完成之后，进行更名操作\n#!/usr/bin/env bash\n\n# shell is funny\n\nread -p \"Are you sure:(y/n) \" an\nif [[ ${an} != \"y\" ]]; then exit; fi\n\ncd /Users/woko/bitcoin\n\nfunction rename_2() {\n    index=0\n    for name in $(ls | grep .dat) ; do\n        if [[ -f ${name} ]]; then\n            rename=$(echo ${index}|awk '{printf(\"blk%05d.dat\",$0)}')\n            echo ${name} \" ==> \" ${rename}\n            mv ${name} ${rename}\n            ((index=index+1))\n        fi\n    done\n}\n\nfunction rename_1() {\n    count=0\n    for (( i = 0; i < 10; ++i )); do\n        index=$(ls ${count}*.dat | wc -l)\n        for name in $(ls ${count}*.dat) ; do\n            if [[ -f ${name} ]]; then\n                ((index=index-1))\n                rename=$(echo \"${count} ${index}\"|awk '{printf(\"%02dblk%05d.dat\",$1,$2)}')\n                echo ${name} \" ==> \" ${rename}\n                mv ${name} ${rename}\n            fi\n        done\n        ((count=count+1))\n        echo \"--------------\"\n    done\n}\n\nrename_1\necho \"==============\"\nrename_2\n\n```\n\n","slug":"btc-data-dat","published":1,"updated":"2019-10-14T07:25:23.831Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69ws0020t6xvh0q0kffa","content":"<h2 id=\"btc-dat数据重组\"><a href=\"#btc-dat数据重组\" class=\"headerlink\" title=\"btc dat数据重组\"></a>btc dat数据重组</h2><p>Bitcoin core同步的数据是dat文件和index文件夹，index文件夹里是ldb </p>\n<p>dat是向各个节点同步的数据，各个区块之间不保证有序。ldb里保存了如何去dat文件里查询区块/交易等的信息。 </p>\n<p>具体维基解释 <a href=\"https://en.bitcoin.it/wiki/Bitcoin_Core_0.11_(ch_2):_Data_Storage\" target=\"_blank\" rel=\"noopener\">https://en.bitcoin.it/wiki/Bitcoin_Core_0.11_(ch_2):_Data_Storage</a> </p>\n<p>其中ldb中区块信息为 </p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&apos;b&apos; + 32-byte block hash -&gt; block index record. Each record stores: </span><br><span class=\"line\"></span><br><span class=\"line\">     * The block header </span><br><span class=\"line\"></span><br><span class=\"line\">     * The height. </span><br><span class=\"line\"></span><br><span class=\"line\">     * The number of transactions. </span><br><span class=\"line\"></span><br><span class=\"line\">     * To what extent this block is validated. </span><br><span class=\"line\"></span><br><span class=\"line\">     * In which file, and where in that file, the block data is stored. </span><br><span class=\"line\"></span><br><span class=\"line\">     * In which file, and where in that file, the undo data is stored.</span><br></pre></td></tr></table></figure>\n\n<p>实现，重组为有序的dat文件 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/*</span><br><span class=\"line\">@Time : 2019/4/4 下午6:57</span><br><span class=\"line\">@Author : xiaoxuez</span><br><span class=\"line\">*/</span><br><span class=\"line\"></span><br><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">   &quot;encoding/binary&quot;</span><br><span class=\"line\">   &quot;encoding/hex&quot;</span><br><span class=\"line\">   &quot;errors&quot;</span><br><span class=\"line\">   &quot;flag&quot;</span><br><span class=\"line\">   &quot;fmt&quot;</span><br><span class=\"line\">   &quot;io&quot;</span><br><span class=\"line\">   &quot;os&quot;</span><br><span class=\"line\">   &quot;path&quot;</span><br><span class=\"line\">   &quot;sync&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">   &quot;git.wokoworks.com/blockchain/btc-explorer/db&quot;</span><br><span class=\"line\">   &quot;git.wokoworks.com/blockchain/btc-explorer/log&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type readBlockChain struct &#123;</span><br><span class=\"line\">   height    uint64</span><br><span class=\"line\">   blockHash [32]byte</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">var indexLDB *db.LDBDatabase</span><br><span class=\"line\">var blSourceDir string</span><br><span class=\"line\">var blDirtyDir string</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">   log.InitHandler(log.Root(), log.LvlTrace, &quot;logs/reorder.log&quot;)</span><br><span class=\"line\">   var err error</span><br><span class=\"line\">   flag.StringVar(&amp;blSourceDir, &quot;old&quot;, &quot;/Users/xiaoxuez/btc_test_db/mainnet/&quot;, &quot;xx&quot;)</span><br><span class=\"line\">   flag.StringVar(&amp;blDirtyDir, &quot;new&quot;, &quot;/Users/xiaoxuez/btc_test_db/reorder&quot;, &quot;xx&quot;)</span><br><span class=\"line\">   flag.Parse()</span><br><span class=\"line\">   //bmdb, err = db.NewLDBDatabase(&quot;/Users/xiaoxuez/btc_test_db/mainnet/index&quot;, 0, 0)</span><br><span class=\"line\">   indexLDB, err = db.NewLDBDatabase(path.Join(blSourceDir, &quot;index&quot;), 0, 0)</span><br><span class=\"line\">   if err != nil &#123;</span><br><span class=\"line\">      panic(err)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   //len must &lt; 24</span><br><span class=\"line\">   var data = []readBlockChain&#123;</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">         height:    0,</span><br><span class=\"line\">         blockHash: hexToHash(&quot;00000000000003a20def7a05a77361b9657ff954b2f2080e135ea6f5970da215&quot;), // 20万-1</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">         height:    20 * 10000,</span><br><span class=\"line\">         blockHash: hexToHash(&quot;0000000000000009c2e82d884ec07b4aafb64ca3ef83baca2b6b0b5eb72c8f02&quot;), // 25万-1</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    25 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;000000000000000067ecc744b5ae34eebbde14d21ca4db51652e4d67e155f07e&quot;), // 30-1</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    30 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;000000000000000002045664f89a1077d0c6c0aaa6dd89b485208cf92d6bbd30&quot;), // 35-1</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    35 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;0000000000000000030034b661aed920a9bdf6bbfa6d2e7a021f78481882fa39&quot;), // 40-1</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    40 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;0000000000000000024c4a35f0485bab79ce341cdd5cc6b15186d9b5b57bf3da&quot;), // 45-1</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    45 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;0000000000000000007962066dcd6675830883516bcf40047d42740a85eb2919&quot;), // 50</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    50 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;00000000000000000013dad60a42a3401a8f37ca02f1c00ac5923e674566a3ae&quot;), // 55</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   if len(data) &gt; 24 &#123;</span><br><span class=\"line\">      log.Error(&quot;parallel number must &lt; 24&quot;, &quot;actual &quot;, len(data))</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   var wg sync.WaitGroup</span><br><span class=\"line\">   for index, v := range data &#123;</span><br><span class=\"line\">      wg.Add(1)</span><br><span class=\"line\">      go func(index int, v readBlockChain) &#123;</span><br><span class=\"line\">         rwBlocks(v.blockHash[:], v.height, fmt.Sprint(index), func() &#123; wg.Done() &#125;)</span><br><span class=\"line\">      &#125;(index, v)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   wg.Wait()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func rwBlocks(startBlock []byte, endHeight uint64, prefix string, callback func()) &#123;</span><br><span class=\"line\">   defer callback()</span><br><span class=\"line\">   fileCache := make(map[uint64]*os.File, 0)</span><br><span class=\"line\">   blockHash := startBlock</span><br><span class=\"line\">   reverWriter := NewReverseWriter(blDirtyDir, 138*1024*1024, prefix)</span><br><span class=\"line\">   defer reverWriter.Flush()</span><br><span class=\"line\">   count := 0</span><br><span class=\"line\">   for &#123;</span><br><span class=\"line\">      content, height, err := rwBlock(fileCache, blockHash)</span><br><span class=\"line\">      if err != nil &#123;</span><br><span class=\"line\">         log.Error(&quot;rw block&quot;, &quot;err&quot;, err.Error())</span><br><span class=\"line\">         return</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      blockHash = content[12:44]</span><br><span class=\"line\">      err = reverWriter.Insert(content)</span><br><span class=\"line\">      if err != nil &#123;</span><br><span class=\"line\">         fmt.Println(&quot;writer err&quot;, err)</span><br><span class=\"line\">         return</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      if height == endHeight &#123;</span><br><span class=\"line\">         log.Info(&quot;finish to save block height&quot;, &quot;height&quot;, height)</span><br><span class=\"line\">         return</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      if height%3000 == 0 &#123;</span><br><span class=\"line\">         log.Trace(&quot;====&gt;&quot;, &quot;height&quot;, height, &quot;parent block hash&quot;, hashToHex(blockHash))</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      count++</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   log.Info(&quot;write file end&quot;, &quot;count&quot;, count)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func rwBlock(fileCache map[uint64]*os.File, block []byte) ([]byte, uint64, error) &#123;</span><br><span class=\"line\">   value, err := indexLDB.Get(append([]byte(&quot;b&quot;), block...))</span><br><span class=\"line\">   if err != nil &#123;</span><br><span class=\"line\">      return []byte&#123;&#125;, 0, errors.New(fmt.Sprintf(&quot;%s%s&quot;, err.Error(), hashToHex(block)))</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   bm := parseBlockMeta(value)</span><br><span class=\"line\">   file, ok := fileCache[bm.file]</span><br><span class=\"line\">   if !ok &#123;</span><br><span class=\"line\">      file, err = os.Open(idx2fname(blSourceDir, uint32(bm.file)))</span><br><span class=\"line\">      if err != nil &#123;</span><br><span class=\"line\">         return []byte&#123;&#125;, 0, err</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      fileCache[bm.file] = file</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   file.Seek(int64(bm.dataPos-8), io.SeekStart)</span><br><span class=\"line\">   res, err := readBlockFromFile(file)</span><br><span class=\"line\"></span><br><span class=\"line\">   if err != nil &#123;</span><br><span class=\"line\">      return []byte&#123;&#125;, 0, err</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   binary.LittleEndian.PutUint32(res[:4], uint32(bm.height))</span><br><span class=\"line\">   return res, bm.height, err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func readBlockFromFile(f *os.File) (res []byte, e error) &#123;</span><br><span class=\"line\">   var buf [4]byte</span><br><span class=\"line\">   _, e = f.Read(buf[:])</span><br><span class=\"line\">   _, e = f.Read(buf[:])</span><br><span class=\"line\">   if e != nil &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   le := uint32(lsb2uint(buf[:]))</span><br><span class=\"line\">   if le &lt; 81 &#123;</span><br><span class=\"line\">      e = errors.New(fmt.Sprintf(&quot;Incorrect block size %d&quot;, le))</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   res = make([]byte, le+8)</span><br><span class=\"line\">   copy(res[4:8], buf[:])</span><br><span class=\"line\">   _, e = f.Read(res[8:])</span><br><span class=\"line\">   if e != nil &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func idx2fname(dir string, fidx uint32) (s string) &#123;</span><br><span class=\"line\">   if fidx == 0xffffffff &#123;</span><br><span class=\"line\">      return &quot;blk99999.dat&quot;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return fmt.Sprintf(&quot;%s/blk%05d.dat&quot;, dir, fidx)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func lsb2uint(lt []byte) (res uint64) &#123;</span><br><span class=\"line\">   for i := 0; i &lt; len(lt); i++ &#123;</span><br><span class=\"line\">      res |= uint64(lt[i]) &lt;&lt; uint(i*8)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type blockMeta struct &#123;</span><br><span class=\"line\">   version uint64</span><br><span class=\"line\">   height  uint64</span><br><span class=\"line\">   status  uint64</span><br><span class=\"line\">   nTx     uint64</span><br><span class=\"line\">   file    uint64</span><br><span class=\"line\">   dataPos uint64</span><br><span class=\"line\">   undoPos uint64</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func parseBlockMeta(raw []byte) (bm blockMeta) &#123;</span><br><span class=\"line\">   var pos uint64</span><br><span class=\"line\">   var i uint64</span><br><span class=\"line\">   bm.version, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.height, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.status, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.nTx, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.file, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.dataPos, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.undoPos, i = readRawData(raw[pos:])</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func readRawData(raw []byte) (uint64, uint64) &#123;</span><br><span class=\"line\">   var n uint64</span><br><span class=\"line\">   var pos uint64</span><br><span class=\"line\">   for &#123;</span><br><span class=\"line\">      data := raw[pos]</span><br><span class=\"line\">      pos += 1</span><br><span class=\"line\">      n = (n &lt;&lt; 7) | (uint64(data) &amp; 0x7f)</span><br><span class=\"line\">      if data&amp;0x80 == 0 &#123;</span><br><span class=\"line\">         return n, pos</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      n += 1</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func hashToHex(hash []byte) (s string) &#123;</span><br><span class=\"line\">   for i := 0; i &lt; 32; i++ &#123;</span><br><span class=\"line\">      s += fmt.Sprintf(&quot;%02x&quot;, hash[31-i])</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func hexToHash(s string) (res [32]byte) &#123;</span><br><span class=\"line\">   d, e := hex.DecodeString(s)</span><br><span class=\"line\">   if e != nil &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   if len(d) != 32 &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   for i := 0; i &lt; 32; i++ &#123;</span><br><span class=\"line\">      res[31-i] = d[i]</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type ReverseWriter struct &#123;</span><br><span class=\"line\">   Dir          string</span><br><span class=\"line\">   CacheMaxSize int</span><br><span class=\"line\">   len          int</span><br><span class=\"line\">   cache        []byte</span><br><span class=\"line\">   seek         int</span><br><span class=\"line\">   index        int</span><br><span class=\"line\">   Prefix       string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func NewReverseWriter(dir string, cacheSize int, prefix string) *ReverseWriter &#123;</span><br><span class=\"line\">   rw := &amp;ReverseWriter&#123;Dir: dir, CacheMaxSize: cacheSize, Prefix: prefix&#125;</span><br><span class=\"line\">   rw.init()</span><br><span class=\"line\">   return rw</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (rw *ReverseWriter) init() &#123;</span><br><span class=\"line\">   rw.len = 0</span><br><span class=\"line\">   rw.cache = make([]byte, rw.CacheMaxSize)</span><br><span class=\"line\">   rw.seek = rw.CacheMaxSize</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (rw *ReverseWriter) Insert(content []byte) error &#123;</span><br><span class=\"line\">   if rw.len+len(content) &gt; rw.CacheMaxSize &#123;</span><br><span class=\"line\">      err := rw.writeToFile()</span><br><span class=\"line\">      if err != nil &#123;</span><br><span class=\"line\">         return err</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      rw.index++</span><br><span class=\"line\">      rw.init()</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   copy(rw.cache[rw.seek-len(content):rw.seek], content)</span><br><span class=\"line\">   rw.seek = rw.seek - len(content)</span><br><span class=\"line\">   rw.len += len(content)</span><br><span class=\"line\">   return nil</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (rw *ReverseWriter) writeToFile() error &#123;</span><br><span class=\"line\">   if rw.len == 0 &#123;</span><br><span class=\"line\">      return nil</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   writer, err := os.OpenFile(fmt.Sprintf(&quot;%s/%sblk%05d.dat&quot;, rw.Dir, rw.Prefix, rw.index), os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0666)</span><br><span class=\"line\">   if err != nil &#123;</span><br><span class=\"line\">      return err</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   _, err = writer.Write(rw.cache[rw.seek:])</span><br><span class=\"line\">   return err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (rw *ReverseWriter) Flush() error &#123;</span><br><span class=\"line\">   err := rw.writeToFile()</span><br><span class=\"line\">   rw.index++</span><br><span class=\"line\">   rw.init()</span><br><span class=\"line\">   return err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">重组完成之后，进行更名操作</span><br><span class=\"line\">#!/usr/bin/env bash</span><br><span class=\"line\"></span><br><span class=\"line\"># shell is funny</span><br><span class=\"line\"></span><br><span class=\"line\">read -p &quot;Are you sure:(y/n) &quot; an</span><br><span class=\"line\">if [[ $&#123;an&#125; != &quot;y&quot; ]]; then exit; fi</span><br><span class=\"line\"></span><br><span class=\"line\">cd /Users/woko/bitcoin</span><br><span class=\"line\"></span><br><span class=\"line\">function rename_2() &#123;</span><br><span class=\"line\">    index=0</span><br><span class=\"line\">    for name in $(ls | grep .dat) ; do</span><br><span class=\"line\">        if [[ -f $&#123;name&#125; ]]; then</span><br><span class=\"line\">            rename=$(echo $&#123;index&#125;|awk &apos;&#123;printf(&quot;blk%05d.dat&quot;,$0)&#125;&apos;)</span><br><span class=\"line\">            echo $&#123;name&#125; &quot; ==&gt; &quot; $&#123;rename&#125;</span><br><span class=\"line\">            mv $&#123;name&#125; $&#123;rename&#125;</span><br><span class=\"line\">            ((index=index+1))</span><br><span class=\"line\">        fi</span><br><span class=\"line\">    done</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">function rename_1() &#123;</span><br><span class=\"line\">    count=0</span><br><span class=\"line\">    for (( i = 0; i &lt; 10; ++i )); do</span><br><span class=\"line\">        index=$(ls $&#123;count&#125;*.dat | wc -l)</span><br><span class=\"line\">        for name in $(ls $&#123;count&#125;*.dat) ; do</span><br><span class=\"line\">            if [[ -f $&#123;name&#125; ]]; then</span><br><span class=\"line\">                ((index=index-1))</span><br><span class=\"line\">                rename=$(echo &quot;$&#123;count&#125; $&#123;index&#125;&quot;|awk &apos;&#123;printf(&quot;%02dblk%05d.dat&quot;,$1,$2)&#125;&apos;)</span><br><span class=\"line\">                echo $&#123;name&#125; &quot; ==&gt; &quot; $&#123;rename&#125;</span><br><span class=\"line\">                mv $&#123;name&#125; $&#123;rename&#125;</span><br><span class=\"line\">            fi</span><br><span class=\"line\">        done</span><br><span class=\"line\">        ((count=count+1))</span><br><span class=\"line\">        echo &quot;--------------&quot;</span><br><span class=\"line\">    done</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">rename_1</span><br><span class=\"line\">echo &quot;==============&quot;</span><br><span class=\"line\">rename_2</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"btc-dat数据重组\"><a href=\"#btc-dat数据重组\" class=\"headerlink\" title=\"btc dat数据重组\"></a>btc dat数据重组</h2><p>Bitcoin core同步的数据是dat文件和index文件夹，index文件夹里是ldb </p>\n<p>dat是向各个节点同步的数据，各个区块之间不保证有序。ldb里保存了如何去dat文件里查询区块/交易等的信息。 </p>\n<p>具体维基解释 <a href=\"https://en.bitcoin.it/wiki/Bitcoin_Core_0.11_(ch_2):_Data_Storage\" target=\"_blank\" rel=\"noopener\">https://en.bitcoin.it/wiki/Bitcoin_Core_0.11_(ch_2):_Data_Storage</a> </p>\n<p>其中ldb中区块信息为 </p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&apos;b&apos; + 32-byte block hash -&gt; block index record. Each record stores: </span><br><span class=\"line\"></span><br><span class=\"line\">     * The block header </span><br><span class=\"line\"></span><br><span class=\"line\">     * The height. </span><br><span class=\"line\"></span><br><span class=\"line\">     * The number of transactions. </span><br><span class=\"line\"></span><br><span class=\"line\">     * To what extent this block is validated. </span><br><span class=\"line\"></span><br><span class=\"line\">     * In which file, and where in that file, the block data is stored. </span><br><span class=\"line\"></span><br><span class=\"line\">     * In which file, and where in that file, the undo data is stored.</span><br></pre></td></tr></table></figure>\n\n<p>实现，重组为有序的dat文件 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/*</span><br><span class=\"line\">@Time : 2019/4/4 下午6:57</span><br><span class=\"line\">@Author : xiaoxuez</span><br><span class=\"line\">*/</span><br><span class=\"line\"></span><br><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">   &quot;encoding/binary&quot;</span><br><span class=\"line\">   &quot;encoding/hex&quot;</span><br><span class=\"line\">   &quot;errors&quot;</span><br><span class=\"line\">   &quot;flag&quot;</span><br><span class=\"line\">   &quot;fmt&quot;</span><br><span class=\"line\">   &quot;io&quot;</span><br><span class=\"line\">   &quot;os&quot;</span><br><span class=\"line\">   &quot;path&quot;</span><br><span class=\"line\">   &quot;sync&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">   &quot;git.wokoworks.com/blockchain/btc-explorer/db&quot;</span><br><span class=\"line\">   &quot;git.wokoworks.com/blockchain/btc-explorer/log&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type readBlockChain struct &#123;</span><br><span class=\"line\">   height    uint64</span><br><span class=\"line\">   blockHash [32]byte</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">var indexLDB *db.LDBDatabase</span><br><span class=\"line\">var blSourceDir string</span><br><span class=\"line\">var blDirtyDir string</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">   log.InitHandler(log.Root(), log.LvlTrace, &quot;logs/reorder.log&quot;)</span><br><span class=\"line\">   var err error</span><br><span class=\"line\">   flag.StringVar(&amp;blSourceDir, &quot;old&quot;, &quot;/Users/xiaoxuez/btc_test_db/mainnet/&quot;, &quot;xx&quot;)</span><br><span class=\"line\">   flag.StringVar(&amp;blDirtyDir, &quot;new&quot;, &quot;/Users/xiaoxuez/btc_test_db/reorder&quot;, &quot;xx&quot;)</span><br><span class=\"line\">   flag.Parse()</span><br><span class=\"line\">   //bmdb, err = db.NewLDBDatabase(&quot;/Users/xiaoxuez/btc_test_db/mainnet/index&quot;, 0, 0)</span><br><span class=\"line\">   indexLDB, err = db.NewLDBDatabase(path.Join(blSourceDir, &quot;index&quot;), 0, 0)</span><br><span class=\"line\">   if err != nil &#123;</span><br><span class=\"line\">      panic(err)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   //len must &lt; 24</span><br><span class=\"line\">   var data = []readBlockChain&#123;</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">         height:    0,</span><br><span class=\"line\">         blockHash: hexToHash(&quot;00000000000003a20def7a05a77361b9657ff954b2f2080e135ea6f5970da215&quot;), // 20万-1</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">         height:    20 * 10000,</span><br><span class=\"line\">         blockHash: hexToHash(&quot;0000000000000009c2e82d884ec07b4aafb64ca3ef83baca2b6b0b5eb72c8f02&quot;), // 25万-1</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    25 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;000000000000000067ecc744b5ae34eebbde14d21ca4db51652e4d67e155f07e&quot;), // 30-1</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    30 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;000000000000000002045664f89a1077d0c6c0aaa6dd89b485208cf92d6bbd30&quot;), // 35-1</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    35 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;0000000000000000030034b661aed920a9bdf6bbfa6d2e7a021f78481882fa39&quot;), // 40-1</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    40 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;0000000000000000024c4a35f0485bab79ce341cdd5cc6b15186d9b5b57bf3da&quot;), // 45-1</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    45 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;0000000000000000007962066dcd6675830883516bcf40047d42740a85eb2919&quot;), // 50</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">      //&#123;</span><br><span class=\"line\">      // height:    50 * 10000,</span><br><span class=\"line\">      // blockHash: hexToHash(&quot;00000000000000000013dad60a42a3401a8f37ca02f1c00ac5923e674566a3ae&quot;), // 55</span><br><span class=\"line\">      //&#125;,</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   if len(data) &gt; 24 &#123;</span><br><span class=\"line\">      log.Error(&quot;parallel number must &lt; 24&quot;, &quot;actual &quot;, len(data))</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   var wg sync.WaitGroup</span><br><span class=\"line\">   for index, v := range data &#123;</span><br><span class=\"line\">      wg.Add(1)</span><br><span class=\"line\">      go func(index int, v readBlockChain) &#123;</span><br><span class=\"line\">         rwBlocks(v.blockHash[:], v.height, fmt.Sprint(index), func() &#123; wg.Done() &#125;)</span><br><span class=\"line\">      &#125;(index, v)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   wg.Wait()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func rwBlocks(startBlock []byte, endHeight uint64, prefix string, callback func()) &#123;</span><br><span class=\"line\">   defer callback()</span><br><span class=\"line\">   fileCache := make(map[uint64]*os.File, 0)</span><br><span class=\"line\">   blockHash := startBlock</span><br><span class=\"line\">   reverWriter := NewReverseWriter(blDirtyDir, 138*1024*1024, prefix)</span><br><span class=\"line\">   defer reverWriter.Flush()</span><br><span class=\"line\">   count := 0</span><br><span class=\"line\">   for &#123;</span><br><span class=\"line\">      content, height, err := rwBlock(fileCache, blockHash)</span><br><span class=\"line\">      if err != nil &#123;</span><br><span class=\"line\">         log.Error(&quot;rw block&quot;, &quot;err&quot;, err.Error())</span><br><span class=\"line\">         return</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      blockHash = content[12:44]</span><br><span class=\"line\">      err = reverWriter.Insert(content)</span><br><span class=\"line\">      if err != nil &#123;</span><br><span class=\"line\">         fmt.Println(&quot;writer err&quot;, err)</span><br><span class=\"line\">         return</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      if height == endHeight &#123;</span><br><span class=\"line\">         log.Info(&quot;finish to save block height&quot;, &quot;height&quot;, height)</span><br><span class=\"line\">         return</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      if height%3000 == 0 &#123;</span><br><span class=\"line\">         log.Trace(&quot;====&gt;&quot;, &quot;height&quot;, height, &quot;parent block hash&quot;, hashToHex(blockHash))</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      count++</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   log.Info(&quot;write file end&quot;, &quot;count&quot;, count)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func rwBlock(fileCache map[uint64]*os.File, block []byte) ([]byte, uint64, error) &#123;</span><br><span class=\"line\">   value, err := indexLDB.Get(append([]byte(&quot;b&quot;), block...))</span><br><span class=\"line\">   if err != nil &#123;</span><br><span class=\"line\">      return []byte&#123;&#125;, 0, errors.New(fmt.Sprintf(&quot;%s%s&quot;, err.Error(), hashToHex(block)))</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   bm := parseBlockMeta(value)</span><br><span class=\"line\">   file, ok := fileCache[bm.file]</span><br><span class=\"line\">   if !ok &#123;</span><br><span class=\"line\">      file, err = os.Open(idx2fname(blSourceDir, uint32(bm.file)))</span><br><span class=\"line\">      if err != nil &#123;</span><br><span class=\"line\">         return []byte&#123;&#125;, 0, err</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      fileCache[bm.file] = file</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   file.Seek(int64(bm.dataPos-8), io.SeekStart)</span><br><span class=\"line\">   res, err := readBlockFromFile(file)</span><br><span class=\"line\"></span><br><span class=\"line\">   if err != nil &#123;</span><br><span class=\"line\">      return []byte&#123;&#125;, 0, err</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   binary.LittleEndian.PutUint32(res[:4], uint32(bm.height))</span><br><span class=\"line\">   return res, bm.height, err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func readBlockFromFile(f *os.File) (res []byte, e error) &#123;</span><br><span class=\"line\">   var buf [4]byte</span><br><span class=\"line\">   _, e = f.Read(buf[:])</span><br><span class=\"line\">   _, e = f.Read(buf[:])</span><br><span class=\"line\">   if e != nil &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   le := uint32(lsb2uint(buf[:]))</span><br><span class=\"line\">   if le &lt; 81 &#123;</span><br><span class=\"line\">      e = errors.New(fmt.Sprintf(&quot;Incorrect block size %d&quot;, le))</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   res = make([]byte, le+8)</span><br><span class=\"line\">   copy(res[4:8], buf[:])</span><br><span class=\"line\">   _, e = f.Read(res[8:])</span><br><span class=\"line\">   if e != nil &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func idx2fname(dir string, fidx uint32) (s string) &#123;</span><br><span class=\"line\">   if fidx == 0xffffffff &#123;</span><br><span class=\"line\">      return &quot;blk99999.dat&quot;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return fmt.Sprintf(&quot;%s/blk%05d.dat&quot;, dir, fidx)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func lsb2uint(lt []byte) (res uint64) &#123;</span><br><span class=\"line\">   for i := 0; i &lt; len(lt); i++ &#123;</span><br><span class=\"line\">      res |= uint64(lt[i]) &lt;&lt; uint(i*8)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type blockMeta struct &#123;</span><br><span class=\"line\">   version uint64</span><br><span class=\"line\">   height  uint64</span><br><span class=\"line\">   status  uint64</span><br><span class=\"line\">   nTx     uint64</span><br><span class=\"line\">   file    uint64</span><br><span class=\"line\">   dataPos uint64</span><br><span class=\"line\">   undoPos uint64</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func parseBlockMeta(raw []byte) (bm blockMeta) &#123;</span><br><span class=\"line\">   var pos uint64</span><br><span class=\"line\">   var i uint64</span><br><span class=\"line\">   bm.version, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.height, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.status, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.nTx, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.file, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.dataPos, i = readRawData(raw[pos:])</span><br><span class=\"line\">   pos += i</span><br><span class=\"line\">   bm.undoPos, i = readRawData(raw[pos:])</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func readRawData(raw []byte) (uint64, uint64) &#123;</span><br><span class=\"line\">   var n uint64</span><br><span class=\"line\">   var pos uint64</span><br><span class=\"line\">   for &#123;</span><br><span class=\"line\">      data := raw[pos]</span><br><span class=\"line\">      pos += 1</span><br><span class=\"line\">      n = (n &lt;&lt; 7) | (uint64(data) &amp; 0x7f)</span><br><span class=\"line\">      if data&amp;0x80 == 0 &#123;</span><br><span class=\"line\">         return n, pos</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      n += 1</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func hashToHex(hash []byte) (s string) &#123;</span><br><span class=\"line\">   for i := 0; i &lt; 32; i++ &#123;</span><br><span class=\"line\">      s += fmt.Sprintf(&quot;%02x&quot;, hash[31-i])</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func hexToHash(s string) (res [32]byte) &#123;</span><br><span class=\"line\">   d, e := hex.DecodeString(s)</span><br><span class=\"line\">   if e != nil &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   if len(d) != 32 &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   for i := 0; i &lt; 32; i++ &#123;</span><br><span class=\"line\">      res[31-i] = d[i]</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type ReverseWriter struct &#123;</span><br><span class=\"line\">   Dir          string</span><br><span class=\"line\">   CacheMaxSize int</span><br><span class=\"line\">   len          int</span><br><span class=\"line\">   cache        []byte</span><br><span class=\"line\">   seek         int</span><br><span class=\"line\">   index        int</span><br><span class=\"line\">   Prefix       string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func NewReverseWriter(dir string, cacheSize int, prefix string) *ReverseWriter &#123;</span><br><span class=\"line\">   rw := &amp;ReverseWriter&#123;Dir: dir, CacheMaxSize: cacheSize, Prefix: prefix&#125;</span><br><span class=\"line\">   rw.init()</span><br><span class=\"line\">   return rw</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (rw *ReverseWriter) init() &#123;</span><br><span class=\"line\">   rw.len = 0</span><br><span class=\"line\">   rw.cache = make([]byte, rw.CacheMaxSize)</span><br><span class=\"line\">   rw.seek = rw.CacheMaxSize</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (rw *ReverseWriter) Insert(content []byte) error &#123;</span><br><span class=\"line\">   if rw.len+len(content) &gt; rw.CacheMaxSize &#123;</span><br><span class=\"line\">      err := rw.writeToFile()</span><br><span class=\"line\">      if err != nil &#123;</span><br><span class=\"line\">         return err</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      rw.index++</span><br><span class=\"line\">      rw.init()</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   copy(rw.cache[rw.seek-len(content):rw.seek], content)</span><br><span class=\"line\">   rw.seek = rw.seek - len(content)</span><br><span class=\"line\">   rw.len += len(content)</span><br><span class=\"line\">   return nil</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (rw *ReverseWriter) writeToFile() error &#123;</span><br><span class=\"line\">   if rw.len == 0 &#123;</span><br><span class=\"line\">      return nil</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   writer, err := os.OpenFile(fmt.Sprintf(&quot;%s/%sblk%05d.dat&quot;, rw.Dir, rw.Prefix, rw.index), os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0666)</span><br><span class=\"line\">   if err != nil &#123;</span><br><span class=\"line\">      return err</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   _, err = writer.Write(rw.cache[rw.seek:])</span><br><span class=\"line\">   return err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (rw *ReverseWriter) Flush() error &#123;</span><br><span class=\"line\">   err := rw.writeToFile()</span><br><span class=\"line\">   rw.index++</span><br><span class=\"line\">   rw.init()</span><br><span class=\"line\">   return err</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">重组完成之后，进行更名操作</span><br><span class=\"line\">#!/usr/bin/env bash</span><br><span class=\"line\"></span><br><span class=\"line\"># shell is funny</span><br><span class=\"line\"></span><br><span class=\"line\">read -p &quot;Are you sure:(y/n) &quot; an</span><br><span class=\"line\">if [[ $&#123;an&#125; != &quot;y&quot; ]]; then exit; fi</span><br><span class=\"line\"></span><br><span class=\"line\">cd /Users/woko/bitcoin</span><br><span class=\"line\"></span><br><span class=\"line\">function rename_2() &#123;</span><br><span class=\"line\">    index=0</span><br><span class=\"line\">    for name in $(ls | grep .dat) ; do</span><br><span class=\"line\">        if [[ -f $&#123;name&#125; ]]; then</span><br><span class=\"line\">            rename=$(echo $&#123;index&#125;|awk &apos;&#123;printf(&quot;blk%05d.dat&quot;,$0)&#125;&apos;)</span><br><span class=\"line\">            echo $&#123;name&#125; &quot; ==&gt; &quot; $&#123;rename&#125;</span><br><span class=\"line\">            mv $&#123;name&#125; $&#123;rename&#125;</span><br><span class=\"line\">            ((index=index+1))</span><br><span class=\"line\">        fi</span><br><span class=\"line\">    done</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">function rename_1() &#123;</span><br><span class=\"line\">    count=0</span><br><span class=\"line\">    for (( i = 0; i &lt; 10; ++i )); do</span><br><span class=\"line\">        index=$(ls $&#123;count&#125;*.dat | wc -l)</span><br><span class=\"line\">        for name in $(ls $&#123;count&#125;*.dat) ; do</span><br><span class=\"line\">            if [[ -f $&#123;name&#125; ]]; then</span><br><span class=\"line\">                ((index=index-1))</span><br><span class=\"line\">                rename=$(echo &quot;$&#123;count&#125; $&#123;index&#125;&quot;|awk &apos;&#123;printf(&quot;%02dblk%05d.dat&quot;,$1,$2)&#125;&apos;)</span><br><span class=\"line\">                echo $&#123;name&#125; &quot; ==&gt; &quot; $&#123;rename&#125;</span><br><span class=\"line\">                mv $&#123;name&#125; $&#123;rename&#125;</span><br><span class=\"line\">            fi</span><br><span class=\"line\">        done</span><br><span class=\"line\">        ((count=count+1))</span><br><span class=\"line\">        echo &quot;--------------&quot;</span><br><span class=\"line\">    done</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">rename_1</span><br><span class=\"line\">echo &quot;==============&quot;</span><br><span class=\"line\">rename_2</span><br></pre></td></tr></table></figure>\n\n"},{"title":"btc","date":"2019-04-14T06:37:56.000Z","_content":"\n### 比特币的基本概念及相关认识\n\n\n\n本篇笔记绝大部分参考自[比特币超级详细入门指南](https://github.com/liuchengxu/blockchain-tutorial)以及[阮一峰老师关于区块链的相关博客](http://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html)\n\n\n\n区块链本质上是分布式的数据库系统，是开放式的账簿系统(ledger)。\n\n\n\n本质上，区块链就是一个有着特定结构的数据库，是一个有序，每一个块都连接到前一个块的链表。也就是说，区块按照插入的顺序进行存储，每个块都与前一个块相连。这样的结构，能够让我们快速地获取链上的最新块，并且高效地通过哈希来检索一个块。\n\n\n\n##### 挖矿（工作量证明）\n\n工作量证明是一种共识算法，在比特币中，这个工作就是找到一个块的有效哈希，并证明其有效性。\n\n获得指定数据的一个哈希值的过程，就叫做哈希计算。一个哈希，就是对所计算数据的一个唯一表示。对于一个哈希函数，输入任意大小的数据，它会输出一个固定大小的哈希值。下面是哈希的几个关键特性：\n\n1. 无法从一个哈希值恢复原始数据。也就是说，哈希并不是加密。\n2. 对于特定的数据，只能有一个哈希，并且这个哈希是唯一的。\n3. 即使是仅仅改变输入数据中的一个字节，也会导致输出一个完全不同的哈希。\n\n在区块链中，哈希被用于保证一个块的一致性。哈希算法的输入数据包含了前一个块的哈希，因此使得不太可能（或者，至少很困难）去修改链中的一个块：因为如果一个人想要修改前面一个块的哈希，那么他必须要重新计算这个块以及后面所有块的哈希。\n\n寻找一个合适的哈希，需要大量的计算，平均是10分钟才能找到一个合适的哈希，生成1个新的区块。\n\n\n\n##### 交易\n\n比特币中交易分为两种：\n\n1. 普通交易，输入会引用之前一笔交易的输出。即花费之前的交易输出\n2. 例外，coinbase交易，即挖矿奖励，只有输出\n\n在交易中，需要注意的是：\n\n- 一笔交易的输入可以引用之前多笔交易的输出\n- 一个输入必须引用一个输出\n- 没有被引用的输出，即为未花费交易输出\n- 输出是不可再分的，即一个输出你无法仅引用它的其中某一部分，要么不要，要么一次性用完。当它的值比需要的值大，那么就会产生一个找零，找零会返还给发送方。\n\n那么，交易的话，需要的是发送方，接收方，交易金额。整个交易的过程如下：\n\n1. 从发送方中找到足够交易金额的未花费交易输出s(可能是多个输出的叠加)，作为交易的输入\n2. 确定输出，输出有可能为2个，一个是接收方，一个是发送者的找零\n\n\n\n值得注意的是，交易生成后，并不是立刻生效，而是先将交易放到一个内存池中，然后当矿工准备挖出一个新块时，它就从内存池中取出所有交易，创建一个候选块，当包含这些交易的块被挖出来添加到区块链以后，里面的交易才开始确认。\n\n\n\n##### 地址\n\n当交易发生时，如何校验发送方和接收方呢，没有用户账户，如何查验自己所有的未花费输出呢。在比特币中，校验方式为，密钥对，公钥和私钥。私钥代表的就是你，所有的交易中含有的信息为公钥相关。\n\n根据协议，公钥的长度是512位。这个长度不太方便传播，因此协议又规定，要为公钥生成一个160位的指纹。所谓指纹，就是一个比较短的、易于传播的哈希值。160位是二进制，写成十六进制，大约是26到35个字符，即地址。\n\n交易产生时，需要对数据进行签名，签名过程需要被签名的数据和私钥，这个签名会被存储在交易输入中。为了对一个签名进行验证，需要被签名的数据，签名，公钥。所以在一个交易的输入中，这三者都会存储。那么，什么时候进行验证呢，当把交易从内存池中取出来放入到一个块之前，对每一笔交易都要进行验证，验证意味着什么呢，其一是检查交易输入有权使用来自之前交易的输出，其二是检查交易签名是正确的。\n\n\n\n交易过程，一笔交易就是一个地址的比特币转移到另一个地址。申报交易时，除了交易金额，转出比特币的一方还必须提供以下数据：\n\n- 上一笔交易的hash(你从哪里得到的这些比特币)\n- 本次交易双方的地址\n- 支付方的公钥\n- 支付方的私钥生成的数字签名\n\n验证这笔交易是否属实，需要三步：\n\n1. 找到上一笔交易，确认支付方的比特币来源\n2. 算出支付方公钥的指纹，确认与支付方的地址一直，从而保证公钥属实\n3. 使用公钥去解开数字签名，保证私钥属实\n\n\n\n交易确认，交易必须写入区块链，才算生效。首先，所有的交易数据都会传送到矿工那里，矿工负责把这些交易写入区块链。根据比特币协议，一个区块的大小最大是 1MB，而一笔交易大概是500字节左右，因此一个区块最多可以包含2000多笔交易。矿工负责把这2000多笔交易打包在一起，组成一个区块然后计算这个区块的 Hash（工作量证明）。另外，鉴于区块链分叉的情况，根据比特币协议规定，分叉点最先达到6个区块的那个分支，被认定为正式的区块链，其他分支都将被放弃，所以，一笔交易真正生效，必须等待至少1个小时。\n\n\n\n粘贴一点数据结构，供参考。\n\n输入结构体定义为\n\n```\ntype TXInput struct {\n    Txid      []byte  //一个输入引用之前交易的一个输出，txid为之前交易的ID\n    Vout      int  //之前交易的输出可能有多个，需要指明是具体哪一个\n    Signature []byte //签名\n    PubKey    []byte //公钥\n}\n```\n\n输出结构体定义为\n\n```\ntype TXOutput struct {\n    Value      int  \n    PubKeyHash []byte //公钥哈希\n}\n```\n\n\n\n看到两个结构体的定义，可以想到，签名的作用仅在于到被验证完毕。输出中公钥哈希的使用场景在于校验，例如查找未花费输出时，判断条件为输出中的公钥哈希和当前公钥进行哈希之后是否匹配，还有另外的场景..下面来回顾一下一个交易完整的生命周期。\n\n1. 起初，创世块里面包含了一个coinbase交易，在coinbase交易中，没有输入，就不需要签名，coinbase交易的输出包含了一个哈希过的公钥（使用的是 **RIPEMD16(SHA256(PubKey))** 算法）\n2. 当有人发送币时，就会创建一笔交易，这笔交易的输入会引用之前交易的输出，还会存储一个公钥(没有被哈希)和整个交易的一个签名\n3. 比特币网络中接收到交易的其他节点会对该交易进行验证，除了一些其他事情，他们还会检查，在一个输入中，公钥哈希与所引用的输出哈希相匹配（这保证了发送方只能花费属于自己的币）；签名是正确的（这保证了交易是由币的实际拥有者所创建）。\n4. 当一个矿工准备挖一个新块时，他会将交易放到块中，然后开始挖矿。\n5. 当新块被挖出来以后，网络中的所有其他节点会接收到一条消息，告诉其他人这个块已经被挖出并被加入到区块链。\n6. 当一个块被加入到区块链以后，交易就算完成，它的输出就可以在新的交易中被引用。\n\n\n\n接下来，就是这其中的一些加密算法啦~\n\n- 私钥生成算法，椭圆曲线加密\n\n- 地址生成算法，Base58,  如果你想要给某个人发送币，只需要知道他的地址就可以了。当我们给某个人发送币时，我们只知道他的地址，因为这个函数使用一个地址作为唯一的参数。然后，地址会被解码，从中提取出公钥哈希并保存在 `PubKeyHash` 字段\n\n- 签名的数据，因为用于签名的这个数据，必须要包含能够唯一识别数据的信息。所以需要签名的数据必须包括以下部分\n\n  1. 存储在已解锁输出的公钥哈希。它识别了一笔交易的“发送方”。\n  2. 存储在新的锁定输出里面的公钥哈希。它识别了一笔交易的“接收方”。\n  3. 新的输出值。\n\n  比特币里， 所签名的并不是一个交易，而是一个去除部分内容的输入副本。\n\n\n\n\n\n##### UTXO集\n\n在查找某个公钥的所有未花费输出时，需要查找所有的区块，区块中的每一笔交易，但是如果区块特别多的情况下，迭代需要的成本就太大了。解决方式就是有一个仅有未花费输出的索引，这就是UTXO集要做的事情，这是一个从所有区块链交易中构建(对区块进行迭代，但是只须做一次)而来的缓存，然后用它来计算余额和验证新的交易。\n\n\n\n##### Merkle树\n\nMerkle树为1种优化机制，实现的是每个块中，都有1个Merkle树，树的叶子节点为一个交易哈希，从下往上，两两成对，连接两个节点哈希，将组合哈希作为新的哈希，新的哈希就成为新的树节点，一直到树根，根哈希就会当作是整个块交易的唯一标识，将它保存到区块头，然后用于工作量证明。\n\nMerkle树的好处就是一个节点可以在不下载整个块的情况下，验证是否包含某笔交易。并且这些只需要一个交易哈希，一个 Merkle 树根哈希和一个 Merkle 路径。\n\n\n\n##### P2PKH\n\n在比特币中有一个 *脚本（Script）*编程语言，它用于锁定交易输出；交易输入提供了解锁输出的数据。这个个脚本叫做 *Pay to Public Key Hash(P2PKH)*，这是比特币最常用的一个脚本。它所做的事情就是向一个公钥哈希支付，也就是说，用某一个公钥锁定一些币。这是**比特币支付的核心**：没有账户，没有资金转移；只有一个脚本检查提供的签名和公钥是否正确。有了一个这样的脚本语言，实际上也可以让比特币成为一个智能合约平台：除了将一个单一的公钥转移资金，这个语言还使得一些其他的支付方案成为可能。\n\n\n\n##### 数据库结构\n\n简单来说，Bitcoin Core使用两个\"bucket\"来存储数据：\n\n1. blocks, 它存储了描述一条链中所有块的元数据\n2. chainstate, 存储了一条链的状态，也就是当前所有的未花费的交易输出，和一些元数据\n\n此外，出于性能的考虑，Bitcoin Core 将每个区块（block）存储为磁盘上的不同文件。如此一来，就不需要仅仅为了读取一个单一的块而将所有（或者部分）的块都加载到内存中。\n\n\n\n##### 网络\n\n区块链网络是去中心化的，这意味着没有服务器，客户端也不需要依赖服务器来获取或处理数据。在区块链网络中，有的是节点，每个节点是网络的一个完全（full-fledged）成员。节点就是一切：它既是一个客户端，也是一个服务器。这一点需要牢记于心，因为这与传统的网页应用非常不同。\n\n区块链网络是一个 P2P（Peer-to-Peer，端到端）的网络，即节点直接连接到其他节点。它的拓扑是扁平的，因为在节点的世界中没有层级之分。每个节点必须与很多其他节点进行交互，它必须请求其他节点的状态，与自己的状态进行比较，当状态过时时进行更新。\n\n当你发生了一笔支付，你所在的节点就会把这笔交易告诉另一个节点，直至传遍整个网络。矿工从网上收集各种新发生的交易，将它们打包写入区块链。一旦写入成功， 矿工所在节点的区块链，就成为最新版本，其他节点都会来复制新增的区块，保证全网的区块链都是一致的。\n\n\n\n节点角色：\n\n- 矿工 这样的节点运行于强大或专用的硬件（比如 ASIC）之上，它们唯一的目标是，尽可能快地挖出新块。矿工是区块链中唯一可能会用到工作量证明的角色，因为挖矿实际上意味着解决 PoW 难题。在权益证明 PoS 的区块链中，没有挖矿。\n- 全节点 这些节点验证矿工挖出来的块的有效性，并对交易进行确认。为此，他们必须拥有区块链的完整拷贝。同时，全节点执行路由操作，帮助其他节点发现彼此。对于网络来说，非常重要的一段就是要有足够多的全节点。因为正是这些节点执行了决策功能：他们决定了一个块或一笔交易的有效性。\n- SPV SPV 表示 Simplified Payment Verification，简单支付验证。这些节点并不存储整个区块链副本，但是仍然能够对交易进行验证（不过不是验证全部交易，而是一个交易子集，比如，发送到某个指定地址的交易）。一个 SPV 节点依赖一个全节点来获取数据，可能有多个 SPV 节点连接到一个全节点。SPV 使得钱包应用成为可能：一个人不需要下载整个区块链，但是仍能够验证他的交易。\n","source":"_posts/btc.md","raw":"---\ntitle: btc\ncategories:\n  - btc\ndate: 2019-4-14 14:37:56\ntags:\n---\n\n### 比特币的基本概念及相关认识\n\n\n\n本篇笔记绝大部分参考自[比特币超级详细入门指南](https://github.com/liuchengxu/blockchain-tutorial)以及[阮一峰老师关于区块链的相关博客](http://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html)\n\n\n\n区块链本质上是分布式的数据库系统，是开放式的账簿系统(ledger)。\n\n\n\n本质上，区块链就是一个有着特定结构的数据库，是一个有序，每一个块都连接到前一个块的链表。也就是说，区块按照插入的顺序进行存储，每个块都与前一个块相连。这样的结构，能够让我们快速地获取链上的最新块，并且高效地通过哈希来检索一个块。\n\n\n\n##### 挖矿（工作量证明）\n\n工作量证明是一种共识算法，在比特币中，这个工作就是找到一个块的有效哈希，并证明其有效性。\n\n获得指定数据的一个哈希值的过程，就叫做哈希计算。一个哈希，就是对所计算数据的一个唯一表示。对于一个哈希函数，输入任意大小的数据，它会输出一个固定大小的哈希值。下面是哈希的几个关键特性：\n\n1. 无法从一个哈希值恢复原始数据。也就是说，哈希并不是加密。\n2. 对于特定的数据，只能有一个哈希，并且这个哈希是唯一的。\n3. 即使是仅仅改变输入数据中的一个字节，也会导致输出一个完全不同的哈希。\n\n在区块链中，哈希被用于保证一个块的一致性。哈希算法的输入数据包含了前一个块的哈希，因此使得不太可能（或者，至少很困难）去修改链中的一个块：因为如果一个人想要修改前面一个块的哈希，那么他必须要重新计算这个块以及后面所有块的哈希。\n\n寻找一个合适的哈希，需要大量的计算，平均是10分钟才能找到一个合适的哈希，生成1个新的区块。\n\n\n\n##### 交易\n\n比特币中交易分为两种：\n\n1. 普通交易，输入会引用之前一笔交易的输出。即花费之前的交易输出\n2. 例外，coinbase交易，即挖矿奖励，只有输出\n\n在交易中，需要注意的是：\n\n- 一笔交易的输入可以引用之前多笔交易的输出\n- 一个输入必须引用一个输出\n- 没有被引用的输出，即为未花费交易输出\n- 输出是不可再分的，即一个输出你无法仅引用它的其中某一部分，要么不要，要么一次性用完。当它的值比需要的值大，那么就会产生一个找零，找零会返还给发送方。\n\n那么，交易的话，需要的是发送方，接收方，交易金额。整个交易的过程如下：\n\n1. 从发送方中找到足够交易金额的未花费交易输出s(可能是多个输出的叠加)，作为交易的输入\n2. 确定输出，输出有可能为2个，一个是接收方，一个是发送者的找零\n\n\n\n值得注意的是，交易生成后，并不是立刻生效，而是先将交易放到一个内存池中，然后当矿工准备挖出一个新块时，它就从内存池中取出所有交易，创建一个候选块，当包含这些交易的块被挖出来添加到区块链以后，里面的交易才开始确认。\n\n\n\n##### 地址\n\n当交易发生时，如何校验发送方和接收方呢，没有用户账户，如何查验自己所有的未花费输出呢。在比特币中，校验方式为，密钥对，公钥和私钥。私钥代表的就是你，所有的交易中含有的信息为公钥相关。\n\n根据协议，公钥的长度是512位。这个长度不太方便传播，因此协议又规定，要为公钥生成一个160位的指纹。所谓指纹，就是一个比较短的、易于传播的哈希值。160位是二进制，写成十六进制，大约是26到35个字符，即地址。\n\n交易产生时，需要对数据进行签名，签名过程需要被签名的数据和私钥，这个签名会被存储在交易输入中。为了对一个签名进行验证，需要被签名的数据，签名，公钥。所以在一个交易的输入中，这三者都会存储。那么，什么时候进行验证呢，当把交易从内存池中取出来放入到一个块之前，对每一笔交易都要进行验证，验证意味着什么呢，其一是检查交易输入有权使用来自之前交易的输出，其二是检查交易签名是正确的。\n\n\n\n交易过程，一笔交易就是一个地址的比特币转移到另一个地址。申报交易时，除了交易金额，转出比特币的一方还必须提供以下数据：\n\n- 上一笔交易的hash(你从哪里得到的这些比特币)\n- 本次交易双方的地址\n- 支付方的公钥\n- 支付方的私钥生成的数字签名\n\n验证这笔交易是否属实，需要三步：\n\n1. 找到上一笔交易，确认支付方的比特币来源\n2. 算出支付方公钥的指纹，确认与支付方的地址一直，从而保证公钥属实\n3. 使用公钥去解开数字签名，保证私钥属实\n\n\n\n交易确认，交易必须写入区块链，才算生效。首先，所有的交易数据都会传送到矿工那里，矿工负责把这些交易写入区块链。根据比特币协议，一个区块的大小最大是 1MB，而一笔交易大概是500字节左右，因此一个区块最多可以包含2000多笔交易。矿工负责把这2000多笔交易打包在一起，组成一个区块然后计算这个区块的 Hash（工作量证明）。另外，鉴于区块链分叉的情况，根据比特币协议规定，分叉点最先达到6个区块的那个分支，被认定为正式的区块链，其他分支都将被放弃，所以，一笔交易真正生效，必须等待至少1个小时。\n\n\n\n粘贴一点数据结构，供参考。\n\n输入结构体定义为\n\n```\ntype TXInput struct {\n    Txid      []byte  //一个输入引用之前交易的一个输出，txid为之前交易的ID\n    Vout      int  //之前交易的输出可能有多个，需要指明是具体哪一个\n    Signature []byte //签名\n    PubKey    []byte //公钥\n}\n```\n\n输出结构体定义为\n\n```\ntype TXOutput struct {\n    Value      int  \n    PubKeyHash []byte //公钥哈希\n}\n```\n\n\n\n看到两个结构体的定义，可以想到，签名的作用仅在于到被验证完毕。输出中公钥哈希的使用场景在于校验，例如查找未花费输出时，判断条件为输出中的公钥哈希和当前公钥进行哈希之后是否匹配，还有另外的场景..下面来回顾一下一个交易完整的生命周期。\n\n1. 起初，创世块里面包含了一个coinbase交易，在coinbase交易中，没有输入，就不需要签名，coinbase交易的输出包含了一个哈希过的公钥（使用的是 **RIPEMD16(SHA256(PubKey))** 算法）\n2. 当有人发送币时，就会创建一笔交易，这笔交易的输入会引用之前交易的输出，还会存储一个公钥(没有被哈希)和整个交易的一个签名\n3. 比特币网络中接收到交易的其他节点会对该交易进行验证，除了一些其他事情，他们还会检查，在一个输入中，公钥哈希与所引用的输出哈希相匹配（这保证了发送方只能花费属于自己的币）；签名是正确的（这保证了交易是由币的实际拥有者所创建）。\n4. 当一个矿工准备挖一个新块时，他会将交易放到块中，然后开始挖矿。\n5. 当新块被挖出来以后，网络中的所有其他节点会接收到一条消息，告诉其他人这个块已经被挖出并被加入到区块链。\n6. 当一个块被加入到区块链以后，交易就算完成，它的输出就可以在新的交易中被引用。\n\n\n\n接下来，就是这其中的一些加密算法啦~\n\n- 私钥生成算法，椭圆曲线加密\n\n- 地址生成算法，Base58,  如果你想要给某个人发送币，只需要知道他的地址就可以了。当我们给某个人发送币时，我们只知道他的地址，因为这个函数使用一个地址作为唯一的参数。然后，地址会被解码，从中提取出公钥哈希并保存在 `PubKeyHash` 字段\n\n- 签名的数据，因为用于签名的这个数据，必须要包含能够唯一识别数据的信息。所以需要签名的数据必须包括以下部分\n\n  1. 存储在已解锁输出的公钥哈希。它识别了一笔交易的“发送方”。\n  2. 存储在新的锁定输出里面的公钥哈希。它识别了一笔交易的“接收方”。\n  3. 新的输出值。\n\n  比特币里， 所签名的并不是一个交易，而是一个去除部分内容的输入副本。\n\n\n\n\n\n##### UTXO集\n\n在查找某个公钥的所有未花费输出时，需要查找所有的区块，区块中的每一笔交易，但是如果区块特别多的情况下，迭代需要的成本就太大了。解决方式就是有一个仅有未花费输出的索引，这就是UTXO集要做的事情，这是一个从所有区块链交易中构建(对区块进行迭代，但是只须做一次)而来的缓存，然后用它来计算余额和验证新的交易。\n\n\n\n##### Merkle树\n\nMerkle树为1种优化机制，实现的是每个块中，都有1个Merkle树，树的叶子节点为一个交易哈希，从下往上，两两成对，连接两个节点哈希，将组合哈希作为新的哈希，新的哈希就成为新的树节点，一直到树根，根哈希就会当作是整个块交易的唯一标识，将它保存到区块头，然后用于工作量证明。\n\nMerkle树的好处就是一个节点可以在不下载整个块的情况下，验证是否包含某笔交易。并且这些只需要一个交易哈希，一个 Merkle 树根哈希和一个 Merkle 路径。\n\n\n\n##### P2PKH\n\n在比特币中有一个 *脚本（Script）*编程语言，它用于锁定交易输出；交易输入提供了解锁输出的数据。这个个脚本叫做 *Pay to Public Key Hash(P2PKH)*，这是比特币最常用的一个脚本。它所做的事情就是向一个公钥哈希支付，也就是说，用某一个公钥锁定一些币。这是**比特币支付的核心**：没有账户，没有资金转移；只有一个脚本检查提供的签名和公钥是否正确。有了一个这样的脚本语言，实际上也可以让比特币成为一个智能合约平台：除了将一个单一的公钥转移资金，这个语言还使得一些其他的支付方案成为可能。\n\n\n\n##### 数据库结构\n\n简单来说，Bitcoin Core使用两个\"bucket\"来存储数据：\n\n1. blocks, 它存储了描述一条链中所有块的元数据\n2. chainstate, 存储了一条链的状态，也就是当前所有的未花费的交易输出，和一些元数据\n\n此外，出于性能的考虑，Bitcoin Core 将每个区块（block）存储为磁盘上的不同文件。如此一来，就不需要仅仅为了读取一个单一的块而将所有（或者部分）的块都加载到内存中。\n\n\n\n##### 网络\n\n区块链网络是去中心化的，这意味着没有服务器，客户端也不需要依赖服务器来获取或处理数据。在区块链网络中，有的是节点，每个节点是网络的一个完全（full-fledged）成员。节点就是一切：它既是一个客户端，也是一个服务器。这一点需要牢记于心，因为这与传统的网页应用非常不同。\n\n区块链网络是一个 P2P（Peer-to-Peer，端到端）的网络，即节点直接连接到其他节点。它的拓扑是扁平的，因为在节点的世界中没有层级之分。每个节点必须与很多其他节点进行交互，它必须请求其他节点的状态，与自己的状态进行比较，当状态过时时进行更新。\n\n当你发生了一笔支付，你所在的节点就会把这笔交易告诉另一个节点，直至传遍整个网络。矿工从网上收集各种新发生的交易，将它们打包写入区块链。一旦写入成功， 矿工所在节点的区块链，就成为最新版本，其他节点都会来复制新增的区块，保证全网的区块链都是一致的。\n\n\n\n节点角色：\n\n- 矿工 这样的节点运行于强大或专用的硬件（比如 ASIC）之上，它们唯一的目标是，尽可能快地挖出新块。矿工是区块链中唯一可能会用到工作量证明的角色，因为挖矿实际上意味着解决 PoW 难题。在权益证明 PoS 的区块链中，没有挖矿。\n- 全节点 这些节点验证矿工挖出来的块的有效性，并对交易进行确认。为此，他们必须拥有区块链的完整拷贝。同时，全节点执行路由操作，帮助其他节点发现彼此。对于网络来说，非常重要的一段就是要有足够多的全节点。因为正是这些节点执行了决策功能：他们决定了一个块或一笔交易的有效性。\n- SPV SPV 表示 Simplified Payment Verification，简单支付验证。这些节点并不存储整个区块链副本，但是仍然能够对交易进行验证（不过不是验证全部交易，而是一个交易子集，比如，发送到某个指定地址的交易）。一个 SPV 节点依赖一个全节点来获取数据，可能有多个 SPV 节点连接到一个全节点。SPV 使得钱包应用成为可能：一个人不需要下载整个区块链，但是仍能够验证他的交易。\n","slug":"btc","published":1,"updated":"2019-10-14T07:25:20.084Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69wu0021t6xv33u3pm35","content":"<h3 id=\"比特币的基本概念及相关认识\"><a href=\"#比特币的基本概念及相关认识\" class=\"headerlink\" title=\"比特币的基本概念及相关认识\"></a>比特币的基本概念及相关认识</h3><p>本篇笔记绝大部分参考自<a href=\"https://github.com/liuchengxu/blockchain-tutorial\">比特币超级详细入门指南</a>以及<a href=\"http://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html\" target=\"_blank\" rel=\"noopener\">阮一峰老师关于区块链的相关博客</a></p>\n<p>区块链本质上是分布式的数据库系统，是开放式的账簿系统(ledger)。</p>\n<p>本质上，区块链就是一个有着特定结构的数据库，是一个有序，每一个块都连接到前一个块的链表。也就是说，区块按照插入的顺序进行存储，每个块都与前一个块相连。这样的结构，能够让我们快速地获取链上的最新块，并且高效地通过哈希来检索一个块。</p>\n<h5 id=\"挖矿（工作量证明）\"><a href=\"#挖矿（工作量证明）\" class=\"headerlink\" title=\"挖矿（工作量证明）\"></a>挖矿（工作量证明）</h5><p>工作量证明是一种共识算法，在比特币中，这个工作就是找到一个块的有效哈希，并证明其有效性。</p>\n<p>获得指定数据的一个哈希值的过程，就叫做哈希计算。一个哈希，就是对所计算数据的一个唯一表示。对于一个哈希函数，输入任意大小的数据，它会输出一个固定大小的哈希值。下面是哈希的几个关键特性：</p>\n<ol>\n<li>无法从一个哈希值恢复原始数据。也就是说，哈希并不是加密。</li>\n<li>对于特定的数据，只能有一个哈希，并且这个哈希是唯一的。</li>\n<li>即使是仅仅改变输入数据中的一个字节，也会导致输出一个完全不同的哈希。</li>\n</ol>\n<p>在区块链中，哈希被用于保证一个块的一致性。哈希算法的输入数据包含了前一个块的哈希，因此使得不太可能（或者，至少很困难）去修改链中的一个块：因为如果一个人想要修改前面一个块的哈希，那么他必须要重新计算这个块以及后面所有块的哈希。</p>\n<p>寻找一个合适的哈希，需要大量的计算，平均是10分钟才能找到一个合适的哈希，生成1个新的区块。</p>\n<h5 id=\"交易\"><a href=\"#交易\" class=\"headerlink\" title=\"交易\"></a>交易</h5><p>比特币中交易分为两种：</p>\n<ol>\n<li>普通交易，输入会引用之前一笔交易的输出。即花费之前的交易输出</li>\n<li>例外，coinbase交易，即挖矿奖励，只有输出</li>\n</ol>\n<p>在交易中，需要注意的是：</p>\n<ul>\n<li>一笔交易的输入可以引用之前多笔交易的输出</li>\n<li>一个输入必须引用一个输出</li>\n<li>没有被引用的输出，即为未花费交易输出</li>\n<li>输出是不可再分的，即一个输出你无法仅引用它的其中某一部分，要么不要，要么一次性用完。当它的值比需要的值大，那么就会产生一个找零，找零会返还给发送方。</li>\n</ul>\n<p>那么，交易的话，需要的是发送方，接收方，交易金额。整个交易的过程如下：</p>\n<ol>\n<li>从发送方中找到足够交易金额的未花费交易输出s(可能是多个输出的叠加)，作为交易的输入</li>\n<li>确定输出，输出有可能为2个，一个是接收方，一个是发送者的找零</li>\n</ol>\n<p>值得注意的是，交易生成后，并不是立刻生效，而是先将交易放到一个内存池中，然后当矿工准备挖出一个新块时，它就从内存池中取出所有交易，创建一个候选块，当包含这些交易的块被挖出来添加到区块链以后，里面的交易才开始确认。</p>\n<h5 id=\"地址\"><a href=\"#地址\" class=\"headerlink\" title=\"地址\"></a>地址</h5><p>当交易发生时，如何校验发送方和接收方呢，没有用户账户，如何查验自己所有的未花费输出呢。在比特币中，校验方式为，密钥对，公钥和私钥。私钥代表的就是你，所有的交易中含有的信息为公钥相关。</p>\n<p>根据协议，公钥的长度是512位。这个长度不太方便传播，因此协议又规定，要为公钥生成一个160位的指纹。所谓指纹，就是一个比较短的、易于传播的哈希值。160位是二进制，写成十六进制，大约是26到35个字符，即地址。</p>\n<p>交易产生时，需要对数据进行签名，签名过程需要被签名的数据和私钥，这个签名会被存储在交易输入中。为了对一个签名进行验证，需要被签名的数据，签名，公钥。所以在一个交易的输入中，这三者都会存储。那么，什么时候进行验证呢，当把交易从内存池中取出来放入到一个块之前，对每一笔交易都要进行验证，验证意味着什么呢，其一是检查交易输入有权使用来自之前交易的输出，其二是检查交易签名是正确的。</p>\n<p>交易过程，一笔交易就是一个地址的比特币转移到另一个地址。申报交易时，除了交易金额，转出比特币的一方还必须提供以下数据：</p>\n<ul>\n<li>上一笔交易的hash(你从哪里得到的这些比特币)</li>\n<li>本次交易双方的地址</li>\n<li>支付方的公钥</li>\n<li>支付方的私钥生成的数字签名</li>\n</ul>\n<p>验证这笔交易是否属实，需要三步：</p>\n<ol>\n<li>找到上一笔交易，确认支付方的比特币来源</li>\n<li>算出支付方公钥的指纹，确认与支付方的地址一直，从而保证公钥属实</li>\n<li>使用公钥去解开数字签名，保证私钥属实</li>\n</ol>\n<p>交易确认，交易必须写入区块链，才算生效。首先，所有的交易数据都会传送到矿工那里，矿工负责把这些交易写入区块链。根据比特币协议，一个区块的大小最大是 1MB，而一笔交易大概是500字节左右，因此一个区块最多可以包含2000多笔交易。矿工负责把这2000多笔交易打包在一起，组成一个区块然后计算这个区块的 Hash（工作量证明）。另外，鉴于区块链分叉的情况，根据比特币协议规定，分叉点最先达到6个区块的那个分支，被认定为正式的区块链，其他分支都将被放弃，所以，一笔交易真正生效，必须等待至少1个小时。</p>\n<p>粘贴一点数据结构，供参考。</p>\n<p>输入结构体定义为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type TXInput struct &#123;</span><br><span class=\"line\">    Txid      []byte  //一个输入引用之前交易的一个输出，txid为之前交易的ID</span><br><span class=\"line\">    Vout      int  //之前交易的输出可能有多个，需要指明是具体哪一个</span><br><span class=\"line\">    Signature []byte //签名</span><br><span class=\"line\">    PubKey    []byte //公钥</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出结构体定义为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type TXOutput struct &#123;</span><br><span class=\"line\">    Value      int  </span><br><span class=\"line\">    PubKeyHash []byte //公钥哈希</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>看到两个结构体的定义，可以想到，签名的作用仅在于到被验证完毕。输出中公钥哈希的使用场景在于校验，例如查找未花费输出时，判断条件为输出中的公钥哈希和当前公钥进行哈希之后是否匹配，还有另外的场景..下面来回顾一下一个交易完整的生命周期。</p>\n<ol>\n<li>起初，创世块里面包含了一个coinbase交易，在coinbase交易中，没有输入，就不需要签名，coinbase交易的输出包含了一个哈希过的公钥（使用的是 <strong>RIPEMD16(SHA256(PubKey))</strong> 算法）</li>\n<li>当有人发送币时，就会创建一笔交易，这笔交易的输入会引用之前交易的输出，还会存储一个公钥(没有被哈希)和整个交易的一个签名</li>\n<li>比特币网络中接收到交易的其他节点会对该交易进行验证，除了一些其他事情，他们还会检查，在一个输入中，公钥哈希与所引用的输出哈希相匹配（这保证了发送方只能花费属于自己的币）；签名是正确的（这保证了交易是由币的实际拥有者所创建）。</li>\n<li>当一个矿工准备挖一个新块时，他会将交易放到块中，然后开始挖矿。</li>\n<li>当新块被挖出来以后，网络中的所有其他节点会接收到一条消息，告诉其他人这个块已经被挖出并被加入到区块链。</li>\n<li>当一个块被加入到区块链以后，交易就算完成，它的输出就可以在新的交易中被引用。</li>\n</ol>\n<p>接下来，就是这其中的一些加密算法啦~</p>\n<ul>\n<li><p>私钥生成算法，椭圆曲线加密</p>\n</li>\n<li><p>地址生成算法，Base58,  如果你想要给某个人发送币，只需要知道他的地址就可以了。当我们给某个人发送币时，我们只知道他的地址，因为这个函数使用一个地址作为唯一的参数。然后，地址会被解码，从中提取出公钥哈希并保存在 <code>PubKeyHash</code> 字段</p>\n</li>\n<li><p>签名的数据，因为用于签名的这个数据，必须要包含能够唯一识别数据的信息。所以需要签名的数据必须包括以下部分</p>\n<ol>\n<li>存储在已解锁输出的公钥哈希。它识别了一笔交易的“发送方”。</li>\n<li>存储在新的锁定输出里面的公钥哈希。它识别了一笔交易的“接收方”。</li>\n<li>新的输出值。</li>\n</ol>\n<p>比特币里， 所签名的并不是一个交易，而是一个去除部分内容的输入副本。</p>\n</li>\n</ul>\n<h5 id=\"UTXO集\"><a href=\"#UTXO集\" class=\"headerlink\" title=\"UTXO集\"></a>UTXO集</h5><p>在查找某个公钥的所有未花费输出时，需要查找所有的区块，区块中的每一笔交易，但是如果区块特别多的情况下，迭代需要的成本就太大了。解决方式就是有一个仅有未花费输出的索引，这就是UTXO集要做的事情，这是一个从所有区块链交易中构建(对区块进行迭代，但是只须做一次)而来的缓存，然后用它来计算余额和验证新的交易。</p>\n<h5 id=\"Merkle树\"><a href=\"#Merkle树\" class=\"headerlink\" title=\"Merkle树\"></a>Merkle树</h5><p>Merkle树为1种优化机制，实现的是每个块中，都有1个Merkle树，树的叶子节点为一个交易哈希，从下往上，两两成对，连接两个节点哈希，将组合哈希作为新的哈希，新的哈希就成为新的树节点，一直到树根，根哈希就会当作是整个块交易的唯一标识，将它保存到区块头，然后用于工作量证明。</p>\n<p>Merkle树的好处就是一个节点可以在不下载整个块的情况下，验证是否包含某笔交易。并且这些只需要一个交易哈希，一个 Merkle 树根哈希和一个 Merkle 路径。</p>\n<h5 id=\"P2PKH\"><a href=\"#P2PKH\" class=\"headerlink\" title=\"P2PKH\"></a>P2PKH</h5><p>在比特币中有一个 <em>脚本（Script）</em>编程语言，它用于锁定交易输出；交易输入提供了解锁输出的数据。这个个脚本叫做 <em>Pay to Public Key Hash(P2PKH)</em>，这是比特币最常用的一个脚本。它所做的事情就是向一个公钥哈希支付，也就是说，用某一个公钥锁定一些币。这是<strong>比特币支付的核心</strong>：没有账户，没有资金转移；只有一个脚本检查提供的签名和公钥是否正确。有了一个这样的脚本语言，实际上也可以让比特币成为一个智能合约平台：除了将一个单一的公钥转移资金，这个语言还使得一些其他的支付方案成为可能。</p>\n<h5 id=\"数据库结构\"><a href=\"#数据库结构\" class=\"headerlink\" title=\"数据库结构\"></a>数据库结构</h5><p>简单来说，Bitcoin Core使用两个”bucket”来存储数据：</p>\n<ol>\n<li>blocks, 它存储了描述一条链中所有块的元数据</li>\n<li>chainstate, 存储了一条链的状态，也就是当前所有的未花费的交易输出，和一些元数据</li>\n</ol>\n<p>此外，出于性能的考虑，Bitcoin Core 将每个区块（block）存储为磁盘上的不同文件。如此一来，就不需要仅仅为了读取一个单一的块而将所有（或者部分）的块都加载到内存中。</p>\n<h5 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h5><p>区块链网络是去中心化的，这意味着没有服务器，客户端也不需要依赖服务器来获取或处理数据。在区块链网络中，有的是节点，每个节点是网络的一个完全（full-fledged）成员。节点就是一切：它既是一个客户端，也是一个服务器。这一点需要牢记于心，因为这与传统的网页应用非常不同。</p>\n<p>区块链网络是一个 P2P（Peer-to-Peer，端到端）的网络，即节点直接连接到其他节点。它的拓扑是扁平的，因为在节点的世界中没有层级之分。每个节点必须与很多其他节点进行交互，它必须请求其他节点的状态，与自己的状态进行比较，当状态过时时进行更新。</p>\n<p>当你发生了一笔支付，你所在的节点就会把这笔交易告诉另一个节点，直至传遍整个网络。矿工从网上收集各种新发生的交易，将它们打包写入区块链。一旦写入成功， 矿工所在节点的区块链，就成为最新版本，其他节点都会来复制新增的区块，保证全网的区块链都是一致的。</p>\n<p>节点角色：</p>\n<ul>\n<li>矿工 这样的节点运行于强大或专用的硬件（比如 ASIC）之上，它们唯一的目标是，尽可能快地挖出新块。矿工是区块链中唯一可能会用到工作量证明的角色，因为挖矿实际上意味着解决 PoW 难题。在权益证明 PoS 的区块链中，没有挖矿。</li>\n<li>全节点 这些节点验证矿工挖出来的块的有效性，并对交易进行确认。为此，他们必须拥有区块链的完整拷贝。同时，全节点执行路由操作，帮助其他节点发现彼此。对于网络来说，非常重要的一段就是要有足够多的全节点。因为正是这些节点执行了决策功能：他们决定了一个块或一笔交易的有效性。</li>\n<li>SPV SPV 表示 Simplified Payment Verification，简单支付验证。这些节点并不存储整个区块链副本，但是仍然能够对交易进行验证（不过不是验证全部交易，而是一个交易子集，比如，发送到某个指定地址的交易）。一个 SPV 节点依赖一个全节点来获取数据，可能有多个 SPV 节点连接到一个全节点。SPV 使得钱包应用成为可能：一个人不需要下载整个区块链，但是仍能够验证他的交易。</li>\n</ul>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h3 id=\"比特币的基本概念及相关认识\"><a href=\"#比特币的基本概念及相关认识\" class=\"headerlink\" title=\"比特币的基本概念及相关认识\"></a>比特币的基本概念及相关认识</h3><p>本篇笔记绝大部分参考自<a href=\"https://github.com/liuchengxu/blockchain-tutorial\">比特币超级详细入门指南</a>以及<a href=\"http://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html\" target=\"_blank\" rel=\"noopener\">阮一峰老师关于区块链的相关博客</a></p>\n<p>区块链本质上是分布式的数据库系统，是开放式的账簿系统(ledger)。</p>\n<p>本质上，区块链就是一个有着特定结构的数据库，是一个有序，每一个块都连接到前一个块的链表。也就是说，区块按照插入的顺序进行存储，每个块都与前一个块相连。这样的结构，能够让我们快速地获取链上的最新块，并且高效地通过哈希来检索一个块。</p>\n<h5 id=\"挖矿（工作量证明）\"><a href=\"#挖矿（工作量证明）\" class=\"headerlink\" title=\"挖矿（工作量证明）\"></a>挖矿（工作量证明）</h5><p>工作量证明是一种共识算法，在比特币中，这个工作就是找到一个块的有效哈希，并证明其有效性。</p>\n<p>获得指定数据的一个哈希值的过程，就叫做哈希计算。一个哈希，就是对所计算数据的一个唯一表示。对于一个哈希函数，输入任意大小的数据，它会输出一个固定大小的哈希值。下面是哈希的几个关键特性：</p>\n<ol>\n<li>无法从一个哈希值恢复原始数据。也就是说，哈希并不是加密。</li>\n<li>对于特定的数据，只能有一个哈希，并且这个哈希是唯一的。</li>\n<li>即使是仅仅改变输入数据中的一个字节，也会导致输出一个完全不同的哈希。</li>\n</ol>\n<p>在区块链中，哈希被用于保证一个块的一致性。哈希算法的输入数据包含了前一个块的哈希，因此使得不太可能（或者，至少很困难）去修改链中的一个块：因为如果一个人想要修改前面一个块的哈希，那么他必须要重新计算这个块以及后面所有块的哈希。</p>\n<p>寻找一个合适的哈希，需要大量的计算，平均是10分钟才能找到一个合适的哈希，生成1个新的区块。</p>\n<h5 id=\"交易\"><a href=\"#交易\" class=\"headerlink\" title=\"交易\"></a>交易</h5><p>比特币中交易分为两种：</p>\n<ol>\n<li>普通交易，输入会引用之前一笔交易的输出。即花费之前的交易输出</li>\n<li>例外，coinbase交易，即挖矿奖励，只有输出</li>\n</ol>\n<p>在交易中，需要注意的是：</p>\n<ul>\n<li>一笔交易的输入可以引用之前多笔交易的输出</li>\n<li>一个输入必须引用一个输出</li>\n<li>没有被引用的输出，即为未花费交易输出</li>\n<li>输出是不可再分的，即一个输出你无法仅引用它的其中某一部分，要么不要，要么一次性用完。当它的值比需要的值大，那么就会产生一个找零，找零会返还给发送方。</li>\n</ul>\n<p>那么，交易的话，需要的是发送方，接收方，交易金额。整个交易的过程如下：</p>\n<ol>\n<li>从发送方中找到足够交易金额的未花费交易输出s(可能是多个输出的叠加)，作为交易的输入</li>\n<li>确定输出，输出有可能为2个，一个是接收方，一个是发送者的找零</li>\n</ol>\n<p>值得注意的是，交易生成后，并不是立刻生效，而是先将交易放到一个内存池中，然后当矿工准备挖出一个新块时，它就从内存池中取出所有交易，创建一个候选块，当包含这些交易的块被挖出来添加到区块链以后，里面的交易才开始确认。</p>\n<h5 id=\"地址\"><a href=\"#地址\" class=\"headerlink\" title=\"地址\"></a>地址</h5><p>当交易发生时，如何校验发送方和接收方呢，没有用户账户，如何查验自己所有的未花费输出呢。在比特币中，校验方式为，密钥对，公钥和私钥。私钥代表的就是你，所有的交易中含有的信息为公钥相关。</p>\n<p>根据协议，公钥的长度是512位。这个长度不太方便传播，因此协议又规定，要为公钥生成一个160位的指纹。所谓指纹，就是一个比较短的、易于传播的哈希值。160位是二进制，写成十六进制，大约是26到35个字符，即地址。</p>\n<p>交易产生时，需要对数据进行签名，签名过程需要被签名的数据和私钥，这个签名会被存储在交易输入中。为了对一个签名进行验证，需要被签名的数据，签名，公钥。所以在一个交易的输入中，这三者都会存储。那么，什么时候进行验证呢，当把交易从内存池中取出来放入到一个块之前，对每一笔交易都要进行验证，验证意味着什么呢，其一是检查交易输入有权使用来自之前交易的输出，其二是检查交易签名是正确的。</p>\n<p>交易过程，一笔交易就是一个地址的比特币转移到另一个地址。申报交易时，除了交易金额，转出比特币的一方还必须提供以下数据：</p>\n<ul>\n<li>上一笔交易的hash(你从哪里得到的这些比特币)</li>\n<li>本次交易双方的地址</li>\n<li>支付方的公钥</li>\n<li>支付方的私钥生成的数字签名</li>\n</ul>\n<p>验证这笔交易是否属实，需要三步：</p>\n<ol>\n<li>找到上一笔交易，确认支付方的比特币来源</li>\n<li>算出支付方公钥的指纹，确认与支付方的地址一直，从而保证公钥属实</li>\n<li>使用公钥去解开数字签名，保证私钥属实</li>\n</ol>\n<p>交易确认，交易必须写入区块链，才算生效。首先，所有的交易数据都会传送到矿工那里，矿工负责把这些交易写入区块链。根据比特币协议，一个区块的大小最大是 1MB，而一笔交易大概是500字节左右，因此一个区块最多可以包含2000多笔交易。矿工负责把这2000多笔交易打包在一起，组成一个区块然后计算这个区块的 Hash（工作量证明）。另外，鉴于区块链分叉的情况，根据比特币协议规定，分叉点最先达到6个区块的那个分支，被认定为正式的区块链，其他分支都将被放弃，所以，一笔交易真正生效，必须等待至少1个小时。</p>\n<p>粘贴一点数据结构，供参考。</p>\n<p>输入结构体定义为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type TXInput struct &#123;</span><br><span class=\"line\">    Txid      []byte  //一个输入引用之前交易的一个输出，txid为之前交易的ID</span><br><span class=\"line\">    Vout      int  //之前交易的输出可能有多个，需要指明是具体哪一个</span><br><span class=\"line\">    Signature []byte //签名</span><br><span class=\"line\">    PubKey    []byte //公钥</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出结构体定义为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type TXOutput struct &#123;</span><br><span class=\"line\">    Value      int  </span><br><span class=\"line\">    PubKeyHash []byte //公钥哈希</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>看到两个结构体的定义，可以想到，签名的作用仅在于到被验证完毕。输出中公钥哈希的使用场景在于校验，例如查找未花费输出时，判断条件为输出中的公钥哈希和当前公钥进行哈希之后是否匹配，还有另外的场景..下面来回顾一下一个交易完整的生命周期。</p>\n<ol>\n<li>起初，创世块里面包含了一个coinbase交易，在coinbase交易中，没有输入，就不需要签名，coinbase交易的输出包含了一个哈希过的公钥（使用的是 <strong>RIPEMD16(SHA256(PubKey))</strong> 算法）</li>\n<li>当有人发送币时，就会创建一笔交易，这笔交易的输入会引用之前交易的输出，还会存储一个公钥(没有被哈希)和整个交易的一个签名</li>\n<li>比特币网络中接收到交易的其他节点会对该交易进行验证，除了一些其他事情，他们还会检查，在一个输入中，公钥哈希与所引用的输出哈希相匹配（这保证了发送方只能花费属于自己的币）；签名是正确的（这保证了交易是由币的实际拥有者所创建）。</li>\n<li>当一个矿工准备挖一个新块时，他会将交易放到块中，然后开始挖矿。</li>\n<li>当新块被挖出来以后，网络中的所有其他节点会接收到一条消息，告诉其他人这个块已经被挖出并被加入到区块链。</li>\n<li>当一个块被加入到区块链以后，交易就算完成，它的输出就可以在新的交易中被引用。</li>\n</ol>\n<p>接下来，就是这其中的一些加密算法啦~</p>\n<ul>\n<li><p>私钥生成算法，椭圆曲线加密</p>\n</li>\n<li><p>地址生成算法，Base58,  如果你想要给某个人发送币，只需要知道他的地址就可以了。当我们给某个人发送币时，我们只知道他的地址，因为这个函数使用一个地址作为唯一的参数。然后，地址会被解码，从中提取出公钥哈希并保存在 <code>PubKeyHash</code> 字段</p>\n</li>\n<li><p>签名的数据，因为用于签名的这个数据，必须要包含能够唯一识别数据的信息。所以需要签名的数据必须包括以下部分</p>\n<ol>\n<li>存储在已解锁输出的公钥哈希。它识别了一笔交易的“发送方”。</li>\n<li>存储在新的锁定输出里面的公钥哈希。它识别了一笔交易的“接收方”。</li>\n<li>新的输出值。</li>\n</ol>\n<p>比特币里， 所签名的并不是一个交易，而是一个去除部分内容的输入副本。</p>\n</li>\n</ul>\n<h5 id=\"UTXO集\"><a href=\"#UTXO集\" class=\"headerlink\" title=\"UTXO集\"></a>UTXO集</h5><p>在查找某个公钥的所有未花费输出时，需要查找所有的区块，区块中的每一笔交易，但是如果区块特别多的情况下，迭代需要的成本就太大了。解决方式就是有一个仅有未花费输出的索引，这就是UTXO集要做的事情，这是一个从所有区块链交易中构建(对区块进行迭代，但是只须做一次)而来的缓存，然后用它来计算余额和验证新的交易。</p>\n<h5 id=\"Merkle树\"><a href=\"#Merkle树\" class=\"headerlink\" title=\"Merkle树\"></a>Merkle树</h5><p>Merkle树为1种优化机制，实现的是每个块中，都有1个Merkle树，树的叶子节点为一个交易哈希，从下往上，两两成对，连接两个节点哈希，将组合哈希作为新的哈希，新的哈希就成为新的树节点，一直到树根，根哈希就会当作是整个块交易的唯一标识，将它保存到区块头，然后用于工作量证明。</p>\n<p>Merkle树的好处就是一个节点可以在不下载整个块的情况下，验证是否包含某笔交易。并且这些只需要一个交易哈希，一个 Merkle 树根哈希和一个 Merkle 路径。</p>\n<h5 id=\"P2PKH\"><a href=\"#P2PKH\" class=\"headerlink\" title=\"P2PKH\"></a>P2PKH</h5><p>在比特币中有一个 <em>脚本（Script）</em>编程语言，它用于锁定交易输出；交易输入提供了解锁输出的数据。这个个脚本叫做 <em>Pay to Public Key Hash(P2PKH)</em>，这是比特币最常用的一个脚本。它所做的事情就是向一个公钥哈希支付，也就是说，用某一个公钥锁定一些币。这是<strong>比特币支付的核心</strong>：没有账户，没有资金转移；只有一个脚本检查提供的签名和公钥是否正确。有了一个这样的脚本语言，实际上也可以让比特币成为一个智能合约平台：除了将一个单一的公钥转移资金，这个语言还使得一些其他的支付方案成为可能。</p>\n<h5 id=\"数据库结构\"><a href=\"#数据库结构\" class=\"headerlink\" title=\"数据库结构\"></a>数据库结构</h5><p>简单来说，Bitcoin Core使用两个”bucket”来存储数据：</p>\n<ol>\n<li>blocks, 它存储了描述一条链中所有块的元数据</li>\n<li>chainstate, 存储了一条链的状态，也就是当前所有的未花费的交易输出，和一些元数据</li>\n</ol>\n<p>此外，出于性能的考虑，Bitcoin Core 将每个区块（block）存储为磁盘上的不同文件。如此一来，就不需要仅仅为了读取一个单一的块而将所有（或者部分）的块都加载到内存中。</p>\n<h5 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h5><p>区块链网络是去中心化的，这意味着没有服务器，客户端也不需要依赖服务器来获取或处理数据。在区块链网络中，有的是节点，每个节点是网络的一个完全（full-fledged）成员。节点就是一切：它既是一个客户端，也是一个服务器。这一点需要牢记于心，因为这与传统的网页应用非常不同。</p>\n<p>区块链网络是一个 P2P（Peer-to-Peer，端到端）的网络，即节点直接连接到其他节点。它的拓扑是扁平的，因为在节点的世界中没有层级之分。每个节点必须与很多其他节点进行交互，它必须请求其他节点的状态，与自己的状态进行比较，当状态过时时进行更新。</p>\n<p>当你发生了一笔支付，你所在的节点就会把这笔交易告诉另一个节点，直至传遍整个网络。矿工从网上收集各种新发生的交易，将它们打包写入区块链。一旦写入成功， 矿工所在节点的区块链，就成为最新版本，其他节点都会来复制新增的区块，保证全网的区块链都是一致的。</p>\n<p>节点角色：</p>\n<ul>\n<li>矿工 这样的节点运行于强大或专用的硬件（比如 ASIC）之上，它们唯一的目标是，尽可能快地挖出新块。矿工是区块链中唯一可能会用到工作量证明的角色，因为挖矿实际上意味着解决 PoW 难题。在权益证明 PoS 的区块链中，没有挖矿。</li>\n<li>全节点 这些节点验证矿工挖出来的块的有效性，并对交易进行确认。为此，他们必须拥有区块链的完整拷贝。同时，全节点执行路由操作，帮助其他节点发现彼此。对于网络来说，非常重要的一段就是要有足够多的全节点。因为正是这些节点执行了决策功能：他们决定了一个块或一笔交易的有效性。</li>\n<li>SPV SPV 表示 Simplified Payment Verification，简单支付验证。这些节点并不存储整个区块链副本，但是仍然能够对交易进行验证（不过不是验证全部交易，而是一个交易子集，比如，发送到某个指定地址的交易）。一个 SPV 节点依赖一个全节点来获取数据，可能有多个 SPV 节点连接到一个全节点。SPV 使得钱包应用成为可能：一个人不需要下载整个区块链，但是仍能够验证他的交易。</li>\n</ul>\n"},{"title":"eth_build","date":"2019-10-14T06:49:01.000Z","_content":"项目选择为go-ethereum，即geth。（原来geth是go-ethereum的简称..）。geth是以太坊、Whisper（去中心化通信协议）和Swarm（去中心化文件系统）节点的一个实现。用于接入以太坊网络，进行账户管理、交易、挖矿、智能合约相关的操作的以太坊客户端。另外，geth是一种CLI应用。\n\n\n\n环境配置\n\n环境为mac\n\n按照[官方文档]( )进行配置就好。采用的是克隆go-ethereum仓库的方式进行配置。\n\n注意的点是，go版本很关键。刚开始下载的go版本就为1.7.+,然后在进行make geth的时候报错了..然后重新brew install go，搞到go版本1.10.+，然后进行make geth还是报错..无奈下载官方建议1.9.+，顺利通过...\n\n\n\nmake解读，使用make命令时调用makefile文件，查看makefile代码，其实make all/make geth其实就是使用go对cmd/目录下各工具进行代码打包成可执行文件。生成文件位于cmd/bin下。\n\n\n\nmake完成后将cmd/bin目录添加到环境变量中，方便之后使用。\n\n\n\n创建3个目录文件夹，分别存放3个账户数据。 —datadir node1 为指定Data directory for the databases and keystore。创建3个账户\n\n```\nxiaoxuez$ ls\nnode1\tnode2\tnode3\nxiaoxuez$ geth --datadir node1 account new\n```\n\n\n\n生成创世块，需要定义.json文件，puppeth工具可以帮忙快速生成创世快文件。puppeth源代码位于cmd/下，make的时候如果只make etheruem的话就只会生成ethereum的可执行文件，make all就都有了~  实在没有的话就单独生成一次。可参照\n\n```\nbuild/env.sh go run build/ci.go install ./cmd/puppeth/\n```\n\n回到正题，puppeth的使用直接见命令行\n\n```\n$ puppeth\n+-----------------------------------------------------------+\n| Welcome to puppeth, your Ethereum private network manager |\n|                                                           |\n| This tool lets you create a new Ethereum network down to  |\n| the genesis block, bootnodes, miners and ethstats servers |\n| without the hassle that it would normally entail.         |\n|                                                           |\n| Puppeth uses SSH to dial in to remote servers, and builds |\n| its network components out of Docker containers using the |\n| docker-compose toolset.                                   |\n+-----------------------------------------------------------+\n\nPlease specify a network name to administer (no spaces or hyphens, please)\n> helloworldprivate\n\nSweet, you can set this via --network=helloworldprivate next time!\n\nINFO [04-10|13:45:58] Administering Ethereum network           name=helloworldprivate\nWARN [04-10|13:45:58] No previous configurations found         path=/Users/xiaoxuez/.puppeth/helloworldprivate\n\nWhat would you like to do? (default = stats)\n 1. Show network stats\n 2. Configure new genesis\n 3. Track new remote server\n 4. Deploy network components\n> 2\n\nWhich consensus engine to use? (default = clique) #共识选择，可直接选择pow,这里我选择的是poa,(不消耗计算力, 可以用于私链测试开发)\n 1. Ethash - proof-of-work\n 2. Clique - proof-of-authority\n> 2\n\nHow many seconds should blocks take? (default = 15)  #5s出一个块\n> 5\n\nWhich accounts are allowed to seal? (mandatory at least one)  #输入有签名权限的账户\n> 0x1186c97871079e86e9adcf11f56b90caa3619ea4\n> 0x34c72adc7499cce01530dc27e67810a79fdbd8ea\n> 0xb37fe8ba7afbeb5e57139e55e737a34574e91a74\n> 0x\n\nWhich accounts should be pre-funded? (advisable at least one)  #输入有预留余额的账户\n> 0xb37fe8ba7afbeb5e57139e55e737a34574e91a74\n> 0x34c72adc7499cce01530dc27e67810a79fdbd8ea\n> 0x1186c97871079e86e9adcf11f56b90caa3619ea4\n> 0x\n\nSpecify your chain/network ID if you want an explicit one (default = random) #输入私链ID, 直接输入回车,已默认随机数作为私链ID\n>\nINFO [04-10|13:47:49] Configured new genesis block\n\nWhat would you like to do? (default = stats)\n 1. Show network stats\n 2. Manage existing genesis\n 3. Track new remote server\n 4. Deploy network components\n> 2\n\n 1. Modify existing fork rules\n 2. Export genesis configuration\n 3. Remove genesis configuration\n> 2\n\nWhich file to save the genesis into? (default = helloworldprivate.json)\n>\nINFO [04-10|13:48:00] Exported existing genesis block\n\nWhat would you like to do? (default = stats)\n 1. Show network stats\n 2. Manage existing genesis\n 3. Track new remote server\n 4. Deploy network components\n> ^C\n$ ls  #结束后会在当前文件夹下看到导出的.json文件\nhelloworldprivate.json\tnode1\t\t\tnode2\t\t\tnode3\n\n```\n\n\n\n接下来就是使用.json文件生成创世块了\n\n```\n#init:Bootstrap and initialize a new genesis block\n$ geth --datadir node1 init helloworldprivate.json\n$ geth --datadir node1 --port 30000 --nodiscover --unlock '0' --password ./node1/password console\n#启动geth, --port: Network listening port ，指定和其他节点链接所用的端口号\n#               --nodiscover: Disables the peer discovery mechanism (manual peer addition)关闭节点发现机制，防止加入有同样初始配置的陌生节点，后续手动配置节点网络，\n#               --unlock: Comma separated list of accounts to unlock, 解锁的账户，以逗号分隔，账户要转帐或者部署合约，需要先解锁\n#               console: 进入控制台，不加console的话，也可在geth启动后通过geth attach\nipc:node0/geth.ipc来访问\n#               --rpc: 表示开启http-rpc服务\n                --rpcport: 指定http-rpc服务监听端口，默认为8545\n                --ws:\n                --wsport:\n                --allow-insecure-unlock\n\n\n```\n\n同样，目前启动3个节点，使用不同端口来模拟多节点，另起终端\n\n```\n$ geth --datadir node2 init helloworldprivate.json\n$ geth --datadir node2 --port 30001 --nodiscover --unlock '0' --password ./node2/password console\n\n$ geth --datadir node3 init helloworldprivate.json\n$ geth --datadir node3 --port 30002 --nodiscover --unlock '0' --password ./node3/password console\n```\n\n三个启动时候unlock 的值都是'0',  之前在每个节点文件下都只创建了一个账户，所以解锁的就是各个节点下的账户，即目前三个账户都是解锁。这里的小疑问是要起3个初始块，猜测是相同初始配置的节点才能加入到同一个网络中。\n\nconsole进入的控制台是一个交互式的JavaScript执行环境，在这里面可以执行JavaScript代码。这个环境里也内置了一些用来操作以太坊的JavaScript对象，例如\n\n- eth：包含一些跟操作区块链相关的方法；\n- net：包含一些查看p2p网络状态的方法；\n- admin：包含一些与管理节点相关的方法；\n- miner：包含启动&停止挖矿的一些方法；\n- personal：主要包含一些管理账户的方法；\n- txpool：包含一些查看交易内存池的方法；\n- web3：包含了以上对象，还包含一些单位换算的方法。\n\n\n\n常见命令有：\n\n- personal.newAccount()：创建账户；\n\n- personal.unlockAccount()：解锁账户；\n\n- eth.accounts：枚举系统中的账户；\n\n- eth.getBalance()：查看账户余额，返回值的单位是 Wei（Wei 是以太坊中最小货币面额单位，类似比特币中的`聪`，1 ether = 10^18 Wei）； `web3.fromWei(eth.getBalance(e), \"ether\") `\n\n  `web3.toWei('1', 'ether')`\n\n\n\n- eth.blockNumber：列出区块总数；blockNumber为eth的属性，直接查看即可\n\n- eth.getTransaction()：获取交易；\n\n- eth.getBlock()：获取区块；如eth.getBlock(\"pending\", true).transactions 查看当前待确认交易。或通过区块号查看eth.getBlock(4)\n\n- miner.start()：开始挖矿；\n\n- miner.stop()：停止挖矿；\n\n- web3.fromWei()：Wei 换算成以太币；\n\n- web3.toWei()：以太币换算成 Wei；如amount = web3.toWei(5,'ether')\n\n- txpool.status：交易池中的状态；\n\n- admin.addPeer()：连接到其他节点；\n\n\n\n接下来，添加peer节点\n\n```\n> admin.peers #查看当前节点链接的节点\n> net.peerCount #查看当前节点链接的节点数\n```\n\n目前三个节点都是没有链接的，所以admin.peers的结果为[]。\n\n\n\n```\n> admin.nodeInfo.enode #查看节点地址，地址组成为encode://<节点id>@ip地址：端口\n\"enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0\"\n```\n\n查看node1节点地址，在node2, node3的console中使用admin.addPeer，将node1分别添加到node2,node3中\n\n```\n> admin.addPeer(\"enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0\")\n\n```\n\n再使用admin.peers查看的时候，可以看到node1链接上2个节点（node2, node3）,node2和node3各自链接上1个节点（node1）\n\n也可使用配置文件的形式添加节点，在节点的datadir下新建static-node.json, 将需要连接的节点地址写入，如：\n\n```\n[\n\"enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0\",\n\"enode://79671ba7d09a4e6d16a64128e2cb24f544ec8740084e1ceb1abcac7b1c2b8a37dae812653360caf30ceff782265b124c1e6ce1d547dc6854bafb85596795751c@[::]:30001?discport=0\",\n\"enode://3237c4eaf0dbf55b459eef14c4ecffe987b5179e482399b282bc5ab3d1559dd8461a9d39460810bf0d8c276fb13a9950eca5c38890dbf11d9dccdb1b61231a78@[::]:30002?discport=0\"\n]\n```\n\n或者直接在geth启动行中添加 - -bootnodes enode:….\n\n那么在geth启动的时候会自动链接。链接到的节点就互相发现组成以太坊私链网络了\n\n\n\n当组成网络之后，就可以开始挖矿了。在某个节点下，调用miner.start()\n\n```\n> miner.start()\nINFO [04-10|17:59:10] Transaction pool price threshold updated price=18000000000\nINFO [04-10|17:59:10] Starting mining operation\nnull\n> INFO [04-10|17:59:10] Commit new mining work                   number=1 txs=2 uncles=0 elapsed=1.058ms\nINFO [04-10|17:59:10] Successfully sealed new block            number=1 hash=3b7e10…38d85e\nINFO [04-10|17:59:10] 🔨 mined potential block                  number=1 hash=3b7e10…38d85e\nINFO [04-10|17:59:10] Commit new mining work                   number=2 txs=0 uncles=0 elapsed=285.156µs\nINFO [04-10|17:59:15] Successfully sealed new block            number=2 hash=1bb861…fbcb78\n```\n\n正常情况是这个样子..  不正常的情况，其一需要先解锁账户\n\n```\nWARN [04-10|17:55:49] Block sealing failed                     err=\"authentication needed: password or unlock\"\n> personal.unlockAccount(eth.accounts[0])\n```\n\n其二，如下\n\n```\n> miner.start()\n\nnull\n```\n\n返回null, 是不得行的~，解决方式如下\n\n```\n> miner.setEtherbase(eth.accounts[0])\ntrue\n> miner.start()\n```\n\n\n\n在某个节点下，提交一个交易，如,  to为账户地址，查看账户地址为eth.accounts\n\n```\n> eth.sendTransaction({from: eth.accounts[0], to: \"b6deeb049de5fb90345b5b84dd1faf2d56c6929e\", value: web3.toWei(200, \"ether\")})\n```\n\n\n\n如果miner没有关掉的话，几秒后就会有含有交易的block产出,  txs为block包含的交易数\n\n```\nINFO [04-10|17:59:15] Imported new chain segment               blocks=2 txs=1 mgas=0.042 elapsed=1.348ms  mgasps=31.157 number=2 hash=1bb861…fbcb78 cache=2.47kB\n```\n\n\n\n挖矿，挖到一个区块之后就停止挖矿可使用\n\n```\n> miner.start(1);admin.sleepBlocks(1);miner.stop();\n```\n\n当然，还有可能是网速原因… 过几分钟再试就好了。\n\n\n\n\n\n智能合约\n\n```\nbrew install solc\n```\n\n…..\n\n\n\n\n\n```\ngeth attach http://0.0.0.0:1112\n\n\n\n\"/Applications/Ethereum Wallet.app/Contents/MacOS/Ethereum Wallet\" --rpc http://localhost:8545\n\n\n\n    --rpcapi=\"db,eth,net,web3,personal,web3\" --rpc --rpcaddr 0.0.0.0 -rpcport 1112 --mine\n\n\n\neth.sendTransaction({from:eth.accounts[0], data:\"0x0100f862a00000000000000000000000000000000000000000000000000000000000000000a00000000000000000000000000000000000000000000000000000000000000000809471562b71999873db5b286df957af199ec94617f78568656c6c6f80808080\"})\n\n\n\n```\n\n\n\n\n\n编译android\n\n```\nmake android\n\n./build/env.sh xgo --go=latest --dest=build/bin -v --targets=android-23/arm64 ./cmd/geth\n\nglide mirror set golang.org/x/text  /home/users/qiangmzsx/var/golang/golang.org/x/text\n\n\n\n```\n\n\n\n\n\n```\neth.sendTransaction({from: eth.accounts[0], to: \"0x71562b71999873DB5b286dF957af199Ec94617F7\", value: 200000})\n```\n","source":"_posts/eth-build.md","raw":"---\ntitle: eth_build\ncategories:\n  - eth\ndate: 2019-10-14 14:49:01\ntags:\n---\n项目选择为go-ethereum，即geth。（原来geth是go-ethereum的简称..）。geth是以太坊、Whisper（去中心化通信协议）和Swarm（去中心化文件系统）节点的一个实现。用于接入以太坊网络，进行账户管理、交易、挖矿、智能合约相关的操作的以太坊客户端。另外，geth是一种CLI应用。\n\n\n\n环境配置\n\n环境为mac\n\n按照[官方文档]( )进行配置就好。采用的是克隆go-ethereum仓库的方式进行配置。\n\n注意的点是，go版本很关键。刚开始下载的go版本就为1.7.+,然后在进行make geth的时候报错了..然后重新brew install go，搞到go版本1.10.+，然后进行make geth还是报错..无奈下载官方建议1.9.+，顺利通过...\n\n\n\nmake解读，使用make命令时调用makefile文件，查看makefile代码，其实make all/make geth其实就是使用go对cmd/目录下各工具进行代码打包成可执行文件。生成文件位于cmd/bin下。\n\n\n\nmake完成后将cmd/bin目录添加到环境变量中，方便之后使用。\n\n\n\n创建3个目录文件夹，分别存放3个账户数据。 —datadir node1 为指定Data directory for the databases and keystore。创建3个账户\n\n```\nxiaoxuez$ ls\nnode1\tnode2\tnode3\nxiaoxuez$ geth --datadir node1 account new\n```\n\n\n\n生成创世块，需要定义.json文件，puppeth工具可以帮忙快速生成创世快文件。puppeth源代码位于cmd/下，make的时候如果只make etheruem的话就只会生成ethereum的可执行文件，make all就都有了~  实在没有的话就单独生成一次。可参照\n\n```\nbuild/env.sh go run build/ci.go install ./cmd/puppeth/\n```\n\n回到正题，puppeth的使用直接见命令行\n\n```\n$ puppeth\n+-----------------------------------------------------------+\n| Welcome to puppeth, your Ethereum private network manager |\n|                                                           |\n| This tool lets you create a new Ethereum network down to  |\n| the genesis block, bootnodes, miners and ethstats servers |\n| without the hassle that it would normally entail.         |\n|                                                           |\n| Puppeth uses SSH to dial in to remote servers, and builds |\n| its network components out of Docker containers using the |\n| docker-compose toolset.                                   |\n+-----------------------------------------------------------+\n\nPlease specify a network name to administer (no spaces or hyphens, please)\n> helloworldprivate\n\nSweet, you can set this via --network=helloworldprivate next time!\n\nINFO [04-10|13:45:58] Administering Ethereum network           name=helloworldprivate\nWARN [04-10|13:45:58] No previous configurations found         path=/Users/xiaoxuez/.puppeth/helloworldprivate\n\nWhat would you like to do? (default = stats)\n 1. Show network stats\n 2. Configure new genesis\n 3. Track new remote server\n 4. Deploy network components\n> 2\n\nWhich consensus engine to use? (default = clique) #共识选择，可直接选择pow,这里我选择的是poa,(不消耗计算力, 可以用于私链测试开发)\n 1. Ethash - proof-of-work\n 2. Clique - proof-of-authority\n> 2\n\nHow many seconds should blocks take? (default = 15)  #5s出一个块\n> 5\n\nWhich accounts are allowed to seal? (mandatory at least one)  #输入有签名权限的账户\n> 0x1186c97871079e86e9adcf11f56b90caa3619ea4\n> 0x34c72adc7499cce01530dc27e67810a79fdbd8ea\n> 0xb37fe8ba7afbeb5e57139e55e737a34574e91a74\n> 0x\n\nWhich accounts should be pre-funded? (advisable at least one)  #输入有预留余额的账户\n> 0xb37fe8ba7afbeb5e57139e55e737a34574e91a74\n> 0x34c72adc7499cce01530dc27e67810a79fdbd8ea\n> 0x1186c97871079e86e9adcf11f56b90caa3619ea4\n> 0x\n\nSpecify your chain/network ID if you want an explicit one (default = random) #输入私链ID, 直接输入回车,已默认随机数作为私链ID\n>\nINFO [04-10|13:47:49] Configured new genesis block\n\nWhat would you like to do? (default = stats)\n 1. Show network stats\n 2. Manage existing genesis\n 3. Track new remote server\n 4. Deploy network components\n> 2\n\n 1. Modify existing fork rules\n 2. Export genesis configuration\n 3. Remove genesis configuration\n> 2\n\nWhich file to save the genesis into? (default = helloworldprivate.json)\n>\nINFO [04-10|13:48:00] Exported existing genesis block\n\nWhat would you like to do? (default = stats)\n 1. Show network stats\n 2. Manage existing genesis\n 3. Track new remote server\n 4. Deploy network components\n> ^C\n$ ls  #结束后会在当前文件夹下看到导出的.json文件\nhelloworldprivate.json\tnode1\t\t\tnode2\t\t\tnode3\n\n```\n\n\n\n接下来就是使用.json文件生成创世块了\n\n```\n#init:Bootstrap and initialize a new genesis block\n$ geth --datadir node1 init helloworldprivate.json\n$ geth --datadir node1 --port 30000 --nodiscover --unlock '0' --password ./node1/password console\n#启动geth, --port: Network listening port ，指定和其他节点链接所用的端口号\n#               --nodiscover: Disables the peer discovery mechanism (manual peer addition)关闭节点发现机制，防止加入有同样初始配置的陌生节点，后续手动配置节点网络，\n#               --unlock: Comma separated list of accounts to unlock, 解锁的账户，以逗号分隔，账户要转帐或者部署合约，需要先解锁\n#               console: 进入控制台，不加console的话，也可在geth启动后通过geth attach\nipc:node0/geth.ipc来访问\n#               --rpc: 表示开启http-rpc服务\n                --rpcport: 指定http-rpc服务监听端口，默认为8545\n                --ws:\n                --wsport:\n                --allow-insecure-unlock\n\n\n```\n\n同样，目前启动3个节点，使用不同端口来模拟多节点，另起终端\n\n```\n$ geth --datadir node2 init helloworldprivate.json\n$ geth --datadir node2 --port 30001 --nodiscover --unlock '0' --password ./node2/password console\n\n$ geth --datadir node3 init helloworldprivate.json\n$ geth --datadir node3 --port 30002 --nodiscover --unlock '0' --password ./node3/password console\n```\n\n三个启动时候unlock 的值都是'0',  之前在每个节点文件下都只创建了一个账户，所以解锁的就是各个节点下的账户，即目前三个账户都是解锁。这里的小疑问是要起3个初始块，猜测是相同初始配置的节点才能加入到同一个网络中。\n\nconsole进入的控制台是一个交互式的JavaScript执行环境，在这里面可以执行JavaScript代码。这个环境里也内置了一些用来操作以太坊的JavaScript对象，例如\n\n- eth：包含一些跟操作区块链相关的方法；\n- net：包含一些查看p2p网络状态的方法；\n- admin：包含一些与管理节点相关的方法；\n- miner：包含启动&停止挖矿的一些方法；\n- personal：主要包含一些管理账户的方法；\n- txpool：包含一些查看交易内存池的方法；\n- web3：包含了以上对象，还包含一些单位换算的方法。\n\n\n\n常见命令有：\n\n- personal.newAccount()：创建账户；\n\n- personal.unlockAccount()：解锁账户；\n\n- eth.accounts：枚举系统中的账户；\n\n- eth.getBalance()：查看账户余额，返回值的单位是 Wei（Wei 是以太坊中最小货币面额单位，类似比特币中的`聪`，1 ether = 10^18 Wei）； `web3.fromWei(eth.getBalance(e), \"ether\") `\n\n  `web3.toWei('1', 'ether')`\n\n\n\n- eth.blockNumber：列出区块总数；blockNumber为eth的属性，直接查看即可\n\n- eth.getTransaction()：获取交易；\n\n- eth.getBlock()：获取区块；如eth.getBlock(\"pending\", true).transactions 查看当前待确认交易。或通过区块号查看eth.getBlock(4)\n\n- miner.start()：开始挖矿；\n\n- miner.stop()：停止挖矿；\n\n- web3.fromWei()：Wei 换算成以太币；\n\n- web3.toWei()：以太币换算成 Wei；如amount = web3.toWei(5,'ether')\n\n- txpool.status：交易池中的状态；\n\n- admin.addPeer()：连接到其他节点；\n\n\n\n接下来，添加peer节点\n\n```\n> admin.peers #查看当前节点链接的节点\n> net.peerCount #查看当前节点链接的节点数\n```\n\n目前三个节点都是没有链接的，所以admin.peers的结果为[]。\n\n\n\n```\n> admin.nodeInfo.enode #查看节点地址，地址组成为encode://<节点id>@ip地址：端口\n\"enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0\"\n```\n\n查看node1节点地址，在node2, node3的console中使用admin.addPeer，将node1分别添加到node2,node3中\n\n```\n> admin.addPeer(\"enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0\")\n\n```\n\n再使用admin.peers查看的时候，可以看到node1链接上2个节点（node2, node3）,node2和node3各自链接上1个节点（node1）\n\n也可使用配置文件的形式添加节点，在节点的datadir下新建static-node.json, 将需要连接的节点地址写入，如：\n\n```\n[\n\"enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0\",\n\"enode://79671ba7d09a4e6d16a64128e2cb24f544ec8740084e1ceb1abcac7b1c2b8a37dae812653360caf30ceff782265b124c1e6ce1d547dc6854bafb85596795751c@[::]:30001?discport=0\",\n\"enode://3237c4eaf0dbf55b459eef14c4ecffe987b5179e482399b282bc5ab3d1559dd8461a9d39460810bf0d8c276fb13a9950eca5c38890dbf11d9dccdb1b61231a78@[::]:30002?discport=0\"\n]\n```\n\n或者直接在geth启动行中添加 - -bootnodes enode:….\n\n那么在geth启动的时候会自动链接。链接到的节点就互相发现组成以太坊私链网络了\n\n\n\n当组成网络之后，就可以开始挖矿了。在某个节点下，调用miner.start()\n\n```\n> miner.start()\nINFO [04-10|17:59:10] Transaction pool price threshold updated price=18000000000\nINFO [04-10|17:59:10] Starting mining operation\nnull\n> INFO [04-10|17:59:10] Commit new mining work                   number=1 txs=2 uncles=0 elapsed=1.058ms\nINFO [04-10|17:59:10] Successfully sealed new block            number=1 hash=3b7e10…38d85e\nINFO [04-10|17:59:10] 🔨 mined potential block                  number=1 hash=3b7e10…38d85e\nINFO [04-10|17:59:10] Commit new mining work                   number=2 txs=0 uncles=0 elapsed=285.156µs\nINFO [04-10|17:59:15] Successfully sealed new block            number=2 hash=1bb861…fbcb78\n```\n\n正常情况是这个样子..  不正常的情况，其一需要先解锁账户\n\n```\nWARN [04-10|17:55:49] Block sealing failed                     err=\"authentication needed: password or unlock\"\n> personal.unlockAccount(eth.accounts[0])\n```\n\n其二，如下\n\n```\n> miner.start()\n\nnull\n```\n\n返回null, 是不得行的~，解决方式如下\n\n```\n> miner.setEtherbase(eth.accounts[0])\ntrue\n> miner.start()\n```\n\n\n\n在某个节点下，提交一个交易，如,  to为账户地址，查看账户地址为eth.accounts\n\n```\n> eth.sendTransaction({from: eth.accounts[0], to: \"b6deeb049de5fb90345b5b84dd1faf2d56c6929e\", value: web3.toWei(200, \"ether\")})\n```\n\n\n\n如果miner没有关掉的话，几秒后就会有含有交易的block产出,  txs为block包含的交易数\n\n```\nINFO [04-10|17:59:15] Imported new chain segment               blocks=2 txs=1 mgas=0.042 elapsed=1.348ms  mgasps=31.157 number=2 hash=1bb861…fbcb78 cache=2.47kB\n```\n\n\n\n挖矿，挖到一个区块之后就停止挖矿可使用\n\n```\n> miner.start(1);admin.sleepBlocks(1);miner.stop();\n```\n\n当然，还有可能是网速原因… 过几分钟再试就好了。\n\n\n\n\n\n智能合约\n\n```\nbrew install solc\n```\n\n…..\n\n\n\n\n\n```\ngeth attach http://0.0.0.0:1112\n\n\n\n\"/Applications/Ethereum Wallet.app/Contents/MacOS/Ethereum Wallet\" --rpc http://localhost:8545\n\n\n\n    --rpcapi=\"db,eth,net,web3,personal,web3\" --rpc --rpcaddr 0.0.0.0 -rpcport 1112 --mine\n\n\n\neth.sendTransaction({from:eth.accounts[0], data:\"0x0100f862a00000000000000000000000000000000000000000000000000000000000000000a00000000000000000000000000000000000000000000000000000000000000000809471562b71999873db5b286df957af199ec94617f78568656c6c6f80808080\"})\n\n\n\n```\n\n\n\n\n\n编译android\n\n```\nmake android\n\n./build/env.sh xgo --go=latest --dest=build/bin -v --targets=android-23/arm64 ./cmd/geth\n\nglide mirror set golang.org/x/text  /home/users/qiangmzsx/var/golang/golang.org/x/text\n\n\n\n```\n\n\n\n\n\n```\neth.sendTransaction({from: eth.accounts[0], to: \"0x71562b71999873DB5b286dF957af199Ec94617F7\", value: 200000})\n```\n","slug":"eth-build","published":1,"updated":"2019-10-14T06:49:59.618Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69ww0022t6xvema0rqo6","content":"<p>项目选择为go-ethereum，即geth。（原来geth是go-ethereum的简称..）。geth是以太坊、Whisper（去中心化通信协议）和Swarm（去中心化文件系统）节点的一个实现。用于接入以太坊网络，进行账户管理、交易、挖矿、智能合约相关的操作的以太坊客户端。另外，geth是一种CLI应用。</p>\n<p>环境配置</p>\n<p>环境为mac</p>\n<p>按照<a href>官方文档</a>进行配置就好。采用的是克隆go-ethereum仓库的方式进行配置。</p>\n<p>注意的点是，go版本很关键。刚开始下载的go版本就为1.7.+,然后在进行make geth的时候报错了..然后重新brew install go，搞到go版本1.10.+，然后进行make geth还是报错..无奈下载官方建议1.9.+，顺利通过…</p>\n<p>make解读，使用make命令时调用makefile文件，查看makefile代码，其实make all/make geth其实就是使用go对cmd/目录下各工具进行代码打包成可执行文件。生成文件位于cmd/bin下。</p>\n<p>make完成后将cmd/bin目录添加到环境变量中，方便之后使用。</p>\n<p>创建3个目录文件夹，分别存放3个账户数据。 —datadir node1 为指定Data directory for the databases and keystore。创建3个账户</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xiaoxuez$ ls</span><br><span class=\"line\">node1\tnode2\tnode3</span><br><span class=\"line\">xiaoxuez$ geth --datadir node1 account new</span><br></pre></td></tr></table></figure>\n\n<p>生成创世块，需要定义.json文件，puppeth工具可以帮忙快速生成创世快文件。puppeth源代码位于cmd/下，make的时候如果只make etheruem的话就只会生成ethereum的可执行文件，make all就都有了~  实在没有的话就单独生成一次。可参照</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">build/env.sh go run build/ci.go install ./cmd/puppeth/</span><br></pre></td></tr></table></figure>\n\n<p>回到正题，puppeth的使用直接见命令行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ puppeth</span><br><span class=\"line\">+-----------------------------------------------------------+</span><br><span class=\"line\">| Welcome to puppeth, your Ethereum private network manager |</span><br><span class=\"line\">|                                                           |</span><br><span class=\"line\">| This tool lets you create a new Ethereum network down to  |</span><br><span class=\"line\">| the genesis block, bootnodes, miners and ethstats servers |</span><br><span class=\"line\">| without the hassle that it would normally entail.         |</span><br><span class=\"line\">|                                                           |</span><br><span class=\"line\">| Puppeth uses SSH to dial in to remote servers, and builds |</span><br><span class=\"line\">| its network components out of Docker containers using the |</span><br><span class=\"line\">| docker-compose toolset.                                   |</span><br><span class=\"line\">+-----------------------------------------------------------+</span><br><span class=\"line\"></span><br><span class=\"line\">Please specify a network name to administer (no spaces or hyphens, please)</span><br><span class=\"line\">&gt; helloworldprivate</span><br><span class=\"line\"></span><br><span class=\"line\">Sweet, you can set this via --network=helloworldprivate next time!</span><br><span class=\"line\"></span><br><span class=\"line\">INFO [04-10|13:45:58] Administering Ethereum network           name=helloworldprivate</span><br><span class=\"line\">WARN [04-10|13:45:58] No previous configurations found         path=/Users/xiaoxuez/.puppeth/helloworldprivate</span><br><span class=\"line\"></span><br><span class=\"line\">What would you like to do? (default = stats)</span><br><span class=\"line\"> 1. Show network stats</span><br><span class=\"line\"> 2. Configure new genesis</span><br><span class=\"line\"> 3. Track new remote server</span><br><span class=\"line\"> 4. Deploy network components</span><br><span class=\"line\">&gt; 2</span><br><span class=\"line\"></span><br><span class=\"line\">Which consensus engine to use? (default = clique) #共识选择，可直接选择pow,这里我选择的是poa,(不消耗计算力, 可以用于私链测试开发)</span><br><span class=\"line\"> 1. Ethash - proof-of-work</span><br><span class=\"line\"> 2. Clique - proof-of-authority</span><br><span class=\"line\">&gt; 2</span><br><span class=\"line\"></span><br><span class=\"line\">How many seconds should blocks take? (default = 15)  #5s出一个块</span><br><span class=\"line\">&gt; 5</span><br><span class=\"line\"></span><br><span class=\"line\">Which accounts are allowed to seal? (mandatory at least one)  #输入有签名权限的账户</span><br><span class=\"line\">&gt; 0x1186c97871079e86e9adcf11f56b90caa3619ea4</span><br><span class=\"line\">&gt; 0x34c72adc7499cce01530dc27e67810a79fdbd8ea</span><br><span class=\"line\">&gt; 0xb37fe8ba7afbeb5e57139e55e737a34574e91a74</span><br><span class=\"line\">&gt; 0x</span><br><span class=\"line\"></span><br><span class=\"line\">Which accounts should be pre-funded? (advisable at least one)  #输入有预留余额的账户</span><br><span class=\"line\">&gt; 0xb37fe8ba7afbeb5e57139e55e737a34574e91a74</span><br><span class=\"line\">&gt; 0x34c72adc7499cce01530dc27e67810a79fdbd8ea</span><br><span class=\"line\">&gt; 0x1186c97871079e86e9adcf11f56b90caa3619ea4</span><br><span class=\"line\">&gt; 0x</span><br><span class=\"line\"></span><br><span class=\"line\">Specify your chain/network ID if you want an explicit one (default = random) #输入私链ID, 直接输入回车,已默认随机数作为私链ID</span><br><span class=\"line\">&gt;</span><br><span class=\"line\">INFO [04-10|13:47:49] Configured new genesis block</span><br><span class=\"line\"></span><br><span class=\"line\">What would you like to do? (default = stats)</span><br><span class=\"line\"> 1. Show network stats</span><br><span class=\"line\"> 2. Manage existing genesis</span><br><span class=\"line\"> 3. Track new remote server</span><br><span class=\"line\"> 4. Deploy network components</span><br><span class=\"line\">&gt; 2</span><br><span class=\"line\"></span><br><span class=\"line\"> 1. Modify existing fork rules</span><br><span class=\"line\"> 2. Export genesis configuration</span><br><span class=\"line\"> 3. Remove genesis configuration</span><br><span class=\"line\">&gt; 2</span><br><span class=\"line\"></span><br><span class=\"line\">Which file to save the genesis into? (default = helloworldprivate.json)</span><br><span class=\"line\">&gt;</span><br><span class=\"line\">INFO [04-10|13:48:00] Exported existing genesis block</span><br><span class=\"line\"></span><br><span class=\"line\">What would you like to do? (default = stats)</span><br><span class=\"line\"> 1. Show network stats</span><br><span class=\"line\"> 2. Manage existing genesis</span><br><span class=\"line\"> 3. Track new remote server</span><br><span class=\"line\"> 4. Deploy network components</span><br><span class=\"line\">&gt; ^C</span><br><span class=\"line\">$ ls  #结束后会在当前文件夹下看到导出的.json文件</span><br><span class=\"line\">helloworldprivate.json\tnode1\t\t\tnode2\t\t\tnode3</span><br></pre></td></tr></table></figure>\n\n<p>接下来就是使用.json文件生成创世块了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#init:Bootstrap and initialize a new genesis block</span><br><span class=\"line\">$ geth --datadir node1 init helloworldprivate.json</span><br><span class=\"line\">$ geth --datadir node1 --port 30000 --nodiscover --unlock &apos;0&apos; --password ./node1/password console</span><br><span class=\"line\">#启动geth, --port: Network listening port ，指定和其他节点链接所用的端口号</span><br><span class=\"line\">#               --nodiscover: Disables the peer discovery mechanism (manual peer addition)关闭节点发现机制，防止加入有同样初始配置的陌生节点，后续手动配置节点网络，</span><br><span class=\"line\">#               --unlock: Comma separated list of accounts to unlock, 解锁的账户，以逗号分隔，账户要转帐或者部署合约，需要先解锁</span><br><span class=\"line\">#               console: 进入控制台，不加console的话，也可在geth启动后通过geth attach</span><br><span class=\"line\">ipc:node0/geth.ipc来访问</span><br><span class=\"line\">#               --rpc: 表示开启http-rpc服务</span><br><span class=\"line\">                --rpcport: 指定http-rpc服务监听端口，默认为8545</span><br><span class=\"line\">                --ws:</span><br><span class=\"line\">                --wsport:</span><br><span class=\"line\">                --allow-insecure-unlock</span><br></pre></td></tr></table></figure>\n\n<p>同样，目前启动3个节点，使用不同端口来模拟多节点，另起终端</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ geth --datadir node2 init helloworldprivate.json</span><br><span class=\"line\">$ geth --datadir node2 --port 30001 --nodiscover --unlock &apos;0&apos; --password ./node2/password console</span><br><span class=\"line\"></span><br><span class=\"line\">$ geth --datadir node3 init helloworldprivate.json</span><br><span class=\"line\">$ geth --datadir node3 --port 30002 --nodiscover --unlock &apos;0&apos; --password ./node3/password console</span><br></pre></td></tr></table></figure>\n\n<p>三个启动时候unlock 的值都是’0’,  之前在每个节点文件下都只创建了一个账户，所以解锁的就是各个节点下的账户，即目前三个账户都是解锁。这里的小疑问是要起3个初始块，猜测是相同初始配置的节点才能加入到同一个网络中。</p>\n<p>console进入的控制台是一个交互式的JavaScript执行环境，在这里面可以执行JavaScript代码。这个环境里也内置了一些用来操作以太坊的JavaScript对象，例如</p>\n<ul>\n<li>eth：包含一些跟操作区块链相关的方法；</li>\n<li>net：包含一些查看p2p网络状态的方法；</li>\n<li>admin：包含一些与管理节点相关的方法；</li>\n<li>miner：包含启动&amp;停止挖矿的一些方法；</li>\n<li>personal：主要包含一些管理账户的方法；</li>\n<li>txpool：包含一些查看交易内存池的方法；</li>\n<li>web3：包含了以上对象，还包含一些单位换算的方法。</li>\n</ul>\n<p>常见命令有：</p>\n<ul>\n<li><p>personal.newAccount()：创建账户；</p>\n</li>\n<li><p>personal.unlockAccount()：解锁账户；</p>\n</li>\n<li><p>eth.accounts：枚举系统中的账户；</p>\n</li>\n<li><p>eth.getBalance()：查看账户余额，返回值的单位是 Wei（Wei 是以太坊中最小货币面额单位，类似比特币中的<code>聪</code>，1 ether = 10^18 Wei）； <code>web3.fromWei(eth.getBalance(e), &quot;ether&quot;)</code></p>\n<p><code>web3.toWei(&#39;1&#39;, &#39;ether&#39;)</code></p>\n</li>\n</ul>\n<ul>\n<li><p>eth.blockNumber：列出区块总数；blockNumber为eth的属性，直接查看即可</p>\n</li>\n<li><p>eth.getTransaction()：获取交易；</p>\n</li>\n<li><p>eth.getBlock()：获取区块；如eth.getBlock(“pending”, true).transactions 查看当前待确认交易。或通过区块号查看eth.getBlock(4)</p>\n</li>\n<li><p>miner.start()：开始挖矿；</p>\n</li>\n<li><p>miner.stop()：停止挖矿；</p>\n</li>\n<li><p>web3.fromWei()：Wei 换算成以太币；</p>\n</li>\n<li><p>web3.toWei()：以太币换算成 Wei；如amount = web3.toWei(5,’ether’)</p>\n</li>\n<li><p>txpool.status：交易池中的状态；</p>\n</li>\n<li><p>admin.addPeer()：连接到其他节点；</p>\n</li>\n</ul>\n<p>接下来，添加peer节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; admin.peers #查看当前节点链接的节点</span><br><span class=\"line\">&gt; net.peerCount #查看当前节点链接的节点数</span><br></pre></td></tr></table></figure>\n\n<p>目前三个节点都是没有链接的，所以admin.peers的结果为[]。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; admin.nodeInfo.enode #查看节点地址，地址组成为encode://&lt;节点id&gt;@ip地址：端口</span><br><span class=\"line\">&quot;enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0&quot;</span><br></pre></td></tr></table></figure>\n\n<p>查看node1节点地址，在node2, node3的console中使用admin.addPeer，将node1分别添加到node2,node3中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; admin.addPeer(&quot;enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0&quot;)</span><br></pre></td></tr></table></figure>\n\n<p>再使用admin.peers查看的时候，可以看到node1链接上2个节点（node2, node3）,node2和node3各自链接上1个节点（node1）</p>\n<p>也可使用配置文件的形式添加节点，在节点的datadir下新建static-node.json, 将需要连接的节点地址写入，如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">&quot;enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0&quot;,</span><br><span class=\"line\">&quot;enode://79671ba7d09a4e6d16a64128e2cb24f544ec8740084e1ceb1abcac7b1c2b8a37dae812653360caf30ceff782265b124c1e6ce1d547dc6854bafb85596795751c@[::]:30001?discport=0&quot;,</span><br><span class=\"line\">&quot;enode://3237c4eaf0dbf55b459eef14c4ecffe987b5179e482399b282bc5ab3d1559dd8461a9d39460810bf0d8c276fb13a9950eca5c38890dbf11d9dccdb1b61231a78@[::]:30002?discport=0&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p>或者直接在geth启动行中添加 - -bootnodes enode:….</p>\n<p>那么在geth启动的时候会自动链接。链接到的节点就互相发现组成以太坊私链网络了</p>\n<p>当组成网络之后，就可以开始挖矿了。在某个节点下，调用miner.start()</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; miner.start()</span><br><span class=\"line\">INFO [04-10|17:59:10] Transaction pool price threshold updated price=18000000000</span><br><span class=\"line\">INFO [04-10|17:59:10] Starting mining operation</span><br><span class=\"line\">null</span><br><span class=\"line\">&gt; INFO [04-10|17:59:10] Commit new mining work                   number=1 txs=2 uncles=0 elapsed=1.058ms</span><br><span class=\"line\">INFO [04-10|17:59:10] Successfully sealed new block            number=1 hash=3b7e10…38d85e</span><br><span class=\"line\">INFO [04-10|17:59:10] 🔨 mined potential block                  number=1 hash=3b7e10…38d85e</span><br><span class=\"line\">INFO [04-10|17:59:10] Commit new mining work                   number=2 txs=0 uncles=0 elapsed=285.156µs</span><br><span class=\"line\">INFO [04-10|17:59:15] Successfully sealed new block            number=2 hash=1bb861…fbcb78</span><br></pre></td></tr></table></figure>\n\n<p>正常情况是这个样子..  不正常的情况，其一需要先解锁账户</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WARN [04-10|17:55:49] Block sealing failed                     err=&quot;authentication needed: password or unlock&quot;</span><br><span class=\"line\">&gt; personal.unlockAccount(eth.accounts[0])</span><br></pre></td></tr></table></figure>\n\n<p>其二，如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; miner.start()</span><br><span class=\"line\"></span><br><span class=\"line\">null</span><br></pre></td></tr></table></figure>\n\n<p>返回null, 是不得行的~，解决方式如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; miner.setEtherbase(eth.accounts[0])</span><br><span class=\"line\">true</span><br><span class=\"line\">&gt; miner.start()</span><br></pre></td></tr></table></figure>\n\n<p>在某个节点下，提交一个交易，如,  to为账户地址，查看账户地址为eth.accounts</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; eth.sendTransaction(&#123;from: eth.accounts[0], to: &quot;b6deeb049de5fb90345b5b84dd1faf2d56c6929e&quot;, value: web3.toWei(200, &quot;ether&quot;)&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>如果miner没有关掉的话，几秒后就会有含有交易的block产出,  txs为block包含的交易数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INFO [04-10|17:59:15] Imported new chain segment               blocks=2 txs=1 mgas=0.042 elapsed=1.348ms  mgasps=31.157 number=2 hash=1bb861…fbcb78 cache=2.47kB</span><br></pre></td></tr></table></figure>\n\n<p>挖矿，挖到一个区块之后就停止挖矿可使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; miner.start(1);admin.sleepBlocks(1);miner.stop();</span><br></pre></td></tr></table></figure>\n\n<p>当然，还有可能是网速原因… 过几分钟再试就好了。</p>\n<p>智能合约</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install solc</span><br></pre></td></tr></table></figure>\n\n<p>…..</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">geth attach http://0.0.0.0:1112</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&quot;/Applications/Ethereum Wallet.app/Contents/MacOS/Ethereum Wallet&quot; --rpc http://localhost:8545</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    --rpcapi=&quot;db,eth,net,web3,personal,web3&quot; --rpc --rpcaddr 0.0.0.0 -rpcport 1112 --mine</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">eth.sendTransaction(&#123;from:eth.accounts[0], data:&quot;0x0100f862a00000000000000000000000000000000000000000000000000000000000000000a00000000000000000000000000000000000000000000000000000000000000000809471562b71999873db5b286df957af199ec94617f78568656c6c6f80808080&quot;&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>编译android</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make android</span><br><span class=\"line\"></span><br><span class=\"line\">./build/env.sh xgo --go=latest --dest=build/bin -v --targets=android-23/arm64 ./cmd/geth</span><br><span class=\"line\"></span><br><span class=\"line\">glide mirror set golang.org/x/text  /home/users/qiangmzsx/var/golang/golang.org/x/text</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eth.sendTransaction(&#123;from: eth.accounts[0], to: &quot;0x71562b71999873DB5b286dF957af199Ec94617F7&quot;, value: 200000&#125;)</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<p>项目选择为go-ethereum，即geth。（原来geth是go-ethereum的简称..）。geth是以太坊、Whisper（去中心化通信协议）和Swarm（去中心化文件系统）节点的一个实现。用于接入以太坊网络，进行账户管理、交易、挖矿、智能合约相关的操作的以太坊客户端。另外，geth是一种CLI应用。</p>\n<p>环境配置</p>\n<p>环境为mac</p>\n<p>按照<a href>官方文档</a>进行配置就好。采用的是克隆go-ethereum仓库的方式进行配置。</p>\n<p>注意的点是，go版本很关键。刚开始下载的go版本就为1.7.+,然后在进行make geth的时候报错了..然后重新brew install go，搞到go版本1.10.+，然后进行make geth还是报错..无奈下载官方建议1.9.+，顺利通过…</p>\n<p>make解读，使用make命令时调用makefile文件，查看makefile代码，其实make all/make geth其实就是使用go对cmd/目录下各工具进行代码打包成可执行文件。生成文件位于cmd/bin下。</p>\n<p>make完成后将cmd/bin目录添加到环境变量中，方便之后使用。</p>\n<p>创建3个目录文件夹，分别存放3个账户数据。 —datadir node1 为指定Data directory for the databases and keystore。创建3个账户</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xiaoxuez$ ls</span><br><span class=\"line\">node1\tnode2\tnode3</span><br><span class=\"line\">xiaoxuez$ geth --datadir node1 account new</span><br></pre></td></tr></table></figure>\n\n<p>生成创世块，需要定义.json文件，puppeth工具可以帮忙快速生成创世快文件。puppeth源代码位于cmd/下，make的时候如果只make etheruem的话就只会生成ethereum的可执行文件，make all就都有了~  实在没有的话就单独生成一次。可参照</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">build/env.sh go run build/ci.go install ./cmd/puppeth/</span><br></pre></td></tr></table></figure>\n\n<p>回到正题，puppeth的使用直接见命令行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ puppeth</span><br><span class=\"line\">+-----------------------------------------------------------+</span><br><span class=\"line\">| Welcome to puppeth, your Ethereum private network manager |</span><br><span class=\"line\">|                                                           |</span><br><span class=\"line\">| This tool lets you create a new Ethereum network down to  |</span><br><span class=\"line\">| the genesis block, bootnodes, miners and ethstats servers |</span><br><span class=\"line\">| without the hassle that it would normally entail.         |</span><br><span class=\"line\">|                                                           |</span><br><span class=\"line\">| Puppeth uses SSH to dial in to remote servers, and builds |</span><br><span class=\"line\">| its network components out of Docker containers using the |</span><br><span class=\"line\">| docker-compose toolset.                                   |</span><br><span class=\"line\">+-----------------------------------------------------------+</span><br><span class=\"line\"></span><br><span class=\"line\">Please specify a network name to administer (no spaces or hyphens, please)</span><br><span class=\"line\">&gt; helloworldprivate</span><br><span class=\"line\"></span><br><span class=\"line\">Sweet, you can set this via --network=helloworldprivate next time!</span><br><span class=\"line\"></span><br><span class=\"line\">INFO [04-10|13:45:58] Administering Ethereum network           name=helloworldprivate</span><br><span class=\"line\">WARN [04-10|13:45:58] No previous configurations found         path=/Users/xiaoxuez/.puppeth/helloworldprivate</span><br><span class=\"line\"></span><br><span class=\"line\">What would you like to do? (default = stats)</span><br><span class=\"line\"> 1. Show network stats</span><br><span class=\"line\"> 2. Configure new genesis</span><br><span class=\"line\"> 3. Track new remote server</span><br><span class=\"line\"> 4. Deploy network components</span><br><span class=\"line\">&gt; 2</span><br><span class=\"line\"></span><br><span class=\"line\">Which consensus engine to use? (default = clique) #共识选择，可直接选择pow,这里我选择的是poa,(不消耗计算力, 可以用于私链测试开发)</span><br><span class=\"line\"> 1. Ethash - proof-of-work</span><br><span class=\"line\"> 2. Clique - proof-of-authority</span><br><span class=\"line\">&gt; 2</span><br><span class=\"line\"></span><br><span class=\"line\">How many seconds should blocks take? (default = 15)  #5s出一个块</span><br><span class=\"line\">&gt; 5</span><br><span class=\"line\"></span><br><span class=\"line\">Which accounts are allowed to seal? (mandatory at least one)  #输入有签名权限的账户</span><br><span class=\"line\">&gt; 0x1186c97871079e86e9adcf11f56b90caa3619ea4</span><br><span class=\"line\">&gt; 0x34c72adc7499cce01530dc27e67810a79fdbd8ea</span><br><span class=\"line\">&gt; 0xb37fe8ba7afbeb5e57139e55e737a34574e91a74</span><br><span class=\"line\">&gt; 0x</span><br><span class=\"line\"></span><br><span class=\"line\">Which accounts should be pre-funded? (advisable at least one)  #输入有预留余额的账户</span><br><span class=\"line\">&gt; 0xb37fe8ba7afbeb5e57139e55e737a34574e91a74</span><br><span class=\"line\">&gt; 0x34c72adc7499cce01530dc27e67810a79fdbd8ea</span><br><span class=\"line\">&gt; 0x1186c97871079e86e9adcf11f56b90caa3619ea4</span><br><span class=\"line\">&gt; 0x</span><br><span class=\"line\"></span><br><span class=\"line\">Specify your chain/network ID if you want an explicit one (default = random) #输入私链ID, 直接输入回车,已默认随机数作为私链ID</span><br><span class=\"line\">&gt;</span><br><span class=\"line\">INFO [04-10|13:47:49] Configured new genesis block</span><br><span class=\"line\"></span><br><span class=\"line\">What would you like to do? (default = stats)</span><br><span class=\"line\"> 1. Show network stats</span><br><span class=\"line\"> 2. Manage existing genesis</span><br><span class=\"line\"> 3. Track new remote server</span><br><span class=\"line\"> 4. Deploy network components</span><br><span class=\"line\">&gt; 2</span><br><span class=\"line\"></span><br><span class=\"line\"> 1. Modify existing fork rules</span><br><span class=\"line\"> 2. Export genesis configuration</span><br><span class=\"line\"> 3. Remove genesis configuration</span><br><span class=\"line\">&gt; 2</span><br><span class=\"line\"></span><br><span class=\"line\">Which file to save the genesis into? (default = helloworldprivate.json)</span><br><span class=\"line\">&gt;</span><br><span class=\"line\">INFO [04-10|13:48:00] Exported existing genesis block</span><br><span class=\"line\"></span><br><span class=\"line\">What would you like to do? (default = stats)</span><br><span class=\"line\"> 1. Show network stats</span><br><span class=\"line\"> 2. Manage existing genesis</span><br><span class=\"line\"> 3. Track new remote server</span><br><span class=\"line\"> 4. Deploy network components</span><br><span class=\"line\">&gt; ^C</span><br><span class=\"line\">$ ls  #结束后会在当前文件夹下看到导出的.json文件</span><br><span class=\"line\">helloworldprivate.json\tnode1\t\t\tnode2\t\t\tnode3</span><br></pre></td></tr></table></figure>\n\n<p>接下来就是使用.json文件生成创世块了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#init:Bootstrap and initialize a new genesis block</span><br><span class=\"line\">$ geth --datadir node1 init helloworldprivate.json</span><br><span class=\"line\">$ geth --datadir node1 --port 30000 --nodiscover --unlock &apos;0&apos; --password ./node1/password console</span><br><span class=\"line\">#启动geth, --port: Network listening port ，指定和其他节点链接所用的端口号</span><br><span class=\"line\">#               --nodiscover: Disables the peer discovery mechanism (manual peer addition)关闭节点发现机制，防止加入有同样初始配置的陌生节点，后续手动配置节点网络，</span><br><span class=\"line\">#               --unlock: Comma separated list of accounts to unlock, 解锁的账户，以逗号分隔，账户要转帐或者部署合约，需要先解锁</span><br><span class=\"line\">#               console: 进入控制台，不加console的话，也可在geth启动后通过geth attach</span><br><span class=\"line\">ipc:node0/geth.ipc来访问</span><br><span class=\"line\">#               --rpc: 表示开启http-rpc服务</span><br><span class=\"line\">                --rpcport: 指定http-rpc服务监听端口，默认为8545</span><br><span class=\"line\">                --ws:</span><br><span class=\"line\">                --wsport:</span><br><span class=\"line\">                --allow-insecure-unlock</span><br></pre></td></tr></table></figure>\n\n<p>同样，目前启动3个节点，使用不同端口来模拟多节点，另起终端</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ geth --datadir node2 init helloworldprivate.json</span><br><span class=\"line\">$ geth --datadir node2 --port 30001 --nodiscover --unlock &apos;0&apos; --password ./node2/password console</span><br><span class=\"line\"></span><br><span class=\"line\">$ geth --datadir node3 init helloworldprivate.json</span><br><span class=\"line\">$ geth --datadir node3 --port 30002 --nodiscover --unlock &apos;0&apos; --password ./node3/password console</span><br></pre></td></tr></table></figure>\n\n<p>三个启动时候unlock 的值都是’0’,  之前在每个节点文件下都只创建了一个账户，所以解锁的就是各个节点下的账户，即目前三个账户都是解锁。这里的小疑问是要起3个初始块，猜测是相同初始配置的节点才能加入到同一个网络中。</p>\n<p>console进入的控制台是一个交互式的JavaScript执行环境，在这里面可以执行JavaScript代码。这个环境里也内置了一些用来操作以太坊的JavaScript对象，例如</p>\n<ul>\n<li>eth：包含一些跟操作区块链相关的方法；</li>\n<li>net：包含一些查看p2p网络状态的方法；</li>\n<li>admin：包含一些与管理节点相关的方法；</li>\n<li>miner：包含启动&amp;停止挖矿的一些方法；</li>\n<li>personal：主要包含一些管理账户的方法；</li>\n<li>txpool：包含一些查看交易内存池的方法；</li>\n<li>web3：包含了以上对象，还包含一些单位换算的方法。</li>\n</ul>\n<p>常见命令有：</p>\n<ul>\n<li><p>personal.newAccount()：创建账户；</p>\n</li>\n<li><p>personal.unlockAccount()：解锁账户；</p>\n</li>\n<li><p>eth.accounts：枚举系统中的账户；</p>\n</li>\n<li><p>eth.getBalance()：查看账户余额，返回值的单位是 Wei（Wei 是以太坊中最小货币面额单位，类似比特币中的<code>聪</code>，1 ether = 10^18 Wei）； <code>web3.fromWei(eth.getBalance(e), &quot;ether&quot;)</code></p>\n<p><code>web3.toWei(&#39;1&#39;, &#39;ether&#39;)</code></p>\n</li>\n</ul>\n<ul>\n<li><p>eth.blockNumber：列出区块总数；blockNumber为eth的属性，直接查看即可</p>\n</li>\n<li><p>eth.getTransaction()：获取交易；</p>\n</li>\n<li><p>eth.getBlock()：获取区块；如eth.getBlock(“pending”, true).transactions 查看当前待确认交易。或通过区块号查看eth.getBlock(4)</p>\n</li>\n<li><p>miner.start()：开始挖矿；</p>\n</li>\n<li><p>miner.stop()：停止挖矿；</p>\n</li>\n<li><p>web3.fromWei()：Wei 换算成以太币；</p>\n</li>\n<li><p>web3.toWei()：以太币换算成 Wei；如amount = web3.toWei(5,’ether’)</p>\n</li>\n<li><p>txpool.status：交易池中的状态；</p>\n</li>\n<li><p>admin.addPeer()：连接到其他节点；</p>\n</li>\n</ul>\n<p>接下来，添加peer节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; admin.peers #查看当前节点链接的节点</span><br><span class=\"line\">&gt; net.peerCount #查看当前节点链接的节点数</span><br></pre></td></tr></table></figure>\n\n<p>目前三个节点都是没有链接的，所以admin.peers的结果为[]。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; admin.nodeInfo.enode #查看节点地址，地址组成为encode://&lt;节点id&gt;@ip地址：端口</span><br><span class=\"line\">&quot;enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0&quot;</span><br></pre></td></tr></table></figure>\n\n<p>查看node1节点地址，在node2, node3的console中使用admin.addPeer，将node1分别添加到node2,node3中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; admin.addPeer(&quot;enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0&quot;)</span><br></pre></td></tr></table></figure>\n\n<p>再使用admin.peers查看的时候，可以看到node1链接上2个节点（node2, node3）,node2和node3各自链接上1个节点（node1）</p>\n<p>也可使用配置文件的形式添加节点，在节点的datadir下新建static-node.json, 将需要连接的节点地址写入，如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">&quot;enode://0480c837fc76671a8d8ee78b74fd04f9439762cc2e2e668b8604dda964c679ec8dd10f8347d7066707a315db8ad5c141e9d5a5b98f3a790660792f4469086f21@[::]:30000?discport=0&quot;,</span><br><span class=\"line\">&quot;enode://79671ba7d09a4e6d16a64128e2cb24f544ec8740084e1ceb1abcac7b1c2b8a37dae812653360caf30ceff782265b124c1e6ce1d547dc6854bafb85596795751c@[::]:30001?discport=0&quot;,</span><br><span class=\"line\">&quot;enode://3237c4eaf0dbf55b459eef14c4ecffe987b5179e482399b282bc5ab3d1559dd8461a9d39460810bf0d8c276fb13a9950eca5c38890dbf11d9dccdb1b61231a78@[::]:30002?discport=0&quot;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p>或者直接在geth启动行中添加 - -bootnodes enode:….</p>\n<p>那么在geth启动的时候会自动链接。链接到的节点就互相发现组成以太坊私链网络了</p>\n<p>当组成网络之后，就可以开始挖矿了。在某个节点下，调用miner.start()</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; miner.start()</span><br><span class=\"line\">INFO [04-10|17:59:10] Transaction pool price threshold updated price=18000000000</span><br><span class=\"line\">INFO [04-10|17:59:10] Starting mining operation</span><br><span class=\"line\">null</span><br><span class=\"line\">&gt; INFO [04-10|17:59:10] Commit new mining work                   number=1 txs=2 uncles=0 elapsed=1.058ms</span><br><span class=\"line\">INFO [04-10|17:59:10] Successfully sealed new block            number=1 hash=3b7e10…38d85e</span><br><span class=\"line\">INFO [04-10|17:59:10] 🔨 mined potential block                  number=1 hash=3b7e10…38d85e</span><br><span class=\"line\">INFO [04-10|17:59:10] Commit new mining work                   number=2 txs=0 uncles=0 elapsed=285.156µs</span><br><span class=\"line\">INFO [04-10|17:59:15] Successfully sealed new block            number=2 hash=1bb861…fbcb78</span><br></pre></td></tr></table></figure>\n\n<p>正常情况是这个样子..  不正常的情况，其一需要先解锁账户</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WARN [04-10|17:55:49] Block sealing failed                     err=&quot;authentication needed: password or unlock&quot;</span><br><span class=\"line\">&gt; personal.unlockAccount(eth.accounts[0])</span><br></pre></td></tr></table></figure>\n\n<p>其二，如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; miner.start()</span><br><span class=\"line\"></span><br><span class=\"line\">null</span><br></pre></td></tr></table></figure>\n\n<p>返回null, 是不得行的~，解决方式如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; miner.setEtherbase(eth.accounts[0])</span><br><span class=\"line\">true</span><br><span class=\"line\">&gt; miner.start()</span><br></pre></td></tr></table></figure>\n\n<p>在某个节点下，提交一个交易，如,  to为账户地址，查看账户地址为eth.accounts</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; eth.sendTransaction(&#123;from: eth.accounts[0], to: &quot;b6deeb049de5fb90345b5b84dd1faf2d56c6929e&quot;, value: web3.toWei(200, &quot;ether&quot;)&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>如果miner没有关掉的话，几秒后就会有含有交易的block产出,  txs为block包含的交易数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INFO [04-10|17:59:15] Imported new chain segment               blocks=2 txs=1 mgas=0.042 elapsed=1.348ms  mgasps=31.157 number=2 hash=1bb861…fbcb78 cache=2.47kB</span><br></pre></td></tr></table></figure>\n\n<p>挖矿，挖到一个区块之后就停止挖矿可使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; miner.start(1);admin.sleepBlocks(1);miner.stop();</span><br></pre></td></tr></table></figure>\n\n<p>当然，还有可能是网速原因… 过几分钟再试就好了。</p>\n<p>智能合约</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install solc</span><br></pre></td></tr></table></figure>\n\n<p>…..</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">geth attach http://0.0.0.0:1112</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&quot;/Applications/Ethereum Wallet.app/Contents/MacOS/Ethereum Wallet&quot; --rpc http://localhost:8545</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    --rpcapi=&quot;db,eth,net,web3,personal,web3&quot; --rpc --rpcaddr 0.0.0.0 -rpcport 1112 --mine</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">eth.sendTransaction(&#123;from:eth.accounts[0], data:&quot;0x0100f862a00000000000000000000000000000000000000000000000000000000000000000a00000000000000000000000000000000000000000000000000000000000000000809471562b71999873db5b286df957af199ec94617f78568656c6c6f80808080&quot;&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>编译android</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make android</span><br><span class=\"line\"></span><br><span class=\"line\">./build/env.sh xgo --go=latest --dest=build/bin -v --targets=android-23/arm64 ./cmd/geth</span><br><span class=\"line\"></span><br><span class=\"line\">glide mirror set golang.org/x/text  /home/users/qiangmzsx/var/golang/golang.org/x/text</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eth.sendTransaction(&#123;from: eth.accounts[0], to: &quot;0x71562b71999873DB5b286dF957af199Ec94617F7&quot;, value: 200000&#125;)</span><br></pre></td></tr></table></figure>\n\n"},{"title":"eos_code","date":"2019-10-14T06:44:30.000Z","_content":"\n### EOS 源码学习之项目结构分析(plugins)\n\n整体的代码位置主要位于plugins、libraries。\n\n**eos项目采用了插件管理的结构**。\n\n\n\n#### 入口\n\nprograms的文件夹结构如下，在[eos官方wiki](https://github.com/EOSIO/eos/wiki/Programs-&-Tools)中可以查看具体每个目录的含义及作用。这里仅备注几个示例。\n\n```\n.. eos/programs:\n\n├── CMakeLists.txt\n├── cleos //命令行工具，如果把eos比作操作系统的话，cleos就类似终端作用  \n├── debug_node\n├── eosio-abigen\n├── eosio-applesedemo\n├── eosio-launcher\n├── genesis\n├── keosd  //钱包\n├── nodeos  //节点核心进程\n└── snapshot\n```\n\n要启动一个节点，需要用到的便是nodeos，cleos中可使用的REST API便是nodeos中暴露出来的。那么，我们看看nodeos。\n\n源代码main.cpp中，代码仅有105行。主要看看main方法吧（不想看代码可以略过代码部分 = =），通过代码可以看到，main方法作用包括设置版本、工作路径等基本信息，以及log的初始化，另外就是startup方法看起来就是关键！\n\n```\nint main(int argc, char** argv)\n{\n   try {\n      app().set_version(eosio::nodeos::config::version);\n      auto root = fc::app_path();\n      app().set_default_data_dir(root / \"eosio/nodeos/data\" );\n      app().set_default_config_dir(root / \"eosio/nodeos/config\" );\n      if(!app().initialize<chain_plugin, http_plugin, net_plugin, producer_plugin>(argc, argv))\n         return -1;\n      initialize_logging();\n      ilog(\"nodeos version ${ver}\", (\"ver\", eosio::utilities::common::itoh(static_cast<uint32_t>(app().version()))));\n      ilog(\"eosio root is ${root}\", (\"root\", root.string()));\n      //重要的代码!!!\n      app().startup();\n      app().exec();\n   } catch (const fc::exception& e) {\n   } .....(此处省略多个catch)\n   return 0;\n}\n```\n\napp()位置位于\n\n```\n./libraries/appbase/application.cpp\n//app()方法返回application的实例(对c++的类的机制不了解，这个实例像是静态对象，反正就是通过返回的实例可以调用相关方法吧，包括startup这个看起来就跟关键的方法)\n```\n\n进入到application.cpp中，例举相关方法\n\n- initialize_..: 初始化插件，功能包括调用各个插件设置命令行参数，以及初始化方法，还有app自身对应初始化操作\n\n- startup:  循环各插件，调用各插件的startup方法\n- exec:  表示完全看不懂= =!!。猜测一下，应该是监听io事件，例如结束进程系列..\n\n从这里可以看出，主要的具体的重要的内容都在各插件内部。\n\n\n\n#### 插件\n\neos项目采用了插件管理的结构。插件的目录如下\n\n```\n.. eos/plugins:\n\n├── CMakeLists.txt\n├── account_history_api_plugin\n├── account_history_plugin\n├── chain_api_plugin\n├── chain_plugin\n├── eosio-make_new_plugin.sh\n├── faucet_testnet_plugin\n├── http_plugin\n├── mongo_db_plugin\n├── net_api_plugin\n├── net_plugin\n├── producer_plugin\n├── template_plugin\n├── txn_test_gen_plugin\n├── wallet_api_plugin\n└── wallet_plugin\n```\n\n完全可以通过命名来理解各插件的含义。要分析的话，直接从相应plugins入手。逐一观察..\n\n\n### eos/nodeos学习\n\n\n\n#### main.cpp\n\n```\n      //设置版本\n      app().set_version(eosio::nodeos::config::version);\n      auto root = fc::app_path();\n      //设置工作路径\n      app().set_default_data_dir(root / \"eosio/nodeos/data\" );\n      app().set_default_config_dir(root / \"eosio/nodeos/config\" );\n      //单节点需要的插件包括以下四个\n      if(!app().initialize<chain_plugin, http_plugin, net_plugin, producer_plugin>(argc, argv))\n         return -1;\n\n      initialize_logging();\n      ilog(\"nodeos version ${ver}\", (\"ver\", eosio::nodeos::config::itoh(static_cast<uint32_t>(app().version()))));\n      ilog(\"eosio root is ${root}\", (\"root\", root.string()));\n      app().startup();\n      app().exec();\n\n\n```\n\n\n\n主要是配置和app的一些调用。然后转到app中。\n\n```\n./libraries/appbase/application.cpp\n```\n\n- app:  返回application的实例（实例只是声明，木有初始化，对c++类机制不太了解，需进一步了解，目前就理解成这个实例就可访问application::method方法）\n\n- initialize_..: 初始化插件，功能包括调用各个插件设置命令行参数，以及初始化方法，还有app自身对应初始化操作\n\n- startup:  循环各插件，调用各插件的startup方法\n\n- exec:  表示完全看不懂= =!!。猜测一下，应该是监听io事件，例如结束进程系列..\n\n\n\n那么针对单个节点启动必要的4个插件，进行逐个学习。\n\n首先是插件父方法：（在application中调用的方法名直接是start_up，没有plugin前缀，这个问题有待解决..）\n\n- set_program_options //设置命令行参数\n\n- plugin_initialize //初始化操作\n\n- plugin_startup  //启动\n\n- plugin_shutdown  //退出\n\n\n\n\n\n#### Chain_plugin\n\n\n\n\n\n#### Producer_plugin\n\n\n\n```\n // dpos共识  地方 -> get_scheduled_producer的定义在chain_controller\n auto scheduled_producer = chain.get_scheduled_producer( slot );\n   // we must control the producer scheduled to produce the next block.\n   if( _producers.find( scheduled_producer ) == _producers.end() )\n   {\n      capture(\"scheduled_producer\", scheduled_producer);\n      return block_production_condition::not_my_turn;\n   }\n```\n\n\n\n\n\n```go\n//chain_controller的一些相关producer方法\n\n//大意猜测更新新区块，包括新区块和签名新区块的producer\nupdate_signing_producer(const producer_object& signing_producer, const signed_block& new_block)\n\n//根据新的producers更新db表？疑问是代码中只有create，没有删除操作\nupdate_or_create_producers( const producer_schedule_type& producers)\n\n//好像这个是关键！详细看一下，对方法的解释为，从投票排名中取出前m个producer,并排除block_signing_key是null的那些，m为配置中的producer_count。然而代码似乎没全..\n_calculate_producer_schedule() {\n  //get_global_properties返回为global_property_object对象，new_active_producers为对象的熟悉\n  //据观察，new_active_producers的赋值目前只出现在wasm的api中，那是不是就可以得出结论new_active_producers是所有的参选producers..这个方法(_calculate_producer_schedule)要做的就是从所有参选者中按排名取前m个，然后去掉block_signing_key是null的那些\n   producer_schedule_type schedule = get_global_properties().new_active_producers;\n   const auto& hps = _head_producer_schedule();\n   schedule.version = hps.version;\n   if( hps != schedule )\n      ++schedule.version;\n   return schedule;\n}\n\n//没看懂..好像是给所有producers怎么搞了一下认证(更新到_db某表)\n_update_producers_authority()\n\n//返回当前区块头的producer\nhead_block_producer()\n\n//根据account_name/ownername获取对于producer\nget_producer(const account_name& ownername)\n\n\n//这个方法也蛮重要的，根据slot_num获取已计划好的producer.其中，slot_num始终对应于未来的某一时刻；另外，对于slot_num的值，相对当前多少区块的间隔，例如，slot_num == 1 则为下一个producer, slot_num == 2，则为在一个区块间隔后的下一个producer。注意的是slot_num代表的是区块间隔，非producer间隔\nget_scheduled_producer(uint32_t slot_num) {\n   const dynamic_global_property_object& dpo = get_dynamic_global_properties();\n  //注意点1，最后用来计算位置的值是一个当前的绝对位置 + slot_num  ？具体回头再看\n   uint64_t current_aslot = dpo.current_absolute_slot + slot_num;\n   ...\n  //位置对producer*重复次数的积取模\n   auto index = current_aslot % (number_of_active_producers * config::producer_repetitions);\n}\n\n//计算producer过去生产的参与率，代码未详\nproducer_participation_rate()\n\n\n\n//大概看了以上方法，有点乱。现在还不能连成线，只是点\n关键\nupdate_last_irreversible_block\n```\n\n\n\n\n### producer源码学习\n\n代码位置为..eos/plugins/producer_plugin/\n\n文件夹结构如下，producer_plugin.hpp为方法的声明， producer_plugin.cpp为具体实现\n\n```\n├── CMakeLists.txt\n├── include\n│   └── eosio\n│       └── producer_plugin\n│           └── producer_plugin.hpp\n└── producer_plugin.cpp\n\n```\n\n\n\n虽然producer_plugin.cpp的代码也只有不到400行，但节省时间和资源，就挑出块相关的说吧。方法调用如下\n\n```\nplugin_startup -> schedule_production_loop(到没到出块时间，到了就出块,这个方法不断循环) -> block_production_loop -> maybe_produce_block\n```\n\nmaybe_produce_block方法是最后决定是不是出块的。以下主要解释maybe_produce_block方法\n\n- 首先会检查区块是否同步到最新。\n\n- 接下来这段代码会判断是否到达出块时间。\n\n  ```\n   uint32_t slot = chain.get_slot_at_time( now );\n     if( slot == 0 )\n     {\n        capture(\"next_time\", chain.get_slot_time(1));\n        return block_production_condition::not_time_yet;\n     }\n  ```\n\n- 然后就选择出块producer了。\n\n  ```\n  auto scheduled_producer = chain.get_scheduled_producer( slot );\n  ```\n\n完了判断这个scheduled_producer是不是自己，是的话，再检查点别的(例如私钥啊等)，最后就出块了。\n\n那么，关键代码就是get_scheduled_producer方法。get_scheduled_producer的追踪要到chain_controller.cpp文件中了。位置位于./eos/libriaries/chain/chain_controller.cpp。以下代码未做特殊说明，都位于chain_controller.cpp中。\n\n首先看get_scheduled_producer的代码，可以看到，③通过从db中读出global_property_object对象gpo（下面会有介绍），gpo.active_producers为当前活跃的producers，然后④⑤为算得当前索引下标index，最后根据index在gpo.active_producers中取出相应producer即为返回值。下标计算的方式就是数学算式index=当前区块位置 % （producers总数 * 每个producer重复出多少块）。最后再除以每个producer重复出多少块。比较不理解的是当前区块位置(代码中的current_aslot)的计算方式。\n\n```\n//具体代码\n/*\n* 1. slot_num始终对应于未来的某一时刻\n* 2.对于slot_num的值，相对当前多少区块的间隔，\n*     例如，slot_num == 1 则为下一个区块的producer,\n*          slot_num == 2，则为在一个区块间隔后的下一个producer。slot_num即为区块间隔数\n* 3.使用方法get_slot_time和get_slot_at_time作为slot_num和时间戳的转换\n* 4.slot_num == 0，返回EOS_NULL_PRODUCER\n*/\naccount_name chain_controller::get_scheduled_producer(uint32_t slot_num)const\n{\n   const dynamic_global_property_object& dpo = get_dynamic_global_properties(); //①\n   uint64_t current_aslot = dpo.current_absolute_slot + slot_num; //②\n   const auto& gpo = _db.get<global_property_object>(); //③\n   auto number_of_active_producers = gpo.active_producers.producers.size();\n   auto index = current_aslot % (number_of_active_producers * config::producer_repetitions);  //④\n   index /= config::producer_repetitions; //⑤\n   FC_ASSERT( gpo.active_producers.producers.size() > 0, \"no producers defined\" );\n\n   return gpo.active_producers.producers[index].producer_name;\n}\n```\n\n\n\n关于global\\_property\\_object主要属性有active\\_producers、new\\_active\\_producers、pending\\_active\\_producers。\n\nactive\\_producers是当前轮的producers, pending\\_active\\_producers为满足排名等要求的producers, new\\_active\\_producers为所有可投票(或者是所有备选)的producer。\n\n在controller_chain.cpp中有如下几个方法：\n\n```\n//从投票排名中取出前m个producer,并排除block_signing_key是null的那些，m为配置中的producer_count。然而代码似乎没全.\n_calculate_producer_schedule() {...}\n\n//更新global_properties\nupdate_global_properties(){...}\n\n//上面提到过的有可能更新active_producers的方法\nupdate_last_irreversible_block(){...}\n\n /*\n *  After applying all transactions successfully we can update\n *  the current block time, block number, producer stats, etc\n */\n_finalize_block(){...}\n```\n\n主要通过上面列举的方法介绍active\\_producers、new\\_active\\_producers、pending\\_active\\_producers是如何关联的。下面一段如果觉得各个方法调用比较蒙的话，可以直接看三个加粗句子，可以了解到active\\_producers、new\\_active\\_producers、pending\\_active\\_producers之间的关联。\n\n在\\_finalize\\_block调用的时候，首先调用update\\_global\\_properties，在update\\_global\\_properties方法中调用了_calculate\\_producer\\_schedule方法，calculate\\_producer\\_schedule方法实现的是**从new\\_active\\_producers中选出符合条件的producers**，然后回到update\\_global\\_properties，**根据选出的producers,更新pending\\_active\\_producers**，然后回到\\_finalize\\_block方法，调用update\\_global\\_properties之后调用update_last_irreversible_block方法，**通过pending_active_producers适当更新active\\_producers**。\n\n然后，new\\_active\\_producers是通过wasm的api进行更新。这样就缕通了，通过投票客户端，进行投票，并控制更新new\\_active\\_producers参数选手，和相应票数。然后根据new\\_active\\_producers和票数决定blocker producers。\n\n那么，blocker producers的顺序呢？?? 不知道是被我疏忽了还是真的没看到。\n\n\n\nproducer源码中，可以看到，上层逻辑在 producer_plugin.cpp中，基本的dpos等逻辑还是在chain_controller.cpp中。\n","source":"_posts/eos-code.md","raw":"---\ntitle: eos_code\ncategories:\n  - eos\ndate: 2019-10-14 14:44:30\ntags:\n---\n\n### EOS 源码学习之项目结构分析(plugins)\n\n整体的代码位置主要位于plugins、libraries。\n\n**eos项目采用了插件管理的结构**。\n\n\n\n#### 入口\n\nprograms的文件夹结构如下，在[eos官方wiki](https://github.com/EOSIO/eos/wiki/Programs-&-Tools)中可以查看具体每个目录的含义及作用。这里仅备注几个示例。\n\n```\n.. eos/programs:\n\n├── CMakeLists.txt\n├── cleos //命令行工具，如果把eos比作操作系统的话，cleos就类似终端作用  \n├── debug_node\n├── eosio-abigen\n├── eosio-applesedemo\n├── eosio-launcher\n├── genesis\n├── keosd  //钱包\n├── nodeos  //节点核心进程\n└── snapshot\n```\n\n要启动一个节点，需要用到的便是nodeos，cleos中可使用的REST API便是nodeos中暴露出来的。那么，我们看看nodeos。\n\n源代码main.cpp中，代码仅有105行。主要看看main方法吧（不想看代码可以略过代码部分 = =），通过代码可以看到，main方法作用包括设置版本、工作路径等基本信息，以及log的初始化，另外就是startup方法看起来就是关键！\n\n```\nint main(int argc, char** argv)\n{\n   try {\n      app().set_version(eosio::nodeos::config::version);\n      auto root = fc::app_path();\n      app().set_default_data_dir(root / \"eosio/nodeos/data\" );\n      app().set_default_config_dir(root / \"eosio/nodeos/config\" );\n      if(!app().initialize<chain_plugin, http_plugin, net_plugin, producer_plugin>(argc, argv))\n         return -1;\n      initialize_logging();\n      ilog(\"nodeos version ${ver}\", (\"ver\", eosio::utilities::common::itoh(static_cast<uint32_t>(app().version()))));\n      ilog(\"eosio root is ${root}\", (\"root\", root.string()));\n      //重要的代码!!!\n      app().startup();\n      app().exec();\n   } catch (const fc::exception& e) {\n   } .....(此处省略多个catch)\n   return 0;\n}\n```\n\napp()位置位于\n\n```\n./libraries/appbase/application.cpp\n//app()方法返回application的实例(对c++的类的机制不了解，这个实例像是静态对象，反正就是通过返回的实例可以调用相关方法吧，包括startup这个看起来就跟关键的方法)\n```\n\n进入到application.cpp中，例举相关方法\n\n- initialize_..: 初始化插件，功能包括调用各个插件设置命令行参数，以及初始化方法，还有app自身对应初始化操作\n\n- startup:  循环各插件，调用各插件的startup方法\n- exec:  表示完全看不懂= =!!。猜测一下，应该是监听io事件，例如结束进程系列..\n\n从这里可以看出，主要的具体的重要的内容都在各插件内部。\n\n\n\n#### 插件\n\neos项目采用了插件管理的结构。插件的目录如下\n\n```\n.. eos/plugins:\n\n├── CMakeLists.txt\n├── account_history_api_plugin\n├── account_history_plugin\n├── chain_api_plugin\n├── chain_plugin\n├── eosio-make_new_plugin.sh\n├── faucet_testnet_plugin\n├── http_plugin\n├── mongo_db_plugin\n├── net_api_plugin\n├── net_plugin\n├── producer_plugin\n├── template_plugin\n├── txn_test_gen_plugin\n├── wallet_api_plugin\n└── wallet_plugin\n```\n\n完全可以通过命名来理解各插件的含义。要分析的话，直接从相应plugins入手。逐一观察..\n\n\n### eos/nodeos学习\n\n\n\n#### main.cpp\n\n```\n      //设置版本\n      app().set_version(eosio::nodeos::config::version);\n      auto root = fc::app_path();\n      //设置工作路径\n      app().set_default_data_dir(root / \"eosio/nodeos/data\" );\n      app().set_default_config_dir(root / \"eosio/nodeos/config\" );\n      //单节点需要的插件包括以下四个\n      if(!app().initialize<chain_plugin, http_plugin, net_plugin, producer_plugin>(argc, argv))\n         return -1;\n\n      initialize_logging();\n      ilog(\"nodeos version ${ver}\", (\"ver\", eosio::nodeos::config::itoh(static_cast<uint32_t>(app().version()))));\n      ilog(\"eosio root is ${root}\", (\"root\", root.string()));\n      app().startup();\n      app().exec();\n\n\n```\n\n\n\n主要是配置和app的一些调用。然后转到app中。\n\n```\n./libraries/appbase/application.cpp\n```\n\n- app:  返回application的实例（实例只是声明，木有初始化，对c++类机制不太了解，需进一步了解，目前就理解成这个实例就可访问application::method方法）\n\n- initialize_..: 初始化插件，功能包括调用各个插件设置命令行参数，以及初始化方法，还有app自身对应初始化操作\n\n- startup:  循环各插件，调用各插件的startup方法\n\n- exec:  表示完全看不懂= =!!。猜测一下，应该是监听io事件，例如结束进程系列..\n\n\n\n那么针对单个节点启动必要的4个插件，进行逐个学习。\n\n首先是插件父方法：（在application中调用的方法名直接是start_up，没有plugin前缀，这个问题有待解决..）\n\n- set_program_options //设置命令行参数\n\n- plugin_initialize //初始化操作\n\n- plugin_startup  //启动\n\n- plugin_shutdown  //退出\n\n\n\n\n\n#### Chain_plugin\n\n\n\n\n\n#### Producer_plugin\n\n\n\n```\n // dpos共识  地方 -> get_scheduled_producer的定义在chain_controller\n auto scheduled_producer = chain.get_scheduled_producer( slot );\n   // we must control the producer scheduled to produce the next block.\n   if( _producers.find( scheduled_producer ) == _producers.end() )\n   {\n      capture(\"scheduled_producer\", scheduled_producer);\n      return block_production_condition::not_my_turn;\n   }\n```\n\n\n\n\n\n```go\n//chain_controller的一些相关producer方法\n\n//大意猜测更新新区块，包括新区块和签名新区块的producer\nupdate_signing_producer(const producer_object& signing_producer, const signed_block& new_block)\n\n//根据新的producers更新db表？疑问是代码中只有create，没有删除操作\nupdate_or_create_producers( const producer_schedule_type& producers)\n\n//好像这个是关键！详细看一下，对方法的解释为，从投票排名中取出前m个producer,并排除block_signing_key是null的那些，m为配置中的producer_count。然而代码似乎没全..\n_calculate_producer_schedule() {\n  //get_global_properties返回为global_property_object对象，new_active_producers为对象的熟悉\n  //据观察，new_active_producers的赋值目前只出现在wasm的api中，那是不是就可以得出结论new_active_producers是所有的参选producers..这个方法(_calculate_producer_schedule)要做的就是从所有参选者中按排名取前m个，然后去掉block_signing_key是null的那些\n   producer_schedule_type schedule = get_global_properties().new_active_producers;\n   const auto& hps = _head_producer_schedule();\n   schedule.version = hps.version;\n   if( hps != schedule )\n      ++schedule.version;\n   return schedule;\n}\n\n//没看懂..好像是给所有producers怎么搞了一下认证(更新到_db某表)\n_update_producers_authority()\n\n//返回当前区块头的producer\nhead_block_producer()\n\n//根据account_name/ownername获取对于producer\nget_producer(const account_name& ownername)\n\n\n//这个方法也蛮重要的，根据slot_num获取已计划好的producer.其中，slot_num始终对应于未来的某一时刻；另外，对于slot_num的值，相对当前多少区块的间隔，例如，slot_num == 1 则为下一个producer, slot_num == 2，则为在一个区块间隔后的下一个producer。注意的是slot_num代表的是区块间隔，非producer间隔\nget_scheduled_producer(uint32_t slot_num) {\n   const dynamic_global_property_object& dpo = get_dynamic_global_properties();\n  //注意点1，最后用来计算位置的值是一个当前的绝对位置 + slot_num  ？具体回头再看\n   uint64_t current_aslot = dpo.current_absolute_slot + slot_num;\n   ...\n  //位置对producer*重复次数的积取模\n   auto index = current_aslot % (number_of_active_producers * config::producer_repetitions);\n}\n\n//计算producer过去生产的参与率，代码未详\nproducer_participation_rate()\n\n\n\n//大概看了以上方法，有点乱。现在还不能连成线，只是点\n关键\nupdate_last_irreversible_block\n```\n\n\n\n\n### producer源码学习\n\n代码位置为..eos/plugins/producer_plugin/\n\n文件夹结构如下，producer_plugin.hpp为方法的声明， producer_plugin.cpp为具体实现\n\n```\n├── CMakeLists.txt\n├── include\n│   └── eosio\n│       └── producer_plugin\n│           └── producer_plugin.hpp\n└── producer_plugin.cpp\n\n```\n\n\n\n虽然producer_plugin.cpp的代码也只有不到400行，但节省时间和资源，就挑出块相关的说吧。方法调用如下\n\n```\nplugin_startup -> schedule_production_loop(到没到出块时间，到了就出块,这个方法不断循环) -> block_production_loop -> maybe_produce_block\n```\n\nmaybe_produce_block方法是最后决定是不是出块的。以下主要解释maybe_produce_block方法\n\n- 首先会检查区块是否同步到最新。\n\n- 接下来这段代码会判断是否到达出块时间。\n\n  ```\n   uint32_t slot = chain.get_slot_at_time( now );\n     if( slot == 0 )\n     {\n        capture(\"next_time\", chain.get_slot_time(1));\n        return block_production_condition::not_time_yet;\n     }\n  ```\n\n- 然后就选择出块producer了。\n\n  ```\n  auto scheduled_producer = chain.get_scheduled_producer( slot );\n  ```\n\n完了判断这个scheduled_producer是不是自己，是的话，再检查点别的(例如私钥啊等)，最后就出块了。\n\n那么，关键代码就是get_scheduled_producer方法。get_scheduled_producer的追踪要到chain_controller.cpp文件中了。位置位于./eos/libriaries/chain/chain_controller.cpp。以下代码未做特殊说明，都位于chain_controller.cpp中。\n\n首先看get_scheduled_producer的代码，可以看到，③通过从db中读出global_property_object对象gpo（下面会有介绍），gpo.active_producers为当前活跃的producers，然后④⑤为算得当前索引下标index，最后根据index在gpo.active_producers中取出相应producer即为返回值。下标计算的方式就是数学算式index=当前区块位置 % （producers总数 * 每个producer重复出多少块）。最后再除以每个producer重复出多少块。比较不理解的是当前区块位置(代码中的current_aslot)的计算方式。\n\n```\n//具体代码\n/*\n* 1. slot_num始终对应于未来的某一时刻\n* 2.对于slot_num的值，相对当前多少区块的间隔，\n*     例如，slot_num == 1 则为下一个区块的producer,\n*          slot_num == 2，则为在一个区块间隔后的下一个producer。slot_num即为区块间隔数\n* 3.使用方法get_slot_time和get_slot_at_time作为slot_num和时间戳的转换\n* 4.slot_num == 0，返回EOS_NULL_PRODUCER\n*/\naccount_name chain_controller::get_scheduled_producer(uint32_t slot_num)const\n{\n   const dynamic_global_property_object& dpo = get_dynamic_global_properties(); //①\n   uint64_t current_aslot = dpo.current_absolute_slot + slot_num; //②\n   const auto& gpo = _db.get<global_property_object>(); //③\n   auto number_of_active_producers = gpo.active_producers.producers.size();\n   auto index = current_aslot % (number_of_active_producers * config::producer_repetitions);  //④\n   index /= config::producer_repetitions; //⑤\n   FC_ASSERT( gpo.active_producers.producers.size() > 0, \"no producers defined\" );\n\n   return gpo.active_producers.producers[index].producer_name;\n}\n```\n\n\n\n关于global\\_property\\_object主要属性有active\\_producers、new\\_active\\_producers、pending\\_active\\_producers。\n\nactive\\_producers是当前轮的producers, pending\\_active\\_producers为满足排名等要求的producers, new\\_active\\_producers为所有可投票(或者是所有备选)的producer。\n\n在controller_chain.cpp中有如下几个方法：\n\n```\n//从投票排名中取出前m个producer,并排除block_signing_key是null的那些，m为配置中的producer_count。然而代码似乎没全.\n_calculate_producer_schedule() {...}\n\n//更新global_properties\nupdate_global_properties(){...}\n\n//上面提到过的有可能更新active_producers的方法\nupdate_last_irreversible_block(){...}\n\n /*\n *  After applying all transactions successfully we can update\n *  the current block time, block number, producer stats, etc\n */\n_finalize_block(){...}\n```\n\n主要通过上面列举的方法介绍active\\_producers、new\\_active\\_producers、pending\\_active\\_producers是如何关联的。下面一段如果觉得各个方法调用比较蒙的话，可以直接看三个加粗句子，可以了解到active\\_producers、new\\_active\\_producers、pending\\_active\\_producers之间的关联。\n\n在\\_finalize\\_block调用的时候，首先调用update\\_global\\_properties，在update\\_global\\_properties方法中调用了_calculate\\_producer\\_schedule方法，calculate\\_producer\\_schedule方法实现的是**从new\\_active\\_producers中选出符合条件的producers**，然后回到update\\_global\\_properties，**根据选出的producers,更新pending\\_active\\_producers**，然后回到\\_finalize\\_block方法，调用update\\_global\\_properties之后调用update_last_irreversible_block方法，**通过pending_active_producers适当更新active\\_producers**。\n\n然后，new\\_active\\_producers是通过wasm的api进行更新。这样就缕通了，通过投票客户端，进行投票，并控制更新new\\_active\\_producers参数选手，和相应票数。然后根据new\\_active\\_producers和票数决定blocker producers。\n\n那么，blocker producers的顺序呢？?? 不知道是被我疏忽了还是真的没看到。\n\n\n\nproducer源码中，可以看到，上层逻辑在 producer_plugin.cpp中，基本的dpos等逻辑还是在chain_controller.cpp中。\n","slug":"eos-code","published":1,"updated":"2019-10-14T06:46:21.817Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69wy0024t6xv77mus96g","content":"<h3 id=\"EOS-源码学习之项目结构分析-plugins\"><a href=\"#EOS-源码学习之项目结构分析-plugins\" class=\"headerlink\" title=\"EOS 源码学习之项目结构分析(plugins)\"></a>EOS 源码学习之项目结构分析(plugins)</h3><p>整体的代码位置主要位于plugins、libraries。</p>\n<p><strong>eos项目采用了插件管理的结构</strong>。</p>\n<h4 id=\"入口\"><a href=\"#入口\" class=\"headerlink\" title=\"入口\"></a>入口</h4><p>programs的文件夹结构如下，在<a href=\"https://github.com/EOSIO/eos/wiki/Programs-&-Tools\">eos官方wiki</a>中可以查看具体每个目录的含义及作用。这里仅备注几个示例。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.. eos/programs:</span><br><span class=\"line\"></span><br><span class=\"line\">├── CMakeLists.txt</span><br><span class=\"line\">├── cleos //命令行工具，如果把eos比作操作系统的话，cleos就类似终端作用  </span><br><span class=\"line\">├── debug_node</span><br><span class=\"line\">├── eosio-abigen</span><br><span class=\"line\">├── eosio-applesedemo</span><br><span class=\"line\">├── eosio-launcher</span><br><span class=\"line\">├── genesis</span><br><span class=\"line\">├── keosd  //钱包</span><br><span class=\"line\">├── nodeos  //节点核心进程</span><br><span class=\"line\">└── snapshot</span><br></pre></td></tr></table></figure>\n\n<p>要启动一个节点，需要用到的便是nodeos，cleos中可使用的REST API便是nodeos中暴露出来的。那么，我们看看nodeos。</p>\n<p>源代码main.cpp中，代码仅有105行。主要看看main方法吧（不想看代码可以略过代码部分 = =），通过代码可以看到，main方法作用包括设置版本、工作路径等基本信息，以及log的初始化，另外就是startup方法看起来就是关键！</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int main(int argc, char** argv)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">   try &#123;</span><br><span class=\"line\">      app().set_version(eosio::nodeos::config::version);</span><br><span class=\"line\">      auto root = fc::app_path();</span><br><span class=\"line\">      app().set_default_data_dir(root / &quot;eosio/nodeos/data&quot; );</span><br><span class=\"line\">      app().set_default_config_dir(root / &quot;eosio/nodeos/config&quot; );</span><br><span class=\"line\">      if(!app().initialize&lt;chain_plugin, http_plugin, net_plugin, producer_plugin&gt;(argc, argv))</span><br><span class=\"line\">         return -1;</span><br><span class=\"line\">      initialize_logging();</span><br><span class=\"line\">      ilog(&quot;nodeos version $&#123;ver&#125;&quot;, (&quot;ver&quot;, eosio::utilities::common::itoh(static_cast&lt;uint32_t&gt;(app().version()))));</span><br><span class=\"line\">      ilog(&quot;eosio root is $&#123;root&#125;&quot;, (&quot;root&quot;, root.string()));</span><br><span class=\"line\">      //重要的代码!!!</span><br><span class=\"line\">      app().startup();</span><br><span class=\"line\">      app().exec();</span><br><span class=\"line\">   &#125; catch (const fc::exception&amp; e) &#123;</span><br><span class=\"line\">   &#125; .....(此处省略多个catch)</span><br><span class=\"line\">   return 0;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>app()位置位于</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./libraries/appbase/application.cpp</span><br><span class=\"line\">//app()方法返回application的实例(对c++的类的机制不了解，这个实例像是静态对象，反正就是通过返回的实例可以调用相关方法吧，包括startup这个看起来就跟关键的方法)</span><br></pre></td></tr></table></figure>\n\n<p>进入到application.cpp中，例举相关方法</p>\n<ul>\n<li><p>initialize_..: 初始化插件，功能包括调用各个插件设置命令行参数，以及初始化方法，还有app自身对应初始化操作</p>\n</li>\n<li><p>startup:  循环各插件，调用各插件的startup方法</p>\n</li>\n<li><p>exec:  表示完全看不懂= =!!。猜测一下，应该是监听io事件，例如结束进程系列..</p>\n</li>\n</ul>\n<p>从这里可以看出，主要的具体的重要的内容都在各插件内部。</p>\n<h4 id=\"插件\"><a href=\"#插件\" class=\"headerlink\" title=\"插件\"></a>插件</h4><p>eos项目采用了插件管理的结构。插件的目录如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.. eos/plugins:</span><br><span class=\"line\"></span><br><span class=\"line\">├── CMakeLists.txt</span><br><span class=\"line\">├── account_history_api_plugin</span><br><span class=\"line\">├── account_history_plugin</span><br><span class=\"line\">├── chain_api_plugin</span><br><span class=\"line\">├── chain_plugin</span><br><span class=\"line\">├── eosio-make_new_plugin.sh</span><br><span class=\"line\">├── faucet_testnet_plugin</span><br><span class=\"line\">├── http_plugin</span><br><span class=\"line\">├── mongo_db_plugin</span><br><span class=\"line\">├── net_api_plugin</span><br><span class=\"line\">├── net_plugin</span><br><span class=\"line\">├── producer_plugin</span><br><span class=\"line\">├── template_plugin</span><br><span class=\"line\">├── txn_test_gen_plugin</span><br><span class=\"line\">├── wallet_api_plugin</span><br><span class=\"line\">└── wallet_plugin</span><br></pre></td></tr></table></figure>\n\n<p>完全可以通过命名来理解各插件的含义。要分析的话，直接从相应plugins入手。逐一观察..</p>\n<h3 id=\"eos-nodeos学习\"><a href=\"#eos-nodeos学习\" class=\"headerlink\" title=\"eos/nodeos学习\"></a>eos/nodeos学习</h3><h4 id=\"main-cpp\"><a href=\"#main-cpp\" class=\"headerlink\" title=\"main.cpp\"></a>main.cpp</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//设置版本</span><br><span class=\"line\">app().set_version(eosio::nodeos::config::version);</span><br><span class=\"line\">auto root = fc::app_path();</span><br><span class=\"line\">//设置工作路径</span><br><span class=\"line\">app().set_default_data_dir(root / &quot;eosio/nodeos/data&quot; );</span><br><span class=\"line\">app().set_default_config_dir(root / &quot;eosio/nodeos/config&quot; );</span><br><span class=\"line\">//单节点需要的插件包括以下四个</span><br><span class=\"line\">if(!app().initialize&lt;chain_plugin, http_plugin, net_plugin, producer_plugin&gt;(argc, argv))</span><br><span class=\"line\">   return -1;</span><br><span class=\"line\"></span><br><span class=\"line\">initialize_logging();</span><br><span class=\"line\">ilog(&quot;nodeos version $&#123;ver&#125;&quot;, (&quot;ver&quot;, eosio::nodeos::config::itoh(static_cast&lt;uint32_t&gt;(app().version()))));</span><br><span class=\"line\">ilog(&quot;eosio root is $&#123;root&#125;&quot;, (&quot;root&quot;, root.string()));</span><br><span class=\"line\">app().startup();</span><br><span class=\"line\">app().exec();</span><br></pre></td></tr></table></figure>\n\n<p>主要是配置和app的一些调用。然后转到app中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./libraries/appbase/application.cpp</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>app:  返回application的实例（实例只是声明，木有初始化，对c++类机制不太了解，需进一步了解，目前就理解成这个实例就可访问application::method方法）</p>\n</li>\n<li><p>initialize_..: 初始化插件，功能包括调用各个插件设置命令行参数，以及初始化方法，还有app自身对应初始化操作</p>\n</li>\n<li><p>startup:  循环各插件，调用各插件的startup方法</p>\n</li>\n<li><p>exec:  表示完全看不懂= =!!。猜测一下，应该是监听io事件，例如结束进程系列..</p>\n</li>\n</ul>\n<p>那么针对单个节点启动必要的4个插件，进行逐个学习。</p>\n<p>首先是插件父方法：（在application中调用的方法名直接是start_up，没有plugin前缀，这个问题有待解决..）</p>\n<ul>\n<li><p>set_program_options //设置命令行参数</p>\n</li>\n<li><p>plugin_initialize //初始化操作</p>\n</li>\n<li><p>plugin_startup  //启动</p>\n</li>\n<li><p>plugin_shutdown  //退出</p>\n</li>\n</ul>\n<h4 id=\"Chain-plugin\"><a href=\"#Chain-plugin\" class=\"headerlink\" title=\"Chain_plugin\"></a>Chain_plugin</h4><h4 id=\"Producer-plugin\"><a href=\"#Producer-plugin\" class=\"headerlink\" title=\"Producer_plugin\"></a>Producer_plugin</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// dpos共识  地方 -&gt; get_scheduled_producer的定义在chain_controller</span><br><span class=\"line\">auto scheduled_producer = chain.get_scheduled_producer( slot );</span><br><span class=\"line\">  // we must control the producer scheduled to produce the next block.</span><br><span class=\"line\">  if( _producers.find( scheduled_producer ) == _producers.end() )</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">     capture(&quot;scheduled_producer&quot;, scheduled_producer);</span><br><span class=\"line\">     return block_production_condition::not_my_turn;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//chain_controller的一些相关producer方法</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//大意猜测更新新区块，包括新区块和签名新区块的producer</span></span><br><span class=\"line\">update_signing_producer(<span class=\"keyword\">const</span> producer_object&amp; signing_producer, <span class=\"keyword\">const</span> signed_block&amp; new_block)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//根据新的producers更新db表？疑问是代码中只有create，没有删除操作</span></span><br><span class=\"line\">update_or_create_producers( <span class=\"keyword\">const</span> producer_schedule_type&amp; producers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//好像这个是关键！详细看一下，对方法的解释为，从投票排名中取出前m个producer,并排除block_signing_key是null的那些，m为配置中的producer_count。然而代码似乎没全..</span></span><br><span class=\"line\">_calculate_producer_schedule() &#123;</span><br><span class=\"line\">  <span class=\"comment\">//get_global_properties返回为global_property_object对象，new_active_producers为对象的熟悉</span></span><br><span class=\"line\">  <span class=\"comment\">//据观察，new_active_producers的赋值目前只出现在wasm的api中，那是不是就可以得出结论new_active_producers是所有的参选producers..这个方法(_calculate_producer_schedule)要做的就是从所有参选者中按排名取前m个，然后去掉block_signing_key是null的那些</span></span><br><span class=\"line\">   producer_schedule_type schedule = get_global_properties().new_active_producers;</span><br><span class=\"line\">   <span class=\"keyword\">const</span> auto&amp; hps = _head_producer_schedule();</span><br><span class=\"line\">   schedule.version = hps.version;</span><br><span class=\"line\">   <span class=\"keyword\">if</span>( hps != schedule )</span><br><span class=\"line\">      ++schedule.version;</span><br><span class=\"line\">   <span class=\"keyword\">return</span> schedule;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//没看懂..好像是给所有producers怎么搞了一下认证(更新到_db某表)</span></span><br><span class=\"line\">_update_producers_authority()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//返回当前区块头的producer</span></span><br><span class=\"line\">head_block_producer()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//根据account_name/ownername获取对于producer</span></span><br><span class=\"line\">get_producer(<span class=\"keyword\">const</span> account_name&amp; ownername)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//这个方法也蛮重要的，根据slot_num获取已计划好的producer.其中，slot_num始终对应于未来的某一时刻；另外，对于slot_num的值，相对当前多少区块的间隔，例如，slot_num == 1 则为下一个producer, slot_num == 2，则为在一个区块间隔后的下一个producer。注意的是slot_num代表的是区块间隔，非producer间隔</span></span><br><span class=\"line\">get_scheduled_producer(uint32_t slot_num) &#123;</span><br><span class=\"line\">   <span class=\"keyword\">const</span> dynamic_global_property_object&amp; dpo = get_dynamic_global_properties();</span><br><span class=\"line\">  <span class=\"comment\">//注意点1，最后用来计算位置的值是一个当前的绝对位置 + slot_num  ？具体回头再看</span></span><br><span class=\"line\">   uint64_t current_aslot = dpo.current_absolute_slot + slot_num;</span><br><span class=\"line\">   ...</span><br><span class=\"line\">  <span class=\"comment\">//位置对producer*重复次数的积取模</span></span><br><span class=\"line\">   auto index = current_aslot % (number_of_active_producers * config::producer_repetitions);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//计算producer过去生产的参与率，代码未详</span></span><br><span class=\"line\">producer_participation_rate()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//大概看了以上方法，有点乱。现在还不能连成线，只是点</span></span><br><span class=\"line\">关键</span><br><span class=\"line\">update_last_irreversible_block</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"producer源码学习\"><a href=\"#producer源码学习\" class=\"headerlink\" title=\"producer源码学习\"></a>producer源码学习</h3><p>代码位置为..eos/plugins/producer_plugin/</p>\n<p>文件夹结构如下，producer_plugin.hpp为方法的声明， producer_plugin.cpp为具体实现</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">├── CMakeLists.txt</span><br><span class=\"line\">├── include</span><br><span class=\"line\">│   └── eosio</span><br><span class=\"line\">│       └── producer_plugin</span><br><span class=\"line\">│           └── producer_plugin.hpp</span><br><span class=\"line\">└── producer_plugin.cpp</span><br></pre></td></tr></table></figure>\n\n<p>虽然producer_plugin.cpp的代码也只有不到400行，但节省时间和资源，就挑出块相关的说吧。方法调用如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plugin_startup -&gt; schedule_production_loop(到没到出块时间，到了就出块,这个方法不断循环) -&gt; block_production_loop -&gt; maybe_produce_block</span><br></pre></td></tr></table></figure>\n\n<p>maybe_produce_block方法是最后决定是不是出块的。以下主要解释maybe_produce_block方法</p>\n<ul>\n<li><p>首先会检查区块是否同步到最新。</p>\n</li>\n<li><p>接下来这段代码会判断是否到达出块时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">uint32_t slot = chain.get_slot_at_time( now );</span><br><span class=\"line\">  if( slot == 0 )</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">     capture(&quot;next_time&quot;, chain.get_slot_time(1));</span><br><span class=\"line\">     return block_production_condition::not_time_yet;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后就选择出块producer了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto scheduled_producer = chain.get_scheduled_producer( slot );</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>完了判断这个scheduled_producer是不是自己，是的话，再检查点别的(例如私钥啊等)，最后就出块了。</p>\n<p>那么，关键代码就是get_scheduled_producer方法。get_scheduled_producer的追踪要到chain_controller.cpp文件中了。位置位于./eos/libriaries/chain/chain_controller.cpp。以下代码未做特殊说明，都位于chain_controller.cpp中。</p>\n<p>首先看get_scheduled_producer的代码，可以看到，③通过从db中读出global_property_object对象gpo（下面会有介绍），gpo.active_producers为当前活跃的producers，然后④⑤为算得当前索引下标index，最后根据index在gpo.active_producers中取出相应producer即为返回值。下标计算的方式就是数学算式index=当前区块位置 % （producers总数 * 每个producer重复出多少块）。最后再除以每个producer重复出多少块。比较不理解的是当前区块位置(代码中的current_aslot)的计算方式。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//具体代码</span><br><span class=\"line\">/*</span><br><span class=\"line\">* 1. slot_num始终对应于未来的某一时刻</span><br><span class=\"line\">* 2.对于slot_num的值，相对当前多少区块的间隔，</span><br><span class=\"line\">*     例如，slot_num == 1 则为下一个区块的producer,</span><br><span class=\"line\">*          slot_num == 2，则为在一个区块间隔后的下一个producer。slot_num即为区块间隔数</span><br><span class=\"line\">* 3.使用方法get_slot_time和get_slot_at_time作为slot_num和时间戳的转换</span><br><span class=\"line\">* 4.slot_num == 0，返回EOS_NULL_PRODUCER</span><br><span class=\"line\">*/</span><br><span class=\"line\">account_name chain_controller::get_scheduled_producer(uint32_t slot_num)const</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">   const dynamic_global_property_object&amp; dpo = get_dynamic_global_properties(); //①</span><br><span class=\"line\">   uint64_t current_aslot = dpo.current_absolute_slot + slot_num; //②</span><br><span class=\"line\">   const auto&amp; gpo = _db.get&lt;global_property_object&gt;(); //③</span><br><span class=\"line\">   auto number_of_active_producers = gpo.active_producers.producers.size();</span><br><span class=\"line\">   auto index = current_aslot % (number_of_active_producers * config::producer_repetitions);  //④</span><br><span class=\"line\">   index /= config::producer_repetitions; //⑤</span><br><span class=\"line\">   FC_ASSERT( gpo.active_producers.producers.size() &gt; 0, &quot;no producers defined&quot; );</span><br><span class=\"line\"></span><br><span class=\"line\">   return gpo.active_producers.producers[index].producer_name;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>关于global_property_object主要属性有active_producers、new_active_producers、pending_active_producers。</p>\n<p>active_producers是当前轮的producers, pending_active_producers为满足排名等要求的producers, new_active_producers为所有可投票(或者是所有备选)的producer。</p>\n<p>在controller_chain.cpp中有如下几个方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//从投票排名中取出前m个producer,并排除block_signing_key是null的那些，m为配置中的producer_count。然而代码似乎没全.</span><br><span class=\"line\">_calculate_producer_schedule() &#123;...&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//更新global_properties</span><br><span class=\"line\">update_global_properties()&#123;...&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//上面提到过的有可能更新active_producers的方法</span><br><span class=\"line\">update_last_irreversible_block()&#123;...&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> /*</span><br><span class=\"line\"> *  After applying all transactions successfully we can update</span><br><span class=\"line\"> *  the current block time, block number, producer stats, etc</span><br><span class=\"line\"> */</span><br><span class=\"line\">_finalize_block()&#123;...&#125;</span><br></pre></td></tr></table></figure>\n\n<p>主要通过上面列举的方法介绍active_producers、new_active_producers、pending_active_producers是如何关联的。下面一段如果觉得各个方法调用比较蒙的话，可以直接看三个加粗句子，可以了解到active_producers、new_active_producers、pending_active_producers之间的关联。</p>\n<p>在_finalize_block调用的时候，首先调用update_global_properties，在update_global_properties方法中调用了_calculate_producer_schedule方法，calculate_producer_schedule方法实现的是<strong>从new_active_producers中选出符合条件的producers</strong>，然后回到update_global_properties，<strong>根据选出的producers,更新pending_active_producers</strong>，然后回到_finalize_block方法，调用update_global_properties之后调用update_last_irreversible_block方法，<strong>通过pending_active_producers适当更新active_producers</strong>。</p>\n<p>然后，new_active_producers是通过wasm的api进行更新。这样就缕通了，通过投票客户端，进行投票，并控制更新new_active_producers参数选手，和相应票数。然后根据new_active_producers和票数决定blocker producers。</p>\n<p>那么，blocker producers的顺序呢？?? 不知道是被我疏忽了还是真的没看到。</p>\n<p>producer源码中，可以看到，上层逻辑在 producer_plugin.cpp中，基本的dpos等逻辑还是在chain_controller.cpp中。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h3 id=\"EOS-源码学习之项目结构分析-plugins\"><a href=\"#EOS-源码学习之项目结构分析-plugins\" class=\"headerlink\" title=\"EOS 源码学习之项目结构分析(plugins)\"></a>EOS 源码学习之项目结构分析(plugins)</h3><p>整体的代码位置主要位于plugins、libraries。</p>\n<p><strong>eos项目采用了插件管理的结构</strong>。</p>\n<h4 id=\"入口\"><a href=\"#入口\" class=\"headerlink\" title=\"入口\"></a>入口</h4><p>programs的文件夹结构如下，在<a href=\"https://github.com/EOSIO/eos/wiki/Programs-&-Tools\">eos官方wiki</a>中可以查看具体每个目录的含义及作用。这里仅备注几个示例。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.. eos/programs:</span><br><span class=\"line\"></span><br><span class=\"line\">├── CMakeLists.txt</span><br><span class=\"line\">├── cleos //命令行工具，如果把eos比作操作系统的话，cleos就类似终端作用  </span><br><span class=\"line\">├── debug_node</span><br><span class=\"line\">├── eosio-abigen</span><br><span class=\"line\">├── eosio-applesedemo</span><br><span class=\"line\">├── eosio-launcher</span><br><span class=\"line\">├── genesis</span><br><span class=\"line\">├── keosd  //钱包</span><br><span class=\"line\">├── nodeos  //节点核心进程</span><br><span class=\"line\">└── snapshot</span><br></pre></td></tr></table></figure>\n\n<p>要启动一个节点，需要用到的便是nodeos，cleos中可使用的REST API便是nodeos中暴露出来的。那么，我们看看nodeos。</p>\n<p>源代码main.cpp中，代码仅有105行。主要看看main方法吧（不想看代码可以略过代码部分 = =），通过代码可以看到，main方法作用包括设置版本、工作路径等基本信息，以及log的初始化，另外就是startup方法看起来就是关键！</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int main(int argc, char** argv)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">   try &#123;</span><br><span class=\"line\">      app().set_version(eosio::nodeos::config::version);</span><br><span class=\"line\">      auto root = fc::app_path();</span><br><span class=\"line\">      app().set_default_data_dir(root / &quot;eosio/nodeos/data&quot; );</span><br><span class=\"line\">      app().set_default_config_dir(root / &quot;eosio/nodeos/config&quot; );</span><br><span class=\"line\">      if(!app().initialize&lt;chain_plugin, http_plugin, net_plugin, producer_plugin&gt;(argc, argv))</span><br><span class=\"line\">         return -1;</span><br><span class=\"line\">      initialize_logging();</span><br><span class=\"line\">      ilog(&quot;nodeos version $&#123;ver&#125;&quot;, (&quot;ver&quot;, eosio::utilities::common::itoh(static_cast&lt;uint32_t&gt;(app().version()))));</span><br><span class=\"line\">      ilog(&quot;eosio root is $&#123;root&#125;&quot;, (&quot;root&quot;, root.string()));</span><br><span class=\"line\">      //重要的代码!!!</span><br><span class=\"line\">      app().startup();</span><br><span class=\"line\">      app().exec();</span><br><span class=\"line\">   &#125; catch (const fc::exception&amp; e) &#123;</span><br><span class=\"line\">   &#125; .....(此处省略多个catch)</span><br><span class=\"line\">   return 0;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>app()位置位于</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./libraries/appbase/application.cpp</span><br><span class=\"line\">//app()方法返回application的实例(对c++的类的机制不了解，这个实例像是静态对象，反正就是通过返回的实例可以调用相关方法吧，包括startup这个看起来就跟关键的方法)</span><br></pre></td></tr></table></figure>\n\n<p>进入到application.cpp中，例举相关方法</p>\n<ul>\n<li><p>initialize_..: 初始化插件，功能包括调用各个插件设置命令行参数，以及初始化方法，还有app自身对应初始化操作</p>\n</li>\n<li><p>startup:  循环各插件，调用各插件的startup方法</p>\n</li>\n<li><p>exec:  表示完全看不懂= =!!。猜测一下，应该是监听io事件，例如结束进程系列..</p>\n</li>\n</ul>\n<p>从这里可以看出，主要的具体的重要的内容都在各插件内部。</p>\n<h4 id=\"插件\"><a href=\"#插件\" class=\"headerlink\" title=\"插件\"></a>插件</h4><p>eos项目采用了插件管理的结构。插件的目录如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.. eos/plugins:</span><br><span class=\"line\"></span><br><span class=\"line\">├── CMakeLists.txt</span><br><span class=\"line\">├── account_history_api_plugin</span><br><span class=\"line\">├── account_history_plugin</span><br><span class=\"line\">├── chain_api_plugin</span><br><span class=\"line\">├── chain_plugin</span><br><span class=\"line\">├── eosio-make_new_plugin.sh</span><br><span class=\"line\">├── faucet_testnet_plugin</span><br><span class=\"line\">├── http_plugin</span><br><span class=\"line\">├── mongo_db_plugin</span><br><span class=\"line\">├── net_api_plugin</span><br><span class=\"line\">├── net_plugin</span><br><span class=\"line\">├── producer_plugin</span><br><span class=\"line\">├── template_plugin</span><br><span class=\"line\">├── txn_test_gen_plugin</span><br><span class=\"line\">├── wallet_api_plugin</span><br><span class=\"line\">└── wallet_plugin</span><br></pre></td></tr></table></figure>\n\n<p>完全可以通过命名来理解各插件的含义。要分析的话，直接从相应plugins入手。逐一观察..</p>\n<h3 id=\"eos-nodeos学习\"><a href=\"#eos-nodeos学习\" class=\"headerlink\" title=\"eos/nodeos学习\"></a>eos/nodeos学习</h3><h4 id=\"main-cpp\"><a href=\"#main-cpp\" class=\"headerlink\" title=\"main.cpp\"></a>main.cpp</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//设置版本</span><br><span class=\"line\">app().set_version(eosio::nodeos::config::version);</span><br><span class=\"line\">auto root = fc::app_path();</span><br><span class=\"line\">//设置工作路径</span><br><span class=\"line\">app().set_default_data_dir(root / &quot;eosio/nodeos/data&quot; );</span><br><span class=\"line\">app().set_default_config_dir(root / &quot;eosio/nodeos/config&quot; );</span><br><span class=\"line\">//单节点需要的插件包括以下四个</span><br><span class=\"line\">if(!app().initialize&lt;chain_plugin, http_plugin, net_plugin, producer_plugin&gt;(argc, argv))</span><br><span class=\"line\">   return -1;</span><br><span class=\"line\"></span><br><span class=\"line\">initialize_logging();</span><br><span class=\"line\">ilog(&quot;nodeos version $&#123;ver&#125;&quot;, (&quot;ver&quot;, eosio::nodeos::config::itoh(static_cast&lt;uint32_t&gt;(app().version()))));</span><br><span class=\"line\">ilog(&quot;eosio root is $&#123;root&#125;&quot;, (&quot;root&quot;, root.string()));</span><br><span class=\"line\">app().startup();</span><br><span class=\"line\">app().exec();</span><br></pre></td></tr></table></figure>\n\n<p>主要是配置和app的一些调用。然后转到app中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./libraries/appbase/application.cpp</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>app:  返回application的实例（实例只是声明，木有初始化，对c++类机制不太了解，需进一步了解，目前就理解成这个实例就可访问application::method方法）</p>\n</li>\n<li><p>initialize_..: 初始化插件，功能包括调用各个插件设置命令行参数，以及初始化方法，还有app自身对应初始化操作</p>\n</li>\n<li><p>startup:  循环各插件，调用各插件的startup方法</p>\n</li>\n<li><p>exec:  表示完全看不懂= =!!。猜测一下，应该是监听io事件，例如结束进程系列..</p>\n</li>\n</ul>\n<p>那么针对单个节点启动必要的4个插件，进行逐个学习。</p>\n<p>首先是插件父方法：（在application中调用的方法名直接是start_up，没有plugin前缀，这个问题有待解决..）</p>\n<ul>\n<li><p>set_program_options //设置命令行参数</p>\n</li>\n<li><p>plugin_initialize //初始化操作</p>\n</li>\n<li><p>plugin_startup  //启动</p>\n</li>\n<li><p>plugin_shutdown  //退出</p>\n</li>\n</ul>\n<h4 id=\"Chain-plugin\"><a href=\"#Chain-plugin\" class=\"headerlink\" title=\"Chain_plugin\"></a>Chain_plugin</h4><h4 id=\"Producer-plugin\"><a href=\"#Producer-plugin\" class=\"headerlink\" title=\"Producer_plugin\"></a>Producer_plugin</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// dpos共识  地方 -&gt; get_scheduled_producer的定义在chain_controller</span><br><span class=\"line\">auto scheduled_producer = chain.get_scheduled_producer( slot );</span><br><span class=\"line\">  // we must control the producer scheduled to produce the next block.</span><br><span class=\"line\">  if( _producers.find( scheduled_producer ) == _producers.end() )</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">     capture(&quot;scheduled_producer&quot;, scheduled_producer);</span><br><span class=\"line\">     return block_production_condition::not_my_turn;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//chain_controller的一些相关producer方法</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//大意猜测更新新区块，包括新区块和签名新区块的producer</span></span><br><span class=\"line\">update_signing_producer(<span class=\"keyword\">const</span> producer_object&amp; signing_producer, <span class=\"keyword\">const</span> signed_block&amp; new_block)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//根据新的producers更新db表？疑问是代码中只有create，没有删除操作</span></span><br><span class=\"line\">update_or_create_producers( <span class=\"keyword\">const</span> producer_schedule_type&amp; producers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//好像这个是关键！详细看一下，对方法的解释为，从投票排名中取出前m个producer,并排除block_signing_key是null的那些，m为配置中的producer_count。然而代码似乎没全..</span></span><br><span class=\"line\">_calculate_producer_schedule() &#123;</span><br><span class=\"line\">  <span class=\"comment\">//get_global_properties返回为global_property_object对象，new_active_producers为对象的熟悉</span></span><br><span class=\"line\">  <span class=\"comment\">//据观察，new_active_producers的赋值目前只出现在wasm的api中，那是不是就可以得出结论new_active_producers是所有的参选producers..这个方法(_calculate_producer_schedule)要做的就是从所有参选者中按排名取前m个，然后去掉block_signing_key是null的那些</span></span><br><span class=\"line\">   producer_schedule_type schedule = get_global_properties().new_active_producers;</span><br><span class=\"line\">   <span class=\"keyword\">const</span> auto&amp; hps = _head_producer_schedule();</span><br><span class=\"line\">   schedule.version = hps.version;</span><br><span class=\"line\">   <span class=\"keyword\">if</span>( hps != schedule )</span><br><span class=\"line\">      ++schedule.version;</span><br><span class=\"line\">   <span class=\"keyword\">return</span> schedule;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//没看懂..好像是给所有producers怎么搞了一下认证(更新到_db某表)</span></span><br><span class=\"line\">_update_producers_authority()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//返回当前区块头的producer</span></span><br><span class=\"line\">head_block_producer()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//根据account_name/ownername获取对于producer</span></span><br><span class=\"line\">get_producer(<span class=\"keyword\">const</span> account_name&amp; ownername)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//这个方法也蛮重要的，根据slot_num获取已计划好的producer.其中，slot_num始终对应于未来的某一时刻；另外，对于slot_num的值，相对当前多少区块的间隔，例如，slot_num == 1 则为下一个producer, slot_num == 2，则为在一个区块间隔后的下一个producer。注意的是slot_num代表的是区块间隔，非producer间隔</span></span><br><span class=\"line\">get_scheduled_producer(uint32_t slot_num) &#123;</span><br><span class=\"line\">   <span class=\"keyword\">const</span> dynamic_global_property_object&amp; dpo = get_dynamic_global_properties();</span><br><span class=\"line\">  <span class=\"comment\">//注意点1，最后用来计算位置的值是一个当前的绝对位置 + slot_num  ？具体回头再看</span></span><br><span class=\"line\">   uint64_t current_aslot = dpo.current_absolute_slot + slot_num;</span><br><span class=\"line\">   ...</span><br><span class=\"line\">  <span class=\"comment\">//位置对producer*重复次数的积取模</span></span><br><span class=\"line\">   auto index = current_aslot % (number_of_active_producers * config::producer_repetitions);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//计算producer过去生产的参与率，代码未详</span></span><br><span class=\"line\">producer_participation_rate()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//大概看了以上方法，有点乱。现在还不能连成线，只是点</span></span><br><span class=\"line\">关键</span><br><span class=\"line\">update_last_irreversible_block</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"producer源码学习\"><a href=\"#producer源码学习\" class=\"headerlink\" title=\"producer源码学习\"></a>producer源码学习</h3><p>代码位置为..eos/plugins/producer_plugin/</p>\n<p>文件夹结构如下，producer_plugin.hpp为方法的声明， producer_plugin.cpp为具体实现</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">├── CMakeLists.txt</span><br><span class=\"line\">├── include</span><br><span class=\"line\">│   └── eosio</span><br><span class=\"line\">│       └── producer_plugin</span><br><span class=\"line\">│           └── producer_plugin.hpp</span><br><span class=\"line\">└── producer_plugin.cpp</span><br></pre></td></tr></table></figure>\n\n<p>虽然producer_plugin.cpp的代码也只有不到400行，但节省时间和资源，就挑出块相关的说吧。方法调用如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plugin_startup -&gt; schedule_production_loop(到没到出块时间，到了就出块,这个方法不断循环) -&gt; block_production_loop -&gt; maybe_produce_block</span><br></pre></td></tr></table></figure>\n\n<p>maybe_produce_block方法是最后决定是不是出块的。以下主要解释maybe_produce_block方法</p>\n<ul>\n<li><p>首先会检查区块是否同步到最新。</p>\n</li>\n<li><p>接下来这段代码会判断是否到达出块时间。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">uint32_t slot = chain.get_slot_at_time( now );</span><br><span class=\"line\">  if( slot == 0 )</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">     capture(&quot;next_time&quot;, chain.get_slot_time(1));</span><br><span class=\"line\">     return block_production_condition::not_time_yet;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后就选择出块producer了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto scheduled_producer = chain.get_scheduled_producer( slot );</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>完了判断这个scheduled_producer是不是自己，是的话，再检查点别的(例如私钥啊等)，最后就出块了。</p>\n<p>那么，关键代码就是get_scheduled_producer方法。get_scheduled_producer的追踪要到chain_controller.cpp文件中了。位置位于./eos/libriaries/chain/chain_controller.cpp。以下代码未做特殊说明，都位于chain_controller.cpp中。</p>\n<p>首先看get_scheduled_producer的代码，可以看到，③通过从db中读出global_property_object对象gpo（下面会有介绍），gpo.active_producers为当前活跃的producers，然后④⑤为算得当前索引下标index，最后根据index在gpo.active_producers中取出相应producer即为返回值。下标计算的方式就是数学算式index=当前区块位置 % （producers总数 * 每个producer重复出多少块）。最后再除以每个producer重复出多少块。比较不理解的是当前区块位置(代码中的current_aslot)的计算方式。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//具体代码</span><br><span class=\"line\">/*</span><br><span class=\"line\">* 1. slot_num始终对应于未来的某一时刻</span><br><span class=\"line\">* 2.对于slot_num的值，相对当前多少区块的间隔，</span><br><span class=\"line\">*     例如，slot_num == 1 则为下一个区块的producer,</span><br><span class=\"line\">*          slot_num == 2，则为在一个区块间隔后的下一个producer。slot_num即为区块间隔数</span><br><span class=\"line\">* 3.使用方法get_slot_time和get_slot_at_time作为slot_num和时间戳的转换</span><br><span class=\"line\">* 4.slot_num == 0，返回EOS_NULL_PRODUCER</span><br><span class=\"line\">*/</span><br><span class=\"line\">account_name chain_controller::get_scheduled_producer(uint32_t slot_num)const</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">   const dynamic_global_property_object&amp; dpo = get_dynamic_global_properties(); //①</span><br><span class=\"line\">   uint64_t current_aslot = dpo.current_absolute_slot + slot_num; //②</span><br><span class=\"line\">   const auto&amp; gpo = _db.get&lt;global_property_object&gt;(); //③</span><br><span class=\"line\">   auto number_of_active_producers = gpo.active_producers.producers.size();</span><br><span class=\"line\">   auto index = current_aslot % (number_of_active_producers * config::producer_repetitions);  //④</span><br><span class=\"line\">   index /= config::producer_repetitions; //⑤</span><br><span class=\"line\">   FC_ASSERT( gpo.active_producers.producers.size() &gt; 0, &quot;no producers defined&quot; );</span><br><span class=\"line\"></span><br><span class=\"line\">   return gpo.active_producers.producers[index].producer_name;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>关于global_property_object主要属性有active_producers、new_active_producers、pending_active_producers。</p>\n<p>active_producers是当前轮的producers, pending_active_producers为满足排名等要求的producers, new_active_producers为所有可投票(或者是所有备选)的producer。</p>\n<p>在controller_chain.cpp中有如下几个方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//从投票排名中取出前m个producer,并排除block_signing_key是null的那些，m为配置中的producer_count。然而代码似乎没全.</span><br><span class=\"line\">_calculate_producer_schedule() &#123;...&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//更新global_properties</span><br><span class=\"line\">update_global_properties()&#123;...&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//上面提到过的有可能更新active_producers的方法</span><br><span class=\"line\">update_last_irreversible_block()&#123;...&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> /*</span><br><span class=\"line\"> *  After applying all transactions successfully we can update</span><br><span class=\"line\"> *  the current block time, block number, producer stats, etc</span><br><span class=\"line\"> */</span><br><span class=\"line\">_finalize_block()&#123;...&#125;</span><br></pre></td></tr></table></figure>\n\n<p>主要通过上面列举的方法介绍active_producers、new_active_producers、pending_active_producers是如何关联的。下面一段如果觉得各个方法调用比较蒙的话，可以直接看三个加粗句子，可以了解到active_producers、new_active_producers、pending_active_producers之间的关联。</p>\n<p>在_finalize_block调用的时候，首先调用update_global_properties，在update_global_properties方法中调用了_calculate_producer_schedule方法，calculate_producer_schedule方法实现的是<strong>从new_active_producers中选出符合条件的producers</strong>，然后回到update_global_properties，<strong>根据选出的producers,更新pending_active_producers</strong>，然后回到_finalize_block方法，调用update_global_properties之后调用update_last_irreversible_block方法，<strong>通过pending_active_producers适当更新active_producers</strong>。</p>\n<p>然后，new_active_producers是通过wasm的api进行更新。这样就缕通了，通过投票客户端，进行投票，并控制更新new_active_producers参数选手，和相应票数。然后根据new_active_producers和票数决定blocker producers。</p>\n<p>那么，blocker producers的顺序呢？?? 不知道是被我疏忽了还是真的没看到。</p>\n<p>producer源码中，可以看到，上层逻辑在 producer_plugin.cpp中，基本的dpos等逻辑还是在chain_controller.cpp中。</p>\n"},{"title":"eth_erc","date":"2019-10-14T06:53:20.000Z","_content":"\n#### ERC\n\nERC，Etuereum Request for Comment。为了创建一个以太坊平台的标准，开发人员应当提交了一个以太坊改进方案(EIP)，改进方案中包括协议规范和合约标准，一旦EIP被委员会批准并最终确定，它就成为ERC/Core\n\n参考自[连接](https://eips.ethereum.org/erc)\n\n\n\n#### Final\n\n- ERC20\n\n  代币标准化的一个起点。在Ethereum平台之上发布的大多数通证（`token`）都使用它。它定义了以下函数接口\n\n  - totalSupply()：返回代币供给总量\n  - balanceOf(address _owner)：返回_owner的帐户余额\n  - transfer(address _to,uint256 _value)：并将数量为_value的代币转入地址_to并触发transfer事件\n  - transferFrom(address _from,address _to,uint256_value)：将地址_from中的_value数量的代币转入地址_to ，并触发transfer事件\n  - approve(address _spender,uint256 _value)：允许_spender提取限额_value的代币\n  - allowance(address _owner,address _spender）：返回_spender可从_owner提款的代币数量上限\n\n  以上函数将触发以下事件：\n\n  - transfer(address indexed _from,address indexed _to,uint256 _value)：每次进行代币转账时都会触发\n  - approval(address indexed _owner,address indexed _spender,uint256 _value)：调用approve()方法将触发该事件\n\n\n\n- ERC20的补充:\n\n  - ERC223\n  - ERC62, 加了两个额外的功能， increaseSupply和decreaseSupply, 这可以增加和减少流通中的令牌供应\n  - ERC827，它允许转让Token并允许持有人允许第三方使用Token。 以太坊上的Token可以被其他应用程序重复使用，这其中也包括钱包和交易所。 当需要支持第三方动态消费限额调整时这一点非常有用。ERC827与ERC-20兼容。\n\n- ERC721\n\n  描述了一个不可互换的Token，即每个Token是不同的，并且每个Token对不同的用户都有不同的价值。\n\n  例子：CryptoKittes，每一个数字猫都是独立的，其价值取决于其稀缺性和用户的购买欲。\n\n- ERC55\n\n  大小写混用的地址表示方法，通过这种表示方法表示的地址隐含了一个**校验和**(checksum)能够验证该地址的有效性。在此之前地址的表示为小写，加入这个之后地址可用大小写混合表示\n\n- ERC137\n\n  Ethereum Domain Name Service (ENS)\n\n  域名服务。地址-域名对应\n\n- ERC162\n\n  Initial ENS Hash Registrar(ENS: 以太坊名称服务)。服务于137\n\n  > 注册商负责为系统用户分配域名，并且是唯一能够更新ENS的实体; ENS注册中心节点的所有者是其注册商。注册商可能是合同或外部拥有的账户，但预计根和最高级注册商至少将作为合同实施。\n  >\n  > \\- EIP 137\n\n  精心设计和管理的注册商对于EIP 137中描述的ENS的成功至关重要。故162则对注册商的管理协议\n\n- ERC165\n\n  ```\n  用来验证这个合约是否实现了特定的接口。\n  ```\n\n  ERC165定义以下功能：\n   1） 如何识别接口；\n   2） 一个智能合约如何发布它执行的接口；\n   3） 如何检测一个智能合约是否执行了ERC-165协议；\n   4） 如何检测一个智能合约是否执行了一个给定的接口；\n\n- ERC181\n\n  ```\n  ENS support for reverse resolution of Ethereum addresses\n  ```\n\n  ENS支持以太坊地址的反向解析\n\n- ERC190\n\n  智能合约包管理标准, 提供包管理工具，提高代码的可重用性和安全性\n\n- ERC1167\n\n  最小代理合约\n\n  为了以不可变的方式简单且廉价地克隆合同功能，该标准规定了一个最小字节码实现，它将所有调用委托给已知的固定地址\n\n- 681\n\n  交易请求URL格式\n\n  表示各种交易的标准方式，尤其是Ethers和ERC＃20令牌中的付款请求作为URL。\n\n\n\n#### Draft\n\n- 1046\n\n  扩展ERC20令牌接口以支持与ERC721令牌相同的元数据标准。\n\n- 1062\n\n  将IPFS哈希形式化为ENS（以太坊名称服务）解析器\n\n  > 将IPFS base58字符串映射到ENS解析器时，首先我们将Base58转换为二进制缓冲区，将缓冲区转换为十六进制加密格式，然后保存到合同中。一旦我们想要获取由特定ENS表示的IPFS资源地址，我们可以先找到以十六进制格式存储的映射信息，将十六进制格式提取到二进制缓冲区，最后将其转换为IPFS Base58地址字符串\n\n- 1066\n\n  状态码。定义了适用于以太坊智能合约的广泛适用的状态代码。目前调用以太坊智能合约，返回状态要么`revert`需要人为干预，要么返回布尔通过/失败状态。该标准概述了与HTTP状态相同的一组共同的以太坊状态代码（ESC）。这提供了一组共享信号，允许智能合约自动响应情况，向用户公开本地化错误消息等。\n\n- 1077\n\n  Executable Signed Messages refunded by the contract\n\n  没怎么看懂..好像是允许第三方帮忙提交交易。如在现有的支付(如apple pay)上进行支付以太坊\n\n- 1078\n\n  使用ENS子域名进行登录/注册\n\n  使用这种方式的话，与auth令牌有点相似。子身份连接到现有身份\n\n- 1080\n\n  允许实现扩展ERC-20或ERC-791的令牌的标准API。该标准提供了恢复被盗或丢失帐户的基本功能，以及提供令牌的退款。\n\n- 1081\n\n  用于在以太坊上发行奖励的标准合同和界面，可用于任何类型的任务，在任何ERC20令牌或ETH中支付。\n\n  为了鼓励以太坊奖金的跨平台互操作性，以及更容易的声誉跟踪，StandardBounties(1081)可以以公开可审计和不可变的方式促进资金管理，以换取与完成任务相对应的可交付成果。\n\n- 1123\n\n  190(包管理)的修订版\n\n- 1129\n\n  以太坊网络上DAPP和服务的公告标准化\n\n- 1132\n\n  通过Token锁定功能扩展ERC20\n\n  ERC20标准的扩展，具有在合同中对Token进行时间锁定的方法。\n\n- 1154\n\n  oracle接口\n\n- 1155\n\n  用于管理多个token类型的标准接口。单个部署的合约可以包括可替换token、不可替换token或其他配置(如，半可替换的token)。20是要求每个token单独部署合约，721是不可替换的token组合单独部署。1155则相当于20+721\n\n- 1175\n\n  所有代币的钱包和商店标准（erc20）\n\n  钱包与经过验证的合同创建的商店之间的相互信任允许您通过简单的流程支付和购买物品。\n\n- 1178\n\n  多类令牌标准\n\n- 1185\n\n  在ENS中存储DNS记录\n\n  此EIP定义了ENS的解析程序配置文件，该配置文件提供用于存储和查找DNS记录的功能。这允许ENS用作权威DNS信息的存储。\n\n- 1191\n\n  将链ID添加到混合大小写校验和地址编码\n\n  该EIP通过可选地将EIP-155定义的链ID添加到校验和计算来扩展EIP-55。\n\n- 1202\n\n  投票标准\n\n- 1271\n\n  在合约中验证签名方法\n\n- 1261\n\n  会员验证Token\n\n  在智能合约中实现会员验证Token\n\n- 1207\n\n  DAuth访问委派标准。智能合约之间的\"OAuth\"\n\n- 1203\n\n  多级Token标准\n\n  于1178有点类型，但似乎更有优势\n\n- 1319\n\n  包注册表界面，1123的伴随者，定义了智能合约包清单的标准。\n\n- 1328\n\n  WalletConnect标准URI格式。遵循831 URI格式\n\n- 1386\n\n  认证管理合约\n\n  管理其证明签名密钥以及针对诸如吊销和验证等操作的链外发布的证明。(有点像授权/取消授权)\n\n- 1387\n\n  启用隐私的Merkle Tree认证\n\n- 1388\n\n  证明发行人管理清单\n\n  1386、1387、1388都是差不多的认证相关，作者也是一样\n\n- 1417\n\n  投票标准。\n\n  于1261(会员) 一起使用的投票标准\n\n- 1438\n\n  dapp组建(头像)和通用钱包\n\n  代码的重用性方向\n\n- 1444\n\n  具有信号到文本的本地化消息传递。本地消息的可读文本。有几种机器有效的方式来表示意图，状态，状态转换和其他语义信号，包括布尔值，枚举和ERC-1066代码\n\n- 1450\n\n  用于发行和交易符合SEC标准的证券的兼容安全令牌\n\n- 1462\n\n  基本安全Token，提供符合证券法规和法律可执行性的要求。\n\n- 1484\n\n  数字身份聚合\n\n  用于聚合数字身份信息的协议，该协议可与现有的，提议的和假设的未来数字身份标准广泛互操作。在区块链上提出了身份管理和聚合框架\n\n- 173\n\n  合约所有权标准\n\n  允许获取合同的所有者地址并将合同所有权转移到不同的地址\n\n- 191\n\n  提出了关于如何处理以太坊合同中的签名数据的规范\n\n- 205\n\n  ENS支持合约abi\n\n  在ENS中存储ABI定义的机制，以便呼叫者轻松查找合同接口\n\n- 725\n\n  代理身份\n\n  密钥管理和执行的代理合同，用于建立区块链身份。\n\n- 777\n\n  Token合约的标准接口和行为\n\n- 801\n\n  A standard interface for canary contracts.完全没懂\n\n- **820**\n\n  伪内省注册合约\n\n  该标准定义了一个通用注册表智能合约，其中任何地址（合同或常规帐户）都可以注册它支持的接口以及哪个智能合约负责其实施。\n\n  于165保持向后兼容\n\n- 823\n\n  token交换标准\n\n  Token合同的标准，提供token交换服务，从而促进交叉token支付。\n\n- 831\n\n  以太坊的URI格式\n\n-\n\n------\n\n\n\n### Core\n\n- 158\n\n  state clear，状态清除。定义了账户被删除的情况\n\n- 155\n\n  简单的重放攻击保护。具体是修改签名或恢复时计算hash时的一些修改(加入链ID)\n\n- 150\n\n  gas花费更改。\n\n\n\n\n\n包管理\n\nToken\n\n- 可/不可置换\n- 符合特定要求，如证券法规、地方法律..\n- 多种Token交叉支付\n\nAuth\n\nENS\n","source":"_posts/eth-erc.md","raw":"---\ntitle: eth_erc\ncategories:\n  - eth\ndate: 2019-10-14 14:53:20\ntags:\n---\n\n#### ERC\n\nERC，Etuereum Request for Comment。为了创建一个以太坊平台的标准，开发人员应当提交了一个以太坊改进方案(EIP)，改进方案中包括协议规范和合约标准，一旦EIP被委员会批准并最终确定，它就成为ERC/Core\n\n参考自[连接](https://eips.ethereum.org/erc)\n\n\n\n#### Final\n\n- ERC20\n\n  代币标准化的一个起点。在Ethereum平台之上发布的大多数通证（`token`）都使用它。它定义了以下函数接口\n\n  - totalSupply()：返回代币供给总量\n  - balanceOf(address _owner)：返回_owner的帐户余额\n  - transfer(address _to,uint256 _value)：并将数量为_value的代币转入地址_to并触发transfer事件\n  - transferFrom(address _from,address _to,uint256_value)：将地址_from中的_value数量的代币转入地址_to ，并触发transfer事件\n  - approve(address _spender,uint256 _value)：允许_spender提取限额_value的代币\n  - allowance(address _owner,address _spender）：返回_spender可从_owner提款的代币数量上限\n\n  以上函数将触发以下事件：\n\n  - transfer(address indexed _from,address indexed _to,uint256 _value)：每次进行代币转账时都会触发\n  - approval(address indexed _owner,address indexed _spender,uint256 _value)：调用approve()方法将触发该事件\n\n\n\n- ERC20的补充:\n\n  - ERC223\n  - ERC62, 加了两个额外的功能， increaseSupply和decreaseSupply, 这可以增加和减少流通中的令牌供应\n  - ERC827，它允许转让Token并允许持有人允许第三方使用Token。 以太坊上的Token可以被其他应用程序重复使用，这其中也包括钱包和交易所。 当需要支持第三方动态消费限额调整时这一点非常有用。ERC827与ERC-20兼容。\n\n- ERC721\n\n  描述了一个不可互换的Token，即每个Token是不同的，并且每个Token对不同的用户都有不同的价值。\n\n  例子：CryptoKittes，每一个数字猫都是独立的，其价值取决于其稀缺性和用户的购买欲。\n\n- ERC55\n\n  大小写混用的地址表示方法，通过这种表示方法表示的地址隐含了一个**校验和**(checksum)能够验证该地址的有效性。在此之前地址的表示为小写，加入这个之后地址可用大小写混合表示\n\n- ERC137\n\n  Ethereum Domain Name Service (ENS)\n\n  域名服务。地址-域名对应\n\n- ERC162\n\n  Initial ENS Hash Registrar(ENS: 以太坊名称服务)。服务于137\n\n  > 注册商负责为系统用户分配域名，并且是唯一能够更新ENS的实体; ENS注册中心节点的所有者是其注册商。注册商可能是合同或外部拥有的账户，但预计根和最高级注册商至少将作为合同实施。\n  >\n  > \\- EIP 137\n\n  精心设计和管理的注册商对于EIP 137中描述的ENS的成功至关重要。故162则对注册商的管理协议\n\n- ERC165\n\n  ```\n  用来验证这个合约是否实现了特定的接口。\n  ```\n\n  ERC165定义以下功能：\n   1） 如何识别接口；\n   2） 一个智能合约如何发布它执行的接口；\n   3） 如何检测一个智能合约是否执行了ERC-165协议；\n   4） 如何检测一个智能合约是否执行了一个给定的接口；\n\n- ERC181\n\n  ```\n  ENS support for reverse resolution of Ethereum addresses\n  ```\n\n  ENS支持以太坊地址的反向解析\n\n- ERC190\n\n  智能合约包管理标准, 提供包管理工具，提高代码的可重用性和安全性\n\n- ERC1167\n\n  最小代理合约\n\n  为了以不可变的方式简单且廉价地克隆合同功能，该标准规定了一个最小字节码实现，它将所有调用委托给已知的固定地址\n\n- 681\n\n  交易请求URL格式\n\n  表示各种交易的标准方式，尤其是Ethers和ERC＃20令牌中的付款请求作为URL。\n\n\n\n#### Draft\n\n- 1046\n\n  扩展ERC20令牌接口以支持与ERC721令牌相同的元数据标准。\n\n- 1062\n\n  将IPFS哈希形式化为ENS（以太坊名称服务）解析器\n\n  > 将IPFS base58字符串映射到ENS解析器时，首先我们将Base58转换为二进制缓冲区，将缓冲区转换为十六进制加密格式，然后保存到合同中。一旦我们想要获取由特定ENS表示的IPFS资源地址，我们可以先找到以十六进制格式存储的映射信息，将十六进制格式提取到二进制缓冲区，最后将其转换为IPFS Base58地址字符串\n\n- 1066\n\n  状态码。定义了适用于以太坊智能合约的广泛适用的状态代码。目前调用以太坊智能合约，返回状态要么`revert`需要人为干预，要么返回布尔通过/失败状态。该标准概述了与HTTP状态相同的一组共同的以太坊状态代码（ESC）。这提供了一组共享信号，允许智能合约自动响应情况，向用户公开本地化错误消息等。\n\n- 1077\n\n  Executable Signed Messages refunded by the contract\n\n  没怎么看懂..好像是允许第三方帮忙提交交易。如在现有的支付(如apple pay)上进行支付以太坊\n\n- 1078\n\n  使用ENS子域名进行登录/注册\n\n  使用这种方式的话，与auth令牌有点相似。子身份连接到现有身份\n\n- 1080\n\n  允许实现扩展ERC-20或ERC-791的令牌的标准API。该标准提供了恢复被盗或丢失帐户的基本功能，以及提供令牌的退款。\n\n- 1081\n\n  用于在以太坊上发行奖励的标准合同和界面，可用于任何类型的任务，在任何ERC20令牌或ETH中支付。\n\n  为了鼓励以太坊奖金的跨平台互操作性，以及更容易的声誉跟踪，StandardBounties(1081)可以以公开可审计和不可变的方式促进资金管理，以换取与完成任务相对应的可交付成果。\n\n- 1123\n\n  190(包管理)的修订版\n\n- 1129\n\n  以太坊网络上DAPP和服务的公告标准化\n\n- 1132\n\n  通过Token锁定功能扩展ERC20\n\n  ERC20标准的扩展，具有在合同中对Token进行时间锁定的方法。\n\n- 1154\n\n  oracle接口\n\n- 1155\n\n  用于管理多个token类型的标准接口。单个部署的合约可以包括可替换token、不可替换token或其他配置(如，半可替换的token)。20是要求每个token单独部署合约，721是不可替换的token组合单独部署。1155则相当于20+721\n\n- 1175\n\n  所有代币的钱包和商店标准（erc20）\n\n  钱包与经过验证的合同创建的商店之间的相互信任允许您通过简单的流程支付和购买物品。\n\n- 1178\n\n  多类令牌标准\n\n- 1185\n\n  在ENS中存储DNS记录\n\n  此EIP定义了ENS的解析程序配置文件，该配置文件提供用于存储和查找DNS记录的功能。这允许ENS用作权威DNS信息的存储。\n\n- 1191\n\n  将链ID添加到混合大小写校验和地址编码\n\n  该EIP通过可选地将EIP-155定义的链ID添加到校验和计算来扩展EIP-55。\n\n- 1202\n\n  投票标准\n\n- 1271\n\n  在合约中验证签名方法\n\n- 1261\n\n  会员验证Token\n\n  在智能合约中实现会员验证Token\n\n- 1207\n\n  DAuth访问委派标准。智能合约之间的\"OAuth\"\n\n- 1203\n\n  多级Token标准\n\n  于1178有点类型，但似乎更有优势\n\n- 1319\n\n  包注册表界面，1123的伴随者，定义了智能合约包清单的标准。\n\n- 1328\n\n  WalletConnect标准URI格式。遵循831 URI格式\n\n- 1386\n\n  认证管理合约\n\n  管理其证明签名密钥以及针对诸如吊销和验证等操作的链外发布的证明。(有点像授权/取消授权)\n\n- 1387\n\n  启用隐私的Merkle Tree认证\n\n- 1388\n\n  证明发行人管理清单\n\n  1386、1387、1388都是差不多的认证相关，作者也是一样\n\n- 1417\n\n  投票标准。\n\n  于1261(会员) 一起使用的投票标准\n\n- 1438\n\n  dapp组建(头像)和通用钱包\n\n  代码的重用性方向\n\n- 1444\n\n  具有信号到文本的本地化消息传递。本地消息的可读文本。有几种机器有效的方式来表示意图，状态，状态转换和其他语义信号，包括布尔值，枚举和ERC-1066代码\n\n- 1450\n\n  用于发行和交易符合SEC标准的证券的兼容安全令牌\n\n- 1462\n\n  基本安全Token，提供符合证券法规和法律可执行性的要求。\n\n- 1484\n\n  数字身份聚合\n\n  用于聚合数字身份信息的协议，该协议可与现有的，提议的和假设的未来数字身份标准广泛互操作。在区块链上提出了身份管理和聚合框架\n\n- 173\n\n  合约所有权标准\n\n  允许获取合同的所有者地址并将合同所有权转移到不同的地址\n\n- 191\n\n  提出了关于如何处理以太坊合同中的签名数据的规范\n\n- 205\n\n  ENS支持合约abi\n\n  在ENS中存储ABI定义的机制，以便呼叫者轻松查找合同接口\n\n- 725\n\n  代理身份\n\n  密钥管理和执行的代理合同，用于建立区块链身份。\n\n- 777\n\n  Token合约的标准接口和行为\n\n- 801\n\n  A standard interface for canary contracts.完全没懂\n\n- **820**\n\n  伪内省注册合约\n\n  该标准定义了一个通用注册表智能合约，其中任何地址（合同或常规帐户）都可以注册它支持的接口以及哪个智能合约负责其实施。\n\n  于165保持向后兼容\n\n- 823\n\n  token交换标准\n\n  Token合同的标准，提供token交换服务，从而促进交叉token支付。\n\n- 831\n\n  以太坊的URI格式\n\n-\n\n------\n\n\n\n### Core\n\n- 158\n\n  state clear，状态清除。定义了账户被删除的情况\n\n- 155\n\n  简单的重放攻击保护。具体是修改签名或恢复时计算hash时的一些修改(加入链ID)\n\n- 150\n\n  gas花费更改。\n\n\n\n\n\n包管理\n\nToken\n\n- 可/不可置换\n- 符合特定要求，如证券法规、地方法律..\n- 多种Token交叉支付\n\nAuth\n\nENS\n","slug":"eth-erc","published":1,"updated":"2019-10-14T06:53:37.089Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69x00026t6xvys3yxl6f","content":"<h4 id=\"ERC\"><a href=\"#ERC\" class=\"headerlink\" title=\"ERC\"></a>ERC</h4><p>ERC，Etuereum Request for Comment。为了创建一个以太坊平台的标准，开发人员应当提交了一个以太坊改进方案(EIP)，改进方案中包括协议规范和合约标准，一旦EIP被委员会批准并最终确定，它就成为ERC/Core</p>\n<p>参考自<a href=\"https://eips.ethereum.org/erc\" target=\"_blank\" rel=\"noopener\">连接</a></p>\n<h4 id=\"Final\"><a href=\"#Final\" class=\"headerlink\" title=\"Final\"></a>Final</h4><ul>\n<li><p>ERC20</p>\n<p>代币标准化的一个起点。在Ethereum平台之上发布的大多数通证（<code>token</code>）都使用它。它定义了以下函数接口</p>\n<ul>\n<li>totalSupply()：返回代币供给总量</li>\n<li>balanceOf(address _owner)：返回_owner的帐户余额</li>\n<li>transfer(address _to,uint256 _value)：并将数量为_value的代币转入地址_to并触发transfer事件</li>\n<li>transferFrom(address _from,address _to,uint256_value)：将地址_from中的_value数量的代币转入地址_to ，并触发transfer事件</li>\n<li>approve(address _spender,uint256 _value)：允许_spender提取限额_value的代币</li>\n<li>allowance(address _owner,address _spender）：返回_spender可从_owner提款的代币数量上限</li>\n</ul>\n<p>以上函数将触发以下事件：</p>\n<ul>\n<li>transfer(address indexed _from,address indexed _to,uint256 _value)：每次进行代币转账时都会触发</li>\n<li>approval(address indexed _owner,address indexed _spender,uint256 _value)：调用approve()方法将触发该事件</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>ERC20的补充:</p>\n<ul>\n<li>ERC223</li>\n<li>ERC62, 加了两个额外的功能， increaseSupply和decreaseSupply, 这可以增加和减少流通中的令牌供应</li>\n<li>ERC827，它允许转让Token并允许持有人允许第三方使用Token。 以太坊上的Token可以被其他应用程序重复使用，这其中也包括钱包和交易所。 当需要支持第三方动态消费限额调整时这一点非常有用。ERC827与ERC-20兼容。</li>\n</ul>\n</li>\n<li><p>ERC721</p>\n<p>描述了一个不可互换的Token，即每个Token是不同的，并且每个Token对不同的用户都有不同的价值。</p>\n<p>例子：CryptoKittes，每一个数字猫都是独立的，其价值取决于其稀缺性和用户的购买欲。</p>\n</li>\n<li><p>ERC55</p>\n<p>大小写混用的地址表示方法，通过这种表示方法表示的地址隐含了一个<strong>校验和</strong>(checksum)能够验证该地址的有效性。在此之前地址的表示为小写，加入这个之后地址可用大小写混合表示</p>\n</li>\n<li><p>ERC137</p>\n<p>Ethereum Domain Name Service (ENS)</p>\n<p>域名服务。地址-域名对应</p>\n</li>\n<li><p>ERC162</p>\n<p>Initial ENS Hash Registrar(ENS: 以太坊名称服务)。服务于137</p>\n<blockquote>\n<p>注册商负责为系统用户分配域名，并且是唯一能够更新ENS的实体; ENS注册中心节点的所有者是其注册商。注册商可能是合同或外部拥有的账户，但预计根和最高级注册商至少将作为合同实施。</p>\n<p>- EIP 137</p>\n</blockquote>\n<p>精心设计和管理的注册商对于EIP 137中描述的ENS的成功至关重要。故162则对注册商的管理协议</p>\n</li>\n<li><p>ERC165</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">用来验证这个合约是否实现了特定的接口。</span><br></pre></td></tr></table></figure>\n\n<p>ERC165定义以下功能：<br> 1） 如何识别接口；<br> 2） 一个智能合约如何发布它执行的接口；<br> 3） 如何检测一个智能合约是否执行了ERC-165协议；<br> 4） 如何检测一个智能合约是否执行了一个给定的接口；</p>\n</li>\n<li><p>ERC181</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ENS support for reverse resolution of Ethereum addresses</span><br></pre></td></tr></table></figure>\n\n<p>ENS支持以太坊地址的反向解析</p>\n</li>\n<li><p>ERC190</p>\n<p>智能合约包管理标准, 提供包管理工具，提高代码的可重用性和安全性</p>\n</li>\n<li><p>ERC1167</p>\n<p>最小代理合约</p>\n<p>为了以不可变的方式简单且廉价地克隆合同功能，该标准规定了一个最小字节码实现，它将所有调用委托给已知的固定地址</p>\n</li>\n<li><p>681</p>\n<p>交易请求URL格式</p>\n<p>表示各种交易的标准方式，尤其是Ethers和ERC＃20令牌中的付款请求作为URL。</p>\n</li>\n</ul>\n<h4 id=\"Draft\"><a href=\"#Draft\" class=\"headerlink\" title=\"Draft\"></a>Draft</h4><ul>\n<li><p>1046</p>\n<p>扩展ERC20令牌接口以支持与ERC721令牌相同的元数据标准。</p>\n</li>\n<li><p>1062</p>\n<p>将IPFS哈希形式化为ENS（以太坊名称服务）解析器</p>\n<blockquote>\n<p>将IPFS base58字符串映射到ENS解析器时，首先我们将Base58转换为二进制缓冲区，将缓冲区转换为十六进制加密格式，然后保存到合同中。一旦我们想要获取由特定ENS表示的IPFS资源地址，我们可以先找到以十六进制格式存储的映射信息，将十六进制格式提取到二进制缓冲区，最后将其转换为IPFS Base58地址字符串</p>\n</blockquote>\n</li>\n<li><p>1066</p>\n<p>状态码。定义了适用于以太坊智能合约的广泛适用的状态代码。目前调用以太坊智能合约，返回状态要么<code>revert</code>需要人为干预，要么返回布尔通过/失败状态。该标准概述了与HTTP状态相同的一组共同的以太坊状态代码（ESC）。这提供了一组共享信号，允许智能合约自动响应情况，向用户公开本地化错误消息等。</p>\n</li>\n<li><p>1077</p>\n<p>Executable Signed Messages refunded by the contract</p>\n<p>没怎么看懂..好像是允许第三方帮忙提交交易。如在现有的支付(如apple pay)上进行支付以太坊</p>\n</li>\n<li><p>1078</p>\n<p>使用ENS子域名进行登录/注册</p>\n<p>使用这种方式的话，与auth令牌有点相似。子身份连接到现有身份</p>\n</li>\n<li><p>1080</p>\n<p>允许实现扩展ERC-20或ERC-791的令牌的标准API。该标准提供了恢复被盗或丢失帐户的基本功能，以及提供令牌的退款。</p>\n</li>\n<li><p>1081</p>\n<p>用于在以太坊上发行奖励的标准合同和界面，可用于任何类型的任务，在任何ERC20令牌或ETH中支付。</p>\n<p>为了鼓励以太坊奖金的跨平台互操作性，以及更容易的声誉跟踪，StandardBounties(1081)可以以公开可审计和不可变的方式促进资金管理，以换取与完成任务相对应的可交付成果。</p>\n</li>\n<li><p>1123</p>\n<p>190(包管理)的修订版</p>\n</li>\n<li><p>1129</p>\n<p>以太坊网络上DAPP和服务的公告标准化</p>\n</li>\n<li><p>1132</p>\n<p>通过Token锁定功能扩展ERC20</p>\n<p>ERC20标准的扩展，具有在合同中对Token进行时间锁定的方法。</p>\n</li>\n<li><p>1154</p>\n<p>oracle接口</p>\n</li>\n<li><p>1155</p>\n<p>用于管理多个token类型的标准接口。单个部署的合约可以包括可替换token、不可替换token或其他配置(如，半可替换的token)。20是要求每个token单独部署合约，721是不可替换的token组合单独部署。1155则相当于20+721</p>\n</li>\n<li><p>1175</p>\n<p>所有代币的钱包和商店标准（erc20）</p>\n<p>钱包与经过验证的合同创建的商店之间的相互信任允许您通过简单的流程支付和购买物品。</p>\n</li>\n<li><p>1178</p>\n<p>多类令牌标准</p>\n</li>\n<li><p>1185</p>\n<p>在ENS中存储DNS记录</p>\n<p>此EIP定义了ENS的解析程序配置文件，该配置文件提供用于存储和查找DNS记录的功能。这允许ENS用作权威DNS信息的存储。</p>\n</li>\n<li><p>1191</p>\n<p>将链ID添加到混合大小写校验和地址编码</p>\n<p>该EIP通过可选地将EIP-155定义的链ID添加到校验和计算来扩展EIP-55。</p>\n</li>\n<li><p>1202</p>\n<p>投票标准</p>\n</li>\n<li><p>1271</p>\n<p>在合约中验证签名方法</p>\n</li>\n<li><p>1261</p>\n<p>会员验证Token</p>\n<p>在智能合约中实现会员验证Token</p>\n</li>\n<li><p>1207</p>\n<p>DAuth访问委派标准。智能合约之间的”OAuth”</p>\n</li>\n<li><p>1203</p>\n<p>多级Token标准</p>\n<p>于1178有点类型，但似乎更有优势</p>\n</li>\n<li><p>1319</p>\n<p>包注册表界面，1123的伴随者，定义了智能合约包清单的标准。</p>\n</li>\n<li><p>1328</p>\n<p>WalletConnect标准URI格式。遵循831 URI格式</p>\n</li>\n<li><p>1386</p>\n<p>认证管理合约</p>\n<p>管理其证明签名密钥以及针对诸如吊销和验证等操作的链外发布的证明。(有点像授权/取消授权)</p>\n</li>\n<li><p>1387</p>\n<p>启用隐私的Merkle Tree认证</p>\n</li>\n<li><p>1388</p>\n<p>证明发行人管理清单</p>\n<p>1386、1387、1388都是差不多的认证相关，作者也是一样</p>\n</li>\n<li><p>1417</p>\n<p>投票标准。</p>\n<p>于1261(会员) 一起使用的投票标准</p>\n</li>\n<li><p>1438</p>\n<p>dapp组建(头像)和通用钱包</p>\n<p>代码的重用性方向</p>\n</li>\n<li><p>1444</p>\n<p>具有信号到文本的本地化消息传递。本地消息的可读文本。有几种机器有效的方式来表示意图，状态，状态转换和其他语义信号，包括布尔值，枚举和ERC-1066代码</p>\n</li>\n<li><p>1450</p>\n<p>用于发行和交易符合SEC标准的证券的兼容安全令牌</p>\n</li>\n<li><p>1462</p>\n<p>基本安全Token，提供符合证券法规和法律可执行性的要求。</p>\n</li>\n<li><p>1484</p>\n<p>数字身份聚合</p>\n<p>用于聚合数字身份信息的协议，该协议可与现有的，提议的和假设的未来数字身份标准广泛互操作。在区块链上提出了身份管理和聚合框架</p>\n</li>\n<li><p>173</p>\n<p>合约所有权标准</p>\n<p>允许获取合同的所有者地址并将合同所有权转移到不同的地址</p>\n</li>\n<li><p>191</p>\n<p>提出了关于如何处理以太坊合同中的签名数据的规范</p>\n</li>\n<li><p>205</p>\n<p>ENS支持合约abi</p>\n<p>在ENS中存储ABI定义的机制，以便呼叫者轻松查找合同接口</p>\n</li>\n<li><p>725</p>\n<p>代理身份</p>\n<p>密钥管理和执行的代理合同，用于建立区块链身份。</p>\n</li>\n<li><p>777</p>\n<p>Token合约的标准接口和行为</p>\n</li>\n<li><p>801</p>\n<p>A standard interface for canary contracts.完全没懂</p>\n</li>\n<li><p><strong>820</strong></p>\n<p>伪内省注册合约</p>\n<p>该标准定义了一个通用注册表智能合约，其中任何地址（合同或常规帐户）都可以注册它支持的接口以及哪个智能合约负责其实施。</p>\n<p>于165保持向后兼容</p>\n</li>\n<li><p>823</p>\n<p>token交换标准</p>\n<p>Token合同的标准，提供token交换服务，从而促进交叉token支付。</p>\n</li>\n<li><p>831</p>\n<p>以太坊的URI格式</p>\n</li>\n</ul>\n<p>-</p>\n<hr>\n<h3 id=\"Core\"><a href=\"#Core\" class=\"headerlink\" title=\"Core\"></a>Core</h3><ul>\n<li><p>158</p>\n<p>state clear，状态清除。定义了账户被删除的情况</p>\n</li>\n<li><p>155</p>\n<p>简单的重放攻击保护。具体是修改签名或恢复时计算hash时的一些修改(加入链ID)</p>\n</li>\n<li><p>150</p>\n<p>gas花费更改。</p>\n</li>\n</ul>\n<p>包管理</p>\n<p>Token</p>\n<ul>\n<li>可/不可置换</li>\n<li>符合特定要求，如证券法规、地方法律..</li>\n<li>多种Token交叉支付</li>\n</ul>\n<p>Auth</p>\n<p>ENS</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h4 id=\"ERC\"><a href=\"#ERC\" class=\"headerlink\" title=\"ERC\"></a>ERC</h4><p>ERC，Etuereum Request for Comment。为了创建一个以太坊平台的标准，开发人员应当提交了一个以太坊改进方案(EIP)，改进方案中包括协议规范和合约标准，一旦EIP被委员会批准并最终确定，它就成为ERC/Core</p>\n<p>参考自<a href=\"https://eips.ethereum.org/erc\" target=\"_blank\" rel=\"noopener\">连接</a></p>\n<h4 id=\"Final\"><a href=\"#Final\" class=\"headerlink\" title=\"Final\"></a>Final</h4><ul>\n<li><p>ERC20</p>\n<p>代币标准化的一个起点。在Ethereum平台之上发布的大多数通证（<code>token</code>）都使用它。它定义了以下函数接口</p>\n<ul>\n<li>totalSupply()：返回代币供给总量</li>\n<li>balanceOf(address _owner)：返回_owner的帐户余额</li>\n<li>transfer(address _to,uint256 _value)：并将数量为_value的代币转入地址_to并触发transfer事件</li>\n<li>transferFrom(address _from,address _to,uint256_value)：将地址_from中的_value数量的代币转入地址_to ，并触发transfer事件</li>\n<li>approve(address _spender,uint256 _value)：允许_spender提取限额_value的代币</li>\n<li>allowance(address _owner,address _spender）：返回_spender可从_owner提款的代币数量上限</li>\n</ul>\n<p>以上函数将触发以下事件：</p>\n<ul>\n<li>transfer(address indexed _from,address indexed _to,uint256 _value)：每次进行代币转账时都会触发</li>\n<li>approval(address indexed _owner,address indexed _spender,uint256 _value)：调用approve()方法将触发该事件</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>ERC20的补充:</p>\n<ul>\n<li>ERC223</li>\n<li>ERC62, 加了两个额外的功能， increaseSupply和decreaseSupply, 这可以增加和减少流通中的令牌供应</li>\n<li>ERC827，它允许转让Token并允许持有人允许第三方使用Token。 以太坊上的Token可以被其他应用程序重复使用，这其中也包括钱包和交易所。 当需要支持第三方动态消费限额调整时这一点非常有用。ERC827与ERC-20兼容。</li>\n</ul>\n</li>\n<li><p>ERC721</p>\n<p>描述了一个不可互换的Token，即每个Token是不同的，并且每个Token对不同的用户都有不同的价值。</p>\n<p>例子：CryptoKittes，每一个数字猫都是独立的，其价值取决于其稀缺性和用户的购买欲。</p>\n</li>\n<li><p>ERC55</p>\n<p>大小写混用的地址表示方法，通过这种表示方法表示的地址隐含了一个<strong>校验和</strong>(checksum)能够验证该地址的有效性。在此之前地址的表示为小写，加入这个之后地址可用大小写混合表示</p>\n</li>\n<li><p>ERC137</p>\n<p>Ethereum Domain Name Service (ENS)</p>\n<p>域名服务。地址-域名对应</p>\n</li>\n<li><p>ERC162</p>\n<p>Initial ENS Hash Registrar(ENS: 以太坊名称服务)。服务于137</p>\n<blockquote>\n<p>注册商负责为系统用户分配域名，并且是唯一能够更新ENS的实体; ENS注册中心节点的所有者是其注册商。注册商可能是合同或外部拥有的账户，但预计根和最高级注册商至少将作为合同实施。</p>\n<p>- EIP 137</p>\n</blockquote>\n<p>精心设计和管理的注册商对于EIP 137中描述的ENS的成功至关重要。故162则对注册商的管理协议</p>\n</li>\n<li><p>ERC165</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">用来验证这个合约是否实现了特定的接口。</span><br></pre></td></tr></table></figure>\n\n<p>ERC165定义以下功能：<br> 1） 如何识别接口；<br> 2） 一个智能合约如何发布它执行的接口；<br> 3） 如何检测一个智能合约是否执行了ERC-165协议；<br> 4） 如何检测一个智能合约是否执行了一个给定的接口；</p>\n</li>\n<li><p>ERC181</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ENS support for reverse resolution of Ethereum addresses</span><br></pre></td></tr></table></figure>\n\n<p>ENS支持以太坊地址的反向解析</p>\n</li>\n<li><p>ERC190</p>\n<p>智能合约包管理标准, 提供包管理工具，提高代码的可重用性和安全性</p>\n</li>\n<li><p>ERC1167</p>\n<p>最小代理合约</p>\n<p>为了以不可变的方式简单且廉价地克隆合同功能，该标准规定了一个最小字节码实现，它将所有调用委托给已知的固定地址</p>\n</li>\n<li><p>681</p>\n<p>交易请求URL格式</p>\n<p>表示各种交易的标准方式，尤其是Ethers和ERC＃20令牌中的付款请求作为URL。</p>\n</li>\n</ul>\n<h4 id=\"Draft\"><a href=\"#Draft\" class=\"headerlink\" title=\"Draft\"></a>Draft</h4><ul>\n<li><p>1046</p>\n<p>扩展ERC20令牌接口以支持与ERC721令牌相同的元数据标准。</p>\n</li>\n<li><p>1062</p>\n<p>将IPFS哈希形式化为ENS（以太坊名称服务）解析器</p>\n<blockquote>\n<p>将IPFS base58字符串映射到ENS解析器时，首先我们将Base58转换为二进制缓冲区，将缓冲区转换为十六进制加密格式，然后保存到合同中。一旦我们想要获取由特定ENS表示的IPFS资源地址，我们可以先找到以十六进制格式存储的映射信息，将十六进制格式提取到二进制缓冲区，最后将其转换为IPFS Base58地址字符串</p>\n</blockquote>\n</li>\n<li><p>1066</p>\n<p>状态码。定义了适用于以太坊智能合约的广泛适用的状态代码。目前调用以太坊智能合约，返回状态要么<code>revert</code>需要人为干预，要么返回布尔通过/失败状态。该标准概述了与HTTP状态相同的一组共同的以太坊状态代码（ESC）。这提供了一组共享信号，允许智能合约自动响应情况，向用户公开本地化错误消息等。</p>\n</li>\n<li><p>1077</p>\n<p>Executable Signed Messages refunded by the contract</p>\n<p>没怎么看懂..好像是允许第三方帮忙提交交易。如在现有的支付(如apple pay)上进行支付以太坊</p>\n</li>\n<li><p>1078</p>\n<p>使用ENS子域名进行登录/注册</p>\n<p>使用这种方式的话，与auth令牌有点相似。子身份连接到现有身份</p>\n</li>\n<li><p>1080</p>\n<p>允许实现扩展ERC-20或ERC-791的令牌的标准API。该标准提供了恢复被盗或丢失帐户的基本功能，以及提供令牌的退款。</p>\n</li>\n<li><p>1081</p>\n<p>用于在以太坊上发行奖励的标准合同和界面，可用于任何类型的任务，在任何ERC20令牌或ETH中支付。</p>\n<p>为了鼓励以太坊奖金的跨平台互操作性，以及更容易的声誉跟踪，StandardBounties(1081)可以以公开可审计和不可变的方式促进资金管理，以换取与完成任务相对应的可交付成果。</p>\n</li>\n<li><p>1123</p>\n<p>190(包管理)的修订版</p>\n</li>\n<li><p>1129</p>\n<p>以太坊网络上DAPP和服务的公告标准化</p>\n</li>\n<li><p>1132</p>\n<p>通过Token锁定功能扩展ERC20</p>\n<p>ERC20标准的扩展，具有在合同中对Token进行时间锁定的方法。</p>\n</li>\n<li><p>1154</p>\n<p>oracle接口</p>\n</li>\n<li><p>1155</p>\n<p>用于管理多个token类型的标准接口。单个部署的合约可以包括可替换token、不可替换token或其他配置(如，半可替换的token)。20是要求每个token单独部署合约，721是不可替换的token组合单独部署。1155则相当于20+721</p>\n</li>\n<li><p>1175</p>\n<p>所有代币的钱包和商店标准（erc20）</p>\n<p>钱包与经过验证的合同创建的商店之间的相互信任允许您通过简单的流程支付和购买物品。</p>\n</li>\n<li><p>1178</p>\n<p>多类令牌标准</p>\n</li>\n<li><p>1185</p>\n<p>在ENS中存储DNS记录</p>\n<p>此EIP定义了ENS的解析程序配置文件，该配置文件提供用于存储和查找DNS记录的功能。这允许ENS用作权威DNS信息的存储。</p>\n</li>\n<li><p>1191</p>\n<p>将链ID添加到混合大小写校验和地址编码</p>\n<p>该EIP通过可选地将EIP-155定义的链ID添加到校验和计算来扩展EIP-55。</p>\n</li>\n<li><p>1202</p>\n<p>投票标准</p>\n</li>\n<li><p>1271</p>\n<p>在合约中验证签名方法</p>\n</li>\n<li><p>1261</p>\n<p>会员验证Token</p>\n<p>在智能合约中实现会员验证Token</p>\n</li>\n<li><p>1207</p>\n<p>DAuth访问委派标准。智能合约之间的”OAuth”</p>\n</li>\n<li><p>1203</p>\n<p>多级Token标准</p>\n<p>于1178有点类型，但似乎更有优势</p>\n</li>\n<li><p>1319</p>\n<p>包注册表界面，1123的伴随者，定义了智能合约包清单的标准。</p>\n</li>\n<li><p>1328</p>\n<p>WalletConnect标准URI格式。遵循831 URI格式</p>\n</li>\n<li><p>1386</p>\n<p>认证管理合约</p>\n<p>管理其证明签名密钥以及针对诸如吊销和验证等操作的链外发布的证明。(有点像授权/取消授权)</p>\n</li>\n<li><p>1387</p>\n<p>启用隐私的Merkle Tree认证</p>\n</li>\n<li><p>1388</p>\n<p>证明发行人管理清单</p>\n<p>1386、1387、1388都是差不多的认证相关，作者也是一样</p>\n</li>\n<li><p>1417</p>\n<p>投票标准。</p>\n<p>于1261(会员) 一起使用的投票标准</p>\n</li>\n<li><p>1438</p>\n<p>dapp组建(头像)和通用钱包</p>\n<p>代码的重用性方向</p>\n</li>\n<li><p>1444</p>\n<p>具有信号到文本的本地化消息传递。本地消息的可读文本。有几种机器有效的方式来表示意图，状态，状态转换和其他语义信号，包括布尔值，枚举和ERC-1066代码</p>\n</li>\n<li><p>1450</p>\n<p>用于发行和交易符合SEC标准的证券的兼容安全令牌</p>\n</li>\n<li><p>1462</p>\n<p>基本安全Token，提供符合证券法规和法律可执行性的要求。</p>\n</li>\n<li><p>1484</p>\n<p>数字身份聚合</p>\n<p>用于聚合数字身份信息的协议，该协议可与现有的，提议的和假设的未来数字身份标准广泛互操作。在区块链上提出了身份管理和聚合框架</p>\n</li>\n<li><p>173</p>\n<p>合约所有权标准</p>\n<p>允许获取合同的所有者地址并将合同所有权转移到不同的地址</p>\n</li>\n<li><p>191</p>\n<p>提出了关于如何处理以太坊合同中的签名数据的规范</p>\n</li>\n<li><p>205</p>\n<p>ENS支持合约abi</p>\n<p>在ENS中存储ABI定义的机制，以便呼叫者轻松查找合同接口</p>\n</li>\n<li><p>725</p>\n<p>代理身份</p>\n<p>密钥管理和执行的代理合同，用于建立区块链身份。</p>\n</li>\n<li><p>777</p>\n<p>Token合约的标准接口和行为</p>\n</li>\n<li><p>801</p>\n<p>A standard interface for canary contracts.完全没懂</p>\n</li>\n<li><p><strong>820</strong></p>\n<p>伪内省注册合约</p>\n<p>该标准定义了一个通用注册表智能合约，其中任何地址（合同或常规帐户）都可以注册它支持的接口以及哪个智能合约负责其实施。</p>\n<p>于165保持向后兼容</p>\n</li>\n<li><p>823</p>\n<p>token交换标准</p>\n<p>Token合同的标准，提供token交换服务，从而促进交叉token支付。</p>\n</li>\n<li><p>831</p>\n<p>以太坊的URI格式</p>\n</li>\n</ul>\n<p>-</p>\n<hr>\n<h3 id=\"Core\"><a href=\"#Core\" class=\"headerlink\" title=\"Core\"></a>Core</h3><ul>\n<li><p>158</p>\n<p>state clear，状态清除。定义了账户被删除的情况</p>\n</li>\n<li><p>155</p>\n<p>简单的重放攻击保护。具体是修改签名或恢复时计算hash时的一些修改(加入链ID)</p>\n</li>\n<li><p>150</p>\n<p>gas花费更改。</p>\n</li>\n</ul>\n<p>包管理</p>\n<p>Token</p>\n<ul>\n<li>可/不可置换</li>\n<li>符合特定要求，如证券法规、地方法律..</li>\n<li>多种Token交叉支付</li>\n</ul>\n<p>Auth</p>\n<p>ENS</p>\n"},{"title":"eth_p2p_udp","date":"2019-10-14T06:54:36.000Z","_content":"\n## p2p-udp\n\n在以太坊的p2p包下，discover包下的udp主要负责节点发现。以太坊的节点发现又是基于kademlia协议。\n\n\n\n#### kademlia\n\n[kad详细解读](http://www.yeolar.com/note/2010/03/21/kademlia/)\n\n简单说来，kad中，每个节点由特定ID为唯一标识符。并且由ID决定K桶和两节点之间的逻辑距离。\n\nID由二进制表示，ID长度有几位，K桶数量就为几。K桶的划分满足，第n个K桶的节点前n-1位与自己ID的前n-1位是相同的。如ID长度为3，那么K桶数量为3，自己的ID为110，那么自己的K桶划分为前0位相同(0xx）、前1位相同(10x),前2位相同(11x)这样的三个K桶。显然，在这样的分布中，满足0xx的节点就会有很多，但满足11x的节点只有111。然后两个节点之前的逻辑距离为ID的异或值，越相近的节点，异或值越小，越远的节点，异或值越大。\n\n\n\n另外，Kademlia 协议包括四种远程 RPC 操作：PING、STORE、FIND_NODE、FIND_VALUE。这些在上面的链接中都有也更详细。尤其是数据存放需要的基本步骤，都有相应提到。\n\n\n\n#### 以太坊的kad\n\n以太坊的kad与上面标准的kad略有不同。\n\n先撸代码吧。\n\n```\nbucketSize      = 16 // Kademlia bucket size\n// We keep buckets for the upper 1/15 of distances because\n// it's very unlikely we'll ever encounter a node that's closer.\nhashBits          = len(common.Hash{}) * 8\nnBuckets          = hashBits / 15       // Number of buckets\nbucketMinDistance = hashBits - nBuckets // Log distance of closest bucket\n```\n\nk桶数量nBuckets，（定为ID长度256(hash长度32byte * 8bit/byte)）/ 15。\n\nk桶大小bucketSize，即每个k桶中的节点最大数量。\n\n节点ID的计算方式(由公钥生成)\n\n```\n//encPubkey取hash\nfunc (e encPubkey) id() enode.ID {\n\treturn enode.ID(crypto.Keccak256Hash(e[:]))\n}\n//pubkey -> encpubkey\nfunc encodePubkey(key *ecdsa.PublicKey) encPubkey {\n\tvar e encPubkey\n\tmath.ReadBits(key.X, e[:len(e)/2])\n\tmath.ReadBits(key.Y, e[len(e)/2:])\n\treturn e\n}\n```\n\n\n\n- 桶的基本结构\n\n```\ntype Table struct {\n\tmutex   sync.Mutex        // protects buckets, bucket content, nursery, rand\n\tbuckets [nBuckets]*bucket // index of known nodes by distance\n\t...\n}\n\n```\n\n```\n// bucket contains nodes, ordered by their last activity. the entry\n// that was most recently active is the first element in entries.\ntype bucket struct {\n   entries      []*node // live entries, sorted by time of last contact\n   replacements []*node // recently seen nodes to be used if revalidation fails\n   ips          netutil.DistinctNetSet\n}\n```\n\nbuckets是所有桶，是一个定长数组，其中，(0<index<nBuckets)的index代表index桶。然后节点的id经过计算映射到某个桶。桶里的节点们又是一个数组，entries数组中为优先可用的节点，他们按上一次联系的时间排序，最最近联系的节点排在数组的最前面。如果entries中某节点在revalidation时失败了，会从replacements中找出某个来代替..\n\n\n\n```\n//增。如果对应的桶b, b.entries的长度没超过最大数量的话，就增加到entries中，否则增加到replacements中\nfunc (tab *Table) add(n *node) {\n   if n.ID() == tab.self.ID() {\n      return\n   }\n   tab.mutex.Lock()\n   defer tab.mutex.Unlock()\n   b := tab.bucket(n.ID())\n   if !tab.bumpOrAdd(b, n) {\n      // Node is not in table. Add it to the replacement list.\n      tab.addReplacement(b, n)\n   }\n}\n\n//删，找到node对应的桶，然后从桶中把节点删除了\nfunc (tab *Table) delete(node *node) {\n\ttab.mutex.Lock()\n\tdefer tab.mutex.Unlock()\n\n\ttab.deleteInBucket(tab.bucket(node.ID()), node)\n}\n\n//查，查呢是返回所有桶中距离target最近的nresults个节点\nfunc (tab *Table) closest(target enode.ID, nresults int) *nodesByDistance {\n\t// This is a very wasteful way to find the closest nodes but\n\t// obviously correct. I believe that tree-based buckets would make\n\t// this easier to implement efficiently.\n\tclose := &nodesByDistance{target: target}\n\tfor _, b := range &tab.buckets {\n\t\tfor _, n := range b.entries {\n\t\t\tclose.push(n, nresults)\n\t\t}\n\t}\n\treturn close\n}\n\n```\n\n\n\n- 主线逻辑操作\n\n```\nfunc (tab *Table) loop() {\n  ...\n  loop:\n\tfor {\n\t\tselect {\n\t\tcase <-refresh.C:  //定时刷新，\n\t\t\ttab.seedRand() //更新随机种子\n\t\t\tif refreshDone == nil {\n\t\t\t\trefreshDone = make(chan struct{})\n\t\t\t\tgo tab.doRefresh(refreshDone)  //进行刷新，刷新完成往refreshDone通道中通知\n\t\t\t}\n\t\tcase req := <-tab.refreshReq: //上层请求刷新，上层有可能需要知道刷新完成时间，故req通道用于通知刷新完成\n\t\t\twaiting = append(waiting, req)  //记录下所有的刷新请求通道\n\t\t\tif refreshDone == nil {\n\t\t\t\trefreshDone = make(chan struct{})\n\t\t\t\tgo tab.doRefresh(refreshDone)\n\t\t\t}\n\t\tcase <-refreshDone:  //刷新完成后，关闭所有请求通道，通知上层已刷新完成\n\t\t\tfor _, ch := range waiting {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t\twaiting, refreshDone = nil, nil //清空waiting数组，和refreshDone通道\n\t\tcase <-revalidate.C:\n\t\t\tgo tab.doRevalidate(revalidateDone)\n\t\tcase <-revalidateDone:\n\t\t\trevalidate.Reset(tab.nextRevalidateTime())\n\t\tcase <-copyNodes.C:\n\t\t\tgo tab.copyLiveNodes()\n\t\tcase <-tab.closeReq:\n\t\t\tbreak loop\n\t\t}\n\t}\n  ...\n}\n\n\n\n//刷新方法\nfunc (tab *Table) doRefresh(done chan struct{}) {\n  defer close(done)\n  ...\n\n  //通过自己为target去找neighbor，前提是需要自己有secp256k1字段，v4版本的node里是含有secp256k1的，即v4版本是满足这个if条件。load后key中的值为node的公钥\n  var key ecdsa.PublicKey\n  if err := tab.self.Load((*enode.Secp256k1)(&key)); err == nil {\n\ttab.lookup(encodePubkey(&key), false)\n  }\n\n\n  //⭐️通过随机target去找neighbor。这里的疑问是注释中提到为什么不使用kad本来刷新的方式是因为findnode taget是512bit,这里为什么是512bit? (是因为findnode target是公钥，公钥长度是64byte/512bit) 后半句说不容易生成一个属于所选桶的sha3前镜像，kad本来刷新的方式是选择最近最少使用的桶，所以这里的意思是知道桶了，但是node的ID是经过hash生成的，hash的范围确定，但倒回去找ID就很复杂的意思吗\n// The Kademlia paper specifies that the bucket refresh should\n// perform a lookup in the least recently used bucket. We cannot\n// adhere to this because the findnode target is a 512bit value\n// (not hash-sized) and it is not easily possible to generate a\n// sha3 preimage that falls into a chosen bucket.\n// We perform a few lookups with a random target instead.\n  for i := 0; i < 3; i++ {\n\t var target encPubkey\n\t crand.Read(target[:])\n\t tab.lookup(target, false)\n  }\n}\n\n```\n\n\n\n\n\n```\n//下面看一下关键方法lookup\nfunc (tab *Table) lookup(targetKey encPubkey, refreshIfEmpty bool) []*node {\n\tvar (\n\t\ttarget         = enode.ID(crypto.Keccak256Hash(targetKey[:]))  //targetid：由公钥进行hash得来\n\t\tasked          = make(map[enode.ID]bool)  //保存询问过的节点，以免重复询问\n\t\tseen           = make(map[enode.ID]bool)  //保存回复过的节点，防止询问的节点多次回复\n\t\treply          = make(chan []*node, alpha) //节点回复的通道，alpha为并发量，每次三个\n\t\tpendingQueries = 0   //待定的查询数量，即询问了 但没回复的数量\n\t\tresult         *nodesByDistance  //查询结果\n\t)\n\t//将自己列为询问过的节点\n\tasked[tab.self.ID()] = true\n\n    //将现有的k桶节点们填充到result中\n\tfor {\n\t\ttab.mutex.Lock()\n\t\t//从自己的所有桶中找出离target最近的bucketSize个节点\n\t\tresult = tab.closest(target, bucketSize)\n\t\ttab.mutex.Unlock()\n\t\t//如果桶中有节点或者refreshIfEmpty为false，跳出循环\n\t\tif len(result.entries) > 0 || !refreshIfEmpty {\n\t\t\tbreak\n\t\t}\n\t\t//如果k桶中无节点，则请求刷新(doRefresh -> 从种子节点中出发..)\n\t\t<-tab.refresh()\n\t\t//请求一次刷新，将refreshIfEmpty置为false,防止一直无节点，一直在这里循环，相当于这个for循环最多只执行两次\n\t\trefreshIfEmpty = false\n\t}\n\n\n\tfor {\n\t\t//向近的节点询问节点，询问过的就不再询问，并且每次询问的节点数<alpha,即每次只询问最近的alpha个节点。之前一直卡在为什么外层要for循环，难道不是每次问的都是相同的吗？还真的不是..要是相同的话，pendingQueries的值就不会++，这个询问for循环就不会再进行了，然后等回答完毕这个方法就完毕了。之所以桶里的前alpha个会不一样，是因为在后面从reply中读出的为问到的节点们，然后添加到本桶里的时候会影响整个排序，result中的应该是最近的就在前面。所以这个就是不断问到新的节点后，不断查询到离自己比较近的节点。到没有最近的节点后，就不再询问。\n\t\tfor i := 0; i < len(result.entries) && pendingQueries < alpha; i++ {\n\t\t\tn := result.entries[i]\n\t\t\tif !asked[n.ID()] {\n\t\t\t\tasked[n.ID()] = true\n\t\t\t\tpendingQueries++\n\t\t\t\t//向节点n询问targetKey的节点们\n\t\t\t\tgo tab.findnode(n, targetKey, reply)\n\t\t\t}\n\t\t}\n\t\t//所有人都回复了，就不再询问了\n\t\tif pendingQueries == 0 {\n\t\t\t// we have asked all closest nodes, stop the search\n\t\t\tbreak\n\t\t}\n\n\t\t//<-reply是最迷惑的，这个是每次从reply中读出一个回复，一个回复为一个节点回复的他的桶节点们，然后range它的桶节点，添加到本桶中\n\t\t// wait for the next reply\n\t\tfor _, n := range <-reply {\n\t\t\tif n != nil && !seen[n.ID()] {\n\t\t\t\tseen[n.ID()] = true\n\t\t\t\t//result.push方法，result中数组的长度为bucketSize，且按离target的距离排序，有点像距离最“近”堆排序..\n\t\t\t\tresult.push(n, bucketSize)\n\t\t\t}\n\t\t}\n\t\t//有过一次回复，pendingQueries递减\n\t\tpendingQueries--\n\t}\n\n\treturn result.entries\n}\n```\n\n\n\n```\n//findnode方法\nfunc (tab *Table) findnode(n *node, targetKey encPubkey, reply chan<- []*node) {\n\t//从db中读出向n节点查询出错的次数(这个出错次数应该会影响n节点的名誉吧)\n\tfails := tab.db.FindFails(n.ID())\n\t//调用上层通信向n节点发出查询消息\n\tr, err := tab.net.findnode(n.ID(), n.addr(), targetKey)\n\n\t//这里看着是直接就返回了消息和错误..看样子tab.net.findnode是同步的..\n\t//如果返回错误或者节点数量为0，都视为失败，出错次数fails++并更新db。如果fails次数达到一定，则会从tab中删除这个节点\n\tif err != nil || len(r) == 0 {\n\t\tfails++\n\t\ttab.db.UpdateFindFails(n.ID(), fails)\n\t\tlog.Trace(\"Findnode failed\", \"id\", n.ID(), \"failcount\", fails, \"err\", err)\n\t\tif fails >= maxFindnodeFailures {\n\t\t\tlog.Trace(\"Too many findnode failures, dropping\", \"id\", n.ID(), \"failcount\", fails)\n\t\t\ttab.delete(n)\n\t\t}\n\t} else if fails > 0 {\n\t\t//如果这次成功了，以前失败过，则可抵消以前的出错次数\n\t\ttab.db.UpdateFindFails(n.ID(), fails-1)\n\t}\n\n\t// 尽可能添加多个node,尽管他们之中可能有些不在线，但是我们会在revalidation时删除他们\n\tfor _, n := range r {\n\t\ttab.add(n)\n\t}\n\t//回复成功\n\treply <- r\n}\n```\n\n\n\nrevalidation的代码就不粘贴了，做的事情是，随机一个桶，找出这个桶里最后一个节点，然后向这个节点发出ping，如果这个节点回复了，就把他移到桶的最前方。如果没回复，就这个桶里的当前情况要么删除它要么替换它。\n\n\n\n⭐️其实还是有疑问的，就是虽然桶的index是确定的，但target是随机的，那么每次target随机，各个桶里节点跟target的距离就会不一样，各个桶里的节点是不是会变化很大。\n\n解: 因为桶里存放的节点的逻辑距离是固定的，又因为每个桶的大小（16）是固定的，只有当桶中有空位时，节点才会被添加进桶。所以我的结论是，桶里节点的变化不会很大，顺序可能会经常变，随机目标是为了查找新的距离自身近的节点（即为了查找前大半部分桶中的节点），再就是为了保持桶的活性（即桶后小半部分桶中的节点）。\n\n\n\n\n\n##### udp\n\nkad使用udp进行通信。作为tab.net。好玩的是上面的tab.net.findnode如何实现同步的。\n\n```\nfunc (t *udp) findnode(toid enode.ID, toaddr *net.UDPAddr, target encPubkey) ([]*node, error) {\n   // If we haven't seen a ping from the destination node for a while, it won't remember\n   // our endpoint proof and reject findnode. Solicit a ping first.\n   if time.Since(t.db.LastPingReceived(toid)) > bondExpiration {\n      t.ping(toid, toaddr)\n      t.waitping(toid)\n   }\n\n   nodes := make([]*node, 0, bucketSize)\n   nreceived := 0\n   errc := t.pending(toid, neighborsPacket, func(r interface{}) bool {\n      reply := r.(*neighbors)\n      for _, rn := range reply.Nodes {\n         nreceived++\n         n, err := t.nodeFromRPC(toaddr, rn)\n         if err != nil {\n            log.Trace(\"Invalid neighbor node received\", \"ip\", rn.IP, \"addr\", toaddr, \"err\", err)\n            continue\n         }\n         nodes = append(nodes, n)\n      }\n      return nreceived >= bucketSize\n   })\n   t.send(toaddr, findnodePacket, &findnode{\n      Target:     target,\n      Expiration: uint64(time.Now().Add(expiration).Unix()),\n   })\n   return nodes, <-errc\n}\n```\n\n上面可以看到findnode是发出了一个findnode包，然后等回复会回调pending的callback。但这个方法确实是同步的，就是说返回的话，就说明收到了回复，callback也回调了。是怎么做到的呢。真的很好玩，利用了errc通道。就是最后一句`return nodes, <-errc`，只有errc通道读出消息来，才会返回数据，这也是callback设计的精妙之处吧。这么设计真的是精妙，get到了。\n\n\n\nudp处理的工作主要是进行通信。通信类型有两组，(发ping - 回pong)、(发findnode - 回neighbors)\n","source":"_posts/eth-p2p-udp.md","raw":"---\ntitle: eth_p2p_udp\ncategories:\n  - eth\ndate: 2019-10-14 14:54:36\ntags:\n---\n\n## p2p-udp\n\n在以太坊的p2p包下，discover包下的udp主要负责节点发现。以太坊的节点发现又是基于kademlia协议。\n\n\n\n#### kademlia\n\n[kad详细解读](http://www.yeolar.com/note/2010/03/21/kademlia/)\n\n简单说来，kad中，每个节点由特定ID为唯一标识符。并且由ID决定K桶和两节点之间的逻辑距离。\n\nID由二进制表示，ID长度有几位，K桶数量就为几。K桶的划分满足，第n个K桶的节点前n-1位与自己ID的前n-1位是相同的。如ID长度为3，那么K桶数量为3，自己的ID为110，那么自己的K桶划分为前0位相同(0xx）、前1位相同(10x),前2位相同(11x)这样的三个K桶。显然，在这样的分布中，满足0xx的节点就会有很多，但满足11x的节点只有111。然后两个节点之前的逻辑距离为ID的异或值，越相近的节点，异或值越小，越远的节点，异或值越大。\n\n\n\n另外，Kademlia 协议包括四种远程 RPC 操作：PING、STORE、FIND_NODE、FIND_VALUE。这些在上面的链接中都有也更详细。尤其是数据存放需要的基本步骤，都有相应提到。\n\n\n\n#### 以太坊的kad\n\n以太坊的kad与上面标准的kad略有不同。\n\n先撸代码吧。\n\n```\nbucketSize      = 16 // Kademlia bucket size\n// We keep buckets for the upper 1/15 of distances because\n// it's very unlikely we'll ever encounter a node that's closer.\nhashBits          = len(common.Hash{}) * 8\nnBuckets          = hashBits / 15       // Number of buckets\nbucketMinDistance = hashBits - nBuckets // Log distance of closest bucket\n```\n\nk桶数量nBuckets，（定为ID长度256(hash长度32byte * 8bit/byte)）/ 15。\n\nk桶大小bucketSize，即每个k桶中的节点最大数量。\n\n节点ID的计算方式(由公钥生成)\n\n```\n//encPubkey取hash\nfunc (e encPubkey) id() enode.ID {\n\treturn enode.ID(crypto.Keccak256Hash(e[:]))\n}\n//pubkey -> encpubkey\nfunc encodePubkey(key *ecdsa.PublicKey) encPubkey {\n\tvar e encPubkey\n\tmath.ReadBits(key.X, e[:len(e)/2])\n\tmath.ReadBits(key.Y, e[len(e)/2:])\n\treturn e\n}\n```\n\n\n\n- 桶的基本结构\n\n```\ntype Table struct {\n\tmutex   sync.Mutex        // protects buckets, bucket content, nursery, rand\n\tbuckets [nBuckets]*bucket // index of known nodes by distance\n\t...\n}\n\n```\n\n```\n// bucket contains nodes, ordered by their last activity. the entry\n// that was most recently active is the first element in entries.\ntype bucket struct {\n   entries      []*node // live entries, sorted by time of last contact\n   replacements []*node // recently seen nodes to be used if revalidation fails\n   ips          netutil.DistinctNetSet\n}\n```\n\nbuckets是所有桶，是一个定长数组，其中，(0<index<nBuckets)的index代表index桶。然后节点的id经过计算映射到某个桶。桶里的节点们又是一个数组，entries数组中为优先可用的节点，他们按上一次联系的时间排序，最最近联系的节点排在数组的最前面。如果entries中某节点在revalidation时失败了，会从replacements中找出某个来代替..\n\n\n\n```\n//增。如果对应的桶b, b.entries的长度没超过最大数量的话，就增加到entries中，否则增加到replacements中\nfunc (tab *Table) add(n *node) {\n   if n.ID() == tab.self.ID() {\n      return\n   }\n   tab.mutex.Lock()\n   defer tab.mutex.Unlock()\n   b := tab.bucket(n.ID())\n   if !tab.bumpOrAdd(b, n) {\n      // Node is not in table. Add it to the replacement list.\n      tab.addReplacement(b, n)\n   }\n}\n\n//删，找到node对应的桶，然后从桶中把节点删除了\nfunc (tab *Table) delete(node *node) {\n\ttab.mutex.Lock()\n\tdefer tab.mutex.Unlock()\n\n\ttab.deleteInBucket(tab.bucket(node.ID()), node)\n}\n\n//查，查呢是返回所有桶中距离target最近的nresults个节点\nfunc (tab *Table) closest(target enode.ID, nresults int) *nodesByDistance {\n\t// This is a very wasteful way to find the closest nodes but\n\t// obviously correct. I believe that tree-based buckets would make\n\t// this easier to implement efficiently.\n\tclose := &nodesByDistance{target: target}\n\tfor _, b := range &tab.buckets {\n\t\tfor _, n := range b.entries {\n\t\t\tclose.push(n, nresults)\n\t\t}\n\t}\n\treturn close\n}\n\n```\n\n\n\n- 主线逻辑操作\n\n```\nfunc (tab *Table) loop() {\n  ...\n  loop:\n\tfor {\n\t\tselect {\n\t\tcase <-refresh.C:  //定时刷新，\n\t\t\ttab.seedRand() //更新随机种子\n\t\t\tif refreshDone == nil {\n\t\t\t\trefreshDone = make(chan struct{})\n\t\t\t\tgo tab.doRefresh(refreshDone)  //进行刷新，刷新完成往refreshDone通道中通知\n\t\t\t}\n\t\tcase req := <-tab.refreshReq: //上层请求刷新，上层有可能需要知道刷新完成时间，故req通道用于通知刷新完成\n\t\t\twaiting = append(waiting, req)  //记录下所有的刷新请求通道\n\t\t\tif refreshDone == nil {\n\t\t\t\trefreshDone = make(chan struct{})\n\t\t\t\tgo tab.doRefresh(refreshDone)\n\t\t\t}\n\t\tcase <-refreshDone:  //刷新完成后，关闭所有请求通道，通知上层已刷新完成\n\t\t\tfor _, ch := range waiting {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t\twaiting, refreshDone = nil, nil //清空waiting数组，和refreshDone通道\n\t\tcase <-revalidate.C:\n\t\t\tgo tab.doRevalidate(revalidateDone)\n\t\tcase <-revalidateDone:\n\t\t\trevalidate.Reset(tab.nextRevalidateTime())\n\t\tcase <-copyNodes.C:\n\t\t\tgo tab.copyLiveNodes()\n\t\tcase <-tab.closeReq:\n\t\t\tbreak loop\n\t\t}\n\t}\n  ...\n}\n\n\n\n//刷新方法\nfunc (tab *Table) doRefresh(done chan struct{}) {\n  defer close(done)\n  ...\n\n  //通过自己为target去找neighbor，前提是需要自己有secp256k1字段，v4版本的node里是含有secp256k1的，即v4版本是满足这个if条件。load后key中的值为node的公钥\n  var key ecdsa.PublicKey\n  if err := tab.self.Load((*enode.Secp256k1)(&key)); err == nil {\n\ttab.lookup(encodePubkey(&key), false)\n  }\n\n\n  //⭐️通过随机target去找neighbor。这里的疑问是注释中提到为什么不使用kad本来刷新的方式是因为findnode taget是512bit,这里为什么是512bit? (是因为findnode target是公钥，公钥长度是64byte/512bit) 后半句说不容易生成一个属于所选桶的sha3前镜像，kad本来刷新的方式是选择最近最少使用的桶，所以这里的意思是知道桶了，但是node的ID是经过hash生成的，hash的范围确定，但倒回去找ID就很复杂的意思吗\n// The Kademlia paper specifies that the bucket refresh should\n// perform a lookup in the least recently used bucket. We cannot\n// adhere to this because the findnode target is a 512bit value\n// (not hash-sized) and it is not easily possible to generate a\n// sha3 preimage that falls into a chosen bucket.\n// We perform a few lookups with a random target instead.\n  for i := 0; i < 3; i++ {\n\t var target encPubkey\n\t crand.Read(target[:])\n\t tab.lookup(target, false)\n  }\n}\n\n```\n\n\n\n\n\n```\n//下面看一下关键方法lookup\nfunc (tab *Table) lookup(targetKey encPubkey, refreshIfEmpty bool) []*node {\n\tvar (\n\t\ttarget         = enode.ID(crypto.Keccak256Hash(targetKey[:]))  //targetid：由公钥进行hash得来\n\t\tasked          = make(map[enode.ID]bool)  //保存询问过的节点，以免重复询问\n\t\tseen           = make(map[enode.ID]bool)  //保存回复过的节点，防止询问的节点多次回复\n\t\treply          = make(chan []*node, alpha) //节点回复的通道，alpha为并发量，每次三个\n\t\tpendingQueries = 0   //待定的查询数量，即询问了 但没回复的数量\n\t\tresult         *nodesByDistance  //查询结果\n\t)\n\t//将自己列为询问过的节点\n\tasked[tab.self.ID()] = true\n\n    //将现有的k桶节点们填充到result中\n\tfor {\n\t\ttab.mutex.Lock()\n\t\t//从自己的所有桶中找出离target最近的bucketSize个节点\n\t\tresult = tab.closest(target, bucketSize)\n\t\ttab.mutex.Unlock()\n\t\t//如果桶中有节点或者refreshIfEmpty为false，跳出循环\n\t\tif len(result.entries) > 0 || !refreshIfEmpty {\n\t\t\tbreak\n\t\t}\n\t\t//如果k桶中无节点，则请求刷新(doRefresh -> 从种子节点中出发..)\n\t\t<-tab.refresh()\n\t\t//请求一次刷新，将refreshIfEmpty置为false,防止一直无节点，一直在这里循环，相当于这个for循环最多只执行两次\n\t\trefreshIfEmpty = false\n\t}\n\n\n\tfor {\n\t\t//向近的节点询问节点，询问过的就不再询问，并且每次询问的节点数<alpha,即每次只询问最近的alpha个节点。之前一直卡在为什么外层要for循环，难道不是每次问的都是相同的吗？还真的不是..要是相同的话，pendingQueries的值就不会++，这个询问for循环就不会再进行了，然后等回答完毕这个方法就完毕了。之所以桶里的前alpha个会不一样，是因为在后面从reply中读出的为问到的节点们，然后添加到本桶里的时候会影响整个排序，result中的应该是最近的就在前面。所以这个就是不断问到新的节点后，不断查询到离自己比较近的节点。到没有最近的节点后，就不再询问。\n\t\tfor i := 0; i < len(result.entries) && pendingQueries < alpha; i++ {\n\t\t\tn := result.entries[i]\n\t\t\tif !asked[n.ID()] {\n\t\t\t\tasked[n.ID()] = true\n\t\t\t\tpendingQueries++\n\t\t\t\t//向节点n询问targetKey的节点们\n\t\t\t\tgo tab.findnode(n, targetKey, reply)\n\t\t\t}\n\t\t}\n\t\t//所有人都回复了，就不再询问了\n\t\tif pendingQueries == 0 {\n\t\t\t// we have asked all closest nodes, stop the search\n\t\t\tbreak\n\t\t}\n\n\t\t//<-reply是最迷惑的，这个是每次从reply中读出一个回复，一个回复为一个节点回复的他的桶节点们，然后range它的桶节点，添加到本桶中\n\t\t// wait for the next reply\n\t\tfor _, n := range <-reply {\n\t\t\tif n != nil && !seen[n.ID()] {\n\t\t\t\tseen[n.ID()] = true\n\t\t\t\t//result.push方法，result中数组的长度为bucketSize，且按离target的距离排序，有点像距离最“近”堆排序..\n\t\t\t\tresult.push(n, bucketSize)\n\t\t\t}\n\t\t}\n\t\t//有过一次回复，pendingQueries递减\n\t\tpendingQueries--\n\t}\n\n\treturn result.entries\n}\n```\n\n\n\n```\n//findnode方法\nfunc (tab *Table) findnode(n *node, targetKey encPubkey, reply chan<- []*node) {\n\t//从db中读出向n节点查询出错的次数(这个出错次数应该会影响n节点的名誉吧)\n\tfails := tab.db.FindFails(n.ID())\n\t//调用上层通信向n节点发出查询消息\n\tr, err := tab.net.findnode(n.ID(), n.addr(), targetKey)\n\n\t//这里看着是直接就返回了消息和错误..看样子tab.net.findnode是同步的..\n\t//如果返回错误或者节点数量为0，都视为失败，出错次数fails++并更新db。如果fails次数达到一定，则会从tab中删除这个节点\n\tif err != nil || len(r) == 0 {\n\t\tfails++\n\t\ttab.db.UpdateFindFails(n.ID(), fails)\n\t\tlog.Trace(\"Findnode failed\", \"id\", n.ID(), \"failcount\", fails, \"err\", err)\n\t\tif fails >= maxFindnodeFailures {\n\t\t\tlog.Trace(\"Too many findnode failures, dropping\", \"id\", n.ID(), \"failcount\", fails)\n\t\t\ttab.delete(n)\n\t\t}\n\t} else if fails > 0 {\n\t\t//如果这次成功了，以前失败过，则可抵消以前的出错次数\n\t\ttab.db.UpdateFindFails(n.ID(), fails-1)\n\t}\n\n\t// 尽可能添加多个node,尽管他们之中可能有些不在线，但是我们会在revalidation时删除他们\n\tfor _, n := range r {\n\t\ttab.add(n)\n\t}\n\t//回复成功\n\treply <- r\n}\n```\n\n\n\nrevalidation的代码就不粘贴了，做的事情是，随机一个桶，找出这个桶里最后一个节点，然后向这个节点发出ping，如果这个节点回复了，就把他移到桶的最前方。如果没回复，就这个桶里的当前情况要么删除它要么替换它。\n\n\n\n⭐️其实还是有疑问的，就是虽然桶的index是确定的，但target是随机的，那么每次target随机，各个桶里节点跟target的距离就会不一样，各个桶里的节点是不是会变化很大。\n\n解: 因为桶里存放的节点的逻辑距离是固定的，又因为每个桶的大小（16）是固定的，只有当桶中有空位时，节点才会被添加进桶。所以我的结论是，桶里节点的变化不会很大，顺序可能会经常变，随机目标是为了查找新的距离自身近的节点（即为了查找前大半部分桶中的节点），再就是为了保持桶的活性（即桶后小半部分桶中的节点）。\n\n\n\n\n\n##### udp\n\nkad使用udp进行通信。作为tab.net。好玩的是上面的tab.net.findnode如何实现同步的。\n\n```\nfunc (t *udp) findnode(toid enode.ID, toaddr *net.UDPAddr, target encPubkey) ([]*node, error) {\n   // If we haven't seen a ping from the destination node for a while, it won't remember\n   // our endpoint proof and reject findnode. Solicit a ping first.\n   if time.Since(t.db.LastPingReceived(toid)) > bondExpiration {\n      t.ping(toid, toaddr)\n      t.waitping(toid)\n   }\n\n   nodes := make([]*node, 0, bucketSize)\n   nreceived := 0\n   errc := t.pending(toid, neighborsPacket, func(r interface{}) bool {\n      reply := r.(*neighbors)\n      for _, rn := range reply.Nodes {\n         nreceived++\n         n, err := t.nodeFromRPC(toaddr, rn)\n         if err != nil {\n            log.Trace(\"Invalid neighbor node received\", \"ip\", rn.IP, \"addr\", toaddr, \"err\", err)\n            continue\n         }\n         nodes = append(nodes, n)\n      }\n      return nreceived >= bucketSize\n   })\n   t.send(toaddr, findnodePacket, &findnode{\n      Target:     target,\n      Expiration: uint64(time.Now().Add(expiration).Unix()),\n   })\n   return nodes, <-errc\n}\n```\n\n上面可以看到findnode是发出了一个findnode包，然后等回复会回调pending的callback。但这个方法确实是同步的，就是说返回的话，就说明收到了回复，callback也回调了。是怎么做到的呢。真的很好玩，利用了errc通道。就是最后一句`return nodes, <-errc`，只有errc通道读出消息来，才会返回数据，这也是callback设计的精妙之处吧。这么设计真的是精妙，get到了。\n\n\n\nudp处理的工作主要是进行通信。通信类型有两组，(发ping - 回pong)、(发findnode - 回neighbors)\n","slug":"eth-p2p-udp","published":1,"updated":"2019-10-14T06:54:45.669Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69x20028t6xvp0zgpc2l","content":"<h2 id=\"p2p-udp\"><a href=\"#p2p-udp\" class=\"headerlink\" title=\"p2p-udp\"></a>p2p-udp</h2><p>在以太坊的p2p包下，discover包下的udp主要负责节点发现。以太坊的节点发现又是基于kademlia协议。</p>\n<h4 id=\"kademlia\"><a href=\"#kademlia\" class=\"headerlink\" title=\"kademlia\"></a>kademlia</h4><p><a href=\"http://www.yeolar.com/note/2010/03/21/kademlia/\" target=\"_blank\" rel=\"noopener\">kad详细解读</a></p>\n<p>简单说来，kad中，每个节点由特定ID为唯一标识符。并且由ID决定K桶和两节点之间的逻辑距离。</p>\n<p>ID由二进制表示，ID长度有几位，K桶数量就为几。K桶的划分满足，第n个K桶的节点前n-1位与自己ID的前n-1位是相同的。如ID长度为3，那么K桶数量为3，自己的ID为110，那么自己的K桶划分为前0位相同(0xx）、前1位相同(10x),前2位相同(11x)这样的三个K桶。显然，在这样的分布中，满足0xx的节点就会有很多，但满足11x的节点只有111。然后两个节点之前的逻辑距离为ID的异或值，越相近的节点，异或值越小，越远的节点，异或值越大。</p>\n<p>另外，Kademlia 协议包括四种远程 RPC 操作：PING、STORE、FIND_NODE、FIND_VALUE。这些在上面的链接中都有也更详细。尤其是数据存放需要的基本步骤，都有相应提到。</p>\n<h4 id=\"以太坊的kad\"><a href=\"#以太坊的kad\" class=\"headerlink\" title=\"以太坊的kad\"></a>以太坊的kad</h4><p>以太坊的kad与上面标准的kad略有不同。</p>\n<p>先撸代码吧。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bucketSize      = 16 // Kademlia bucket size</span><br><span class=\"line\">// We keep buckets for the upper 1/15 of distances because</span><br><span class=\"line\">// it&apos;s very unlikely we&apos;ll ever encounter a node that&apos;s closer.</span><br><span class=\"line\">hashBits          = len(common.Hash&#123;&#125;) * 8</span><br><span class=\"line\">nBuckets          = hashBits / 15       // Number of buckets</span><br><span class=\"line\">bucketMinDistance = hashBits - nBuckets // Log distance of closest bucket</span><br></pre></td></tr></table></figure>\n\n<p>k桶数量nBuckets，（定为ID长度256(hash长度32byte * 8bit/byte)）/ 15。</p>\n<p>k桶大小bucketSize，即每个k桶中的节点最大数量。</p>\n<p>节点ID的计算方式(由公钥生成)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//encPubkey取hash</span><br><span class=\"line\">func (e encPubkey) id() enode.ID &#123;</span><br><span class=\"line\">\treturn enode.ID(crypto.Keccak256Hash(e[:]))</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//pubkey -&gt; encpubkey</span><br><span class=\"line\">func encodePubkey(key *ecdsa.PublicKey) encPubkey &#123;</span><br><span class=\"line\">\tvar e encPubkey</span><br><span class=\"line\">\tmath.ReadBits(key.X, e[:len(e)/2])</span><br><span class=\"line\">\tmath.ReadBits(key.Y, e[len(e)/2:])</span><br><span class=\"line\">\treturn e</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>桶的基本结构</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Table struct &#123;</span><br><span class=\"line\">\tmutex   sync.Mutex        // protects buckets, bucket content, nursery, rand</span><br><span class=\"line\">\tbuckets [nBuckets]*bucket // index of known nodes by distance</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// bucket contains nodes, ordered by their last activity. the entry</span><br><span class=\"line\">// that was most recently active is the first element in entries.</span><br><span class=\"line\">type bucket struct &#123;</span><br><span class=\"line\">   entries      []*node // live entries, sorted by time of last contact</span><br><span class=\"line\">   replacements []*node // recently seen nodes to be used if revalidation fails</span><br><span class=\"line\">   ips          netutil.DistinctNetSet</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>buckets是所有桶，是一个定长数组，其中，(0&lt;index&lt;nBuckets)的index代表index桶。然后节点的id经过计算映射到某个桶。桶里的节点们又是一个数组，entries数组中为优先可用的节点，他们按上一次联系的时间排序，最最近联系的节点排在数组的最前面。如果entries中某节点在revalidation时失败了，会从replacements中找出某个来代替..</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//增。如果对应的桶b, b.entries的长度没超过最大数量的话，就增加到entries中，否则增加到replacements中</span><br><span class=\"line\">func (tab *Table) add(n *node) &#123;</span><br><span class=\"line\">   if n.ID() == tab.self.ID() &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   tab.mutex.Lock()</span><br><span class=\"line\">   defer tab.mutex.Unlock()</span><br><span class=\"line\">   b := tab.bucket(n.ID())</span><br><span class=\"line\">   if !tab.bumpOrAdd(b, n) &#123;</span><br><span class=\"line\">      // Node is not in table. Add it to the replacement list.</span><br><span class=\"line\">      tab.addReplacement(b, n)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//删，找到node对应的桶，然后从桶中把节点删除了</span><br><span class=\"line\">func (tab *Table) delete(node *node) &#123;</span><br><span class=\"line\">\ttab.mutex.Lock()</span><br><span class=\"line\">\tdefer tab.mutex.Unlock()</span><br><span class=\"line\"></span><br><span class=\"line\">\ttab.deleteInBucket(tab.bucket(node.ID()), node)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//查，查呢是返回所有桶中距离target最近的nresults个节点</span><br><span class=\"line\">func (tab *Table) closest(target enode.ID, nresults int) *nodesByDistance &#123;</span><br><span class=\"line\">\t// This is a very wasteful way to find the closest nodes but</span><br><span class=\"line\">\t// obviously correct. I believe that tree-based buckets would make</span><br><span class=\"line\">\t// this easier to implement efficiently.</span><br><span class=\"line\">\tclose := &amp;nodesByDistance&#123;target: target&#125;</span><br><span class=\"line\">\tfor _, b := range &amp;tab.buckets &#123;</span><br><span class=\"line\">\t\tfor _, n := range b.entries &#123;</span><br><span class=\"line\">\t\t\tclose.push(n, nresults)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn close</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>主线逻辑操作</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (tab *Table) loop() &#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  loop:</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase &lt;-refresh.C:  //定时刷新，</span><br><span class=\"line\">\t\t\ttab.seedRand() //更新随机种子</span><br><span class=\"line\">\t\t\tif refreshDone == nil &#123;</span><br><span class=\"line\">\t\t\t\trefreshDone = make(chan struct&#123;&#125;)</span><br><span class=\"line\">\t\t\t\tgo tab.doRefresh(refreshDone)  //进行刷新，刷新完成往refreshDone通道中通知</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\tcase req := &lt;-tab.refreshReq: //上层请求刷新，上层有可能需要知道刷新完成时间，故req通道用于通知刷新完成</span><br><span class=\"line\">\t\t\twaiting = append(waiting, req)  //记录下所有的刷新请求通道</span><br><span class=\"line\">\t\t\tif refreshDone == nil &#123;</span><br><span class=\"line\">\t\t\t\trefreshDone = make(chan struct&#123;&#125;)</span><br><span class=\"line\">\t\t\t\tgo tab.doRefresh(refreshDone)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\tcase &lt;-refreshDone:  //刷新完成后，关闭所有请求通道，通知上层已刷新完成</span><br><span class=\"line\">\t\t\tfor _, ch := range waiting &#123;</span><br><span class=\"line\">\t\t\t\tclose(ch)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\twaiting, refreshDone = nil, nil //清空waiting数组，和refreshDone通道</span><br><span class=\"line\">\t\tcase &lt;-revalidate.C:</span><br><span class=\"line\">\t\t\tgo tab.doRevalidate(revalidateDone)</span><br><span class=\"line\">\t\tcase &lt;-revalidateDone:</span><br><span class=\"line\">\t\t\trevalidate.Reset(tab.nextRevalidateTime())</span><br><span class=\"line\">\t\tcase &lt;-copyNodes.C:</span><br><span class=\"line\">\t\t\tgo tab.copyLiveNodes()</span><br><span class=\"line\">\t\tcase &lt;-tab.closeReq:</span><br><span class=\"line\">\t\t\tbreak loop</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">//刷新方法</span><br><span class=\"line\">func (tab *Table) doRefresh(done chan struct&#123;&#125;) &#123;</span><br><span class=\"line\">  defer close(done)</span><br><span class=\"line\">  ...</span><br><span class=\"line\"></span><br><span class=\"line\">  //通过自己为target去找neighbor，前提是需要自己有secp256k1字段，v4版本的node里是含有secp256k1的，即v4版本是满足这个if条件。load后key中的值为node的公钥</span><br><span class=\"line\">  var key ecdsa.PublicKey</span><br><span class=\"line\">  if err := tab.self.Load((*enode.Secp256k1)(&amp;key)); err == nil &#123;</span><br><span class=\"line\">\ttab.lookup(encodePubkey(&amp;key), false)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">  //⭐️通过随机target去找neighbor。这里的疑问是注释中提到为什么不使用kad本来刷新的方式是因为findnode taget是512bit,这里为什么是512bit? (是因为findnode target是公钥，公钥长度是64byte/512bit) 后半句说不容易生成一个属于所选桶的sha3前镜像，kad本来刷新的方式是选择最近最少使用的桶，所以这里的意思是知道桶了，但是node的ID是经过hash生成的，hash的范围确定，但倒回去找ID就很复杂的意思吗</span><br><span class=\"line\">// The Kademlia paper specifies that the bucket refresh should</span><br><span class=\"line\">// perform a lookup in the least recently used bucket. We cannot</span><br><span class=\"line\">// adhere to this because the findnode target is a 512bit value</span><br><span class=\"line\">// (not hash-sized) and it is not easily possible to generate a</span><br><span class=\"line\">// sha3 preimage that falls into a chosen bucket.</span><br><span class=\"line\">// We perform a few lookups with a random target instead.</span><br><span class=\"line\">  for i := 0; i &lt; 3; i++ &#123;</span><br><span class=\"line\">\t var target encPubkey</span><br><span class=\"line\">\t crand.Read(target[:])</span><br><span class=\"line\">\t tab.lookup(target, false)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//下面看一下关键方法lookup</span><br><span class=\"line\">func (tab *Table) lookup(targetKey encPubkey, refreshIfEmpty bool) []*node &#123;</span><br><span class=\"line\">\tvar (</span><br><span class=\"line\">\t\ttarget         = enode.ID(crypto.Keccak256Hash(targetKey[:]))  //targetid：由公钥进行hash得来</span><br><span class=\"line\">\t\tasked          = make(map[enode.ID]bool)  //保存询问过的节点，以免重复询问</span><br><span class=\"line\">\t\tseen           = make(map[enode.ID]bool)  //保存回复过的节点，防止询问的节点多次回复</span><br><span class=\"line\">\t\treply          = make(chan []*node, alpha) //节点回复的通道，alpha为并发量，每次三个</span><br><span class=\"line\">\t\tpendingQueries = 0   //待定的查询数量，即询问了 但没回复的数量</span><br><span class=\"line\">\t\tresult         *nodesByDistance  //查询结果</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\t//将自己列为询问过的节点</span><br><span class=\"line\">\tasked[tab.self.ID()] = true</span><br><span class=\"line\"></span><br><span class=\"line\">    //将现有的k桶节点们填充到result中</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\ttab.mutex.Lock()</span><br><span class=\"line\">\t\t//从自己的所有桶中找出离target最近的bucketSize个节点</span><br><span class=\"line\">\t\tresult = tab.closest(target, bucketSize)</span><br><span class=\"line\">\t\ttab.mutex.Unlock()</span><br><span class=\"line\">\t\t//如果桶中有节点或者refreshIfEmpty为false，跳出循环</span><br><span class=\"line\">\t\tif len(result.entries) &gt; 0 || !refreshIfEmpty &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//如果k桶中无节点，则请求刷新(doRefresh -&gt; 从种子节点中出发..)</span><br><span class=\"line\">\t\t&lt;-tab.refresh()</span><br><span class=\"line\">\t\t//请求一次刷新，将refreshIfEmpty置为false,防止一直无节点，一直在这里循环，相当于这个for循环最多只执行两次</span><br><span class=\"line\">\t\trefreshIfEmpty = false</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\t//向近的节点询问节点，询问过的就不再询问，并且每次询问的节点数&lt;alpha,即每次只询问最近的alpha个节点。之前一直卡在为什么外层要for循环，难道不是每次问的都是相同的吗？还真的不是..要是相同的话，pendingQueries的值就不会++，这个询问for循环就不会再进行了，然后等回答完毕这个方法就完毕了。之所以桶里的前alpha个会不一样，是因为在后面从reply中读出的为问到的节点们，然后添加到本桶里的时候会影响整个排序，result中的应该是最近的就在前面。所以这个就是不断问到新的节点后，不断查询到离自己比较近的节点。到没有最近的节点后，就不再询问。</span><br><span class=\"line\">\t\tfor i := 0; i &lt; len(result.entries) &amp;&amp; pendingQueries &lt; alpha; i++ &#123;</span><br><span class=\"line\">\t\t\tn := result.entries[i]</span><br><span class=\"line\">\t\t\tif !asked[n.ID()] &#123;</span><br><span class=\"line\">\t\t\t\tasked[n.ID()] = true</span><br><span class=\"line\">\t\t\t\tpendingQueries++</span><br><span class=\"line\">\t\t\t\t//向节点n询问targetKey的节点们</span><br><span class=\"line\">\t\t\t\tgo tab.findnode(n, targetKey, reply)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//所有人都回复了，就不再询问了</span><br><span class=\"line\">\t\tif pendingQueries == 0 &#123;</span><br><span class=\"line\">\t\t\t// we have asked all closest nodes, stop the search</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t//&lt;-reply是最迷惑的，这个是每次从reply中读出一个回复，一个回复为一个节点回复的他的桶节点们，然后range它的桶节点，添加到本桶中</span><br><span class=\"line\">\t\t// wait for the next reply</span><br><span class=\"line\">\t\tfor _, n := range &lt;-reply &#123;</span><br><span class=\"line\">\t\t\tif n != nil &amp;&amp; !seen[n.ID()] &#123;</span><br><span class=\"line\">\t\t\t\tseen[n.ID()] = true</span><br><span class=\"line\">\t\t\t\t//result.push方法，result中数组的长度为bucketSize，且按离target的距离排序，有点像距离最“近”堆排序..</span><br><span class=\"line\">\t\t\t\tresult.push(n, bucketSize)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//有过一次回复，pendingQueries递减</span><br><span class=\"line\">\t\tpendingQueries--</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn result.entries</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//findnode方法</span><br><span class=\"line\">func (tab *Table) findnode(n *node, targetKey encPubkey, reply chan&lt;- []*node) &#123;</span><br><span class=\"line\">\t//从db中读出向n节点查询出错的次数(这个出错次数应该会影响n节点的名誉吧)</span><br><span class=\"line\">\tfails := tab.db.FindFails(n.ID())</span><br><span class=\"line\">\t//调用上层通信向n节点发出查询消息</span><br><span class=\"line\">\tr, err := tab.net.findnode(n.ID(), n.addr(), targetKey)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//这里看着是直接就返回了消息和错误..看样子tab.net.findnode是同步的..</span><br><span class=\"line\">\t//如果返回错误或者节点数量为0，都视为失败，出错次数fails++并更新db。如果fails次数达到一定，则会从tab中删除这个节点</span><br><span class=\"line\">\tif err != nil || len(r) == 0 &#123;</span><br><span class=\"line\">\t\tfails++</span><br><span class=\"line\">\t\ttab.db.UpdateFindFails(n.ID(), fails)</span><br><span class=\"line\">\t\tlog.Trace(&quot;Findnode failed&quot;, &quot;id&quot;, n.ID(), &quot;failcount&quot;, fails, &quot;err&quot;, err)</span><br><span class=\"line\">\t\tif fails &gt;= maxFindnodeFailures &#123;</span><br><span class=\"line\">\t\t\tlog.Trace(&quot;Too many findnode failures, dropping&quot;, &quot;id&quot;, n.ID(), &quot;failcount&quot;, fails)</span><br><span class=\"line\">\t\t\ttab.delete(n)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125; else if fails &gt; 0 &#123;</span><br><span class=\"line\">\t\t//如果这次成功了，以前失败过，则可抵消以前的出错次数</span><br><span class=\"line\">\t\ttab.db.UpdateFindFails(n.ID(), fails-1)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 尽可能添加多个node,尽管他们之中可能有些不在线，但是我们会在revalidation时删除他们</span><br><span class=\"line\">\tfor _, n := range r &#123;</span><br><span class=\"line\">\t\ttab.add(n)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//回复成功</span><br><span class=\"line\">\treply &lt;- r</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>revalidation的代码就不粘贴了，做的事情是，随机一个桶，找出这个桶里最后一个节点，然后向这个节点发出ping，如果这个节点回复了，就把他移到桶的最前方。如果没回复，就这个桶里的当前情况要么删除它要么替换它。</p>\n<p>⭐️其实还是有疑问的，就是虽然桶的index是确定的，但target是随机的，那么每次target随机，各个桶里节点跟target的距离就会不一样，各个桶里的节点是不是会变化很大。</p>\n<p>解: 因为桶里存放的节点的逻辑距离是固定的，又因为每个桶的大小（16）是固定的，只有当桶中有空位时，节点才会被添加进桶。所以我的结论是，桶里节点的变化不会很大，顺序可能会经常变，随机目标是为了查找新的距离自身近的节点（即为了查找前大半部分桶中的节点），再就是为了保持桶的活性（即桶后小半部分桶中的节点）。</p>\n<h5 id=\"udp\"><a href=\"#udp\" class=\"headerlink\" title=\"udp\"></a>udp</h5><p>kad使用udp进行通信。作为tab.net。好玩的是上面的tab.net.findnode如何实现同步的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (t *udp) findnode(toid enode.ID, toaddr *net.UDPAddr, target encPubkey) ([]*node, error) &#123;</span><br><span class=\"line\">   // If we haven&apos;t seen a ping from the destination node for a while, it won&apos;t remember</span><br><span class=\"line\">   // our endpoint proof and reject findnode. Solicit a ping first.</span><br><span class=\"line\">   if time.Since(t.db.LastPingReceived(toid)) &gt; bondExpiration &#123;</span><br><span class=\"line\">      t.ping(toid, toaddr)</span><br><span class=\"line\">      t.waitping(toid)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   nodes := make([]*node, 0, bucketSize)</span><br><span class=\"line\">   nreceived := 0</span><br><span class=\"line\">   errc := t.pending(toid, neighborsPacket, func(r interface&#123;&#125;) bool &#123;</span><br><span class=\"line\">      reply := r.(*neighbors)</span><br><span class=\"line\">      for _, rn := range reply.Nodes &#123;</span><br><span class=\"line\">         nreceived++</span><br><span class=\"line\">         n, err := t.nodeFromRPC(toaddr, rn)</span><br><span class=\"line\">         if err != nil &#123;</span><br><span class=\"line\">            log.Trace(&quot;Invalid neighbor node received&quot;, &quot;ip&quot;, rn.IP, &quot;addr&quot;, toaddr, &quot;err&quot;, err)</span><br><span class=\"line\">            continue</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">         nodes = append(nodes, n)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      return nreceived &gt;= bucketSize</span><br><span class=\"line\">   &#125;)</span><br><span class=\"line\">   t.send(toaddr, findnodePacket, &amp;findnode&#123;</span><br><span class=\"line\">      Target:     target,</span><br><span class=\"line\">      Expiration: uint64(time.Now().Add(expiration).Unix()),</span><br><span class=\"line\">   &#125;)</span><br><span class=\"line\">   return nodes, &lt;-errc</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上面可以看到findnode是发出了一个findnode包，然后等回复会回调pending的callback。但这个方法确实是同步的，就是说返回的话，就说明收到了回复，callback也回调了。是怎么做到的呢。真的很好玩，利用了errc通道。就是最后一句<code>return nodes, &lt;-errc</code>，只有errc通道读出消息来，才会返回数据，这也是callback设计的精妙之处吧。这么设计真的是精妙，get到了。</p>\n<p>udp处理的工作主要是进行通信。通信类型有两组，(发ping - 回pong)、(发findnode - 回neighbors)</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"p2p-udp\"><a href=\"#p2p-udp\" class=\"headerlink\" title=\"p2p-udp\"></a>p2p-udp</h2><p>在以太坊的p2p包下，discover包下的udp主要负责节点发现。以太坊的节点发现又是基于kademlia协议。</p>\n<h4 id=\"kademlia\"><a href=\"#kademlia\" class=\"headerlink\" title=\"kademlia\"></a>kademlia</h4><p><a href=\"http://www.yeolar.com/note/2010/03/21/kademlia/\" target=\"_blank\" rel=\"noopener\">kad详细解读</a></p>\n<p>简单说来，kad中，每个节点由特定ID为唯一标识符。并且由ID决定K桶和两节点之间的逻辑距离。</p>\n<p>ID由二进制表示，ID长度有几位，K桶数量就为几。K桶的划分满足，第n个K桶的节点前n-1位与自己ID的前n-1位是相同的。如ID长度为3，那么K桶数量为3，自己的ID为110，那么自己的K桶划分为前0位相同(0xx）、前1位相同(10x),前2位相同(11x)这样的三个K桶。显然，在这样的分布中，满足0xx的节点就会有很多，但满足11x的节点只有111。然后两个节点之前的逻辑距离为ID的异或值，越相近的节点，异或值越小，越远的节点，异或值越大。</p>\n<p>另外，Kademlia 协议包括四种远程 RPC 操作：PING、STORE、FIND_NODE、FIND_VALUE。这些在上面的链接中都有也更详细。尤其是数据存放需要的基本步骤，都有相应提到。</p>\n<h4 id=\"以太坊的kad\"><a href=\"#以太坊的kad\" class=\"headerlink\" title=\"以太坊的kad\"></a>以太坊的kad</h4><p>以太坊的kad与上面标准的kad略有不同。</p>\n<p>先撸代码吧。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bucketSize      = 16 // Kademlia bucket size</span><br><span class=\"line\">// We keep buckets for the upper 1/15 of distances because</span><br><span class=\"line\">// it&apos;s very unlikely we&apos;ll ever encounter a node that&apos;s closer.</span><br><span class=\"line\">hashBits          = len(common.Hash&#123;&#125;) * 8</span><br><span class=\"line\">nBuckets          = hashBits / 15       // Number of buckets</span><br><span class=\"line\">bucketMinDistance = hashBits - nBuckets // Log distance of closest bucket</span><br></pre></td></tr></table></figure>\n\n<p>k桶数量nBuckets，（定为ID长度256(hash长度32byte * 8bit/byte)）/ 15。</p>\n<p>k桶大小bucketSize，即每个k桶中的节点最大数量。</p>\n<p>节点ID的计算方式(由公钥生成)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//encPubkey取hash</span><br><span class=\"line\">func (e encPubkey) id() enode.ID &#123;</span><br><span class=\"line\">\treturn enode.ID(crypto.Keccak256Hash(e[:]))</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//pubkey -&gt; encpubkey</span><br><span class=\"line\">func encodePubkey(key *ecdsa.PublicKey) encPubkey &#123;</span><br><span class=\"line\">\tvar e encPubkey</span><br><span class=\"line\">\tmath.ReadBits(key.X, e[:len(e)/2])</span><br><span class=\"line\">\tmath.ReadBits(key.Y, e[len(e)/2:])</span><br><span class=\"line\">\treturn e</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>桶的基本结构</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Table struct &#123;</span><br><span class=\"line\">\tmutex   sync.Mutex        // protects buckets, bucket content, nursery, rand</span><br><span class=\"line\">\tbuckets [nBuckets]*bucket // index of known nodes by distance</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// bucket contains nodes, ordered by their last activity. the entry</span><br><span class=\"line\">// that was most recently active is the first element in entries.</span><br><span class=\"line\">type bucket struct &#123;</span><br><span class=\"line\">   entries      []*node // live entries, sorted by time of last contact</span><br><span class=\"line\">   replacements []*node // recently seen nodes to be used if revalidation fails</span><br><span class=\"line\">   ips          netutil.DistinctNetSet</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>buckets是所有桶，是一个定长数组，其中，(0&lt;index&lt;nBuckets)的index代表index桶。然后节点的id经过计算映射到某个桶。桶里的节点们又是一个数组，entries数组中为优先可用的节点，他们按上一次联系的时间排序，最最近联系的节点排在数组的最前面。如果entries中某节点在revalidation时失败了，会从replacements中找出某个来代替..</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//增。如果对应的桶b, b.entries的长度没超过最大数量的话，就增加到entries中，否则增加到replacements中</span><br><span class=\"line\">func (tab *Table) add(n *node) &#123;</span><br><span class=\"line\">   if n.ID() == tab.self.ID() &#123;</span><br><span class=\"line\">      return</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   tab.mutex.Lock()</span><br><span class=\"line\">   defer tab.mutex.Unlock()</span><br><span class=\"line\">   b := tab.bucket(n.ID())</span><br><span class=\"line\">   if !tab.bumpOrAdd(b, n) &#123;</span><br><span class=\"line\">      // Node is not in table. Add it to the replacement list.</span><br><span class=\"line\">      tab.addReplacement(b, n)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//删，找到node对应的桶，然后从桶中把节点删除了</span><br><span class=\"line\">func (tab *Table) delete(node *node) &#123;</span><br><span class=\"line\">\ttab.mutex.Lock()</span><br><span class=\"line\">\tdefer tab.mutex.Unlock()</span><br><span class=\"line\"></span><br><span class=\"line\">\ttab.deleteInBucket(tab.bucket(node.ID()), node)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//查，查呢是返回所有桶中距离target最近的nresults个节点</span><br><span class=\"line\">func (tab *Table) closest(target enode.ID, nresults int) *nodesByDistance &#123;</span><br><span class=\"line\">\t// This is a very wasteful way to find the closest nodes but</span><br><span class=\"line\">\t// obviously correct. I believe that tree-based buckets would make</span><br><span class=\"line\">\t// this easier to implement efficiently.</span><br><span class=\"line\">\tclose := &amp;nodesByDistance&#123;target: target&#125;</span><br><span class=\"line\">\tfor _, b := range &amp;tab.buckets &#123;</span><br><span class=\"line\">\t\tfor _, n := range b.entries &#123;</span><br><span class=\"line\">\t\t\tclose.push(n, nresults)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn close</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>主线逻辑操作</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (tab *Table) loop() &#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  loop:</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase &lt;-refresh.C:  //定时刷新，</span><br><span class=\"line\">\t\t\ttab.seedRand() //更新随机种子</span><br><span class=\"line\">\t\t\tif refreshDone == nil &#123;</span><br><span class=\"line\">\t\t\t\trefreshDone = make(chan struct&#123;&#125;)</span><br><span class=\"line\">\t\t\t\tgo tab.doRefresh(refreshDone)  //进行刷新，刷新完成往refreshDone通道中通知</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\tcase req := &lt;-tab.refreshReq: //上层请求刷新，上层有可能需要知道刷新完成时间，故req通道用于通知刷新完成</span><br><span class=\"line\">\t\t\twaiting = append(waiting, req)  //记录下所有的刷新请求通道</span><br><span class=\"line\">\t\t\tif refreshDone == nil &#123;</span><br><span class=\"line\">\t\t\t\trefreshDone = make(chan struct&#123;&#125;)</span><br><span class=\"line\">\t\t\t\tgo tab.doRefresh(refreshDone)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\tcase &lt;-refreshDone:  //刷新完成后，关闭所有请求通道，通知上层已刷新完成</span><br><span class=\"line\">\t\t\tfor _, ch := range waiting &#123;</span><br><span class=\"line\">\t\t\t\tclose(ch)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\twaiting, refreshDone = nil, nil //清空waiting数组，和refreshDone通道</span><br><span class=\"line\">\t\tcase &lt;-revalidate.C:</span><br><span class=\"line\">\t\t\tgo tab.doRevalidate(revalidateDone)</span><br><span class=\"line\">\t\tcase &lt;-revalidateDone:</span><br><span class=\"line\">\t\t\trevalidate.Reset(tab.nextRevalidateTime())</span><br><span class=\"line\">\t\tcase &lt;-copyNodes.C:</span><br><span class=\"line\">\t\t\tgo tab.copyLiveNodes()</span><br><span class=\"line\">\t\tcase &lt;-tab.closeReq:</span><br><span class=\"line\">\t\t\tbreak loop</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">//刷新方法</span><br><span class=\"line\">func (tab *Table) doRefresh(done chan struct&#123;&#125;) &#123;</span><br><span class=\"line\">  defer close(done)</span><br><span class=\"line\">  ...</span><br><span class=\"line\"></span><br><span class=\"line\">  //通过自己为target去找neighbor，前提是需要自己有secp256k1字段，v4版本的node里是含有secp256k1的，即v4版本是满足这个if条件。load后key中的值为node的公钥</span><br><span class=\"line\">  var key ecdsa.PublicKey</span><br><span class=\"line\">  if err := tab.self.Load((*enode.Secp256k1)(&amp;key)); err == nil &#123;</span><br><span class=\"line\">\ttab.lookup(encodePubkey(&amp;key), false)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">  //⭐️通过随机target去找neighbor。这里的疑问是注释中提到为什么不使用kad本来刷新的方式是因为findnode taget是512bit,这里为什么是512bit? (是因为findnode target是公钥，公钥长度是64byte/512bit) 后半句说不容易生成一个属于所选桶的sha3前镜像，kad本来刷新的方式是选择最近最少使用的桶，所以这里的意思是知道桶了，但是node的ID是经过hash生成的，hash的范围确定，但倒回去找ID就很复杂的意思吗</span><br><span class=\"line\">// The Kademlia paper specifies that the bucket refresh should</span><br><span class=\"line\">// perform a lookup in the least recently used bucket. We cannot</span><br><span class=\"line\">// adhere to this because the findnode target is a 512bit value</span><br><span class=\"line\">// (not hash-sized) and it is not easily possible to generate a</span><br><span class=\"line\">// sha3 preimage that falls into a chosen bucket.</span><br><span class=\"line\">// We perform a few lookups with a random target instead.</span><br><span class=\"line\">  for i := 0; i &lt; 3; i++ &#123;</span><br><span class=\"line\">\t var target encPubkey</span><br><span class=\"line\">\t crand.Read(target[:])</span><br><span class=\"line\">\t tab.lookup(target, false)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//下面看一下关键方法lookup</span><br><span class=\"line\">func (tab *Table) lookup(targetKey encPubkey, refreshIfEmpty bool) []*node &#123;</span><br><span class=\"line\">\tvar (</span><br><span class=\"line\">\t\ttarget         = enode.ID(crypto.Keccak256Hash(targetKey[:]))  //targetid：由公钥进行hash得来</span><br><span class=\"line\">\t\tasked          = make(map[enode.ID]bool)  //保存询问过的节点，以免重复询问</span><br><span class=\"line\">\t\tseen           = make(map[enode.ID]bool)  //保存回复过的节点，防止询问的节点多次回复</span><br><span class=\"line\">\t\treply          = make(chan []*node, alpha) //节点回复的通道，alpha为并发量，每次三个</span><br><span class=\"line\">\t\tpendingQueries = 0   //待定的查询数量，即询问了 但没回复的数量</span><br><span class=\"line\">\t\tresult         *nodesByDistance  //查询结果</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\t//将自己列为询问过的节点</span><br><span class=\"line\">\tasked[tab.self.ID()] = true</span><br><span class=\"line\"></span><br><span class=\"line\">    //将现有的k桶节点们填充到result中</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\ttab.mutex.Lock()</span><br><span class=\"line\">\t\t//从自己的所有桶中找出离target最近的bucketSize个节点</span><br><span class=\"line\">\t\tresult = tab.closest(target, bucketSize)</span><br><span class=\"line\">\t\ttab.mutex.Unlock()</span><br><span class=\"line\">\t\t//如果桶中有节点或者refreshIfEmpty为false，跳出循环</span><br><span class=\"line\">\t\tif len(result.entries) &gt; 0 || !refreshIfEmpty &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//如果k桶中无节点，则请求刷新(doRefresh -&gt; 从种子节点中出发..)</span><br><span class=\"line\">\t\t&lt;-tab.refresh()</span><br><span class=\"line\">\t\t//请求一次刷新，将refreshIfEmpty置为false,防止一直无节点，一直在这里循环，相当于这个for循环最多只执行两次</span><br><span class=\"line\">\t\trefreshIfEmpty = false</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\t//向近的节点询问节点，询问过的就不再询问，并且每次询问的节点数&lt;alpha,即每次只询问最近的alpha个节点。之前一直卡在为什么外层要for循环，难道不是每次问的都是相同的吗？还真的不是..要是相同的话，pendingQueries的值就不会++，这个询问for循环就不会再进行了，然后等回答完毕这个方法就完毕了。之所以桶里的前alpha个会不一样，是因为在后面从reply中读出的为问到的节点们，然后添加到本桶里的时候会影响整个排序，result中的应该是最近的就在前面。所以这个就是不断问到新的节点后，不断查询到离自己比较近的节点。到没有最近的节点后，就不再询问。</span><br><span class=\"line\">\t\tfor i := 0; i &lt; len(result.entries) &amp;&amp; pendingQueries &lt; alpha; i++ &#123;</span><br><span class=\"line\">\t\t\tn := result.entries[i]</span><br><span class=\"line\">\t\t\tif !asked[n.ID()] &#123;</span><br><span class=\"line\">\t\t\t\tasked[n.ID()] = true</span><br><span class=\"line\">\t\t\t\tpendingQueries++</span><br><span class=\"line\">\t\t\t\t//向节点n询问targetKey的节点们</span><br><span class=\"line\">\t\t\t\tgo tab.findnode(n, targetKey, reply)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//所有人都回复了，就不再询问了</span><br><span class=\"line\">\t\tif pendingQueries == 0 &#123;</span><br><span class=\"line\">\t\t\t// we have asked all closest nodes, stop the search</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t//&lt;-reply是最迷惑的，这个是每次从reply中读出一个回复，一个回复为一个节点回复的他的桶节点们，然后range它的桶节点，添加到本桶中</span><br><span class=\"line\">\t\t// wait for the next reply</span><br><span class=\"line\">\t\tfor _, n := range &lt;-reply &#123;</span><br><span class=\"line\">\t\t\tif n != nil &amp;&amp; !seen[n.ID()] &#123;</span><br><span class=\"line\">\t\t\t\tseen[n.ID()] = true</span><br><span class=\"line\">\t\t\t\t//result.push方法，result中数组的长度为bucketSize，且按离target的距离排序，有点像距离最“近”堆排序..</span><br><span class=\"line\">\t\t\t\tresult.push(n, bucketSize)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//有过一次回复，pendingQueries递减</span><br><span class=\"line\">\t\tpendingQueries--</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn result.entries</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//findnode方法</span><br><span class=\"line\">func (tab *Table) findnode(n *node, targetKey encPubkey, reply chan&lt;- []*node) &#123;</span><br><span class=\"line\">\t//从db中读出向n节点查询出错的次数(这个出错次数应该会影响n节点的名誉吧)</span><br><span class=\"line\">\tfails := tab.db.FindFails(n.ID())</span><br><span class=\"line\">\t//调用上层通信向n节点发出查询消息</span><br><span class=\"line\">\tr, err := tab.net.findnode(n.ID(), n.addr(), targetKey)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//这里看着是直接就返回了消息和错误..看样子tab.net.findnode是同步的..</span><br><span class=\"line\">\t//如果返回错误或者节点数量为0，都视为失败，出错次数fails++并更新db。如果fails次数达到一定，则会从tab中删除这个节点</span><br><span class=\"line\">\tif err != nil || len(r) == 0 &#123;</span><br><span class=\"line\">\t\tfails++</span><br><span class=\"line\">\t\ttab.db.UpdateFindFails(n.ID(), fails)</span><br><span class=\"line\">\t\tlog.Trace(&quot;Findnode failed&quot;, &quot;id&quot;, n.ID(), &quot;failcount&quot;, fails, &quot;err&quot;, err)</span><br><span class=\"line\">\t\tif fails &gt;= maxFindnodeFailures &#123;</span><br><span class=\"line\">\t\t\tlog.Trace(&quot;Too many findnode failures, dropping&quot;, &quot;id&quot;, n.ID(), &quot;failcount&quot;, fails)</span><br><span class=\"line\">\t\t\ttab.delete(n)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125; else if fails &gt; 0 &#123;</span><br><span class=\"line\">\t\t//如果这次成功了，以前失败过，则可抵消以前的出错次数</span><br><span class=\"line\">\t\ttab.db.UpdateFindFails(n.ID(), fails-1)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 尽可能添加多个node,尽管他们之中可能有些不在线，但是我们会在revalidation时删除他们</span><br><span class=\"line\">\tfor _, n := range r &#123;</span><br><span class=\"line\">\t\ttab.add(n)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//回复成功</span><br><span class=\"line\">\treply &lt;- r</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>revalidation的代码就不粘贴了，做的事情是，随机一个桶，找出这个桶里最后一个节点，然后向这个节点发出ping，如果这个节点回复了，就把他移到桶的最前方。如果没回复，就这个桶里的当前情况要么删除它要么替换它。</p>\n<p>⭐️其实还是有疑问的，就是虽然桶的index是确定的，但target是随机的，那么每次target随机，各个桶里节点跟target的距离就会不一样，各个桶里的节点是不是会变化很大。</p>\n<p>解: 因为桶里存放的节点的逻辑距离是固定的，又因为每个桶的大小（16）是固定的，只有当桶中有空位时，节点才会被添加进桶。所以我的结论是，桶里节点的变化不会很大，顺序可能会经常变，随机目标是为了查找新的距离自身近的节点（即为了查找前大半部分桶中的节点），再就是为了保持桶的活性（即桶后小半部分桶中的节点）。</p>\n<h5 id=\"udp\"><a href=\"#udp\" class=\"headerlink\" title=\"udp\"></a>udp</h5><p>kad使用udp进行通信。作为tab.net。好玩的是上面的tab.net.findnode如何实现同步的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (t *udp) findnode(toid enode.ID, toaddr *net.UDPAddr, target encPubkey) ([]*node, error) &#123;</span><br><span class=\"line\">   // If we haven&apos;t seen a ping from the destination node for a while, it won&apos;t remember</span><br><span class=\"line\">   // our endpoint proof and reject findnode. Solicit a ping first.</span><br><span class=\"line\">   if time.Since(t.db.LastPingReceived(toid)) &gt; bondExpiration &#123;</span><br><span class=\"line\">      t.ping(toid, toaddr)</span><br><span class=\"line\">      t.waitping(toid)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   nodes := make([]*node, 0, bucketSize)</span><br><span class=\"line\">   nreceived := 0</span><br><span class=\"line\">   errc := t.pending(toid, neighborsPacket, func(r interface&#123;&#125;) bool &#123;</span><br><span class=\"line\">      reply := r.(*neighbors)</span><br><span class=\"line\">      for _, rn := range reply.Nodes &#123;</span><br><span class=\"line\">         nreceived++</span><br><span class=\"line\">         n, err := t.nodeFromRPC(toaddr, rn)</span><br><span class=\"line\">         if err != nil &#123;</span><br><span class=\"line\">            log.Trace(&quot;Invalid neighbor node received&quot;, &quot;ip&quot;, rn.IP, &quot;addr&quot;, toaddr, &quot;err&quot;, err)</span><br><span class=\"line\">            continue</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">         nodes = append(nodes, n)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      return nreceived &gt;= bucketSize</span><br><span class=\"line\">   &#125;)</span><br><span class=\"line\">   t.send(toaddr, findnodePacket, &amp;findnode&#123;</span><br><span class=\"line\">      Target:     target,</span><br><span class=\"line\">      Expiration: uint64(time.Now().Add(expiration).Unix()),</span><br><span class=\"line\">   &#125;)</span><br><span class=\"line\">   return nodes, &lt;-errc</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上面可以看到findnode是发出了一个findnode包，然后等回复会回调pending的callback。但这个方法确实是同步的，就是说返回的话，就说明收到了回复，callback也回调了。是怎么做到的呢。真的很好玩，利用了errc通道。就是最后一句<code>return nodes, &lt;-errc</code>，只有errc通道读出消息来，才会返回数据，这也是callback设计的精妙之处吧。这么设计真的是精妙，get到了。</p>\n<p>udp处理的工作主要是进行通信。通信类型有两组，(发ping - 回pong)、(发findnode - 回neighbors)</p>\n"},{"title":"eth_rlp","date":"2019-10-14T06:48:31.000Z","_content":"#### 序列化 RLP\n\n#### 编码\n\n对象序列化的方式有很多，如json编码，如\n\n```\ntype Student struct{\n    Name string `json:\"name\"`\n    Sex string `json:\"sex\"`\n}\ns := Student{Name:\"icattlecoder\",Sex:\"male\"}\nbs,_ := json.Marsal(&s)\n\n```\n\n但编码的结果为`{\"name\":\"icattlecoder\",\"sex\":\"male\"}`,实际有效数据是icattlecoder和male，共计16个字节，可以看到json序列化时引入了太多的冗余信息，所以，以太坊设计了结果更小的编码方式—— RLP编码\n\n\n\n> RLP的全称为Recursive Length Prefix，中文翻译过来叫递归长度前缀编码，它是以太坊序列化所采用的编码方式。RLP主要用于以太坊中数据的网络传输和持久化存储。\n\n\n\nRLP实际只给以下两种类型数据编码：\n\n- byte数组\n- byte数组的数组，称之为列表\n\n**规则1**：对于值在[0, 127]之间的单个字节，其编码是其本身。\n\n例1：`a`的编码是`97`。\n\n**规则2**：如果byte数组长度`l <= 55`，编码的结果是数组本身，再加上`128+l`作为前缀。\n\n例2：空字符串编码是`128`，即`128 = 128 + 0`。\n\n例3：`abc`编码结果是`131 97 98 99`，其中`131=128+len(\"abc\")`，`97 98 99`依次是`a b c`。\n\n**规则3**：如果数组长度大于55， 编码结果第一个是183加数组长度的编码的长度，然后是数组长度的本身的编码，最后是byte数组的编码。\n\n呃，大于55是第一个是183+ 数组长度**编码**的长度，第二位才是长度的编码\n\n如编码下面这段字符串：\n\n```\nThe length of this sentence is more than 55 bytes, I know it because I pre-designed it\n```\n\n这段字符串共86个字节，而86的编码只需要一个字节，那就是它自己，因此，编码的结果如下：\n\n```\n184 86 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110 116101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101 11544 32 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114 101 45 100101 115 105 103 110 101 100 32 105 116\n```\n\n其中前三个字节的计算方式如下：\n\n1. `184 = 183 + 1`，因为数组长度`86`编码后仅占用一个字节。\n2. `86`即数组长度`86`\n3. `84`是`T`的编码\n\n\n\n编码一个重复1024次\"a\"的字符串，其结果为：`185 4 0 97 97 97 97 97 97 ...`。\n1024按 big endian编码为`0　0　4 0`，省略掉前面的零，长度为2，因此`185 = 183 + 2`。\n\n规则1~3定义了byte数组的编码方案，下面介绍列表的编码规则。在此之前，我们先定义**列表长度**是指子列表编码后的长度之和。\n\n\n\n**规则4**：如果列表长度小于55，编码结果第一位是192加列表长度的编码的长度，然后依次连接各子列表的编码。\n\n注意规则4本身是递归定义的。\n例6：`[\"abc\", \"def\"]`的编码结果是`200 131 97 98 99 131 100 101 102`。\n其中`abc`的编码为`131 97 98 99`,`def`的编码为`131 100 101 102`。两个子字符串的编码后总长度是8，因此编码结果第一位计算得出：`192 + 8 = 200`\n\n\n\n**规则5**：如果列表长度超过55，编码结果第一位是247加列表长度的编码长度，然后是列表长度本身的编码，最后依次连接各子列表的编码。\n\n规则5本身也是递归定义的，和规则3相似。\n\n例7：\n\n```\n[\"The length of this sentence is more than 55 bytes, \", \"I know it because I pre-designed it\"]\n```\n\n的编码结果是:\n\n```\n248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114101 45 100 101 115 105 103 110 101 100 32 105 116\n```\n\n其中前两个字节的计算方式如下：\n\n1. `248 = 247 +1`\n2. `88 = 86 + 2`，在**规则3**的示例中，长度为`86`，而在此例中，由于有两个子字符串，每个子字符串本身的长度的编码各占1字节，因此总共占2字节。\n   第3个字节`179`依据**规则2**得出`179 = 128 + 51`\n\n第55个字节`163`同样依据**规则2**得出`163 = 128 + 35`\n\n\n\n例8：最后我们再来看个稍复杂点的例子以加深理解**递归**长度前缀，\n\n```\n[\"abc\",[\"The length of this sentence is more than 55 bytes, \", \"I know it because I pre-designed it\"]]\n```\n\n编码结果是：\n\n```\n248 94 131 97 98 99 248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105115 32 115 101 110 116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 5332 98 121 116 101 115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 10132 73 32 112 114 101 45 100 101 115 105 103 110 101 100 32 105 116\n```\n\n列表第一项字符串`abc`根据**规则2**，编码结果为`131 97 98 99`,长度为4。\n列表第二项也是一个列表项：\n\n```\n[\"The length of this sentence is more than 55 bytes, \", \"I know it because I pre-designed it\"]\n```\n\n根据**规则5**，结果为\n\n```\n248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114101 45 100 101 115 105 103 110 101 100 32 105 116\n```\n\n长度为90，因此，整个列表的编码结果第二位是`90 + 4 = 94`, 占用1个字节，第一位`247 + 1 = 248`\n\n以上5条就是RPL的全部编码规则。\n\n\n\n#### 解码\n\n解码时，首先根据编码结果第一个字节`f`的大小，执行以下的规则判断：\n\n1. 如果f∈ [0,128),　那么它是一个字节本身。\n2. 如果f∈[128,184)，那么它是一个长度不超过55的byte数组，数组的长度为 `l=f-128`\n3. 如果f∈[184,192)，那么它是一个长度超过55的数组，长度本身的编码长度`ll=f-183`,然后从第二个字节开始读取长度为ll的bytes，按照BigEndian编码成整数l，l即为数组的长度。\n4. 如果f∈(192,247]，那么它是一个编码后总长度不超过55的列表，列表长度为`l=f-192`。递归使用规则1~4进行解码。\n5. 如果f∈(247,256]，那么它是编码后长度大于55的列表，其长度本身的编码长度`ll=f-247`,然后从第二个字节读取长度为ll的bytes,按BigEndian编码成整数l，l即为子列表长度。然后递归根据解码规则进行解码。\n\n\n\n#### 代码实现\n\n语言在具体实现RLP编码时，首先需要将对像映射成byte数组或列表两种形式。以go语言编码struct为例，会将其映射为列表，例如`Student`这个对象处理成列表`[\"icattlecoder\",\"male\"]`\n\n```\ntype Student struct{\n    Name string\n    Sex string\n}\ns := Student{Name:\"icattlecoder\",Sex:\"male\"}\nbuff := bytes.Buffer{}\nrpl.Encode(&buff, &s)\nprint(buff.Bytes())\n// [210 140 105 99 97 116 116 108 101 99 111 100 101 114 132 109 97 108 101]\n```\n\n如果编码map类型，可以采用以下列表形式：\n\n```\n[[\"\",\"\"],[\"\",\"\"],[\"\",\"\"]]\n```\n\n\n\n##### 代码学习收获\n\n- bytes.Buffer\n\n  在需要字符拼接频繁时，可使用Buffer\n\n  buffer是一个变长的 bytes，具有 Read 和Write 方法。 Buffer 的 零值 是一个 空的 buffer，但是可以使用。\n  Buffer 就像一个集装箱容器，可以存东西，取东西（存取数据）\n\n  ```\n  b1 := new(bytes.Buffer)\n  b1.Write([]byte(\"asd\"))\n  b1.Bytes() --> asd\n  ```\n\n  在字符串倒来倒去的时候，或者是变长时候，Go中可以使用“+”合并字符串，但是这种合并方式效率非常低，**每合并一次，都是创建一个新的字符串,就必须遍历复制一次字符串**，在Java中会选择使用StringBuilder, 在go中，类似的方法就是bytes.Buffer(线程不安全)。\n\n\n\n- sync.Pool\n\n  对象池。创建的时候可以指定一个New函数，获取对象的时候如何在池里面找不到缓存的对象将会使用指定的new函数创建一个返回\n\n  它的用途仅仅是增加对象重用的几率，减少gc的负担，而开销方面也不是很便宜的\n\n- 接口函数\n\n  在oo中，实现方法的多态，需要多个子类。在go中，使用接口函数即可实现类似功能，而且非常简便\n\n  ```\n  type print func()\n  type A struct {\n  \tprint\n  }\n  func printString() {\n  \tfmt.Println(\"I am a string...\")\n  }\n  func printInt() {\n  \tfmt.Println(\"123456\")\n  }\n  func TestA_SetPrint(t *testing.T) {\n  \ta := &A{}\n  \ta.SetPrint(printString)\n  \ta.print()\n  \t//I am a string...\n  }\n  //还是很像多态，只是将方法print作为父，其余printString、printInt都是子，调用的时候调用指向子的引用。\n  ```\n\n\n\n  \n","source":"_posts/eth-rlp.md","raw":"---\ntitle: eth_rlp\ncategories:\n  - eth\ndate: 2019-10-14 14:48:31\ntags:\n---\n#### 序列化 RLP\n\n#### 编码\n\n对象序列化的方式有很多，如json编码，如\n\n```\ntype Student struct{\n    Name string `json:\"name\"`\n    Sex string `json:\"sex\"`\n}\ns := Student{Name:\"icattlecoder\",Sex:\"male\"}\nbs,_ := json.Marsal(&s)\n\n```\n\n但编码的结果为`{\"name\":\"icattlecoder\",\"sex\":\"male\"}`,实际有效数据是icattlecoder和male，共计16个字节，可以看到json序列化时引入了太多的冗余信息，所以，以太坊设计了结果更小的编码方式—— RLP编码\n\n\n\n> RLP的全称为Recursive Length Prefix，中文翻译过来叫递归长度前缀编码，它是以太坊序列化所采用的编码方式。RLP主要用于以太坊中数据的网络传输和持久化存储。\n\n\n\nRLP实际只给以下两种类型数据编码：\n\n- byte数组\n- byte数组的数组，称之为列表\n\n**规则1**：对于值在[0, 127]之间的单个字节，其编码是其本身。\n\n例1：`a`的编码是`97`。\n\n**规则2**：如果byte数组长度`l <= 55`，编码的结果是数组本身，再加上`128+l`作为前缀。\n\n例2：空字符串编码是`128`，即`128 = 128 + 0`。\n\n例3：`abc`编码结果是`131 97 98 99`，其中`131=128+len(\"abc\")`，`97 98 99`依次是`a b c`。\n\n**规则3**：如果数组长度大于55， 编码结果第一个是183加数组长度的编码的长度，然后是数组长度的本身的编码，最后是byte数组的编码。\n\n呃，大于55是第一个是183+ 数组长度**编码**的长度，第二位才是长度的编码\n\n如编码下面这段字符串：\n\n```\nThe length of this sentence is more than 55 bytes, I know it because I pre-designed it\n```\n\n这段字符串共86个字节，而86的编码只需要一个字节，那就是它自己，因此，编码的结果如下：\n\n```\n184 86 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110 116101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101 11544 32 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114 101 45 100101 115 105 103 110 101 100 32 105 116\n```\n\n其中前三个字节的计算方式如下：\n\n1. `184 = 183 + 1`，因为数组长度`86`编码后仅占用一个字节。\n2. `86`即数组长度`86`\n3. `84`是`T`的编码\n\n\n\n编码一个重复1024次\"a\"的字符串，其结果为：`185 4 0 97 97 97 97 97 97 ...`。\n1024按 big endian编码为`0　0　4 0`，省略掉前面的零，长度为2，因此`185 = 183 + 2`。\n\n规则1~3定义了byte数组的编码方案，下面介绍列表的编码规则。在此之前，我们先定义**列表长度**是指子列表编码后的长度之和。\n\n\n\n**规则4**：如果列表长度小于55，编码结果第一位是192加列表长度的编码的长度，然后依次连接各子列表的编码。\n\n注意规则4本身是递归定义的。\n例6：`[\"abc\", \"def\"]`的编码结果是`200 131 97 98 99 131 100 101 102`。\n其中`abc`的编码为`131 97 98 99`,`def`的编码为`131 100 101 102`。两个子字符串的编码后总长度是8，因此编码结果第一位计算得出：`192 + 8 = 200`\n\n\n\n**规则5**：如果列表长度超过55，编码结果第一位是247加列表长度的编码长度，然后是列表长度本身的编码，最后依次连接各子列表的编码。\n\n规则5本身也是递归定义的，和规则3相似。\n\n例7：\n\n```\n[\"The length of this sentence is more than 55 bytes, \", \"I know it because I pre-designed it\"]\n```\n\n的编码结果是:\n\n```\n248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114101 45 100 101 115 105 103 110 101 100 32 105 116\n```\n\n其中前两个字节的计算方式如下：\n\n1. `248 = 247 +1`\n2. `88 = 86 + 2`，在**规则3**的示例中，长度为`86`，而在此例中，由于有两个子字符串，每个子字符串本身的长度的编码各占1字节，因此总共占2字节。\n   第3个字节`179`依据**规则2**得出`179 = 128 + 51`\n\n第55个字节`163`同样依据**规则2**得出`163 = 128 + 35`\n\n\n\n例8：最后我们再来看个稍复杂点的例子以加深理解**递归**长度前缀，\n\n```\n[\"abc\",[\"The length of this sentence is more than 55 bytes, \", \"I know it because I pre-designed it\"]]\n```\n\n编码结果是：\n\n```\n248 94 131 97 98 99 248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105115 32 115 101 110 116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 5332 98 121 116 101 115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 10132 73 32 112 114 101 45 100 101 115 105 103 110 101 100 32 105 116\n```\n\n列表第一项字符串`abc`根据**规则2**，编码结果为`131 97 98 99`,长度为4。\n列表第二项也是一个列表项：\n\n```\n[\"The length of this sentence is more than 55 bytes, \", \"I know it because I pre-designed it\"]\n```\n\n根据**规则5**，结果为\n\n```\n248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114101 45 100 101 115 105 103 110 101 100 32 105 116\n```\n\n长度为90，因此，整个列表的编码结果第二位是`90 + 4 = 94`, 占用1个字节，第一位`247 + 1 = 248`\n\n以上5条就是RPL的全部编码规则。\n\n\n\n#### 解码\n\n解码时，首先根据编码结果第一个字节`f`的大小，执行以下的规则判断：\n\n1. 如果f∈ [0,128),　那么它是一个字节本身。\n2. 如果f∈[128,184)，那么它是一个长度不超过55的byte数组，数组的长度为 `l=f-128`\n3. 如果f∈[184,192)，那么它是一个长度超过55的数组，长度本身的编码长度`ll=f-183`,然后从第二个字节开始读取长度为ll的bytes，按照BigEndian编码成整数l，l即为数组的长度。\n4. 如果f∈(192,247]，那么它是一个编码后总长度不超过55的列表，列表长度为`l=f-192`。递归使用规则1~4进行解码。\n5. 如果f∈(247,256]，那么它是编码后长度大于55的列表，其长度本身的编码长度`ll=f-247`,然后从第二个字节读取长度为ll的bytes,按BigEndian编码成整数l，l即为子列表长度。然后递归根据解码规则进行解码。\n\n\n\n#### 代码实现\n\n语言在具体实现RLP编码时，首先需要将对像映射成byte数组或列表两种形式。以go语言编码struct为例，会将其映射为列表，例如`Student`这个对象处理成列表`[\"icattlecoder\",\"male\"]`\n\n```\ntype Student struct{\n    Name string\n    Sex string\n}\ns := Student{Name:\"icattlecoder\",Sex:\"male\"}\nbuff := bytes.Buffer{}\nrpl.Encode(&buff, &s)\nprint(buff.Bytes())\n// [210 140 105 99 97 116 116 108 101 99 111 100 101 114 132 109 97 108 101]\n```\n\n如果编码map类型，可以采用以下列表形式：\n\n```\n[[\"\",\"\"],[\"\",\"\"],[\"\",\"\"]]\n```\n\n\n\n##### 代码学习收获\n\n- bytes.Buffer\n\n  在需要字符拼接频繁时，可使用Buffer\n\n  buffer是一个变长的 bytes，具有 Read 和Write 方法。 Buffer 的 零值 是一个 空的 buffer，但是可以使用。\n  Buffer 就像一个集装箱容器，可以存东西，取东西（存取数据）\n\n  ```\n  b1 := new(bytes.Buffer)\n  b1.Write([]byte(\"asd\"))\n  b1.Bytes() --> asd\n  ```\n\n  在字符串倒来倒去的时候，或者是变长时候，Go中可以使用“+”合并字符串，但是这种合并方式效率非常低，**每合并一次，都是创建一个新的字符串,就必须遍历复制一次字符串**，在Java中会选择使用StringBuilder, 在go中，类似的方法就是bytes.Buffer(线程不安全)。\n\n\n\n- sync.Pool\n\n  对象池。创建的时候可以指定一个New函数，获取对象的时候如何在池里面找不到缓存的对象将会使用指定的new函数创建一个返回\n\n  它的用途仅仅是增加对象重用的几率，减少gc的负担，而开销方面也不是很便宜的\n\n- 接口函数\n\n  在oo中，实现方法的多态，需要多个子类。在go中，使用接口函数即可实现类似功能，而且非常简便\n\n  ```\n  type print func()\n  type A struct {\n  \tprint\n  }\n  func printString() {\n  \tfmt.Println(\"I am a string...\")\n  }\n  func printInt() {\n  \tfmt.Println(\"123456\")\n  }\n  func TestA_SetPrint(t *testing.T) {\n  \ta := &A{}\n  \ta.SetPrint(printString)\n  \ta.print()\n  \t//I am a string...\n  }\n  //还是很像多态，只是将方法print作为父，其余printString、printInt都是子，调用的时候调用指向子的引用。\n  ```\n\n\n\n  \n","slug":"eth-rlp","published":1,"updated":"2019-10-14T06:48:50.308Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69x3002at6xviyz6j1kt","content":"<h4 id=\"序列化-RLP\"><a href=\"#序列化-RLP\" class=\"headerlink\" title=\"序列化 RLP\"></a>序列化 RLP</h4><h4 id=\"编码\"><a href=\"#编码\" class=\"headerlink\" title=\"编码\"></a>编码</h4><p>对象序列化的方式有很多，如json编码，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Student struct&#123;</span><br><span class=\"line\">    Name string `json:&quot;name&quot;`</span><br><span class=\"line\">    Sex string `json:&quot;sex&quot;`</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">s := Student&#123;Name:&quot;icattlecoder&quot;,Sex:&quot;male&quot;&#125;</span><br><span class=\"line\">bs,_ := json.Marsal(&amp;s)</span><br></pre></td></tr></table></figure>\n\n<p>但编码的结果为<code>{&quot;name&quot;:&quot;icattlecoder&quot;,&quot;sex&quot;:&quot;male&quot;}</code>,实际有效数据是icattlecoder和male，共计16个字节，可以看到json序列化时引入了太多的冗余信息，所以，以太坊设计了结果更小的编码方式—— RLP编码</p>\n<blockquote>\n<p>RLP的全称为Recursive Length Prefix，中文翻译过来叫递归长度前缀编码，它是以太坊序列化所采用的编码方式。RLP主要用于以太坊中数据的网络传输和持久化存储。</p>\n</blockquote>\n<p>RLP实际只给以下两种类型数据编码：</p>\n<ul>\n<li>byte数组</li>\n<li>byte数组的数组，称之为列表</li>\n</ul>\n<p><strong>规则1</strong>：对于值在[0, 127]之间的单个字节，其编码是其本身。</p>\n<p>例1：<code>a</code>的编码是<code>97</code>。</p>\n<p><strong>规则2</strong>：如果byte数组长度<code>l &lt;= 55</code>，编码的结果是数组本身，再加上<code>128+l</code>作为前缀。</p>\n<p>例2：空字符串编码是<code>128</code>，即<code>128 = 128 + 0</code>。</p>\n<p>例3：<code>abc</code>编码结果是<code>131 97 98 99</code>，其中<code>131=128+len(&quot;abc&quot;)</code>，<code>97 98 99</code>依次是<code>a b c</code>。</p>\n<p><strong>规则3</strong>：如果数组长度大于55， 编码结果第一个是183加数组长度的编码的长度，然后是数组长度的本身的编码，最后是byte数组的编码。</p>\n<p>呃，大于55是第一个是183+ 数组长度<strong>编码</strong>的长度，第二位才是长度的编码</p>\n<p>如编码下面这段字符串：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">The length of this sentence is more than 55 bytes, I know it because I pre-designed it</span><br></pre></td></tr></table></figure>\n\n<p>这段字符串共86个字节，而86的编码只需要一个字节，那就是它自己，因此，编码的结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">184 86 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110 116101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101 11544 32 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114 101 45 100101 115 105 103 110 101 100 32 105 116</span><br></pre></td></tr></table></figure>\n\n<p>其中前三个字节的计算方式如下：</p>\n<ol>\n<li><code>184 = 183 + 1</code>，因为数组长度<code>86</code>编码后仅占用一个字节。</li>\n<li><code>86</code>即数组长度<code>86</code></li>\n<li><code>84</code>是<code>T</code>的编码</li>\n</ol>\n<p>编码一个重复1024次”a”的字符串，其结果为：<code>185 4 0 97 97 97 97 97 97 ...</code>。<br>1024按 big endian编码为<code>0　0　4 0</code>，省略掉前面的零，长度为2，因此<code>185 = 183 + 2</code>。</p>\n<p>规则1~3定义了byte数组的编码方案，下面介绍列表的编码规则。在此之前，我们先定义<strong>列表长度</strong>是指子列表编码后的长度之和。</p>\n<p><strong>规则4</strong>：如果列表长度小于55，编码结果第一位是192加列表长度的编码的长度，然后依次连接各子列表的编码。</p>\n<p>注意规则4本身是递归定义的。<br>例6：<code>[&quot;abc&quot;, &quot;def&quot;]</code>的编码结果是<code>200 131 97 98 99 131 100 101 102</code>。<br>其中<code>abc</code>的编码为<code>131 97 98 99</code>,<code>def</code>的编码为<code>131 100 101 102</code>。两个子字符串的编码后总长度是8，因此编码结果第一位计算得出：<code>192 + 8 = 200</code></p>\n<p><strong>规则5</strong>：如果列表长度超过55，编码结果第一位是247加列表长度的编码长度，然后是列表长度本身的编码，最后依次连接各子列表的编码。</p>\n<p>规则5本身也是递归定义的，和规则3相似。</p>\n<p>例7：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&quot;The length of this sentence is more than 55 bytes, &quot;, &quot;I know it because I pre-designed it&quot;]</span><br></pre></td></tr></table></figure>\n\n<p>的编码结果是:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114101 45 100 101 115 105 103 110 101 100 32 105 116</span><br></pre></td></tr></table></figure>\n\n<p>其中前两个字节的计算方式如下：</p>\n<ol>\n<li><code>248 = 247 +1</code></li>\n<li><code>88 = 86 + 2</code>，在<strong>规则3</strong>的示例中，长度为<code>86</code>，而在此例中，由于有两个子字符串，每个子字符串本身的长度的编码各占1字节，因此总共占2字节。<br>第3个字节<code>179</code>依据<strong>规则2</strong>得出<code>179 = 128 + 51</code></li>\n</ol>\n<p>第55个字节<code>163</code>同样依据<strong>规则2</strong>得出<code>163 = 128 + 35</code></p>\n<p>例8：最后我们再来看个稍复杂点的例子以加深理解<strong>递归</strong>长度前缀，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&quot;abc&quot;,[&quot;The length of this sentence is more than 55 bytes, &quot;, &quot;I know it because I pre-designed it&quot;]]</span><br></pre></td></tr></table></figure>\n\n<p>编码结果是：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">248 94 131 97 98 99 248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105115 32 115 101 110 116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 5332 98 121 116 101 115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 10132 73 32 112 114 101 45 100 101 115 105 103 110 101 100 32 105 116</span><br></pre></td></tr></table></figure>\n\n<p>列表第一项字符串<code>abc</code>根据<strong>规则2</strong>，编码结果为<code>131 97 98 99</code>,长度为4。<br>列表第二项也是一个列表项：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&quot;The length of this sentence is more than 55 bytes, &quot;, &quot;I know it because I pre-designed it&quot;]</span><br></pre></td></tr></table></figure>\n\n<p>根据<strong>规则5</strong>，结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114101 45 100 101 115 105 103 110 101 100 32 105 116</span><br></pre></td></tr></table></figure>\n\n<p>长度为90，因此，整个列表的编码结果第二位是<code>90 + 4 = 94</code>, 占用1个字节，第一位<code>247 + 1 = 248</code></p>\n<p>以上5条就是RPL的全部编码规则。</p>\n<h4 id=\"解码\"><a href=\"#解码\" class=\"headerlink\" title=\"解码\"></a>解码</h4><p>解码时，首先根据编码结果第一个字节<code>f</code>的大小，执行以下的规则判断：</p>\n<ol>\n<li>如果f∈ [0,128),　那么它是一个字节本身。</li>\n<li>如果f∈[128,184)，那么它是一个长度不超过55的byte数组，数组的长度为 <code>l=f-128</code></li>\n<li>如果f∈[184,192)，那么它是一个长度超过55的数组，长度本身的编码长度<code>ll=f-183</code>,然后从第二个字节开始读取长度为ll的bytes，按照BigEndian编码成整数l，l即为数组的长度。</li>\n<li>如果f∈(192,247]，那么它是一个编码后总长度不超过55的列表，列表长度为<code>l=f-192</code>。递归使用规则1~4进行解码。</li>\n<li>如果f∈(247,256]，那么它是编码后长度大于55的列表，其长度本身的编码长度<code>ll=f-247</code>,然后从第二个字节读取长度为ll的bytes,按BigEndian编码成整数l，l即为子列表长度。然后递归根据解码规则进行解码。</li>\n</ol>\n<h4 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h4><p>语言在具体实现RLP编码时，首先需要将对像映射成byte数组或列表两种形式。以go语言编码struct为例，会将其映射为列表，例如<code>Student</code>这个对象处理成列表<code>[&quot;icattlecoder&quot;,&quot;male&quot;]</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Student struct&#123;</span><br><span class=\"line\">    Name string</span><br><span class=\"line\">    Sex string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">s := Student&#123;Name:&quot;icattlecoder&quot;,Sex:&quot;male&quot;&#125;</span><br><span class=\"line\">buff := bytes.Buffer&#123;&#125;</span><br><span class=\"line\">rpl.Encode(&amp;buff, &amp;s)</span><br><span class=\"line\">print(buff.Bytes())</span><br><span class=\"line\">// [210 140 105 99 97 116 116 108 101 99 111 100 101 114 132 109 97 108 101]</span><br></pre></td></tr></table></figure>\n\n<p>如果编码map类型，可以采用以下列表形式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[[&quot;&quot;,&quot;&quot;],[&quot;&quot;,&quot;&quot;],[&quot;&quot;,&quot;&quot;]]</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"代码学习收获\"><a href=\"#代码学习收获\" class=\"headerlink\" title=\"代码学习收获\"></a>代码学习收获</h5><ul>\n<li><p>bytes.Buffer</p>\n<p>在需要字符拼接频繁时，可使用Buffer</p>\n<p>buffer是一个变长的 bytes，具有 Read 和Write 方法。 Buffer 的 零值 是一个 空的 buffer，但是可以使用。<br>Buffer 就像一个集装箱容器，可以存东西，取东西（存取数据）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b1 := new(bytes.Buffer)</span><br><span class=\"line\">b1.Write([]byte(&quot;asd&quot;))</span><br><span class=\"line\">b1.Bytes() --&gt; asd</span><br></pre></td></tr></table></figure>\n\n<p>在字符串倒来倒去的时候，或者是变长时候，Go中可以使用“+”合并字符串，但是这种合并方式效率非常低，<strong>每合并一次，都是创建一个新的字符串,就必须遍历复制一次字符串</strong>，在Java中会选择使用StringBuilder, 在go中，类似的方法就是bytes.Buffer(线程不安全)。</p>\n</li>\n</ul>\n<ul>\n<li><p>sync.Pool</p>\n<p>对象池。创建的时候可以指定一个New函数，获取对象的时候如何在池里面找不到缓存的对象将会使用指定的new函数创建一个返回</p>\n<p>它的用途仅仅是增加对象重用的几率，减少gc的负担，而开销方面也不是很便宜的</p>\n</li>\n<li><p>接口函数</p>\n<p>在oo中，实现方法的多态，需要多个子类。在go中，使用接口函数即可实现类似功能，而且非常简便</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type print func()</span><br><span class=\"line\">type A struct &#123;</span><br><span class=\"line\">\tprint</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func printString() &#123;</span><br><span class=\"line\">\tfmt.Println(&quot;I am a string...&quot;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func printInt() &#123;</span><br><span class=\"line\">\tfmt.Println(&quot;123456&quot;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func TestA_SetPrint(t *testing.T) &#123;</span><br><span class=\"line\">\ta := &amp;A&#123;&#125;</span><br><span class=\"line\">\ta.SetPrint(printString)</span><br><span class=\"line\">\ta.print()</span><br><span class=\"line\">\t//I am a string...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//还是很像多态，只是将方法print作为父，其余printString、printInt都是子，调用的时候调用指向子的引用。</span><br></pre></td></tr></table></figure>\n\n\n</li>\n</ul>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h4 id=\"序列化-RLP\"><a href=\"#序列化-RLP\" class=\"headerlink\" title=\"序列化 RLP\"></a>序列化 RLP</h4><h4 id=\"编码\"><a href=\"#编码\" class=\"headerlink\" title=\"编码\"></a>编码</h4><p>对象序列化的方式有很多，如json编码，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Student struct&#123;</span><br><span class=\"line\">    Name string `json:&quot;name&quot;`</span><br><span class=\"line\">    Sex string `json:&quot;sex&quot;`</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">s := Student&#123;Name:&quot;icattlecoder&quot;,Sex:&quot;male&quot;&#125;</span><br><span class=\"line\">bs,_ := json.Marsal(&amp;s)</span><br></pre></td></tr></table></figure>\n\n<p>但编码的结果为<code>{&quot;name&quot;:&quot;icattlecoder&quot;,&quot;sex&quot;:&quot;male&quot;}</code>,实际有效数据是icattlecoder和male，共计16个字节，可以看到json序列化时引入了太多的冗余信息，所以，以太坊设计了结果更小的编码方式—— RLP编码</p>\n<blockquote>\n<p>RLP的全称为Recursive Length Prefix，中文翻译过来叫递归长度前缀编码，它是以太坊序列化所采用的编码方式。RLP主要用于以太坊中数据的网络传输和持久化存储。</p>\n</blockquote>\n<p>RLP实际只给以下两种类型数据编码：</p>\n<ul>\n<li>byte数组</li>\n<li>byte数组的数组，称之为列表</li>\n</ul>\n<p><strong>规则1</strong>：对于值在[0, 127]之间的单个字节，其编码是其本身。</p>\n<p>例1：<code>a</code>的编码是<code>97</code>。</p>\n<p><strong>规则2</strong>：如果byte数组长度<code>l &lt;= 55</code>，编码的结果是数组本身，再加上<code>128+l</code>作为前缀。</p>\n<p>例2：空字符串编码是<code>128</code>，即<code>128 = 128 + 0</code>。</p>\n<p>例3：<code>abc</code>编码结果是<code>131 97 98 99</code>，其中<code>131=128+len(&quot;abc&quot;)</code>，<code>97 98 99</code>依次是<code>a b c</code>。</p>\n<p><strong>规则3</strong>：如果数组长度大于55， 编码结果第一个是183加数组长度的编码的长度，然后是数组长度的本身的编码，最后是byte数组的编码。</p>\n<p>呃，大于55是第一个是183+ 数组长度<strong>编码</strong>的长度，第二位才是长度的编码</p>\n<p>如编码下面这段字符串：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">The length of this sentence is more than 55 bytes, I know it because I pre-designed it</span><br></pre></td></tr></table></figure>\n\n<p>这段字符串共86个字节，而86的编码只需要一个字节，那就是它自己，因此，编码的结果如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">184 86 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110 116101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101 11544 32 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114 101 45 100101 115 105 103 110 101 100 32 105 116</span><br></pre></td></tr></table></figure>\n\n<p>其中前三个字节的计算方式如下：</p>\n<ol>\n<li><code>184 = 183 + 1</code>，因为数组长度<code>86</code>编码后仅占用一个字节。</li>\n<li><code>86</code>即数组长度<code>86</code></li>\n<li><code>84</code>是<code>T</code>的编码</li>\n</ol>\n<p>编码一个重复1024次”a”的字符串，其结果为：<code>185 4 0 97 97 97 97 97 97 ...</code>。<br>1024按 big endian编码为<code>0　0　4 0</code>，省略掉前面的零，长度为2，因此<code>185 = 183 + 2</code>。</p>\n<p>规则1~3定义了byte数组的编码方案，下面介绍列表的编码规则。在此之前，我们先定义<strong>列表长度</strong>是指子列表编码后的长度之和。</p>\n<p><strong>规则4</strong>：如果列表长度小于55，编码结果第一位是192加列表长度的编码的长度，然后依次连接各子列表的编码。</p>\n<p>注意规则4本身是递归定义的。<br>例6：<code>[&quot;abc&quot;, &quot;def&quot;]</code>的编码结果是<code>200 131 97 98 99 131 100 101 102</code>。<br>其中<code>abc</code>的编码为<code>131 97 98 99</code>,<code>def</code>的编码为<code>131 100 101 102</code>。两个子字符串的编码后总长度是8，因此编码结果第一位计算得出：<code>192 + 8 = 200</code></p>\n<p><strong>规则5</strong>：如果列表长度超过55，编码结果第一位是247加列表长度的编码长度，然后是列表长度本身的编码，最后依次连接各子列表的编码。</p>\n<p>规则5本身也是递归定义的，和规则3相似。</p>\n<p>例7：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&quot;The length of this sentence is more than 55 bytes, &quot;, &quot;I know it because I pre-designed it&quot;]</span><br></pre></td></tr></table></figure>\n\n<p>的编码结果是:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114101 45 100 101 115 105 103 110 101 100 32 105 116</span><br></pre></td></tr></table></figure>\n\n<p>其中前两个字节的计算方式如下：</p>\n<ol>\n<li><code>248 = 247 +1</code></li>\n<li><code>88 = 86 + 2</code>，在<strong>规则3</strong>的示例中，长度为<code>86</code>，而在此例中，由于有两个子字符串，每个子字符串本身的长度的编码各占1字节，因此总共占2字节。<br>第3个字节<code>179</code>依据<strong>规则2</strong>得出<code>179 = 128 + 51</code></li>\n</ol>\n<p>第55个字节<code>163</code>同样依据<strong>规则2</strong>得出<code>163 = 128 + 35</code></p>\n<p>例8：最后我们再来看个稍复杂点的例子以加深理解<strong>递归</strong>长度前缀，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&quot;abc&quot;,[&quot;The length of this sentence is more than 55 bytes, &quot;, &quot;I know it because I pre-designed it&quot;]]</span><br></pre></td></tr></table></figure>\n\n<p>编码结果是：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">248 94 131 97 98 99 248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105115 32 115 101 110 116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 5332 98 121 116 101 115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 10132 73 32 112 114 101 45 100 101 115 105 103 110 101 100 32 105 116</span><br></pre></td></tr></table></figure>\n\n<p>列表第一项字符串<code>abc</code>根据<strong>规则2</strong>，编码结果为<code>131 97 98 99</code>,长度为4。<br>列表第二项也是一个列表项：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&quot;The length of this sentence is more than 55 bytes, &quot;, &quot;I know it because I pre-designed it&quot;]</span><br></pre></td></tr></table></figure>\n\n<p>根据<strong>规则5</strong>，结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">248 88 179 84 104 101 32 108 101 110 103 116 104 32 111 102 32 116 104 105 115 32 115 101 110116 101 110 99 101 32 105 115 32 109 111 114 101 32 116 104 97 110 32 53 53 32 98 121 116 101115 44 32 163 73 32 107 110 111 119 32 105 116 32 98 101 99 97 117 115 101 32 73 32 112 114101 45 100 101 115 105 103 110 101 100 32 105 116</span><br></pre></td></tr></table></figure>\n\n<p>长度为90，因此，整个列表的编码结果第二位是<code>90 + 4 = 94</code>, 占用1个字节，第一位<code>247 + 1 = 248</code></p>\n<p>以上5条就是RPL的全部编码规则。</p>\n<h4 id=\"解码\"><a href=\"#解码\" class=\"headerlink\" title=\"解码\"></a>解码</h4><p>解码时，首先根据编码结果第一个字节<code>f</code>的大小，执行以下的规则判断：</p>\n<ol>\n<li>如果f∈ [0,128),　那么它是一个字节本身。</li>\n<li>如果f∈[128,184)，那么它是一个长度不超过55的byte数组，数组的长度为 <code>l=f-128</code></li>\n<li>如果f∈[184,192)，那么它是一个长度超过55的数组，长度本身的编码长度<code>ll=f-183</code>,然后从第二个字节开始读取长度为ll的bytes，按照BigEndian编码成整数l，l即为数组的长度。</li>\n<li>如果f∈(192,247]，那么它是一个编码后总长度不超过55的列表，列表长度为<code>l=f-192</code>。递归使用规则1~4进行解码。</li>\n<li>如果f∈(247,256]，那么它是编码后长度大于55的列表，其长度本身的编码长度<code>ll=f-247</code>,然后从第二个字节读取长度为ll的bytes,按BigEndian编码成整数l，l即为子列表长度。然后递归根据解码规则进行解码。</li>\n</ol>\n<h4 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h4><p>语言在具体实现RLP编码时，首先需要将对像映射成byte数组或列表两种形式。以go语言编码struct为例，会将其映射为列表，例如<code>Student</code>这个对象处理成列表<code>[&quot;icattlecoder&quot;,&quot;male&quot;]</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Student struct&#123;</span><br><span class=\"line\">    Name string</span><br><span class=\"line\">    Sex string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">s := Student&#123;Name:&quot;icattlecoder&quot;,Sex:&quot;male&quot;&#125;</span><br><span class=\"line\">buff := bytes.Buffer&#123;&#125;</span><br><span class=\"line\">rpl.Encode(&amp;buff, &amp;s)</span><br><span class=\"line\">print(buff.Bytes())</span><br><span class=\"line\">// [210 140 105 99 97 116 116 108 101 99 111 100 101 114 132 109 97 108 101]</span><br></pre></td></tr></table></figure>\n\n<p>如果编码map类型，可以采用以下列表形式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[[&quot;&quot;,&quot;&quot;],[&quot;&quot;,&quot;&quot;],[&quot;&quot;,&quot;&quot;]]</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"代码学习收获\"><a href=\"#代码学习收获\" class=\"headerlink\" title=\"代码学习收获\"></a>代码学习收获</h5><ul>\n<li><p>bytes.Buffer</p>\n<p>在需要字符拼接频繁时，可使用Buffer</p>\n<p>buffer是一个变长的 bytes，具有 Read 和Write 方法。 Buffer 的 零值 是一个 空的 buffer，但是可以使用。<br>Buffer 就像一个集装箱容器，可以存东西，取东西（存取数据）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b1 := new(bytes.Buffer)</span><br><span class=\"line\">b1.Write([]byte(&quot;asd&quot;))</span><br><span class=\"line\">b1.Bytes() --&gt; asd</span><br></pre></td></tr></table></figure>\n\n<p>在字符串倒来倒去的时候，或者是变长时候，Go中可以使用“+”合并字符串，但是这种合并方式效率非常低，<strong>每合并一次，都是创建一个新的字符串,就必须遍历复制一次字符串</strong>，在Java中会选择使用StringBuilder, 在go中，类似的方法就是bytes.Buffer(线程不安全)。</p>\n</li>\n</ul>\n<ul>\n<li><p>sync.Pool</p>\n<p>对象池。创建的时候可以指定一个New函数，获取对象的时候如何在池里面找不到缓存的对象将会使用指定的new函数创建一个返回</p>\n<p>它的用途仅仅是增加对象重用的几率，减少gc的负担，而开销方面也不是很便宜的</p>\n</li>\n<li><p>接口函数</p>\n<p>在oo中，实现方法的多态，需要多个子类。在go中，使用接口函数即可实现类似功能，而且非常简便</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type print func()</span><br><span class=\"line\">type A struct &#123;</span><br><span class=\"line\">\tprint</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func printString() &#123;</span><br><span class=\"line\">\tfmt.Println(&quot;I am a string...&quot;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func printInt() &#123;</span><br><span class=\"line\">\tfmt.Println(&quot;123456&quot;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func TestA_SetPrint(t *testing.T) &#123;</span><br><span class=\"line\">\ta := &amp;A&#123;&#125;</span><br><span class=\"line\">\ta.SetPrint(printString)</span><br><span class=\"line\">\ta.print()</span><br><span class=\"line\">\t//I am a string...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//还是很像多态，只是将方法print作为父，其余printString、printInt都是子，调用的时候调用指向子的引用。</span><br></pre></td></tr></table></figure>\n\n\n</li>\n</ul>\n"},{"title":"eth","date":"2019-10-14T06:50:23.000Z","_content":"\n## 以太坊基本认识和理解笔记\n\n\n\n#### 基本架构图\n\n图…..\n\n核心模块: 基础结构，共识算法，网络模块，其它模块。这几个模块的内容，跟比特币的模块有点像啊。\n\n合约层是使用Solidity语言编写的智能合约，其运行在EVM以太坊虚拟机上，并会通过HTTP-RPC或JSON-RPC调用和以太坊的核心层交互。\n\n以太坊架构的最上层是DApp应用层，它通过Web3.js这种JavaScript API和智能合约层进行交互。\n\n\n\n#### 基本概念\n\n##### ether\n\nether为以太坊中的内置货币。例如，矿工挖出新矿时，奖励的便是ether。它的主要目的是提供主要流动性层，以实现各种数字资产之间的有效交换，更重要的是提供支付交易费用的机制。\n\n- 首先，谁需要ether呢？\n\n  1. 打算开发使用ethereum区块链的应用的开发者。\n  2. 想要在ethereum区块链上访问并与智能合同交互的用户。\n\n- 其次，ether与bitcoin的关系是什么呢？\n\n  > Ethereum would never be possible without bitcoin—both the technology and the currency—and we see ourselves not as a competing currency but as complementary within the digital ecosystem. Ether is to be treated as \"crypto-fuel\", a token whose purpose is to pay for computation, and is not intended to be used as or considered a currency, asset, share or anything else.\n\n​         意思呢，就是二者并非竞争关系，而是互相补充的关系。ether的目的是计算付费，并不打算用作货币，资产，股票或其他任何东西。在一些以太坊的生态中，ether与bitcoin是可以进行价值兑换的。\n\n\n\n##### gas\n\ngas为计算花费的基本单位。通常，一步的计算花费1gas，但是一些操作耗费更高的气体量，因为它们在计算上更昂贵，或者增加了作为状态的一部分必须存储的数据量。交易数据中的每个字节的费用5gas,收费系统的目的是要求攻击者按比例支付她们消费的每种资源，包括计算量，带宽和存储量。\n\n一笔交易，除了需要包含接收方，发件人签名，ether的数量，之外，还需要包含数据字段（可选），一个STARTGAS值，表示允许执行事务执行的最大计算步骤数，和一个GASPRICE值，即为每gas的花费的ether。\n\n举个例子，现有一笔交易，内容为发送的ether为10，STARTGAS为2000，GASPRICE为0.001，和一个64bytes的数据，那么计算允许的所需要的ether为单价\\*数量=2000 \\* 0.001=2。 比较详细的交易如下\n\n1. 检查交易是否有效\n\n2. 检查发送方账户是否至少含有2000\\*0.001=2 ether, 如果有，则从发送方账户中减去2 ether\n\n3. 总共有2000gas, 假设交易长度为170bytes, 每bytes 5gas,那么减去850，剩余1150gas\n\n4. 从发送方账户余额中减去发送的10 ether, 并添加到合约账户中\n\n5. 运行代码进行计算，假设计算过程消耗了187gas, 那么剩余1150-187=963gas\n\n6. 将963gas转换为ether, 此项交易中单价是0.001，那么返回到发送方的ether为0.963\n\n\n\n##### 账户\n\n 在以太坊中，状态由账户对象组成，每个账户都有一个20byte的地址，状态转换是账户之间价值和信息的直接转移。以太坊账户包含四个字段：\n\n- nonce, 用来确保每笔交易柜台一次只能处理\n- 账户当前的ether余额\n- 账户的合约代码，如果存在的话\n- 账户的存储空间，默认为空\n\n通常，有两种账户，外部的个人拥有的账户，使用私钥进行控制； 以及合约账户，被合约代码控制。个人账户能够发送消息以及创建并签署交易。合约账户收到其激活码可读写内存，发送消息以及创建新的合约\n\n\n\n##### 消息和交易\n\n交易需要包含以下内容：\n\n- 消息的收件人\n- 识别发件人的签名\n- 发送的ether数量\n- 可选的数据字段\n- 一个`STARTGAS`值，表示允许执行事务执行的最大计算步骤数\n- 一个`GASPRICE`值，表示发件人按计算步骤支付的费用\n\n消息包含：\n\n- 消息的发送者（隐式）\n- 消息的收件人\n- 与消息一起传输的ether数量\n- 可选的数据字段\n- 一个`STARTGAS`值\n\n从本质上讲，消息就像一个交易，除了它是由合同产生的而不是由外部参与者产生的。当一个正在执行代码的合同执行`CALL`操作码时，产生一条消息，该操作码产生并执行一条消息。就像一个交易，一条消息导致收件人账户运行其代码。因此，合约可以与外部参与者完全相同的方式与其他合约有关系。\n\n请注意，交易或合同分配的gas限额适用于该交易和所有子执行消耗的gas量。例如，如果外部参与者A向B发送1000个gas的事务，并且B在向C发送消息之前消耗600gas，并且C的内部执行在返回之前消耗300gas，则B在运行之前可以花费另外100个gas。\n\n请注意，消息在回复方面与事务等效：如果消息执行耗尽，那么该消息的执行以及该执行触发的所有其他执行都会恢复，但父执行不需要恢复。这意味着合同可以调用另一份合同是“安全的”，就好像A用G气调用B一样，那么A的执行保证最多会损失G气。最后，请注意，有一个操作码`CREATE`可以创建合同; 其执行机制通常与执行机制类似`CALL`，但执行输出决定了新创建合同的代码。\n\n\n\n##### 状态转换\n\n以太坊状态转换功能`APPLY(S,TX) -> S'`可以定义如下：\n\n1. 检查交易是否格式正确（即具有正确数量的值），签名是否有效，并且nonce与发件人帐户中的nonce相匹配。如果不是，则返回错误。\n\n2. 计算交易费用`STARTGAS * GASPRICE`，并从签名确定发送地址。从发件人帐户余额中扣除费用并增加发件人的nonce。如果没有足够的余额可用，请返回错误。\n\n3. 初始化`GAS = STARTGAS`并在每个字节中取出一定数量的气体以支付交易中的字节数。\n\n4. 将交易金额从发件人的帐户转移到收款帐户。如果接收帐户尚不存在，请创建它。如果接收账户是合同，则运行合同代码以完成或直到执行用完为止。\n\n5. 如果由于发件人没有足够的资金或代码执行耗尽而导致价值转移失败，请恢复除支付费用之外的所有状态更改，并将费用添加到矿工帐户。\n\n6. 否则，将所有剩余天然气的费用退还给发送方，并将支付的天然气费用发送给矿工\n\n\n\n##### 代码执行\n\n合约中的代码采用low-level,基于堆栈的字节码语言编写，称为\"以太网虚拟机代码\"或\"EVM代码\"。该代码由一系列字节组成，其中每个字节表示一个操作。一般来说，代码执行是在当前程序计数器(从零开始)重复执行操作，然后将程序计数器递增1，直到代码结束或错误`STOP`或`RETURN`指令被检测到的一个无限循环。这些操作可以访问三种类型的存储空间：\n\n1. 堆栈，后进先出容器，其值可以被压入和弹出\n2. 内存。一个无限扩展的字节数组\n3. 合同的长期存储，一个key/value的存储，与计算结束后重置的堆栈和内存不同，存储长期存在。\n\n代码还可以访问传入消息的值，发送者和数据以及块头数据，代码也可以返回一个字节数组作为输出。\n\nEVM代码的正式执行模型非常简单。当以太坊虚拟机运行时，它的完整计算状态可以由元组定义`(block_state, transaction, message, code, memory, stack, pc, gas)`，其中`block_state`是包含所有帐户并包括余额和存储的全局状态。在每一轮执行开始时，当前的指令是通过取`pc`第`code`（或0 `pc >= len(code)`）个字节的第n个字节来找到的，并且每条指令都有它自己的定义，以表明它如何影响元组。例如，`ADD`从堆叠中弹出两个物品并推动它们的总和，减`gas`1和增`pc`1，`SSTORE`从堆栈中弹出前两个项目，并将第二个项目插入到第一个项目指定的索引处的合同存储器中。虽然有很多方法可以通过即时编译来优化以太坊虚拟机的执行，但以太坊的基本实现可以通过几百行代码完成。\n\n\n\n##### 区块链和采矿\n\n以太坊的区块链和比特币的区块链有很多地方相似，也有不同的地方。最大的不同点在于，以太坊区块包含交易列表及最新状态二者的副本，除此之外，在区块中还存储了两个其他的值，区块号，和难度（计算难度）。以太坊中的基本块验证算法如下：\n\n1. 检查前面的块引用是否存在并且是有效的。\n2. 检查块的时间戳大于引用的前一个块的时间戳，并且在未来15分钟内\n3. 检查块号，难度，交易根，叔叔根和气体限制（各种低级以太坊特定概念）是否有效。\n4. 检查块的工作证明是否有效。\n5. 让我们`S[0]`成为上一个区块结束时的状态吧。\n6. 让`TX`块成为具有`n`个交易的交易清单。对于所有`i`的`0...n-1`设置`S[i+1] = APPLY(S[i],TX[i])`。如果任何应用程序返回一个错误，或者如果在这个点上阻塞的气体总量超过了这个数量`GASLIMIT`，返回一个错误。\n7. 我们`S_FINAL`是`S[n]`，而且将支付给矿工块奖励。\n8. 检查状态的Merkle树根`S_FINAL`是否等于块头中提供的最终状态根。如果是，则该块有效; 否则，它是无效的。\n\n这种方法乍一看似乎效率很低，因为它需要在每个块中存储整个状态，但实际上效率应该与比特币相当。原因是状态存储在树状结构中，并且在每个块之后只需要改变树的一小部分。因此，一般来说，在两个相邻块之间，绝大多数树应该是相同的，因此数据可以被存储一次并且使用指针（即子树的散列）被引用两次。一种称为“Patricia树”的特殊树被用来实现这一点，包括对Merkle树概念的修改，允许节点被插入和删除，而不仅仅是有效地改变。另外，因为所有的状态信息都是最后一个块的一部分，没有必要存储整个区块链的历史——如果可以应用到比特币上，就可以计算出在太空中节省5-20x的成本。\n\n就物理硬件而言，一个常见问题是在哪里执行合同代码。这有一个简单的答案：执行合同代码的过程是状态转换函数的定义的一部分，它是块验证算法的一部分，所以如果一个事务被添加到块`B`中，该事务生成的代码执行将被执行所有节点现在和将来都会下载并验证块`B`。\n\n\n\n##### 应用\n\n总的来说，在以太坊之上有三种类型的应用程序。第一类是金融应用程序，为用户提供更强大的管理方式，并使用他们的资金签订合同。这包括子货币，金融衍生品，套期保值合约，储蓄钱包，遗嘱以及最终甚至是一些类别的全面雇佣合同。第二类是半金融应用，涉及金钱，但也有非常重要的非货币方面的工作; 一个完美的例子就是为计算问题的解决方案自我实施奖励。最后，还有诸如在线投票和分散治理等应用程序，这些应用程序根本没有财务。\n\n该章节并不完全，仅摘取了介绍部分，详细内容还需到[以太坊白皮书](https://github.com/ethereum/wiki/wiki/White-Paper)中查阅\n\n\n\n###### 令牌系统\n\n区块链上的代币系统有许多应用程序，从代表资产（如美元或黄金）的子货币到公司股票，代表智能财产的单个代币，安全不可伪造的优惠券，甚至与常规值完全无关的代币系统，用作点激励制度。令牌系统在Ethereum中实现起来非常简单。要理解的关键是，所有货币或标记系统基本上都是一个数据库，只有一个操作：从A中减去X个单位并将X个单位给予B，但条件是（1）A至少有X个单位交易和（2）交易由A批准。实现令牌系统所需的一切就是将该逻辑实施到合同中。\n\n\n\n###### 金融衍生产品和稳定价值货币\n\n金融衍生工具是“智能合约”中最常见的应用，也是最简单的代码实现之一。实施金融合同面临的主要挑战是，其中大部分要求参考外部价格报价; 例如，一个非常理想的应用程序是一种智能合约，可以抵御以太币（或另一种加密货币）相对于美元的波动性，但这样做需要合约知道ETH / USD的价值。最简单的方法是通过由特定方（例如纳斯达克）维护的“数据馈送”合同，以便该方能够根据需要更新合同，并提供一个接口，以允许其他合同发送向该合同发送消息并取回提供价格的响应。\n\n###### 身份和声誉系统\n\n所有的最早的替代性加密货币，[Namecoin](http://namecoin.org/)试图使用类似比特币的[区块](http://namecoin.org/)链来提供名称注册系统，用户可以在公共数据库中将他们的名称与其他数据一起注册。主要引用的用例是[DNS](http://en.wikipedia.org/wiki/Domain_Name_System)系统，将域名（比如“bitcoin.org”）（或者在Namecoin的例子中，“bitcoin.bit”）映射到IP地址。其他用例包括电子邮件认证和潜在更高级的信誉系统。\n\n###### 分散的文件存储\n\n以太坊合同可以允许开发分散式文件存储生态系统，个人用户可以通过租用自己的硬盘来赚取少量的资金，未使用的空间可以用来进一步降低文件存储成本。\n\n这种设备的关键在于我们称之为“分散式Dropbox合同”。该合同的工作如下。首先，将所需数据分成块，对每个块进行隐私加密，并从中构建一个Merkle树。然后用合约规则规定，每N个块，合约将在Merkle树中选择一个随机索引（使用之前的块散列，可从合同代码访问，作为随机源），并将X ether赋予第一个实体为该交易提供一个简化的支付验证类似树中该特定索引处块的所有权证明。当用户想要重新下载他们的文件时，他们可以使用微支付通道协议（例如，支付每32千字节1个szabo）来恢复文件;\n\n该协议的一个重要特点是，虽然看起来好像一个人相信许多随机节点不会决定忘记文件，但可以通过秘密共享将文件分割成许多块，从而将风险降低到接近于零，并且看合同，看看每件作品仍然在某个节点中。如果合同仍在支付金钱，那么它提供了一个密码证明，表明某人仍在存储该文件。\n\n###### 分散的自治组织\n\n“分散式自治组织”的一般概念是拥有一定数量的成员或股东的虚拟实体的概念，这些成员或股东可能拥有67％的多数股东有权利用该实体的资金并修改其代码。成员们将共同决定组织如何分配资金。分配DAO资金的方法可以从赏金，工资到甚至更多外来机制（如内部货币）以奖励工作。这基本上复制了传统公司或非营利组织的法律标志，但仅使用加密区块链技术执行。\n\n参考地址如下\n\n1. http://baijiahao.baidu.com/s?id=1595831842043592716&wfr=spider&for=pc\n2. https://github.com/ethereum/wiki/wiki/White-Paper\n","source":"_posts/eth.md","raw":"---\ntitle: eth\ncategories:\n  - eth\ndate: 2019-10-14 14:50:23\ntags:\n---\n\n## 以太坊基本认识和理解笔记\n\n\n\n#### 基本架构图\n\n图…..\n\n核心模块: 基础结构，共识算法，网络模块，其它模块。这几个模块的内容，跟比特币的模块有点像啊。\n\n合约层是使用Solidity语言编写的智能合约，其运行在EVM以太坊虚拟机上，并会通过HTTP-RPC或JSON-RPC调用和以太坊的核心层交互。\n\n以太坊架构的最上层是DApp应用层，它通过Web3.js这种JavaScript API和智能合约层进行交互。\n\n\n\n#### 基本概念\n\n##### ether\n\nether为以太坊中的内置货币。例如，矿工挖出新矿时，奖励的便是ether。它的主要目的是提供主要流动性层，以实现各种数字资产之间的有效交换，更重要的是提供支付交易费用的机制。\n\n- 首先，谁需要ether呢？\n\n  1. 打算开发使用ethereum区块链的应用的开发者。\n  2. 想要在ethereum区块链上访问并与智能合同交互的用户。\n\n- 其次，ether与bitcoin的关系是什么呢？\n\n  > Ethereum would never be possible without bitcoin—both the technology and the currency—and we see ourselves not as a competing currency but as complementary within the digital ecosystem. Ether is to be treated as \"crypto-fuel\", a token whose purpose is to pay for computation, and is not intended to be used as or considered a currency, asset, share or anything else.\n\n​         意思呢，就是二者并非竞争关系，而是互相补充的关系。ether的目的是计算付费，并不打算用作货币，资产，股票或其他任何东西。在一些以太坊的生态中，ether与bitcoin是可以进行价值兑换的。\n\n\n\n##### gas\n\ngas为计算花费的基本单位。通常，一步的计算花费1gas，但是一些操作耗费更高的气体量，因为它们在计算上更昂贵，或者增加了作为状态的一部分必须存储的数据量。交易数据中的每个字节的费用5gas,收费系统的目的是要求攻击者按比例支付她们消费的每种资源，包括计算量，带宽和存储量。\n\n一笔交易，除了需要包含接收方，发件人签名，ether的数量，之外，还需要包含数据字段（可选），一个STARTGAS值，表示允许执行事务执行的最大计算步骤数，和一个GASPRICE值，即为每gas的花费的ether。\n\n举个例子，现有一笔交易，内容为发送的ether为10，STARTGAS为2000，GASPRICE为0.001，和一个64bytes的数据，那么计算允许的所需要的ether为单价\\*数量=2000 \\* 0.001=2。 比较详细的交易如下\n\n1. 检查交易是否有效\n\n2. 检查发送方账户是否至少含有2000\\*0.001=2 ether, 如果有，则从发送方账户中减去2 ether\n\n3. 总共有2000gas, 假设交易长度为170bytes, 每bytes 5gas,那么减去850，剩余1150gas\n\n4. 从发送方账户余额中减去发送的10 ether, 并添加到合约账户中\n\n5. 运行代码进行计算，假设计算过程消耗了187gas, 那么剩余1150-187=963gas\n\n6. 将963gas转换为ether, 此项交易中单价是0.001，那么返回到发送方的ether为0.963\n\n\n\n##### 账户\n\n 在以太坊中，状态由账户对象组成，每个账户都有一个20byte的地址，状态转换是账户之间价值和信息的直接转移。以太坊账户包含四个字段：\n\n- nonce, 用来确保每笔交易柜台一次只能处理\n- 账户当前的ether余额\n- 账户的合约代码，如果存在的话\n- 账户的存储空间，默认为空\n\n通常，有两种账户，外部的个人拥有的账户，使用私钥进行控制； 以及合约账户，被合约代码控制。个人账户能够发送消息以及创建并签署交易。合约账户收到其激活码可读写内存，发送消息以及创建新的合约\n\n\n\n##### 消息和交易\n\n交易需要包含以下内容：\n\n- 消息的收件人\n- 识别发件人的签名\n- 发送的ether数量\n- 可选的数据字段\n- 一个`STARTGAS`值，表示允许执行事务执行的最大计算步骤数\n- 一个`GASPRICE`值，表示发件人按计算步骤支付的费用\n\n消息包含：\n\n- 消息的发送者（隐式）\n- 消息的收件人\n- 与消息一起传输的ether数量\n- 可选的数据字段\n- 一个`STARTGAS`值\n\n从本质上讲，消息就像一个交易，除了它是由合同产生的而不是由外部参与者产生的。当一个正在执行代码的合同执行`CALL`操作码时，产生一条消息，该操作码产生并执行一条消息。就像一个交易，一条消息导致收件人账户运行其代码。因此，合约可以与外部参与者完全相同的方式与其他合约有关系。\n\n请注意，交易或合同分配的gas限额适用于该交易和所有子执行消耗的gas量。例如，如果外部参与者A向B发送1000个gas的事务，并且B在向C发送消息之前消耗600gas，并且C的内部执行在返回之前消耗300gas，则B在运行之前可以花费另外100个gas。\n\n请注意，消息在回复方面与事务等效：如果消息执行耗尽，那么该消息的执行以及该执行触发的所有其他执行都会恢复，但父执行不需要恢复。这意味着合同可以调用另一份合同是“安全的”，就好像A用G气调用B一样，那么A的执行保证最多会损失G气。最后，请注意，有一个操作码`CREATE`可以创建合同; 其执行机制通常与执行机制类似`CALL`，但执行输出决定了新创建合同的代码。\n\n\n\n##### 状态转换\n\n以太坊状态转换功能`APPLY(S,TX) -> S'`可以定义如下：\n\n1. 检查交易是否格式正确（即具有正确数量的值），签名是否有效，并且nonce与发件人帐户中的nonce相匹配。如果不是，则返回错误。\n\n2. 计算交易费用`STARTGAS * GASPRICE`，并从签名确定发送地址。从发件人帐户余额中扣除费用并增加发件人的nonce。如果没有足够的余额可用，请返回错误。\n\n3. 初始化`GAS = STARTGAS`并在每个字节中取出一定数量的气体以支付交易中的字节数。\n\n4. 将交易金额从发件人的帐户转移到收款帐户。如果接收帐户尚不存在，请创建它。如果接收账户是合同，则运行合同代码以完成或直到执行用完为止。\n\n5. 如果由于发件人没有足够的资金或代码执行耗尽而导致价值转移失败，请恢复除支付费用之外的所有状态更改，并将费用添加到矿工帐户。\n\n6. 否则，将所有剩余天然气的费用退还给发送方，并将支付的天然气费用发送给矿工\n\n\n\n##### 代码执行\n\n合约中的代码采用low-level,基于堆栈的字节码语言编写，称为\"以太网虚拟机代码\"或\"EVM代码\"。该代码由一系列字节组成，其中每个字节表示一个操作。一般来说，代码执行是在当前程序计数器(从零开始)重复执行操作，然后将程序计数器递增1，直到代码结束或错误`STOP`或`RETURN`指令被检测到的一个无限循环。这些操作可以访问三种类型的存储空间：\n\n1. 堆栈，后进先出容器，其值可以被压入和弹出\n2. 内存。一个无限扩展的字节数组\n3. 合同的长期存储，一个key/value的存储，与计算结束后重置的堆栈和内存不同，存储长期存在。\n\n代码还可以访问传入消息的值，发送者和数据以及块头数据，代码也可以返回一个字节数组作为输出。\n\nEVM代码的正式执行模型非常简单。当以太坊虚拟机运行时，它的完整计算状态可以由元组定义`(block_state, transaction, message, code, memory, stack, pc, gas)`，其中`block_state`是包含所有帐户并包括余额和存储的全局状态。在每一轮执行开始时，当前的指令是通过取`pc`第`code`（或0 `pc >= len(code)`）个字节的第n个字节来找到的，并且每条指令都有它自己的定义，以表明它如何影响元组。例如，`ADD`从堆叠中弹出两个物品并推动它们的总和，减`gas`1和增`pc`1，`SSTORE`从堆栈中弹出前两个项目，并将第二个项目插入到第一个项目指定的索引处的合同存储器中。虽然有很多方法可以通过即时编译来优化以太坊虚拟机的执行，但以太坊的基本实现可以通过几百行代码完成。\n\n\n\n##### 区块链和采矿\n\n以太坊的区块链和比特币的区块链有很多地方相似，也有不同的地方。最大的不同点在于，以太坊区块包含交易列表及最新状态二者的副本，除此之外，在区块中还存储了两个其他的值，区块号，和难度（计算难度）。以太坊中的基本块验证算法如下：\n\n1. 检查前面的块引用是否存在并且是有效的。\n2. 检查块的时间戳大于引用的前一个块的时间戳，并且在未来15分钟内\n3. 检查块号，难度，交易根，叔叔根和气体限制（各种低级以太坊特定概念）是否有效。\n4. 检查块的工作证明是否有效。\n5. 让我们`S[0]`成为上一个区块结束时的状态吧。\n6. 让`TX`块成为具有`n`个交易的交易清单。对于所有`i`的`0...n-1`设置`S[i+1] = APPLY(S[i],TX[i])`。如果任何应用程序返回一个错误，或者如果在这个点上阻塞的气体总量超过了这个数量`GASLIMIT`，返回一个错误。\n7. 我们`S_FINAL`是`S[n]`，而且将支付给矿工块奖励。\n8. 检查状态的Merkle树根`S_FINAL`是否等于块头中提供的最终状态根。如果是，则该块有效; 否则，它是无效的。\n\n这种方法乍一看似乎效率很低，因为它需要在每个块中存储整个状态，但实际上效率应该与比特币相当。原因是状态存储在树状结构中，并且在每个块之后只需要改变树的一小部分。因此，一般来说，在两个相邻块之间，绝大多数树应该是相同的，因此数据可以被存储一次并且使用指针（即子树的散列）被引用两次。一种称为“Patricia树”的特殊树被用来实现这一点，包括对Merkle树概念的修改，允许节点被插入和删除，而不仅仅是有效地改变。另外，因为所有的状态信息都是最后一个块的一部分，没有必要存储整个区块链的历史——如果可以应用到比特币上，就可以计算出在太空中节省5-20x的成本。\n\n就物理硬件而言，一个常见问题是在哪里执行合同代码。这有一个简单的答案：执行合同代码的过程是状态转换函数的定义的一部分，它是块验证算法的一部分，所以如果一个事务被添加到块`B`中，该事务生成的代码执行将被执行所有节点现在和将来都会下载并验证块`B`。\n\n\n\n##### 应用\n\n总的来说，在以太坊之上有三种类型的应用程序。第一类是金融应用程序，为用户提供更强大的管理方式，并使用他们的资金签订合同。这包括子货币，金融衍生品，套期保值合约，储蓄钱包，遗嘱以及最终甚至是一些类别的全面雇佣合同。第二类是半金融应用，涉及金钱，但也有非常重要的非货币方面的工作; 一个完美的例子就是为计算问题的解决方案自我实施奖励。最后，还有诸如在线投票和分散治理等应用程序，这些应用程序根本没有财务。\n\n该章节并不完全，仅摘取了介绍部分，详细内容还需到[以太坊白皮书](https://github.com/ethereum/wiki/wiki/White-Paper)中查阅\n\n\n\n###### 令牌系统\n\n区块链上的代币系统有许多应用程序，从代表资产（如美元或黄金）的子货币到公司股票，代表智能财产的单个代币，安全不可伪造的优惠券，甚至与常规值完全无关的代币系统，用作点激励制度。令牌系统在Ethereum中实现起来非常简单。要理解的关键是，所有货币或标记系统基本上都是一个数据库，只有一个操作：从A中减去X个单位并将X个单位给予B，但条件是（1）A至少有X个单位交易和（2）交易由A批准。实现令牌系统所需的一切就是将该逻辑实施到合同中。\n\n\n\n###### 金融衍生产品和稳定价值货币\n\n金融衍生工具是“智能合约”中最常见的应用，也是最简单的代码实现之一。实施金融合同面临的主要挑战是，其中大部分要求参考外部价格报价; 例如，一个非常理想的应用程序是一种智能合约，可以抵御以太币（或另一种加密货币）相对于美元的波动性，但这样做需要合约知道ETH / USD的价值。最简单的方法是通过由特定方（例如纳斯达克）维护的“数据馈送”合同，以便该方能够根据需要更新合同，并提供一个接口，以允许其他合同发送向该合同发送消息并取回提供价格的响应。\n\n###### 身份和声誉系统\n\n所有的最早的替代性加密货币，[Namecoin](http://namecoin.org/)试图使用类似比特币的[区块](http://namecoin.org/)链来提供名称注册系统，用户可以在公共数据库中将他们的名称与其他数据一起注册。主要引用的用例是[DNS](http://en.wikipedia.org/wiki/Domain_Name_System)系统，将域名（比如“bitcoin.org”）（或者在Namecoin的例子中，“bitcoin.bit”）映射到IP地址。其他用例包括电子邮件认证和潜在更高级的信誉系统。\n\n###### 分散的文件存储\n\n以太坊合同可以允许开发分散式文件存储生态系统，个人用户可以通过租用自己的硬盘来赚取少量的资金，未使用的空间可以用来进一步降低文件存储成本。\n\n这种设备的关键在于我们称之为“分散式Dropbox合同”。该合同的工作如下。首先，将所需数据分成块，对每个块进行隐私加密，并从中构建一个Merkle树。然后用合约规则规定，每N个块，合约将在Merkle树中选择一个随机索引（使用之前的块散列，可从合同代码访问，作为随机源），并将X ether赋予第一个实体为该交易提供一个简化的支付验证类似树中该特定索引处块的所有权证明。当用户想要重新下载他们的文件时，他们可以使用微支付通道协议（例如，支付每32千字节1个szabo）来恢复文件;\n\n该协议的一个重要特点是，虽然看起来好像一个人相信许多随机节点不会决定忘记文件，但可以通过秘密共享将文件分割成许多块，从而将风险降低到接近于零，并且看合同，看看每件作品仍然在某个节点中。如果合同仍在支付金钱，那么它提供了一个密码证明，表明某人仍在存储该文件。\n\n###### 分散的自治组织\n\n“分散式自治组织”的一般概念是拥有一定数量的成员或股东的虚拟实体的概念，这些成员或股东可能拥有67％的多数股东有权利用该实体的资金并修改其代码。成员们将共同决定组织如何分配资金。分配DAO资金的方法可以从赏金，工资到甚至更多外来机制（如内部货币）以奖励工作。这基本上复制了传统公司或非营利组织的法律标志，但仅使用加密区块链技术执行。\n\n参考地址如下\n\n1. http://baijiahao.baidu.com/s?id=1595831842043592716&wfr=spider&for=pc\n2. https://github.com/ethereum/wiki/wiki/White-Paper\n","slug":"eth","published":1,"updated":"2019-10-14T06:50:45.748Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69x5002ct6xve80e8m2u","content":"<h2 id=\"以太坊基本认识和理解笔记\"><a href=\"#以太坊基本认识和理解笔记\" class=\"headerlink\" title=\"以太坊基本认识和理解笔记\"></a>以太坊基本认识和理解笔记</h2><h4 id=\"基本架构图\"><a href=\"#基本架构图\" class=\"headerlink\" title=\"基本架构图\"></a>基本架构图</h4><p>图…..</p>\n<p>核心模块: 基础结构，共识算法，网络模块，其它模块。这几个模块的内容，跟比特币的模块有点像啊。</p>\n<p>合约层是使用Solidity语言编写的智能合约，其运行在EVM以太坊虚拟机上，并会通过HTTP-RPC或JSON-RPC调用和以太坊的核心层交互。</p>\n<p>以太坊架构的最上层是DApp应用层，它通过Web3.js这种JavaScript API和智能合约层进行交互。</p>\n<h4 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h4><h5 id=\"ether\"><a href=\"#ether\" class=\"headerlink\" title=\"ether\"></a>ether</h5><p>ether为以太坊中的内置货币。例如，矿工挖出新矿时，奖励的便是ether。它的主要目的是提供主要流动性层，以实现各种数字资产之间的有效交换，更重要的是提供支付交易费用的机制。</p>\n<ul>\n<li><p>首先，谁需要ether呢？</p>\n<ol>\n<li>打算开发使用ethereum区块链的应用的开发者。</li>\n<li>想要在ethereum区块链上访问并与智能合同交互的用户。</li>\n</ol>\n</li>\n<li><p>其次，ether与bitcoin的关系是什么呢？</p>\n<blockquote>\n<p>Ethereum would never be possible without bitcoin—both the technology and the currency—and we see ourselves not as a competing currency but as complementary within the digital ecosystem. Ether is to be treated as “crypto-fuel”, a token whose purpose is to pay for computation, and is not intended to be used as or considered a currency, asset, share or anything else.</p>\n</blockquote>\n</li>\n</ul>\n<p>​         意思呢，就是二者并非竞争关系，而是互相补充的关系。ether的目的是计算付费，并不打算用作货币，资产，股票或其他任何东西。在一些以太坊的生态中，ether与bitcoin是可以进行价值兑换的。</p>\n<h5 id=\"gas\"><a href=\"#gas\" class=\"headerlink\" title=\"gas\"></a>gas</h5><p>gas为计算花费的基本单位。通常，一步的计算花费1gas，但是一些操作耗费更高的气体量，因为它们在计算上更昂贵，或者增加了作为状态的一部分必须存储的数据量。交易数据中的每个字节的费用5gas,收费系统的目的是要求攻击者按比例支付她们消费的每种资源，包括计算量，带宽和存储量。</p>\n<p>一笔交易，除了需要包含接收方，发件人签名，ether的数量，之外，还需要包含数据字段（可选），一个STARTGAS值，表示允许执行事务执行的最大计算步骤数，和一个GASPRICE值，即为每gas的花费的ether。</p>\n<p>举个例子，现有一笔交易，内容为发送的ether为10，STARTGAS为2000，GASPRICE为0.001，和一个64bytes的数据，那么计算允许的所需要的ether为单价*数量=2000 * 0.001=2。 比较详细的交易如下</p>\n<ol>\n<li><p>检查交易是否有效</p>\n</li>\n<li><p>检查发送方账户是否至少含有2000*0.001=2 ether, 如果有，则从发送方账户中减去2 ether</p>\n</li>\n<li><p>总共有2000gas, 假设交易长度为170bytes, 每bytes 5gas,那么减去850，剩余1150gas</p>\n</li>\n<li><p>从发送方账户余额中减去发送的10 ether, 并添加到合约账户中</p>\n</li>\n<li><p>运行代码进行计算，假设计算过程消耗了187gas, 那么剩余1150-187=963gas</p>\n</li>\n<li><p>将963gas转换为ether, 此项交易中单价是0.001，那么返回到发送方的ether为0.963</p>\n</li>\n</ol>\n<h5 id=\"账户\"><a href=\"#账户\" class=\"headerlink\" title=\"账户\"></a>账户</h5><p> 在以太坊中，状态由账户对象组成，每个账户都有一个20byte的地址，状态转换是账户之间价值和信息的直接转移。以太坊账户包含四个字段：</p>\n<ul>\n<li>nonce, 用来确保每笔交易柜台一次只能处理</li>\n<li>账户当前的ether余额</li>\n<li>账户的合约代码，如果存在的话</li>\n<li>账户的存储空间，默认为空</li>\n</ul>\n<p>通常，有两种账户，外部的个人拥有的账户，使用私钥进行控制； 以及合约账户，被合约代码控制。个人账户能够发送消息以及创建并签署交易。合约账户收到其激活码可读写内存，发送消息以及创建新的合约</p>\n<h5 id=\"消息和交易\"><a href=\"#消息和交易\" class=\"headerlink\" title=\"消息和交易\"></a>消息和交易</h5><p>交易需要包含以下内容：</p>\n<ul>\n<li>消息的收件人</li>\n<li>识别发件人的签名</li>\n<li>发送的ether数量</li>\n<li>可选的数据字段</li>\n<li>一个<code>STARTGAS</code>值，表示允许执行事务执行的最大计算步骤数</li>\n<li>一个<code>GASPRICE</code>值，表示发件人按计算步骤支付的费用</li>\n</ul>\n<p>消息包含：</p>\n<ul>\n<li>消息的发送者（隐式）</li>\n<li>消息的收件人</li>\n<li>与消息一起传输的ether数量</li>\n<li>可选的数据字段</li>\n<li>一个<code>STARTGAS</code>值</li>\n</ul>\n<p>从本质上讲，消息就像一个交易，除了它是由合同产生的而不是由外部参与者产生的。当一个正在执行代码的合同执行<code>CALL</code>操作码时，产生一条消息，该操作码产生并执行一条消息。就像一个交易，一条消息导致收件人账户运行其代码。因此，合约可以与外部参与者完全相同的方式与其他合约有关系。</p>\n<p>请注意，交易或合同分配的gas限额适用于该交易和所有子执行消耗的gas量。例如，如果外部参与者A向B发送1000个gas的事务，并且B在向C发送消息之前消耗600gas，并且C的内部执行在返回之前消耗300gas，则B在运行之前可以花费另外100个gas。</p>\n<p>请注意，消息在回复方面与事务等效：如果消息执行耗尽，那么该消息的执行以及该执行触发的所有其他执行都会恢复，但父执行不需要恢复。这意味着合同可以调用另一份合同是“安全的”，就好像A用G气调用B一样，那么A的执行保证最多会损失G气。最后，请注意，有一个操作码<code>CREATE</code>可以创建合同; 其执行机制通常与执行机制类似<code>CALL</code>，但执行输出决定了新创建合同的代码。</p>\n<h5 id=\"状态转换\"><a href=\"#状态转换\" class=\"headerlink\" title=\"状态转换\"></a>状态转换</h5><p>以太坊状态转换功能<code>APPLY(S,TX) -&gt; S&#39;</code>可以定义如下：</p>\n<ol>\n<li><p>检查交易是否格式正确（即具有正确数量的值），签名是否有效，并且nonce与发件人帐户中的nonce相匹配。如果不是，则返回错误。</p>\n</li>\n<li><p>计算交易费用<code>STARTGAS * GASPRICE</code>，并从签名确定发送地址。从发件人帐户余额中扣除费用并增加发件人的nonce。如果没有足够的余额可用，请返回错误。</p>\n</li>\n<li><p>初始化<code>GAS = STARTGAS</code>并在每个字节中取出一定数量的气体以支付交易中的字节数。</p>\n</li>\n<li><p>将交易金额从发件人的帐户转移到收款帐户。如果接收帐户尚不存在，请创建它。如果接收账户是合同，则运行合同代码以完成或直到执行用完为止。</p>\n</li>\n<li><p>如果由于发件人没有足够的资金或代码执行耗尽而导致价值转移失败，请恢复除支付费用之外的所有状态更改，并将费用添加到矿工帐户。</p>\n</li>\n<li><p>否则，将所有剩余天然气的费用退还给发送方，并将支付的天然气费用发送给矿工</p>\n</li>\n</ol>\n<h5 id=\"代码执行\"><a href=\"#代码执行\" class=\"headerlink\" title=\"代码执行\"></a>代码执行</h5><p>合约中的代码采用low-level,基于堆栈的字节码语言编写，称为”以太网虚拟机代码”或”EVM代码”。该代码由一系列字节组成，其中每个字节表示一个操作。一般来说，代码执行是在当前程序计数器(从零开始)重复执行操作，然后将程序计数器递增1，直到代码结束或错误<code>STOP</code>或<code>RETURN</code>指令被检测到的一个无限循环。这些操作可以访问三种类型的存储空间：</p>\n<ol>\n<li>堆栈，后进先出容器，其值可以被压入和弹出</li>\n<li>内存。一个无限扩展的字节数组</li>\n<li>合同的长期存储，一个key/value的存储，与计算结束后重置的堆栈和内存不同，存储长期存在。</li>\n</ol>\n<p>代码还可以访问传入消息的值，发送者和数据以及块头数据，代码也可以返回一个字节数组作为输出。</p>\n<p>EVM代码的正式执行模型非常简单。当以太坊虚拟机运行时，它的完整计算状态可以由元组定义<code>(block_state, transaction, message, code, memory, stack, pc, gas)</code>，其中<code>block_state</code>是包含所有帐户并包括余额和存储的全局状态。在每一轮执行开始时，当前的指令是通过取<code>pc</code>第<code>code</code>（或0 <code>pc &gt;= len(code)</code>）个字节的第n个字节来找到的，并且每条指令都有它自己的定义，以表明它如何影响元组。例如，<code>ADD</code>从堆叠中弹出两个物品并推动它们的总和，减<code>gas</code>1和增<code>pc</code>1，<code>SSTORE</code>从堆栈中弹出前两个项目，并将第二个项目插入到第一个项目指定的索引处的合同存储器中。虽然有很多方法可以通过即时编译来优化以太坊虚拟机的执行，但以太坊的基本实现可以通过几百行代码完成。</p>\n<h5 id=\"区块链和采矿\"><a href=\"#区块链和采矿\" class=\"headerlink\" title=\"区块链和采矿\"></a>区块链和采矿</h5><p>以太坊的区块链和比特币的区块链有很多地方相似，也有不同的地方。最大的不同点在于，以太坊区块包含交易列表及最新状态二者的副本，除此之外，在区块中还存储了两个其他的值，区块号，和难度（计算难度）。以太坊中的基本块验证算法如下：</p>\n<ol>\n<li>检查前面的块引用是否存在并且是有效的。</li>\n<li>检查块的时间戳大于引用的前一个块的时间戳，并且在未来15分钟内</li>\n<li>检查块号，难度，交易根，叔叔根和气体限制（各种低级以太坊特定概念）是否有效。</li>\n<li>检查块的工作证明是否有效。</li>\n<li>让我们<code>S[0]</code>成为上一个区块结束时的状态吧。</li>\n<li>让<code>TX</code>块成为具有<code>n</code>个交易的交易清单。对于所有<code>i</code>的<code>0...n-1</code>设置<code>S[i+1] = APPLY(S[i],TX[i])</code>。如果任何应用程序返回一个错误，或者如果在这个点上阻塞的气体总量超过了这个数量<code>GASLIMIT</code>，返回一个错误。</li>\n<li>我们<code>S_FINAL</code>是<code>S[n]</code>，而且将支付给矿工块奖励。</li>\n<li>检查状态的Merkle树根<code>S_FINAL</code>是否等于块头中提供的最终状态根。如果是，则该块有效; 否则，它是无效的。</li>\n</ol>\n<p>这种方法乍一看似乎效率很低，因为它需要在每个块中存储整个状态，但实际上效率应该与比特币相当。原因是状态存储在树状结构中，并且在每个块之后只需要改变树的一小部分。因此，一般来说，在两个相邻块之间，绝大多数树应该是相同的，因此数据可以被存储一次并且使用指针（即子树的散列）被引用两次。一种称为“Patricia树”的特殊树被用来实现这一点，包括对Merkle树概念的修改，允许节点被插入和删除，而不仅仅是有效地改变。另外，因为所有的状态信息都是最后一个块的一部分，没有必要存储整个区块链的历史——如果可以应用到比特币上，就可以计算出在太空中节省5-20x的成本。</p>\n<p>就物理硬件而言，一个常见问题是在哪里执行合同代码。这有一个简单的答案：执行合同代码的过程是状态转换函数的定义的一部分，它是块验证算法的一部分，所以如果一个事务被添加到块<code>B</code>中，该事务生成的代码执行将被执行所有节点现在和将来都会下载并验证块<code>B</code>。</p>\n<h5 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h5><p>总的来说，在以太坊之上有三种类型的应用程序。第一类是金融应用程序，为用户提供更强大的管理方式，并使用他们的资金签订合同。这包括子货币，金融衍生品，套期保值合约，储蓄钱包，遗嘱以及最终甚至是一些类别的全面雇佣合同。第二类是半金融应用，涉及金钱，但也有非常重要的非货币方面的工作; 一个完美的例子就是为计算问题的解决方案自我实施奖励。最后，还有诸如在线投票和分散治理等应用程序，这些应用程序根本没有财务。</p>\n<p>该章节并不完全，仅摘取了介绍部分，详细内容还需到<a href=\"https://github.com/ethereum/wiki/wiki/White-Paper\">以太坊白皮书</a>中查阅</p>\n<h6 id=\"令牌系统\"><a href=\"#令牌系统\" class=\"headerlink\" title=\"令牌系统\"></a>令牌系统</h6><p>区块链上的代币系统有许多应用程序，从代表资产（如美元或黄金）的子货币到公司股票，代表智能财产的单个代币，安全不可伪造的优惠券，甚至与常规值完全无关的代币系统，用作点激励制度。令牌系统在Ethereum中实现起来非常简单。要理解的关键是，所有货币或标记系统基本上都是一个数据库，只有一个操作：从A中减去X个单位并将X个单位给予B，但条件是（1）A至少有X个单位交易和（2）交易由A批准。实现令牌系统所需的一切就是将该逻辑实施到合同中。</p>\n<h6 id=\"金融衍生产品和稳定价值货币\"><a href=\"#金融衍生产品和稳定价值货币\" class=\"headerlink\" title=\"金融衍生产品和稳定价值货币\"></a>金融衍生产品和稳定价值货币</h6><p>金融衍生工具是“智能合约”中最常见的应用，也是最简单的代码实现之一。实施金融合同面临的主要挑战是，其中大部分要求参考外部价格报价; 例如，一个非常理想的应用程序是一种智能合约，可以抵御以太币（或另一种加密货币）相对于美元的波动性，但这样做需要合约知道ETH / USD的价值。最简单的方法是通过由特定方（例如纳斯达克）维护的“数据馈送”合同，以便该方能够根据需要更新合同，并提供一个接口，以允许其他合同发送向该合同发送消息并取回提供价格的响应。</p>\n<h6 id=\"身份和声誉系统\"><a href=\"#身份和声誉系统\" class=\"headerlink\" title=\"身份和声誉系统\"></a>身份和声誉系统</h6><p>所有的最早的替代性加密货币，<a href=\"http://namecoin.org/\" target=\"_blank\" rel=\"noopener\">Namecoin</a>试图使用类似比特币的<a href=\"http://namecoin.org/\" target=\"_blank\" rel=\"noopener\">区块</a>链来提供名称注册系统，用户可以在公共数据库中将他们的名称与其他数据一起注册。主要引用的用例是<a href=\"http://en.wikipedia.org/wiki/Domain_Name_System\" target=\"_blank\" rel=\"noopener\">DNS</a>系统，将域名（比如“bitcoin.org”）（或者在Namecoin的例子中，“bitcoin.bit”）映射到IP地址。其他用例包括电子邮件认证和潜在更高级的信誉系统。</p>\n<h6 id=\"分散的文件存储\"><a href=\"#分散的文件存储\" class=\"headerlink\" title=\"分散的文件存储\"></a>分散的文件存储</h6><p>以太坊合同可以允许开发分散式文件存储生态系统，个人用户可以通过租用自己的硬盘来赚取少量的资金，未使用的空间可以用来进一步降低文件存储成本。</p>\n<p>这种设备的关键在于我们称之为“分散式Dropbox合同”。该合同的工作如下。首先，将所需数据分成块，对每个块进行隐私加密，并从中构建一个Merkle树。然后用合约规则规定，每N个块，合约将在Merkle树中选择一个随机索引（使用之前的块散列，可从合同代码访问，作为随机源），并将X ether赋予第一个实体为该交易提供一个简化的支付验证类似树中该特定索引处块的所有权证明。当用户想要重新下载他们的文件时，他们可以使用微支付通道协议（例如，支付每32千字节1个szabo）来恢复文件;</p>\n<p>该协议的一个重要特点是，虽然看起来好像一个人相信许多随机节点不会决定忘记文件，但可以通过秘密共享将文件分割成许多块，从而将风险降低到接近于零，并且看合同，看看每件作品仍然在某个节点中。如果合同仍在支付金钱，那么它提供了一个密码证明，表明某人仍在存储该文件。</p>\n<h6 id=\"分散的自治组织\"><a href=\"#分散的自治组织\" class=\"headerlink\" title=\"分散的自治组织\"></a>分散的自治组织</h6><p>“分散式自治组织”的一般概念是拥有一定数量的成员或股东的虚拟实体的概念，这些成员或股东可能拥有67％的多数股东有权利用该实体的资金并修改其代码。成员们将共同决定组织如何分配资金。分配DAO资金的方法可以从赏金，工资到甚至更多外来机制（如内部货币）以奖励工作。这基本上复制了传统公司或非营利组织的法律标志，但仅使用加密区块链技术执行。</p>\n<p>参考地址如下</p>\n<ol>\n<li><a href=\"http://baijiahao.baidu.com/s?id=1595831842043592716&amp;wfr=spider&amp;for=pc\" target=\"_blank\" rel=\"noopener\">http://baijiahao.baidu.com/s?id=1595831842043592716&amp;wfr=spider&amp;for=pc</a></li>\n<li><a href=\"https://github.com/ethereum/wiki/wiki/White-Paper\">https://github.com/ethereum/wiki/wiki/White-Paper</a></li>\n</ol>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"以太坊基本认识和理解笔记\"><a href=\"#以太坊基本认识和理解笔记\" class=\"headerlink\" title=\"以太坊基本认识和理解笔记\"></a>以太坊基本认识和理解笔记</h2><h4 id=\"基本架构图\"><a href=\"#基本架构图\" class=\"headerlink\" title=\"基本架构图\"></a>基本架构图</h4><p>图…..</p>\n<p>核心模块: 基础结构，共识算法，网络模块，其它模块。这几个模块的内容，跟比特币的模块有点像啊。</p>\n<p>合约层是使用Solidity语言编写的智能合约，其运行在EVM以太坊虚拟机上，并会通过HTTP-RPC或JSON-RPC调用和以太坊的核心层交互。</p>\n<p>以太坊架构的最上层是DApp应用层，它通过Web3.js这种JavaScript API和智能合约层进行交互。</p>\n<h4 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h4><h5 id=\"ether\"><a href=\"#ether\" class=\"headerlink\" title=\"ether\"></a>ether</h5><p>ether为以太坊中的内置货币。例如，矿工挖出新矿时，奖励的便是ether。它的主要目的是提供主要流动性层，以实现各种数字资产之间的有效交换，更重要的是提供支付交易费用的机制。</p>\n<ul>\n<li><p>首先，谁需要ether呢？</p>\n<ol>\n<li>打算开发使用ethereum区块链的应用的开发者。</li>\n<li>想要在ethereum区块链上访问并与智能合同交互的用户。</li>\n</ol>\n</li>\n<li><p>其次，ether与bitcoin的关系是什么呢？</p>\n<blockquote>\n<p>Ethereum would never be possible without bitcoin—both the technology and the currency—and we see ourselves not as a competing currency but as complementary within the digital ecosystem. Ether is to be treated as “crypto-fuel”, a token whose purpose is to pay for computation, and is not intended to be used as or considered a currency, asset, share or anything else.</p>\n</blockquote>\n</li>\n</ul>\n<p>​         意思呢，就是二者并非竞争关系，而是互相补充的关系。ether的目的是计算付费，并不打算用作货币，资产，股票或其他任何东西。在一些以太坊的生态中，ether与bitcoin是可以进行价值兑换的。</p>\n<h5 id=\"gas\"><a href=\"#gas\" class=\"headerlink\" title=\"gas\"></a>gas</h5><p>gas为计算花费的基本单位。通常，一步的计算花费1gas，但是一些操作耗费更高的气体量，因为它们在计算上更昂贵，或者增加了作为状态的一部分必须存储的数据量。交易数据中的每个字节的费用5gas,收费系统的目的是要求攻击者按比例支付她们消费的每种资源，包括计算量，带宽和存储量。</p>\n<p>一笔交易，除了需要包含接收方，发件人签名，ether的数量，之外，还需要包含数据字段（可选），一个STARTGAS值，表示允许执行事务执行的最大计算步骤数，和一个GASPRICE值，即为每gas的花费的ether。</p>\n<p>举个例子，现有一笔交易，内容为发送的ether为10，STARTGAS为2000，GASPRICE为0.001，和一个64bytes的数据，那么计算允许的所需要的ether为单价*数量=2000 * 0.001=2。 比较详细的交易如下</p>\n<ol>\n<li><p>检查交易是否有效</p>\n</li>\n<li><p>检查发送方账户是否至少含有2000*0.001=2 ether, 如果有，则从发送方账户中减去2 ether</p>\n</li>\n<li><p>总共有2000gas, 假设交易长度为170bytes, 每bytes 5gas,那么减去850，剩余1150gas</p>\n</li>\n<li><p>从发送方账户余额中减去发送的10 ether, 并添加到合约账户中</p>\n</li>\n<li><p>运行代码进行计算，假设计算过程消耗了187gas, 那么剩余1150-187=963gas</p>\n</li>\n<li><p>将963gas转换为ether, 此项交易中单价是0.001，那么返回到发送方的ether为0.963</p>\n</li>\n</ol>\n<h5 id=\"账户\"><a href=\"#账户\" class=\"headerlink\" title=\"账户\"></a>账户</h5><p> 在以太坊中，状态由账户对象组成，每个账户都有一个20byte的地址，状态转换是账户之间价值和信息的直接转移。以太坊账户包含四个字段：</p>\n<ul>\n<li>nonce, 用来确保每笔交易柜台一次只能处理</li>\n<li>账户当前的ether余额</li>\n<li>账户的合约代码，如果存在的话</li>\n<li>账户的存储空间，默认为空</li>\n</ul>\n<p>通常，有两种账户，外部的个人拥有的账户，使用私钥进行控制； 以及合约账户，被合约代码控制。个人账户能够发送消息以及创建并签署交易。合约账户收到其激活码可读写内存，发送消息以及创建新的合约</p>\n<h5 id=\"消息和交易\"><a href=\"#消息和交易\" class=\"headerlink\" title=\"消息和交易\"></a>消息和交易</h5><p>交易需要包含以下内容：</p>\n<ul>\n<li>消息的收件人</li>\n<li>识别发件人的签名</li>\n<li>发送的ether数量</li>\n<li>可选的数据字段</li>\n<li>一个<code>STARTGAS</code>值，表示允许执行事务执行的最大计算步骤数</li>\n<li>一个<code>GASPRICE</code>值，表示发件人按计算步骤支付的费用</li>\n</ul>\n<p>消息包含：</p>\n<ul>\n<li>消息的发送者（隐式）</li>\n<li>消息的收件人</li>\n<li>与消息一起传输的ether数量</li>\n<li>可选的数据字段</li>\n<li>一个<code>STARTGAS</code>值</li>\n</ul>\n<p>从本质上讲，消息就像一个交易，除了它是由合同产生的而不是由外部参与者产生的。当一个正在执行代码的合同执行<code>CALL</code>操作码时，产生一条消息，该操作码产生并执行一条消息。就像一个交易，一条消息导致收件人账户运行其代码。因此，合约可以与外部参与者完全相同的方式与其他合约有关系。</p>\n<p>请注意，交易或合同分配的gas限额适用于该交易和所有子执行消耗的gas量。例如，如果外部参与者A向B发送1000个gas的事务，并且B在向C发送消息之前消耗600gas，并且C的内部执行在返回之前消耗300gas，则B在运行之前可以花费另外100个gas。</p>\n<p>请注意，消息在回复方面与事务等效：如果消息执行耗尽，那么该消息的执行以及该执行触发的所有其他执行都会恢复，但父执行不需要恢复。这意味着合同可以调用另一份合同是“安全的”，就好像A用G气调用B一样，那么A的执行保证最多会损失G气。最后，请注意，有一个操作码<code>CREATE</code>可以创建合同; 其执行机制通常与执行机制类似<code>CALL</code>，但执行输出决定了新创建合同的代码。</p>\n<h5 id=\"状态转换\"><a href=\"#状态转换\" class=\"headerlink\" title=\"状态转换\"></a>状态转换</h5><p>以太坊状态转换功能<code>APPLY(S,TX) -&gt; S&#39;</code>可以定义如下：</p>\n<ol>\n<li><p>检查交易是否格式正确（即具有正确数量的值），签名是否有效，并且nonce与发件人帐户中的nonce相匹配。如果不是，则返回错误。</p>\n</li>\n<li><p>计算交易费用<code>STARTGAS * GASPRICE</code>，并从签名确定发送地址。从发件人帐户余额中扣除费用并增加发件人的nonce。如果没有足够的余额可用，请返回错误。</p>\n</li>\n<li><p>初始化<code>GAS = STARTGAS</code>并在每个字节中取出一定数量的气体以支付交易中的字节数。</p>\n</li>\n<li><p>将交易金额从发件人的帐户转移到收款帐户。如果接收帐户尚不存在，请创建它。如果接收账户是合同，则运行合同代码以完成或直到执行用完为止。</p>\n</li>\n<li><p>如果由于发件人没有足够的资金或代码执行耗尽而导致价值转移失败，请恢复除支付费用之外的所有状态更改，并将费用添加到矿工帐户。</p>\n</li>\n<li><p>否则，将所有剩余天然气的费用退还给发送方，并将支付的天然气费用发送给矿工</p>\n</li>\n</ol>\n<h5 id=\"代码执行\"><a href=\"#代码执行\" class=\"headerlink\" title=\"代码执行\"></a>代码执行</h5><p>合约中的代码采用low-level,基于堆栈的字节码语言编写，称为”以太网虚拟机代码”或”EVM代码”。该代码由一系列字节组成，其中每个字节表示一个操作。一般来说，代码执行是在当前程序计数器(从零开始)重复执行操作，然后将程序计数器递增1，直到代码结束或错误<code>STOP</code>或<code>RETURN</code>指令被检测到的一个无限循环。这些操作可以访问三种类型的存储空间：</p>\n<ol>\n<li>堆栈，后进先出容器，其值可以被压入和弹出</li>\n<li>内存。一个无限扩展的字节数组</li>\n<li>合同的长期存储，一个key/value的存储，与计算结束后重置的堆栈和内存不同，存储长期存在。</li>\n</ol>\n<p>代码还可以访问传入消息的值，发送者和数据以及块头数据，代码也可以返回一个字节数组作为输出。</p>\n<p>EVM代码的正式执行模型非常简单。当以太坊虚拟机运行时，它的完整计算状态可以由元组定义<code>(block_state, transaction, message, code, memory, stack, pc, gas)</code>，其中<code>block_state</code>是包含所有帐户并包括余额和存储的全局状态。在每一轮执行开始时，当前的指令是通过取<code>pc</code>第<code>code</code>（或0 <code>pc &gt;= len(code)</code>）个字节的第n个字节来找到的，并且每条指令都有它自己的定义，以表明它如何影响元组。例如，<code>ADD</code>从堆叠中弹出两个物品并推动它们的总和，减<code>gas</code>1和增<code>pc</code>1，<code>SSTORE</code>从堆栈中弹出前两个项目，并将第二个项目插入到第一个项目指定的索引处的合同存储器中。虽然有很多方法可以通过即时编译来优化以太坊虚拟机的执行，但以太坊的基本实现可以通过几百行代码完成。</p>\n<h5 id=\"区块链和采矿\"><a href=\"#区块链和采矿\" class=\"headerlink\" title=\"区块链和采矿\"></a>区块链和采矿</h5><p>以太坊的区块链和比特币的区块链有很多地方相似，也有不同的地方。最大的不同点在于，以太坊区块包含交易列表及最新状态二者的副本，除此之外，在区块中还存储了两个其他的值，区块号，和难度（计算难度）。以太坊中的基本块验证算法如下：</p>\n<ol>\n<li>检查前面的块引用是否存在并且是有效的。</li>\n<li>检查块的时间戳大于引用的前一个块的时间戳，并且在未来15分钟内</li>\n<li>检查块号，难度，交易根，叔叔根和气体限制（各种低级以太坊特定概念）是否有效。</li>\n<li>检查块的工作证明是否有效。</li>\n<li>让我们<code>S[0]</code>成为上一个区块结束时的状态吧。</li>\n<li>让<code>TX</code>块成为具有<code>n</code>个交易的交易清单。对于所有<code>i</code>的<code>0...n-1</code>设置<code>S[i+1] = APPLY(S[i],TX[i])</code>。如果任何应用程序返回一个错误，或者如果在这个点上阻塞的气体总量超过了这个数量<code>GASLIMIT</code>，返回一个错误。</li>\n<li>我们<code>S_FINAL</code>是<code>S[n]</code>，而且将支付给矿工块奖励。</li>\n<li>检查状态的Merkle树根<code>S_FINAL</code>是否等于块头中提供的最终状态根。如果是，则该块有效; 否则，它是无效的。</li>\n</ol>\n<p>这种方法乍一看似乎效率很低，因为它需要在每个块中存储整个状态，但实际上效率应该与比特币相当。原因是状态存储在树状结构中，并且在每个块之后只需要改变树的一小部分。因此，一般来说，在两个相邻块之间，绝大多数树应该是相同的，因此数据可以被存储一次并且使用指针（即子树的散列）被引用两次。一种称为“Patricia树”的特殊树被用来实现这一点，包括对Merkle树概念的修改，允许节点被插入和删除，而不仅仅是有效地改变。另外，因为所有的状态信息都是最后一个块的一部分，没有必要存储整个区块链的历史——如果可以应用到比特币上，就可以计算出在太空中节省5-20x的成本。</p>\n<p>就物理硬件而言，一个常见问题是在哪里执行合同代码。这有一个简单的答案：执行合同代码的过程是状态转换函数的定义的一部分，它是块验证算法的一部分，所以如果一个事务被添加到块<code>B</code>中，该事务生成的代码执行将被执行所有节点现在和将来都会下载并验证块<code>B</code>。</p>\n<h5 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h5><p>总的来说，在以太坊之上有三种类型的应用程序。第一类是金融应用程序，为用户提供更强大的管理方式，并使用他们的资金签订合同。这包括子货币，金融衍生品，套期保值合约，储蓄钱包，遗嘱以及最终甚至是一些类别的全面雇佣合同。第二类是半金融应用，涉及金钱，但也有非常重要的非货币方面的工作; 一个完美的例子就是为计算问题的解决方案自我实施奖励。最后，还有诸如在线投票和分散治理等应用程序，这些应用程序根本没有财务。</p>\n<p>该章节并不完全，仅摘取了介绍部分，详细内容还需到<a href=\"https://github.com/ethereum/wiki/wiki/White-Paper\">以太坊白皮书</a>中查阅</p>\n<h6 id=\"令牌系统\"><a href=\"#令牌系统\" class=\"headerlink\" title=\"令牌系统\"></a>令牌系统</h6><p>区块链上的代币系统有许多应用程序，从代表资产（如美元或黄金）的子货币到公司股票，代表智能财产的单个代币，安全不可伪造的优惠券，甚至与常规值完全无关的代币系统，用作点激励制度。令牌系统在Ethereum中实现起来非常简单。要理解的关键是，所有货币或标记系统基本上都是一个数据库，只有一个操作：从A中减去X个单位并将X个单位给予B，但条件是（1）A至少有X个单位交易和（2）交易由A批准。实现令牌系统所需的一切就是将该逻辑实施到合同中。</p>\n<h6 id=\"金融衍生产品和稳定价值货币\"><a href=\"#金融衍生产品和稳定价值货币\" class=\"headerlink\" title=\"金融衍生产品和稳定价值货币\"></a>金融衍生产品和稳定价值货币</h6><p>金融衍生工具是“智能合约”中最常见的应用，也是最简单的代码实现之一。实施金融合同面临的主要挑战是，其中大部分要求参考外部价格报价; 例如，一个非常理想的应用程序是一种智能合约，可以抵御以太币（或另一种加密货币）相对于美元的波动性，但这样做需要合约知道ETH / USD的价值。最简单的方法是通过由特定方（例如纳斯达克）维护的“数据馈送”合同，以便该方能够根据需要更新合同，并提供一个接口，以允许其他合同发送向该合同发送消息并取回提供价格的响应。</p>\n<h6 id=\"身份和声誉系统\"><a href=\"#身份和声誉系统\" class=\"headerlink\" title=\"身份和声誉系统\"></a>身份和声誉系统</h6><p>所有的最早的替代性加密货币，<a href=\"http://namecoin.org/\" target=\"_blank\" rel=\"noopener\">Namecoin</a>试图使用类似比特币的<a href=\"http://namecoin.org/\" target=\"_blank\" rel=\"noopener\">区块</a>链来提供名称注册系统，用户可以在公共数据库中将他们的名称与其他数据一起注册。主要引用的用例是<a href=\"http://en.wikipedia.org/wiki/Domain_Name_System\" target=\"_blank\" rel=\"noopener\">DNS</a>系统，将域名（比如“bitcoin.org”）（或者在Namecoin的例子中，“bitcoin.bit”）映射到IP地址。其他用例包括电子邮件认证和潜在更高级的信誉系统。</p>\n<h6 id=\"分散的文件存储\"><a href=\"#分散的文件存储\" class=\"headerlink\" title=\"分散的文件存储\"></a>分散的文件存储</h6><p>以太坊合同可以允许开发分散式文件存储生态系统，个人用户可以通过租用自己的硬盘来赚取少量的资金，未使用的空间可以用来进一步降低文件存储成本。</p>\n<p>这种设备的关键在于我们称之为“分散式Dropbox合同”。该合同的工作如下。首先，将所需数据分成块，对每个块进行隐私加密，并从中构建一个Merkle树。然后用合约规则规定，每N个块，合约将在Merkle树中选择一个随机索引（使用之前的块散列，可从合同代码访问，作为随机源），并将X ether赋予第一个实体为该交易提供一个简化的支付验证类似树中该特定索引处块的所有权证明。当用户想要重新下载他们的文件时，他们可以使用微支付通道协议（例如，支付每32千字节1个szabo）来恢复文件;</p>\n<p>该协议的一个重要特点是，虽然看起来好像一个人相信许多随机节点不会决定忘记文件，但可以通过秘密共享将文件分割成许多块，从而将风险降低到接近于零，并且看合同，看看每件作品仍然在某个节点中。如果合同仍在支付金钱，那么它提供了一个密码证明，表明某人仍在存储该文件。</p>\n<h6 id=\"分散的自治组织\"><a href=\"#分散的自治组织\" class=\"headerlink\" title=\"分散的自治组织\"></a>分散的自治组织</h6><p>“分散式自治组织”的一般概念是拥有一定数量的成员或股东的虚拟实体的概念，这些成员或股东可能拥有67％的多数股东有权利用该实体的资金并修改其代码。成员们将共同决定组织如何分配资金。分配DAO资金的方法可以从赏金，工资到甚至更多外来机制（如内部货币）以奖励工作。这基本上复制了传统公司或非营利组织的法律标志，但仅使用加密区块链技术执行。</p>\n<p>参考地址如下</p>\n<ol>\n<li><a href=\"http://baijiahao.baidu.com/s?id=1595831842043592716&amp;wfr=spider&amp;for=pc\" target=\"_blank\" rel=\"noopener\">http://baijiahao.baidu.com/s?id=1595831842043592716&amp;wfr=spider&amp;for=pc</a></li>\n<li><a href=\"https://github.com/ethereum/wiki/wiki/White-Paper\">https://github.com/ethereum/wiki/wiki/White-Paper</a></li>\n</ol>\n"},{"title":"fabric_example","date":"2019-04-11T07:05:29.000Z","_content":"\nfabric-examples学习笔记\n\n由于docker images下载的速度实在太… 这个时间就先看看examples吧\n\n版本release-1.1\n\n\n\nchaincode\n\n- Example-01\n\n    func main() {\n    \terr := shim.Start(new(SimpleChaincode))\n    \tif err != nil {\n    \t\tfmt.Printf(\"Error starting Simple chaincode: %s\", err)\n    \t}\n    }\n\n第一个例子就详细看一下结构，后面的都类似。\n\nmain方法里shim.Start(new(结构体))是入口，所有代码实现的部分都是实现这个结构体。这个结构体需要实现的方法\n\n-     Init(stub shim.ChaincodeStubInterface) pb.Response\n-     Invoke(stub shim.ChaincodeStubInterface) pb.Response\n\n在这个例子中，有两个账户及其余额，Init方法为设置两个账户的名字及余额。Invoke方法实现的是从A账户转账到B账户。顾名思义的话，Init为初始化方法，Invoke猜测应该是使用反射，可实现为分发的功能，分发到其他方法中，实现具体相应功能。例如\n\n    func (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\n    \tfunction, args := stub.GetFunctionAndParameters() //获取调用的方法名及其参数\n    \tif function == \"invoke\" {\n    \t\t// Make payment of X units from A to B\n    \t\treturn t.invoke(stub, args)  //调用相应方法\n    \t} else if function == \"delete\" {\n    \t\t// Deletes an entity from its state\n    \t\treturn t.delete(stub, args)  //调用相应方法\n    \t} else if function == \"query\" {\n    \t\t// the old \"Query\" is now implemtned in invoke\n    \t\treturn t.query(stub, args)  //调用相应方法\n    \t}\n\n    \treturn shim.Error(\"Invalid invoke function name. Expecting \\\"invoke\\\" \\\"delete\\\" \\\"query\\\"\")\n    }\n\n好吧其实这是example-02的代码了  - . -\n\n\n\n- Example-02\n\n功能上来说的话，01是两个固定的账户，02是账本上的两个账户的操作。第一，操作增多了，有查询删除，实现为在invoke中进行分发，代码如上…第二，牵涉到账本了，看似像一个key-value的数据存储，代码如下\n\n    //存\n    err = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n    //取\n    Avalbytes, err := stub.GetState(A)\n\n猜测肯定是数据库方面的了，更深入的之后再看。尤其是stub，shim.ChaincodeStubInterface。这个对象是所有跟上层接轨的接口，其实现需要查看。这里先略过\n\n\n\n- Example -03\n\n这个例子中，好像重点在下面这个代码\n\n    func (t *SimpleChaincode) query(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n      ···\n      // Write the state to the ledger - this put is illegal within Run\n    \terr = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n      ···\n    }\n\n意思好像是在query方法中不能进行putState。延伸一下的话，是只有在原始invoke方法中才能进行putState，修改数据库。当然啦，这个小写的invoke方法也是可以实现的\n\n\n\n- Example-04\n\n这个例子为example了在链码中调用其他链码，主要api为\n\n    response := stub.InvokeChaincode(chainCodeToCall, invokeArgs, channelID)\n\n- Example-05\n\n这个例子也是调用其他链码，但是说明了调用的链码和当前链码不是同一个channel上需要指明channel。这个不是很明白。\n\n使用InvokeChaincode方法，传入的参数依次是 被调用的链码名称，调用参数(包括调用方法和参数)， channel name\n\n看4，5test并没有看出来4 5调用的差别...\n\n\n\n- Test\n\n    \tscc := new(SimpleChaincode)\n    \tstub := shim.NewMockStub(\"ex03\", scc)\n    \tres := stub.MockInvoke(\"1\", [][]byte{[]byte(\"query\"), []byte(\"A\"), []byte(\"345\"))\n    \tif res.Status != shim.OK {\n    \t\tfmt.Println(\"Query failed\", string(res.Message))\n    \t\tt.FailNow()\n    \t}\n\n\n\n还有个启动两个链码的\n\n    \tscc := new(SimpleChaincode)\n    \tstub := shim.NewMockStub(\"ex05\", scc)\n\n    \tccEx2 := new(ex02.SimpleChaincode)\n    \tstubEx2 := shim.NewMockStub(chaincodeName, ccEx2)\n    \tcheckInit(t, stubEx2, [][]byte{[]byte(\"init\"), []byte(\"a\"), []byte(\"222\"), []byte(\"b\"), []byte(\"333\")})\n    \t//在当前模拟peer，添加chaincode\n    \tstub.MockPeerChaincode(chaincodeName, stubEx2)\n\n\n\n\n\n看官方文档的介绍，Tutorials似乎提供了4个tutorial，分别为Application开发(使用的node sdk)、网络搭建、链码开发、链码操作。作为入门的话，肯定要都过一遍啦~\n\n\n\n网络搭建\n\n示例中包含2组，每组2个peer节点，以及1个单独的order服务\n\n首先clone fabric-example仓库，然后找到下载docker images的地方，下载docker-images官方是使用curl … | bash 的一行命令，下载速度很慢，经过网上很多好心人提示，说curl 那个连接其实是一个脚本，直接用网站打开那个连接，复制粘贴脚本到本地，命名*.sh，然后直接运行就好了，这个脚本大概看一下，有3个方法的调用，2个方法都有下载docker images, 还有1个方法是下载二进制文件，这个二进制文件下载后会保存在当前目录下的bin文件夹下。bin里面的内容如下\n\n    $ ls\n    configtxgen\t\tconfigtxlator\t\tcryptogen\t\tget-docker-images.sh\torderer\t\t\tpeer\n\n然后把这个bin文件夹拷贝到fabric-example下。\n\n    $ cd first-network\n    $ ./byfn.sh -m generate\n\n如果bin里面内容缺失，这里就会报各种命令不存在。再则，下载的fabric-example的版本应该和二进制可执行文件的版本一致，不然还是会报错..可直接修改下载脚本里的版本。\n\n    $ ./byfn.sh -m up\n\n其中，对于版本问题是是严谨。各个版本都要一样。另外，上面提到的那个curl 链接的那个脚本，在fabric仓库下其实是有的，script/bootstrap.sh。可直接拷贝粘贴\n\n\n\n然后针对byfn脚本具体分析一下整个过程和结构的吧~\n\n☝️，$ ./byfn.sh -m generate的功能。\n\n- 使用cryptogen工具来为节点生成加密证书。这些证书可代表节点的身份，被允许签署/验证身份验证进行实体沟通和交易。\n  - cryptogen通过配置文件进行工作，配置文件中定义了各个节点信息。如crypto-config.yaml\n        OrdererOrgs:\n          - Name: Orderer\n            Domain: example.com\n            # ---------------------------------------------------------------------------\n            # \"Specs\" - See PeerOrgs below for complete description\n            # ---------------------------------------------------------------------------\n            Specs:\n              - Hostname: orderer\n        PeerOrgs:\n        # -----------------------------------------------------\n        # Org1\n        # ----------------------------------------------------\n        - Name: Org1\n          Domain: org1.example.com\n          Template:\n              Count: 2\n          Users:\n              Count: 1\n    使用命令为cryptogen generate --config=./crypto-config.yaml，成功后会在当前文件夹下生成crypto-config文件夹,  各个证书以节点角色/Domain/…的文件形式存在\n- 使用configtxgen tool来生成一些部署实体所需要的零件。也需要配置文件，配置文件定义了网络模板。主要零件类型有\n  - orderer genesis block, orderer服务启动必备，注意的是每个组织的根证书都包含在gensis.block中。\n  - channel configuration transaction, 该配置在orderer服务启动创建channel时配置channel。这里就已经形成了channel的读写策略（即哪些实体可以读，哪些实体可以写，下同）。\n  - and two anchor peer transactions - one for each Peer Org. 用于指定在channel中，当前peer组织中都有哪些peer结点。这里就已经形成了组织的读写策略。\n\n- 最后就是 up启动网络了，最重要的命令即... docker-compose -f $COMPOSE_FILE...， 查看docker-compose-cli.yaml，定义了6个容器服务，其中最后一个为cli, 执行为./scripts/script.sh。查看这个脚本大概为创建channel、加入channel、升级组织配置、安装部署chaincode、调用chaincode...后面每一步应该都会自己搞一次..这里还是先跳过\n  到这里，我就感觉脑子里放不下东西了已经，很尴尬…先跟着向导继续走吧\n\n  嗯,  很难受。\n\n  具体看了一下cli， 大致是将证书，script等都作为数据卷挂载到容器上，然后在容器上调用script操作。channel的加入，似乎是通过各证书验证身份。链码的部署调用都是通过peer chaincode … 命令进行\n","source":"_posts/fabric-example.md","raw":"---\ntitle: fabric_example\ncategories:\n  - fabric\ndate: 2019-4-11 15:05:29\ntags:\n---\n\nfabric-examples学习笔记\n\n由于docker images下载的速度实在太… 这个时间就先看看examples吧\n\n版本release-1.1\n\n\n\nchaincode\n\n- Example-01\n\n    func main() {\n    \terr := shim.Start(new(SimpleChaincode))\n    \tif err != nil {\n    \t\tfmt.Printf(\"Error starting Simple chaincode: %s\", err)\n    \t}\n    }\n\n第一个例子就详细看一下结构，后面的都类似。\n\nmain方法里shim.Start(new(结构体))是入口，所有代码实现的部分都是实现这个结构体。这个结构体需要实现的方法\n\n-     Init(stub shim.ChaincodeStubInterface) pb.Response\n-     Invoke(stub shim.ChaincodeStubInterface) pb.Response\n\n在这个例子中，有两个账户及其余额，Init方法为设置两个账户的名字及余额。Invoke方法实现的是从A账户转账到B账户。顾名思义的话，Init为初始化方法，Invoke猜测应该是使用反射，可实现为分发的功能，分发到其他方法中，实现具体相应功能。例如\n\n    func (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\n    \tfunction, args := stub.GetFunctionAndParameters() //获取调用的方法名及其参数\n    \tif function == \"invoke\" {\n    \t\t// Make payment of X units from A to B\n    \t\treturn t.invoke(stub, args)  //调用相应方法\n    \t} else if function == \"delete\" {\n    \t\t// Deletes an entity from its state\n    \t\treturn t.delete(stub, args)  //调用相应方法\n    \t} else if function == \"query\" {\n    \t\t// the old \"Query\" is now implemtned in invoke\n    \t\treturn t.query(stub, args)  //调用相应方法\n    \t}\n\n    \treturn shim.Error(\"Invalid invoke function name. Expecting \\\"invoke\\\" \\\"delete\\\" \\\"query\\\"\")\n    }\n\n好吧其实这是example-02的代码了  - . -\n\n\n\n- Example-02\n\n功能上来说的话，01是两个固定的账户，02是账本上的两个账户的操作。第一，操作增多了，有查询删除，实现为在invoke中进行分发，代码如上…第二，牵涉到账本了，看似像一个key-value的数据存储，代码如下\n\n    //存\n    err = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n    //取\n    Avalbytes, err := stub.GetState(A)\n\n猜测肯定是数据库方面的了，更深入的之后再看。尤其是stub，shim.ChaincodeStubInterface。这个对象是所有跟上层接轨的接口，其实现需要查看。这里先略过\n\n\n\n- Example -03\n\n这个例子中，好像重点在下面这个代码\n\n    func (t *SimpleChaincode) query(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n      ···\n      // Write the state to the ledger - this put is illegal within Run\n    \terr = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n      ···\n    }\n\n意思好像是在query方法中不能进行putState。延伸一下的话，是只有在原始invoke方法中才能进行putState，修改数据库。当然啦，这个小写的invoke方法也是可以实现的\n\n\n\n- Example-04\n\n这个例子为example了在链码中调用其他链码，主要api为\n\n    response := stub.InvokeChaincode(chainCodeToCall, invokeArgs, channelID)\n\n- Example-05\n\n这个例子也是调用其他链码，但是说明了调用的链码和当前链码不是同一个channel上需要指明channel。这个不是很明白。\n\n使用InvokeChaincode方法，传入的参数依次是 被调用的链码名称，调用参数(包括调用方法和参数)， channel name\n\n看4，5test并没有看出来4 5调用的差别...\n\n\n\n- Test\n\n    \tscc := new(SimpleChaincode)\n    \tstub := shim.NewMockStub(\"ex03\", scc)\n    \tres := stub.MockInvoke(\"1\", [][]byte{[]byte(\"query\"), []byte(\"A\"), []byte(\"345\"))\n    \tif res.Status != shim.OK {\n    \t\tfmt.Println(\"Query failed\", string(res.Message))\n    \t\tt.FailNow()\n    \t}\n\n\n\n还有个启动两个链码的\n\n    \tscc := new(SimpleChaincode)\n    \tstub := shim.NewMockStub(\"ex05\", scc)\n\n    \tccEx2 := new(ex02.SimpleChaincode)\n    \tstubEx2 := shim.NewMockStub(chaincodeName, ccEx2)\n    \tcheckInit(t, stubEx2, [][]byte{[]byte(\"init\"), []byte(\"a\"), []byte(\"222\"), []byte(\"b\"), []byte(\"333\")})\n    \t//在当前模拟peer，添加chaincode\n    \tstub.MockPeerChaincode(chaincodeName, stubEx2)\n\n\n\n\n\n看官方文档的介绍，Tutorials似乎提供了4个tutorial，分别为Application开发(使用的node sdk)、网络搭建、链码开发、链码操作。作为入门的话，肯定要都过一遍啦~\n\n\n\n网络搭建\n\n示例中包含2组，每组2个peer节点，以及1个单独的order服务\n\n首先clone fabric-example仓库，然后找到下载docker images的地方，下载docker-images官方是使用curl … | bash 的一行命令，下载速度很慢，经过网上很多好心人提示，说curl 那个连接其实是一个脚本，直接用网站打开那个连接，复制粘贴脚本到本地，命名*.sh，然后直接运行就好了，这个脚本大概看一下，有3个方法的调用，2个方法都有下载docker images, 还有1个方法是下载二进制文件，这个二进制文件下载后会保存在当前目录下的bin文件夹下。bin里面的内容如下\n\n    $ ls\n    configtxgen\t\tconfigtxlator\t\tcryptogen\t\tget-docker-images.sh\torderer\t\t\tpeer\n\n然后把这个bin文件夹拷贝到fabric-example下。\n\n    $ cd first-network\n    $ ./byfn.sh -m generate\n\n如果bin里面内容缺失，这里就会报各种命令不存在。再则，下载的fabric-example的版本应该和二进制可执行文件的版本一致，不然还是会报错..可直接修改下载脚本里的版本。\n\n    $ ./byfn.sh -m up\n\n其中，对于版本问题是是严谨。各个版本都要一样。另外，上面提到的那个curl 链接的那个脚本，在fabric仓库下其实是有的，script/bootstrap.sh。可直接拷贝粘贴\n\n\n\n然后针对byfn脚本具体分析一下整个过程和结构的吧~\n\n☝️，$ ./byfn.sh -m generate的功能。\n\n- 使用cryptogen工具来为节点生成加密证书。这些证书可代表节点的身份，被允许签署/验证身份验证进行实体沟通和交易。\n  - cryptogen通过配置文件进行工作，配置文件中定义了各个节点信息。如crypto-config.yaml\n        OrdererOrgs:\n          - Name: Orderer\n            Domain: example.com\n            # ---------------------------------------------------------------------------\n            # \"Specs\" - See PeerOrgs below for complete description\n            # ---------------------------------------------------------------------------\n            Specs:\n              - Hostname: orderer\n        PeerOrgs:\n        # -----------------------------------------------------\n        # Org1\n        # ----------------------------------------------------\n        - Name: Org1\n          Domain: org1.example.com\n          Template:\n              Count: 2\n          Users:\n              Count: 1\n    使用命令为cryptogen generate --config=./crypto-config.yaml，成功后会在当前文件夹下生成crypto-config文件夹,  各个证书以节点角色/Domain/…的文件形式存在\n- 使用configtxgen tool来生成一些部署实体所需要的零件。也需要配置文件，配置文件定义了网络模板。主要零件类型有\n  - orderer genesis block, orderer服务启动必备，注意的是每个组织的根证书都包含在gensis.block中。\n  - channel configuration transaction, 该配置在orderer服务启动创建channel时配置channel。这里就已经形成了channel的读写策略（即哪些实体可以读，哪些实体可以写，下同）。\n  - and two anchor peer transactions - one for each Peer Org. 用于指定在channel中，当前peer组织中都有哪些peer结点。这里就已经形成了组织的读写策略。\n\n- 最后就是 up启动网络了，最重要的命令即... docker-compose -f $COMPOSE_FILE...， 查看docker-compose-cli.yaml，定义了6个容器服务，其中最后一个为cli, 执行为./scripts/script.sh。查看这个脚本大概为创建channel、加入channel、升级组织配置、安装部署chaincode、调用chaincode...后面每一步应该都会自己搞一次..这里还是先跳过\n  到这里，我就感觉脑子里放不下东西了已经，很尴尬…先跟着向导继续走吧\n\n  嗯,  很难受。\n\n  具体看了一下cli， 大致是将证书，script等都作为数据卷挂载到容器上，然后在容器上调用script操作。channel的加入，似乎是通过各证书验证身份。链码的部署调用都是通过peer chaincode … 命令进行\n","slug":"fabric-example","published":1,"updated":"2019-10-14T07:06:19.696Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69x7002et6xv66rijl73","content":"<p>fabric-examples学习笔记</p>\n<p>由于docker images下载的速度实在太… 这个时间就先看看examples吧</p>\n<p>版本release-1.1</p>\n<p>chaincode</p>\n<ul>\n<li><p>Example-01</p>\n<p>  func main() {</p>\n<pre><code>err := shim.Start(new(SimpleChaincode))\nif err != nil {\n    fmt.Printf(&quot;Error starting Simple chaincode: %s&quot;, err)\n}</code></pre><p>  }</p>\n</li>\n</ul>\n<p>第一个例子就详细看一下结构，后面的都类似。</p>\n<p>main方法里shim.Start(new(结构体))是入口，所有代码实现的部分都是实现这个结构体。这个结构体需要实现的方法</p>\n<ul>\n<li>Init(stub shim.ChaincodeStubInterface) pb.Response</li>\n<li>Invoke(stub shim.ChaincodeStubInterface) pb.Response</li>\n</ul>\n<p>在这个例子中，有两个账户及其余额，Init方法为设置两个账户的名字及余额。Invoke方法实现的是从A账户转账到B账户。顾名思义的话，Init为初始化方法，Invoke猜测应该是使用反射，可实现为分发的功能，分发到其他方法中，实现具体相应功能。例如</p>\n<pre><code>func (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\n    function, args := stub.GetFunctionAndParameters() //获取调用的方法名及其参数\n    if function == &quot;invoke&quot; {\n        // Make payment of X units from A to B\n        return t.invoke(stub, args)  //调用相应方法\n    } else if function == &quot;delete&quot; {\n        // Deletes an entity from its state\n        return t.delete(stub, args)  //调用相应方法\n    } else if function == &quot;query&quot; {\n        // the old &quot;Query&quot; is now implemtned in invoke\n        return t.query(stub, args)  //调用相应方法\n    }\n\n    return shim.Error(&quot;Invalid invoke function name. Expecting \\&quot;invoke\\&quot; \\&quot;delete\\&quot; \\&quot;query\\&quot;&quot;)\n}</code></pre><p>好吧其实这是example-02的代码了  - . -</p>\n<ul>\n<li>Example-02</li>\n</ul>\n<p>功能上来说的话，01是两个固定的账户，02是账本上的两个账户的操作。第一，操作增多了，有查询删除，实现为在invoke中进行分发，代码如上…第二，牵涉到账本了，看似像一个key-value的数据存储，代码如下</p>\n<pre><code>//存\nerr = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n//取\nAvalbytes, err := stub.GetState(A)</code></pre><p>猜测肯定是数据库方面的了，更深入的之后再看。尤其是stub，shim.ChaincodeStubInterface。这个对象是所有跟上层接轨的接口，其实现需要查看。这里先略过</p>\n<ul>\n<li>Example -03</li>\n</ul>\n<p>这个例子中，好像重点在下面这个代码</p>\n<pre><code>func (t *SimpleChaincode) query(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n  ···\n  // Write the state to the ledger - this put is illegal within Run\n    err = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n  ···\n}</code></pre><p>意思好像是在query方法中不能进行putState。延伸一下的话，是只有在原始invoke方法中才能进行putState，修改数据库。当然啦，这个小写的invoke方法也是可以实现的</p>\n<ul>\n<li>Example-04</li>\n</ul>\n<p>这个例子为example了在链码中调用其他链码，主要api为</p>\n<pre><code>response := stub.InvokeChaincode(chainCodeToCall, invokeArgs, channelID)</code></pre><ul>\n<li>Example-05</li>\n</ul>\n<p>这个例子也是调用其他链码，但是说明了调用的链码和当前链码不是同一个channel上需要指明channel。这个不是很明白。</p>\n<p>使用InvokeChaincode方法，传入的参数依次是 被调用的链码名称，调用参数(包括调用方法和参数)， channel name</p>\n<p>看4，5test并没有看出来4 5调用的差别…</p>\n<ul>\n<li><p>Test</p>\n<pre><code>scc := new(SimpleChaincode)\nstub := shim.NewMockStub(&quot;ex03&quot;, scc)\nres := stub.MockInvoke(&quot;1&quot;, [][]byte{[]byte(&quot;query&quot;), []byte(&quot;A&quot;), []byte(&quot;345&quot;))\nif res.Status != shim.OK {\n    fmt.Println(&quot;Query failed&quot;, string(res.Message))\n    t.FailNow()\n}</code></pre></li>\n</ul>\n<p>还有个启动两个链码的</p>\n<pre><code>scc := new(SimpleChaincode)\nstub := shim.NewMockStub(&quot;ex05&quot;, scc)\n\nccEx2 := new(ex02.SimpleChaincode)\nstubEx2 := shim.NewMockStub(chaincodeName, ccEx2)\ncheckInit(t, stubEx2, [][]byte{[]byte(&quot;init&quot;), []byte(&quot;a&quot;), []byte(&quot;222&quot;), []byte(&quot;b&quot;), []byte(&quot;333&quot;)})\n//在当前模拟peer，添加chaincode\nstub.MockPeerChaincode(chaincodeName, stubEx2)</code></pre><p>看官方文档的介绍，Tutorials似乎提供了4个tutorial，分别为Application开发(使用的node sdk)、网络搭建、链码开发、链码操作。作为入门的话，肯定要都过一遍啦~</p>\n<p>网络搭建</p>\n<p>示例中包含2组，每组2个peer节点，以及1个单独的order服务</p>\n<p>首先clone fabric-example仓库，然后找到下载docker images的地方，下载docker-images官方是使用curl … | bash 的一行命令，下载速度很慢，经过网上很多好心人提示，说curl 那个连接其实是一个脚本，直接用网站打开那个连接，复制粘贴脚本到本地，命名*.sh，然后直接运行就好了，这个脚本大概看一下，有3个方法的调用，2个方法都有下载docker images, 还有1个方法是下载二进制文件，这个二进制文件下载后会保存在当前目录下的bin文件夹下。bin里面的内容如下</p>\n<pre><code>$ ls\nconfigtxgen        configtxlator        cryptogen        get-docker-images.sh    orderer            peer</code></pre><p>然后把这个bin文件夹拷贝到fabric-example下。</p>\n<pre><code>$ cd first-network\n$ ./byfn.sh -m generate</code></pre><p>如果bin里面内容缺失，这里就会报各种命令不存在。再则，下载的fabric-example的版本应该和二进制可执行文件的版本一致，不然还是会报错..可直接修改下载脚本里的版本。</p>\n<pre><code>$ ./byfn.sh -m up</code></pre><p>其中，对于版本问题是是严谨。各个版本都要一样。另外，上面提到的那个curl 链接的那个脚本，在fabric仓库下其实是有的，script/bootstrap.sh。可直接拷贝粘贴</p>\n<p>然后针对byfn脚本具体分析一下整个过程和结构的吧~</p>\n<p>☝️，$ ./byfn.sh -m generate的功能。</p>\n<ul>\n<li><p>使用cryptogen工具来为节点生成加密证书。这些证书可代表节点的身份，被允许签署/验证身份验证进行实体沟通和交易。</p>\n<ul>\n<li>cryptogen通过配置文件进行工作，配置文件中定义了各个节点信息。如crypto-config.yaml<pre><code>OrdererOrgs:\n  - Name: Orderer\n    Domain: example.com\n    # ---------------------------------------------------------------------------\n    # &quot;Specs&quot; - See PeerOrgs below for complete description\n    # ---------------------------------------------------------------------------\n    Specs:\n      - Hostname: orderer\nPeerOrgs:\n# -----------------------------------------------------\n# Org1\n# ----------------------------------------------------\n- Name: Org1\n  Domain: org1.example.com\n  Template:\n      Count: 2\n  Users:\n      Count: 1</code></pre>使用命令为cryptogen generate –config=./crypto-config.yaml，成功后会在当前文件夹下生成crypto-config文件夹,  各个证书以节点角色/Domain/…的文件形式存在</li>\n</ul>\n</li>\n<li><p>使用configtxgen tool来生成一些部署实体所需要的零件。也需要配置文件，配置文件定义了网络模板。主要零件类型有</p>\n<ul>\n<li>orderer genesis block, orderer服务启动必备，注意的是每个组织的根证书都包含在gensis.block中。</li>\n<li>channel configuration transaction, 该配置在orderer服务启动创建channel时配置channel。这里就已经形成了channel的读写策略（即哪些实体可以读，哪些实体可以写，下同）。</li>\n<li>and two anchor peer transactions - one for each Peer Org. 用于指定在channel中，当前peer组织中都有哪些peer结点。这里就已经形成了组织的读写策略。</li>\n</ul>\n</li>\n<li><p>最后就是 up启动网络了，最重要的命令即… docker-compose -f $COMPOSE_FILE…， 查看docker-compose-cli.yaml，定义了6个容器服务，其中最后一个为cli, 执行为./scripts/script.sh。查看这个脚本大概为创建channel、加入channel、升级组织配置、安装部署chaincode、调用chaincode…后面每一步应该都会自己搞一次..这里还是先跳过<br>到这里，我就感觉脑子里放不下东西了已经，很尴尬…先跟着向导继续走吧</p>\n<p>嗯,  很难受。</p>\n<p>具体看了一下cli， 大致是将证书，script等都作为数据卷挂载到容器上，然后在容器上调用script操作。channel的加入，似乎是通过各证书验证身份。链码的部署调用都是通过peer chaincode … 命令进行</p>\n</li>\n</ul>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<p>fabric-examples学习笔记</p>\n<p>由于docker images下载的速度实在太… 这个时间就先看看examples吧</p>\n<p>版本release-1.1</p>\n<p>chaincode</p>\n<ul>\n<li><p>Example-01</p>\n<p>  func main() {</p>\n<pre><code>err := shim.Start(new(SimpleChaincode))\nif err != nil {\n    fmt.Printf(&quot;Error starting Simple chaincode: %s&quot;, err)\n}</code></pre><p>  }</p>\n</li>\n</ul>\n<p>第一个例子就详细看一下结构，后面的都类似。</p>\n<p>main方法里shim.Start(new(结构体))是入口，所有代码实现的部分都是实现这个结构体。这个结构体需要实现的方法</p>\n<ul>\n<li>Init(stub shim.ChaincodeStubInterface) pb.Response</li>\n<li>Invoke(stub shim.ChaincodeStubInterface) pb.Response</li>\n</ul>\n<p>在这个例子中，有两个账户及其余额，Init方法为设置两个账户的名字及余额。Invoke方法实现的是从A账户转账到B账户。顾名思义的话，Init为初始化方法，Invoke猜测应该是使用反射，可实现为分发的功能，分发到其他方法中，实现具体相应功能。例如</p>\n<pre><code>func (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\n    function, args := stub.GetFunctionAndParameters() //获取调用的方法名及其参数\n    if function == &quot;invoke&quot; {\n        // Make payment of X units from A to B\n        return t.invoke(stub, args)  //调用相应方法\n    } else if function == &quot;delete&quot; {\n        // Deletes an entity from its state\n        return t.delete(stub, args)  //调用相应方法\n    } else if function == &quot;query&quot; {\n        // the old &quot;Query&quot; is now implemtned in invoke\n        return t.query(stub, args)  //调用相应方法\n    }\n\n    return shim.Error(&quot;Invalid invoke function name. Expecting \\&quot;invoke\\&quot; \\&quot;delete\\&quot; \\&quot;query\\&quot;&quot;)\n}</code></pre><p>好吧其实这是example-02的代码了  - . -</p>\n<ul>\n<li>Example-02</li>\n</ul>\n<p>功能上来说的话，01是两个固定的账户，02是账本上的两个账户的操作。第一，操作增多了，有查询删除，实现为在invoke中进行分发，代码如上…第二，牵涉到账本了，看似像一个key-value的数据存储，代码如下</p>\n<pre><code>//存\nerr = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n//取\nAvalbytes, err := stub.GetState(A)</code></pre><p>猜测肯定是数据库方面的了，更深入的之后再看。尤其是stub，shim.ChaincodeStubInterface。这个对象是所有跟上层接轨的接口，其实现需要查看。这里先略过</p>\n<ul>\n<li>Example -03</li>\n</ul>\n<p>这个例子中，好像重点在下面这个代码</p>\n<pre><code>func (t *SimpleChaincode) query(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n  ···\n  // Write the state to the ledger - this put is illegal within Run\n    err = stub.PutState(A, []byte(strconv.Itoa(Aval)))\n  ···\n}</code></pre><p>意思好像是在query方法中不能进行putState。延伸一下的话，是只有在原始invoke方法中才能进行putState，修改数据库。当然啦，这个小写的invoke方法也是可以实现的</p>\n<ul>\n<li>Example-04</li>\n</ul>\n<p>这个例子为example了在链码中调用其他链码，主要api为</p>\n<pre><code>response := stub.InvokeChaincode(chainCodeToCall, invokeArgs, channelID)</code></pre><ul>\n<li>Example-05</li>\n</ul>\n<p>这个例子也是调用其他链码，但是说明了调用的链码和当前链码不是同一个channel上需要指明channel。这个不是很明白。</p>\n<p>使用InvokeChaincode方法，传入的参数依次是 被调用的链码名称，调用参数(包括调用方法和参数)， channel name</p>\n<p>看4，5test并没有看出来4 5调用的差别…</p>\n<ul>\n<li><p>Test</p>\n<pre><code>scc := new(SimpleChaincode)\nstub := shim.NewMockStub(&quot;ex03&quot;, scc)\nres := stub.MockInvoke(&quot;1&quot;, [][]byte{[]byte(&quot;query&quot;), []byte(&quot;A&quot;), []byte(&quot;345&quot;))\nif res.Status != shim.OK {\n    fmt.Println(&quot;Query failed&quot;, string(res.Message))\n    t.FailNow()\n}</code></pre></li>\n</ul>\n<p>还有个启动两个链码的</p>\n<pre><code>scc := new(SimpleChaincode)\nstub := shim.NewMockStub(&quot;ex05&quot;, scc)\n\nccEx2 := new(ex02.SimpleChaincode)\nstubEx2 := shim.NewMockStub(chaincodeName, ccEx2)\ncheckInit(t, stubEx2, [][]byte{[]byte(&quot;init&quot;), []byte(&quot;a&quot;), []byte(&quot;222&quot;), []byte(&quot;b&quot;), []byte(&quot;333&quot;)})\n//在当前模拟peer，添加chaincode\nstub.MockPeerChaincode(chaincodeName, stubEx2)</code></pre><p>看官方文档的介绍，Tutorials似乎提供了4个tutorial，分别为Application开发(使用的node sdk)、网络搭建、链码开发、链码操作。作为入门的话，肯定要都过一遍啦~</p>\n<p>网络搭建</p>\n<p>示例中包含2组，每组2个peer节点，以及1个单独的order服务</p>\n<p>首先clone fabric-example仓库，然后找到下载docker images的地方，下载docker-images官方是使用curl … | bash 的一行命令，下载速度很慢，经过网上很多好心人提示，说curl 那个连接其实是一个脚本，直接用网站打开那个连接，复制粘贴脚本到本地，命名*.sh，然后直接运行就好了，这个脚本大概看一下，有3个方法的调用，2个方法都有下载docker images, 还有1个方法是下载二进制文件，这个二进制文件下载后会保存在当前目录下的bin文件夹下。bin里面的内容如下</p>\n<pre><code>$ ls\nconfigtxgen        configtxlator        cryptogen        get-docker-images.sh    orderer            peer</code></pre><p>然后把这个bin文件夹拷贝到fabric-example下。</p>\n<pre><code>$ cd first-network\n$ ./byfn.sh -m generate</code></pre><p>如果bin里面内容缺失，这里就会报各种命令不存在。再则，下载的fabric-example的版本应该和二进制可执行文件的版本一致，不然还是会报错..可直接修改下载脚本里的版本。</p>\n<pre><code>$ ./byfn.sh -m up</code></pre><p>其中，对于版本问题是是严谨。各个版本都要一样。另外，上面提到的那个curl 链接的那个脚本，在fabric仓库下其实是有的，script/bootstrap.sh。可直接拷贝粘贴</p>\n<p>然后针对byfn脚本具体分析一下整个过程和结构的吧~</p>\n<p>☝️，$ ./byfn.sh -m generate的功能。</p>\n<ul>\n<li><p>使用cryptogen工具来为节点生成加密证书。这些证书可代表节点的身份，被允许签署/验证身份验证进行实体沟通和交易。</p>\n<ul>\n<li>cryptogen通过配置文件进行工作，配置文件中定义了各个节点信息。如crypto-config.yaml<pre><code>OrdererOrgs:\n  - Name: Orderer\n    Domain: example.com\n    # ---------------------------------------------------------------------------\n    # &quot;Specs&quot; - See PeerOrgs below for complete description\n    # ---------------------------------------------------------------------------\n    Specs:\n      - Hostname: orderer\nPeerOrgs:\n# -----------------------------------------------------\n# Org1\n# ----------------------------------------------------\n- Name: Org1\n  Domain: org1.example.com\n  Template:\n      Count: 2\n  Users:\n      Count: 1</code></pre>使用命令为cryptogen generate –config=./crypto-config.yaml，成功后会在当前文件夹下生成crypto-config文件夹,  各个证书以节点角色/Domain/…的文件形式存在</li>\n</ul>\n</li>\n<li><p>使用configtxgen tool来生成一些部署实体所需要的零件。也需要配置文件，配置文件定义了网络模板。主要零件类型有</p>\n<ul>\n<li>orderer genesis block, orderer服务启动必备，注意的是每个组织的根证书都包含在gensis.block中。</li>\n<li>channel configuration transaction, 该配置在orderer服务启动创建channel时配置channel。这里就已经形成了channel的读写策略（即哪些实体可以读，哪些实体可以写，下同）。</li>\n<li>and two anchor peer transactions - one for each Peer Org. 用于指定在channel中，当前peer组织中都有哪些peer结点。这里就已经形成了组织的读写策略。</li>\n</ul>\n</li>\n<li><p>最后就是 up启动网络了，最重要的命令即… docker-compose -f $COMPOSE_FILE…， 查看docker-compose-cli.yaml，定义了6个容器服务，其中最后一个为cli, 执行为./scripts/script.sh。查看这个脚本大概为创建channel、加入channel、升级组织配置、安装部署chaincode、调用chaincode…后面每一步应该都会自己搞一次..这里还是先跳过<br>到这里，我就感觉脑子里放不下东西了已经，很尴尬…先跟着向导继续走吧</p>\n<p>嗯,  很难受。</p>\n<p>具体看了一下cli， 大致是将证书，script等都作为数据卷挂载到容器上，然后在容器上调用script操作。channel的加入，似乎是通过各证书验证身份。链码的部署调用都是通过peer chaincode … 命令进行</p>\n</li>\n</ul>\n"},{"title":"zilliqa_network","date":"2019-10-14T06:40:49.000Z","_content":"\n## Zilliqa网络分片篇翻译\n\n[英文版本](https://docs.zilliqa.com/whitepaper.pdf)\n\n\n\n### 区块\n\nZILLIQA协议介绍两种类型的区块（所以存在两条链）：交易区块(TX-Block)和目录服务区块（DS-Block）。TX-Block记录用户的交易，DS-Block为参与共识协议的矿工的元数据。TX-Block存储被DS-Block中的节点同意的交易，每个DS-Block与多个TX-Blocks相关。\n\n...\n\n\n\n### 网络层\n\nZILLIQA被设计成是交易率按比例决定。主要的想法是，分片。即，将挖矿网络分成小分片，每个小分片处理交易是并行的。在本节中，我们将介绍网络和交易分片。\n\n#### 网络分片\n\n网络分片。将挖矿网络分成小分片是一个两个的过程，首先，一组专用的称为目录服务委员会（或DS委员会）的节点被选举出来，然后他们将将网络和节点分到他们的分片中。在下面，将具体介绍细节。\n\n- 目录服务委员会（Directory Service Committee）：为了促进网络的切分，我们首先会选举出一组节点，成为目录服务(DS)节点。DS节点形成一个DS委员会。DS节点的选举是基于proof-of-work1算法。\n\n  ```\n  //Algorithm 1: PoW1 for DS committee election.\n  Input: i: Current DS-epoch, DSi−1: Prev. DS committee\n  composition.\n  Output: header: DS-Block header.\n   On each competing node:\n  // get epoch randomness from the DS blockchain\n  // DBi−1: Most recent DS-Block before start of i-th epoch\n   r1 ← GetEpochRand(DBi−1)\n  // get epoch randomness from the transaction blockchain\n  // TBj : Most recent TX-Block before start of i-th epoch\n   r2 ← GetEpochRand(TBj )\n  // pk: node’s public key, IP = node’s IP address\n   nonce, mixHash ← Ethash-PoW(pk, IP, r1, r2)\n   header ← BuildHeader(nonce, mixHash, pk)\n  // header includes pk and nonce among other fields\n  // IP, header is multicast to members in the DS committee\n   MulticastToDSi−1(IP, header)\n   return header\n  ```\n\n  比其他节点更早成功产生一个有效的随机数的节点，将为新块提供区块头。回想一下DS-Block头和签名部分，当一个节点解决了POW1，它便可以生产仅仅1个区块头，区块头随后会被多点广播给DS委员会的所有节点，DS委员会将对产生的区块头进行共识后生成签名部分。2f个DS节点签名了区块头，这个区块便被确认添加到DS区块链中。\n\n   在成功引导阶段后，在任何时候，规定DS节点的组成为一个预定义的窗口大小n0。在最近n0节点中并成功挖掘DS-Block的节点将加入DS委员会。\n\n  连续挖到两个DS-Block之间的平均时间称为DS-epoch。DS-eposh的值的设置是减小两个竞争块几率的一种方法。在DS-epoch的开始，一个新的DS节点加入DS委员然后DS委员会中最老的成员会<u>被挤出(原文为is churned out..不知道该怎么翻译比较好)</u>。这固定了在DS-eposh期间DS委员会的大小始终是n0。DS委员中最新的成员将成为leader, 并领导该时期的共识协议。 这进一步导致了DS委员会成员的严格排序。\n\n  可以看到的是，如果DS委员会的规模n0足够大（比如说800），那么在n0个委员会成员中极有可能最多有1/3是拜占庭。\n\n- 冲突解决：我们的共识协议不允许在DS区块链中分叉。  当多个节点大致同时解决难题时，可能会出现分叉。 为了解决冲突，每个DS节点从接收到的头中检索nonce字段，并按递增顺序对它们进行排序。 让我们假设第i个DS节点的最大随机数是max(nⁱ)。\n\n  DS委员会的leader然后提出自己的header（对应于他所见过的最大随机数），并运行一致的协议来就DS-         Block header达成一致。 只有当相应的随机数大于或等于max(nⁱ)时，<u>第i个DS节点才同意接受建议的header（没理解上）</u>。 一旦达成共识，DS-Block的签名部分就建立起来了，然后成为领导者\n\n- 分片生成：一旦选出DS委员会，网络的实际分片就可以开始。 为了使节点参与下面的共识协议，它必须执行工作证明（PoW2）。 分片协议在每个DS时期开始时重复。 算法2给出了PoW2的算法\n\n  ```\n  Algorithm 2: PoW2 for shard membership.\n  Input: i: Current DS-epoch, DSi: Current DS committee\n  composition.\n  Output: nonce, mixHash: outputs of Ethash-PoW\n   On each competing node:\n  // get epoch randomness from the DS blockchain\n  // DBi−1: Most recent DS-Block before start of i-th epoch\n   r ← GetEpochRand(DBi)\n  // pk: node’s public key, IP = node’s IP address\n   nonce, mixHash ← Ethash-PoW(pk, IP, r)\n  // IP, header is multicast to members in the DS committee\n   MulticastToDSi(nonce, mixHash, pk, IP)\n   return nonce, mixHash\n\n  ```\n\n  然后将计算出的PoW2的有效随机数（和混合散列）多播到DS委员会。 DS节点将共同接受足够的PoW解决方案，以分解为L个共识委员会或分片，每个都具有n0个节点以达成共识。一旦DS委员会负责人收到足够数量的PoW2解决方案，他就启动一个协商一致的协议，以就该组有效的PoW2解决方案达成一致。在共识协议结束时，leader生成由DS节点签名的EC-Schnorr多重签名。为了进一步进行下去，超过2/3的DS节点必须同意一组可接受的PoW2解决方案。\n  Sharding利用确定性函数将节点分配给分片。让我们假设我们需要每个都有n0个节点的碎片。随机数值按升序排序，第一个有n0个节点的节点们被分配给第一个分片，下一个n0分配到下一个分片，依此类推。在碎片中提出最大随机数的矿工的身份被宣布为leader。这进一步诱导了对分片成员的严格排序。也可以表明，如果n0足够大（比如800以上），那么在每个碎片内至多有1/3个是具有高概率的拜占庭\n\n#### 公共信道\n\nDS节点在公共信道上发布某些信息，包括DS节点的身份和连接信息，每个分片中的节点列表以及交易的分片逻辑（在第V-D节中解释）。 公共频道不可信，并假定所有节点均可访问。 在我们的实现中，我们的广播原语实现了这样的公共频道。 我们区块链的用户想要提交交易以进行接受，然后可以检查分片信息以获取负责处理其交易的碎片。 在公共频道上发布的信息预计将由任何节点或用户可验证的DS节点的2/3以上进行签名。\n\n#### 新节点加入ZILLIQA\n\n对于新节点加入网络，它可以尝试解决PoW1成为DS节点或PoW2成为分片的成员。 为此，它需要从区块链获得关于PoW1或PoW2所需的随机性的信息。 一旦获得了随机性信息，新节点就可以将其解决方案提交给DS委员会。\n\n#### 交易分片和过程\n\n如以上所述，网络分片创建了每个能够并行处理交易的分片。 在本节中，我们将介绍特定交易如何分配给分片以及如何处理交易。 为此，我们使用以下抽象：A -ⁿ->B来指示从发件人账户A到收件人账户B的n个ZIL的交易\n\n- 交易分配：任何交易都表示A -ⁿ->B被单个分片处理。 假设有L个分片，编号为0到L-1，事务被分配到由发送者地址的(log₂L + 1)右边的位（bit）标识的碎片。即，实例中A的账户地址。因为账户地址是一个160位(bit)的整型数据，所以L的范围应该为**log₂L + 1 ≤ 160**。但实际上，它会小于100。\n\n  一旦识别了分配的分片，事务就会被多播到分片中的一些节点，节点然后再进一步广播它。 一旦交易到达指定分片的领导者，它将把交易包含在TX-Block中并运行共识协议。\n\n  双花（或重播攻击）可以使用每笔交易中的随机数轻松检测。 回想一下，每笔交易都有一个随机数，用于统计发件人帐户发送的交易数量。 一旦交易进入交易区块链，nonce在账户状态中更新，从而处于全局状态。 当前值小于或等于全局状态当前值的交易被矿工拒绝。 根据发件人的帐户地址本地分片交易允许分片成员检测双倍支出，因为发件人的每个交易都将在同一分片中处理。\n\n- 交易处理：委员会内的所有节点都可以提出交易。这些交易被发送给领导者以运行一组协议，其中一组交易形成下一个TX块。由每个分片建议的块称为微块（由类型标记0x00标识）。一个微块包含EC-Schnorr多重签名，由分片中的2/3个节点组成。leader还建立一个标识签名者公钥的位图B。如果分片的第i个成员签署了TX-Block头部，则B [i] = 1。当一个分片在TX块上达成共识时，其领导者将块头和签名多播给一些DS节点。 DS节点然后在DS委员会内广播它，以便该块到达其领导者。块的数据部分可以异步发送到节点。 DS委员会然后汇集从碎片发送的所有块，并且在它们之间运行另一轮共识协议以达成最终块。最后的块是由类型标记0x01标识的TX块。最后一个块包含来自DS委员会的超过2/3个n0节点的EC-Schnorr多重签名。 DS委员会的leader还构建了一个位图B，用于标识签名者的公钥。如果DS委员会的第i个成员签署了TX-Block标题，则B [i] = 1。最后的块头和签名，然后被组播到每个分片中的一些节点。实际的TX块数据不是由DS节点发送的。\n\n  在每个分片中，采取以下步骤来处理最终的块:\n\n  1. 分片中的每个节点使用DS节点的公钥验证EC-Schnorr多重签名。 如果签名对由位图表示的超过2/3个n0公钥有效，则节点执行下一个检查。\n  2. 对于包含在最终块头中的每个交易hash，节点检查其相应的交易内容是否可用。 如果相应的交易由节点所属的分片提出，则将交易数据的散列与包含在最后块header中的散列进行比较。 如果交易是由另一个分片提出的，则交易数据跨分片异步共享\n  3. 一旦交易数据可用，最终块的data部分被重构并且TX块被附加到本地交易区块链。 账户状态和全局状态相应地被更新。\n  4. 如果交易内容不可用，则节点在其本地账户视图中临时使该交易的发送账户失效，以便该账户的任何其他未决交易被拒绝，直到本地交易内容可以与全局状态同步。 这些被拒绝的事务将不得不由发送节点重试\n\n\n\n\n\n### 共识层\n\n\n\n如以上提到的，每个分片和DS委员会需要分别在微块和终块上跑一个共识协议。在这一块，我们将展示在每一个分片和DS委员会中定义的共识协议的共识层。在讨论中，我们将分片和DS委员会代指为共识组。\n\n##### 实用拜占庭容错\n\nZILLIQA共识协议的核心依赖于实用拜占庭容错(PBFT)协议。然而我们通过在PBFT中使用EC-Schnorr多签名来提升效率。EC-Schnorr多重签名的使用将正常情况下的通信延迟从O(n*n)降低为O(n)，并将签名大小从O(n)减小到O(1)，其中n是共识组的大小。 在这个部分，我们提供PBFT的概述。\n\n在PBFT中，共识组内的所有节点都按顺序排列，它有一个主节点（或领导者），其他节点称为备份节点。 每轮PBFT都有三个阶段，如下所述：\n\n- 预准备阶段:  在这个阶段，领导者宣布该小组将应该达成一致共识的下一个记录（在我们的案例中是TX-Block）\n- 准备阶段：在接收到预先准备消息后，每个节点验证其正确性并将准备消息多播给所有其他节点\n- 提交阶段：在收到超过2/3\\*n准备消息时，节点向组播组发送提交消息。最后，节点等待超过2/3\\*n的提交消息，以确保有足够数量的节点做出相同的决定。 因此，所有诚实的节点都接受相同的有效记录。\n\nPBFT依靠正确的领导者开始每个阶段，并在足够多节点存在时继续进行。 如果领导是拜占庭，它可能会拖延整个共识协议。 为了应对这一挑战，PBFT提供了视图更改协议来使用另一个取代拜占庭领袖。 如果节点在有限的时间内没有看到任何进展，他们可以独立宣布改变领导者的愿望。 如果超过2/3\\*n个节点的法定人数决定领导者有问题，那么在已知计划中的下一个领导者就会接管。\n\n 由于在准备/提交阶段每个节点的多播，正常情况下PBFT的通信复杂度为O（n*n）\n\n\n\n##### 提高效率\n\n经典的PBFT使用消息认证码（MAC）进行节点之间的认证通信。 由于MAC需要在每两个节点之间共享密钥，所以一个共识组中的节点可以在同一个记录上达成一致，其中每个节点的通信复杂度为O（n*n）。 由于二次复杂性，当委员会有20多个节点时，PBFT变得不切实际。\n\n为了提高效率，我们使用来源于ByzCoin的想法：\n\n- 我们用数字签名替换MAC来有效地减少O（n）的通信开销。\n- 与此同时，为了让其他节点能够验证协议，一种典型的方法是从诚实的多数收集签名并将它们附加到协议中，从而导致协商规模与协商组的大小成线性关系。 为了改善这一点，我们使用EC-Schnorr多重签名来将几个签名聚合成O（1） - 大小多重签名\n\n然而，我们不能直接在PBFT设置中使用经典的EC-Schnorr多重签名方案。 这是因为在古典设置中，所有签名者都同意签署给定的消息，并且签名只有在所有签名者都签名后才有效。 在PBFT设置中，我们只需要在共识组中超过2/3\\*n个节点签署消息。 所需的主要修改之一是为参与签名过程的签名者维护位图B. 如果第i个节点参与该过程，则B [i] = 1，否则为0。位图由领导者构建。 位图可以被任何验证者用来验证签名。 最终的协议留在附录B中。\n\n\n\n##### Zilliqa共识\n\n在ZILLIQA中，我们使用PBFT作为基础共识协议，并采用两轮EC-Schnorr多重签名来替换PBFT中的准备阶段和提交阶段。 下面将解释对PBFT阶段的不同修改。\n\n- 预准备阶段: 与标准PBFT中一样，领导者将TX-Block或声明（由领导者签名）分发给共识组中的所有节点。\n- 准备阶段：所有诚实的节点检查TX块的有效性，并且领导者收集来自超过2/3\\*n个节点的响应。 这保证领导者提出的陈述是安全的并且与以前的所有历史一致。 签名是使用EC-Schnorr多重签名生成的。 领导者还构建签署TX块的节点的位图\n- 提交阶段：为了确保超过2/3\\*n的节点知道超过2/3\\*n节点验证了TX-Block的事实。我们进行第二轮EC-Schnorr多重签名。 正在签署的声明是上一轮生成的多重签名。\n\n在三个阶段结束时，就领导者提出的TX-Block将达成共识。\n\n\n\n##### 领导者改变\n\n在我们的共识协议中，如果领导者是诚实的，它可以不断的推动共识小组中的节点就新的交易达成协议。 但是，如果领导是拜占庭，它可以有意地延迟或丢弃来自诚实节点的消息，并减慢协议。 为了惩罚这些恶意领导者，我们的协议会定期更改每个分片的领导和DS委员会。 这可以防止拜占庭领袖在无限期的时间内拖延共识协议。 由于所有节点都是有序的，下一个领导者将以循环方式选择。\n\n 事实上，每一个微块后分片的领导者都会改变，并且在每个最后一个区块之后DS委员会的领导者也会更改。 让我们假设共识组的大小为n，那么在一个DS-epoch时期内，我们允许的最终块的最大值为n，每个最终块最多在1个分片聚合1个微块。\n","source":"_posts/zilliqa-network.md","raw":"---\ntitle: zilliqa_network\ncategories:\n  - zilliqa\ndate: 2019-10-14 14:40:49\ntags:\n---\n\n## Zilliqa网络分片篇翻译\n\n[英文版本](https://docs.zilliqa.com/whitepaper.pdf)\n\n\n\n### 区块\n\nZILLIQA协议介绍两种类型的区块（所以存在两条链）：交易区块(TX-Block)和目录服务区块（DS-Block）。TX-Block记录用户的交易，DS-Block为参与共识协议的矿工的元数据。TX-Block存储被DS-Block中的节点同意的交易，每个DS-Block与多个TX-Blocks相关。\n\n...\n\n\n\n### 网络层\n\nZILLIQA被设计成是交易率按比例决定。主要的想法是，分片。即，将挖矿网络分成小分片，每个小分片处理交易是并行的。在本节中，我们将介绍网络和交易分片。\n\n#### 网络分片\n\n网络分片。将挖矿网络分成小分片是一个两个的过程，首先，一组专用的称为目录服务委员会（或DS委员会）的节点被选举出来，然后他们将将网络和节点分到他们的分片中。在下面，将具体介绍细节。\n\n- 目录服务委员会（Directory Service Committee）：为了促进网络的切分，我们首先会选举出一组节点，成为目录服务(DS)节点。DS节点形成一个DS委员会。DS节点的选举是基于proof-of-work1算法。\n\n  ```\n  //Algorithm 1: PoW1 for DS committee election.\n  Input: i: Current DS-epoch, DSi−1: Prev. DS committee\n  composition.\n  Output: header: DS-Block header.\n   On each competing node:\n  // get epoch randomness from the DS blockchain\n  // DBi−1: Most recent DS-Block before start of i-th epoch\n   r1 ← GetEpochRand(DBi−1)\n  // get epoch randomness from the transaction blockchain\n  // TBj : Most recent TX-Block before start of i-th epoch\n   r2 ← GetEpochRand(TBj )\n  // pk: node’s public key, IP = node’s IP address\n   nonce, mixHash ← Ethash-PoW(pk, IP, r1, r2)\n   header ← BuildHeader(nonce, mixHash, pk)\n  // header includes pk and nonce among other fields\n  // IP, header is multicast to members in the DS committee\n   MulticastToDSi−1(IP, header)\n   return header\n  ```\n\n  比其他节点更早成功产生一个有效的随机数的节点，将为新块提供区块头。回想一下DS-Block头和签名部分，当一个节点解决了POW1，它便可以生产仅仅1个区块头，区块头随后会被多点广播给DS委员会的所有节点，DS委员会将对产生的区块头进行共识后生成签名部分。2f个DS节点签名了区块头，这个区块便被确认添加到DS区块链中。\n\n   在成功引导阶段后，在任何时候，规定DS节点的组成为一个预定义的窗口大小n0。在最近n0节点中并成功挖掘DS-Block的节点将加入DS委员会。\n\n  连续挖到两个DS-Block之间的平均时间称为DS-epoch。DS-eposh的值的设置是减小两个竞争块几率的一种方法。在DS-epoch的开始，一个新的DS节点加入DS委员然后DS委员会中最老的成员会<u>被挤出(原文为is churned out..不知道该怎么翻译比较好)</u>。这固定了在DS-eposh期间DS委员会的大小始终是n0。DS委员中最新的成员将成为leader, 并领导该时期的共识协议。 这进一步导致了DS委员会成员的严格排序。\n\n  可以看到的是，如果DS委员会的规模n0足够大（比如说800），那么在n0个委员会成员中极有可能最多有1/3是拜占庭。\n\n- 冲突解决：我们的共识协议不允许在DS区块链中分叉。  当多个节点大致同时解决难题时，可能会出现分叉。 为了解决冲突，每个DS节点从接收到的头中检索nonce字段，并按递增顺序对它们进行排序。 让我们假设第i个DS节点的最大随机数是max(nⁱ)。\n\n  DS委员会的leader然后提出自己的header（对应于他所见过的最大随机数），并运行一致的协议来就DS-         Block header达成一致。 只有当相应的随机数大于或等于max(nⁱ)时，<u>第i个DS节点才同意接受建议的header（没理解上）</u>。 一旦达成共识，DS-Block的签名部分就建立起来了，然后成为领导者\n\n- 分片生成：一旦选出DS委员会，网络的实际分片就可以开始。 为了使节点参与下面的共识协议，它必须执行工作证明（PoW2）。 分片协议在每个DS时期开始时重复。 算法2给出了PoW2的算法\n\n  ```\n  Algorithm 2: PoW2 for shard membership.\n  Input: i: Current DS-epoch, DSi: Current DS committee\n  composition.\n  Output: nonce, mixHash: outputs of Ethash-PoW\n   On each competing node:\n  // get epoch randomness from the DS blockchain\n  // DBi−1: Most recent DS-Block before start of i-th epoch\n   r ← GetEpochRand(DBi)\n  // pk: node’s public key, IP = node’s IP address\n   nonce, mixHash ← Ethash-PoW(pk, IP, r)\n  // IP, header is multicast to members in the DS committee\n   MulticastToDSi(nonce, mixHash, pk, IP)\n   return nonce, mixHash\n\n  ```\n\n  然后将计算出的PoW2的有效随机数（和混合散列）多播到DS委员会。 DS节点将共同接受足够的PoW解决方案，以分解为L个共识委员会或分片，每个都具有n0个节点以达成共识。一旦DS委员会负责人收到足够数量的PoW2解决方案，他就启动一个协商一致的协议，以就该组有效的PoW2解决方案达成一致。在共识协议结束时，leader生成由DS节点签名的EC-Schnorr多重签名。为了进一步进行下去，超过2/3的DS节点必须同意一组可接受的PoW2解决方案。\n  Sharding利用确定性函数将节点分配给分片。让我们假设我们需要每个都有n0个节点的碎片。随机数值按升序排序，第一个有n0个节点的节点们被分配给第一个分片，下一个n0分配到下一个分片，依此类推。在碎片中提出最大随机数的矿工的身份被宣布为leader。这进一步诱导了对分片成员的严格排序。也可以表明，如果n0足够大（比如800以上），那么在每个碎片内至多有1/3个是具有高概率的拜占庭\n\n#### 公共信道\n\nDS节点在公共信道上发布某些信息，包括DS节点的身份和连接信息，每个分片中的节点列表以及交易的分片逻辑（在第V-D节中解释）。 公共频道不可信，并假定所有节点均可访问。 在我们的实现中，我们的广播原语实现了这样的公共频道。 我们区块链的用户想要提交交易以进行接受，然后可以检查分片信息以获取负责处理其交易的碎片。 在公共频道上发布的信息预计将由任何节点或用户可验证的DS节点的2/3以上进行签名。\n\n#### 新节点加入ZILLIQA\n\n对于新节点加入网络，它可以尝试解决PoW1成为DS节点或PoW2成为分片的成员。 为此，它需要从区块链获得关于PoW1或PoW2所需的随机性的信息。 一旦获得了随机性信息，新节点就可以将其解决方案提交给DS委员会。\n\n#### 交易分片和过程\n\n如以上所述，网络分片创建了每个能够并行处理交易的分片。 在本节中，我们将介绍特定交易如何分配给分片以及如何处理交易。 为此，我们使用以下抽象：A -ⁿ->B来指示从发件人账户A到收件人账户B的n个ZIL的交易\n\n- 交易分配：任何交易都表示A -ⁿ->B被单个分片处理。 假设有L个分片，编号为0到L-1，事务被分配到由发送者地址的(log₂L + 1)右边的位（bit）标识的碎片。即，实例中A的账户地址。因为账户地址是一个160位(bit)的整型数据，所以L的范围应该为**log₂L + 1 ≤ 160**。但实际上，它会小于100。\n\n  一旦识别了分配的分片，事务就会被多播到分片中的一些节点，节点然后再进一步广播它。 一旦交易到达指定分片的领导者，它将把交易包含在TX-Block中并运行共识协议。\n\n  双花（或重播攻击）可以使用每笔交易中的随机数轻松检测。 回想一下，每笔交易都有一个随机数，用于统计发件人帐户发送的交易数量。 一旦交易进入交易区块链，nonce在账户状态中更新，从而处于全局状态。 当前值小于或等于全局状态当前值的交易被矿工拒绝。 根据发件人的帐户地址本地分片交易允许分片成员检测双倍支出，因为发件人的每个交易都将在同一分片中处理。\n\n- 交易处理：委员会内的所有节点都可以提出交易。这些交易被发送给领导者以运行一组协议，其中一组交易形成下一个TX块。由每个分片建议的块称为微块（由类型标记0x00标识）。一个微块包含EC-Schnorr多重签名，由分片中的2/3个节点组成。leader还建立一个标识签名者公钥的位图B。如果分片的第i个成员签署了TX-Block头部，则B [i] = 1。当一个分片在TX块上达成共识时，其领导者将块头和签名多播给一些DS节点。 DS节点然后在DS委员会内广播它，以便该块到达其领导者。块的数据部分可以异步发送到节点。 DS委员会然后汇集从碎片发送的所有块，并且在它们之间运行另一轮共识协议以达成最终块。最后的块是由类型标记0x01标识的TX块。最后一个块包含来自DS委员会的超过2/3个n0节点的EC-Schnorr多重签名。 DS委员会的leader还构建了一个位图B，用于标识签名者的公钥。如果DS委员会的第i个成员签署了TX-Block标题，则B [i] = 1。最后的块头和签名，然后被组播到每个分片中的一些节点。实际的TX块数据不是由DS节点发送的。\n\n  在每个分片中，采取以下步骤来处理最终的块:\n\n  1. 分片中的每个节点使用DS节点的公钥验证EC-Schnorr多重签名。 如果签名对由位图表示的超过2/3个n0公钥有效，则节点执行下一个检查。\n  2. 对于包含在最终块头中的每个交易hash，节点检查其相应的交易内容是否可用。 如果相应的交易由节点所属的分片提出，则将交易数据的散列与包含在最后块header中的散列进行比较。 如果交易是由另一个分片提出的，则交易数据跨分片异步共享\n  3. 一旦交易数据可用，最终块的data部分被重构并且TX块被附加到本地交易区块链。 账户状态和全局状态相应地被更新。\n  4. 如果交易内容不可用，则节点在其本地账户视图中临时使该交易的发送账户失效，以便该账户的任何其他未决交易被拒绝，直到本地交易内容可以与全局状态同步。 这些被拒绝的事务将不得不由发送节点重试\n\n\n\n\n\n### 共识层\n\n\n\n如以上提到的，每个分片和DS委员会需要分别在微块和终块上跑一个共识协议。在这一块，我们将展示在每一个分片和DS委员会中定义的共识协议的共识层。在讨论中，我们将分片和DS委员会代指为共识组。\n\n##### 实用拜占庭容错\n\nZILLIQA共识协议的核心依赖于实用拜占庭容错(PBFT)协议。然而我们通过在PBFT中使用EC-Schnorr多签名来提升效率。EC-Schnorr多重签名的使用将正常情况下的通信延迟从O(n*n)降低为O(n)，并将签名大小从O(n)减小到O(1)，其中n是共识组的大小。 在这个部分，我们提供PBFT的概述。\n\n在PBFT中，共识组内的所有节点都按顺序排列，它有一个主节点（或领导者），其他节点称为备份节点。 每轮PBFT都有三个阶段，如下所述：\n\n- 预准备阶段:  在这个阶段，领导者宣布该小组将应该达成一致共识的下一个记录（在我们的案例中是TX-Block）\n- 准备阶段：在接收到预先准备消息后，每个节点验证其正确性并将准备消息多播给所有其他节点\n- 提交阶段：在收到超过2/3\\*n准备消息时，节点向组播组发送提交消息。最后，节点等待超过2/3\\*n的提交消息，以确保有足够数量的节点做出相同的决定。 因此，所有诚实的节点都接受相同的有效记录。\n\nPBFT依靠正确的领导者开始每个阶段，并在足够多节点存在时继续进行。 如果领导是拜占庭，它可能会拖延整个共识协议。 为了应对这一挑战，PBFT提供了视图更改协议来使用另一个取代拜占庭领袖。 如果节点在有限的时间内没有看到任何进展，他们可以独立宣布改变领导者的愿望。 如果超过2/3\\*n个节点的法定人数决定领导者有问题，那么在已知计划中的下一个领导者就会接管。\n\n 由于在准备/提交阶段每个节点的多播，正常情况下PBFT的通信复杂度为O（n*n）\n\n\n\n##### 提高效率\n\n经典的PBFT使用消息认证码（MAC）进行节点之间的认证通信。 由于MAC需要在每两个节点之间共享密钥，所以一个共识组中的节点可以在同一个记录上达成一致，其中每个节点的通信复杂度为O（n*n）。 由于二次复杂性，当委员会有20多个节点时，PBFT变得不切实际。\n\n为了提高效率，我们使用来源于ByzCoin的想法：\n\n- 我们用数字签名替换MAC来有效地减少O（n）的通信开销。\n- 与此同时，为了让其他节点能够验证协议，一种典型的方法是从诚实的多数收集签名并将它们附加到协议中，从而导致协商规模与协商组的大小成线性关系。 为了改善这一点，我们使用EC-Schnorr多重签名来将几个签名聚合成O（1） - 大小多重签名\n\n然而，我们不能直接在PBFT设置中使用经典的EC-Schnorr多重签名方案。 这是因为在古典设置中，所有签名者都同意签署给定的消息，并且签名只有在所有签名者都签名后才有效。 在PBFT设置中，我们只需要在共识组中超过2/3\\*n个节点签署消息。 所需的主要修改之一是为参与签名过程的签名者维护位图B. 如果第i个节点参与该过程，则B [i] = 1，否则为0。位图由领导者构建。 位图可以被任何验证者用来验证签名。 最终的协议留在附录B中。\n\n\n\n##### Zilliqa共识\n\n在ZILLIQA中，我们使用PBFT作为基础共识协议，并采用两轮EC-Schnorr多重签名来替换PBFT中的准备阶段和提交阶段。 下面将解释对PBFT阶段的不同修改。\n\n- 预准备阶段: 与标准PBFT中一样，领导者将TX-Block或声明（由领导者签名）分发给共识组中的所有节点。\n- 准备阶段：所有诚实的节点检查TX块的有效性，并且领导者收集来自超过2/3\\*n个节点的响应。 这保证领导者提出的陈述是安全的并且与以前的所有历史一致。 签名是使用EC-Schnorr多重签名生成的。 领导者还构建签署TX块的节点的位图\n- 提交阶段：为了确保超过2/3\\*n的节点知道超过2/3\\*n节点验证了TX-Block的事实。我们进行第二轮EC-Schnorr多重签名。 正在签署的声明是上一轮生成的多重签名。\n\n在三个阶段结束时，就领导者提出的TX-Block将达成共识。\n\n\n\n##### 领导者改变\n\n在我们的共识协议中，如果领导者是诚实的，它可以不断的推动共识小组中的节点就新的交易达成协议。 但是，如果领导是拜占庭，它可以有意地延迟或丢弃来自诚实节点的消息，并减慢协议。 为了惩罚这些恶意领导者，我们的协议会定期更改每个分片的领导和DS委员会。 这可以防止拜占庭领袖在无限期的时间内拖延共识协议。 由于所有节点都是有序的，下一个领导者将以循环方式选择。\n\n 事实上，每一个微块后分片的领导者都会改变，并且在每个最后一个区块之后DS委员会的领导者也会更改。 让我们假设共识组的大小为n，那么在一个DS-epoch时期内，我们允许的最终块的最大值为n，每个最终块最多在1个分片聚合1个微块。\n","slug":"zilliqa-network","published":1,"updated":"2019-10-14T06:41:19.167Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69x8002gt6xvkj9hogtu","content":"<h2 id=\"Zilliqa网络分片篇翻译\"><a href=\"#Zilliqa网络分片篇翻译\" class=\"headerlink\" title=\"Zilliqa网络分片篇翻译\"></a>Zilliqa网络分片篇翻译</h2><p><a href=\"https://docs.zilliqa.com/whitepaper.pdf\" target=\"_blank\" rel=\"noopener\">英文版本</a></p>\n<h3 id=\"区块\"><a href=\"#区块\" class=\"headerlink\" title=\"区块\"></a>区块</h3><p>ZILLIQA协议介绍两种类型的区块（所以存在两条链）：交易区块(TX-Block)和目录服务区块（DS-Block）。TX-Block记录用户的交易，DS-Block为参与共识协议的矿工的元数据。TX-Block存储被DS-Block中的节点同意的交易，每个DS-Block与多个TX-Blocks相关。</p>\n<p>…</p>\n<h3 id=\"网络层\"><a href=\"#网络层\" class=\"headerlink\" title=\"网络层\"></a>网络层</h3><p>ZILLIQA被设计成是交易率按比例决定。主要的想法是，分片。即，将挖矿网络分成小分片，每个小分片处理交易是并行的。在本节中，我们将介绍网络和交易分片。</p>\n<h4 id=\"网络分片\"><a href=\"#网络分片\" class=\"headerlink\" title=\"网络分片\"></a>网络分片</h4><p>网络分片。将挖矿网络分成小分片是一个两个的过程，首先，一组专用的称为目录服务委员会（或DS委员会）的节点被选举出来，然后他们将将网络和节点分到他们的分片中。在下面，将具体介绍细节。</p>\n<ul>\n<li><p>目录服务委员会（Directory Service Committee）：为了促进网络的切分，我们首先会选举出一组节点，成为目录服务(DS)节点。DS节点形成一个DS委员会。DS节点的选举是基于proof-of-work1算法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//Algorithm 1: PoW1 for DS committee election.</span><br><span class=\"line\">Input: i: Current DS-epoch, DSi−1: Prev. DS committee</span><br><span class=\"line\">composition.</span><br><span class=\"line\">Output: header: DS-Block header.</span><br><span class=\"line\"> On each competing node:</span><br><span class=\"line\">// get epoch randomness from the DS blockchain</span><br><span class=\"line\">// DBi−1: Most recent DS-Block before start of i-th epoch</span><br><span class=\"line\"> r1 ← GetEpochRand(DBi−1)</span><br><span class=\"line\">// get epoch randomness from the transaction blockchain</span><br><span class=\"line\">// TBj : Most recent TX-Block before start of i-th epoch</span><br><span class=\"line\"> r2 ← GetEpochRand(TBj )</span><br><span class=\"line\">// pk: node’s public key, IP = node’s IP address</span><br><span class=\"line\"> nonce, mixHash ← Ethash-PoW(pk, IP, r1, r2)</span><br><span class=\"line\"> header ← BuildHeader(nonce, mixHash, pk)</span><br><span class=\"line\">// header includes pk and nonce among other fields</span><br><span class=\"line\">// IP, header is multicast to members in the DS committee</span><br><span class=\"line\"> MulticastToDSi−1(IP, header)</span><br><span class=\"line\"> return header</span><br></pre></td></tr></table></figure>\n\n<p>比其他节点更早成功产生一个有效的随机数的节点，将为新块提供区块头。回想一下DS-Block头和签名部分，当一个节点解决了POW1，它便可以生产仅仅1个区块头，区块头随后会被多点广播给DS委员会的所有节点，DS委员会将对产生的区块头进行共识后生成签名部分。2f个DS节点签名了区块头，这个区块便被确认添加到DS区块链中。</p>\n<p> 在成功引导阶段后，在任何时候，规定DS节点的组成为一个预定义的窗口大小n0。在最近n0节点中并成功挖掘DS-Block的节点将加入DS委员会。</p>\n<p>连续挖到两个DS-Block之间的平均时间称为DS-epoch。DS-eposh的值的设置是减小两个竞争块几率的一种方法。在DS-epoch的开始，一个新的DS节点加入DS委员然后DS委员会中最老的成员会<u>被挤出(原文为is churned out..不知道该怎么翻译比较好)</u>。这固定了在DS-eposh期间DS委员会的大小始终是n0。DS委员中最新的成员将成为leader, 并领导该时期的共识协议。 这进一步导致了DS委员会成员的严格排序。</p>\n<p>可以看到的是，如果DS委员会的规模n0足够大（比如说800），那么在n0个委员会成员中极有可能最多有1/3是拜占庭。</p>\n</li>\n<li><p>冲突解决：我们的共识协议不允许在DS区块链中分叉。  当多个节点大致同时解决难题时，可能会出现分叉。 为了解决冲突，每个DS节点从接收到的头中检索nonce字段，并按递增顺序对它们进行排序。 让我们假设第i个DS节点的最大随机数是max(nⁱ)。</p>\n<p>DS委员会的leader然后提出自己的header（对应于他所见过的最大随机数），并运行一致的协议来就DS-         Block header达成一致。 只有当相应的随机数大于或等于max(nⁱ)时，<u>第i个DS节点才同意接受建议的header（没理解上）</u>。 一旦达成共识，DS-Block的签名部分就建立起来了，然后成为领导者</p>\n</li>\n<li><p>分片生成：一旦选出DS委员会，网络的实际分片就可以开始。 为了使节点参与下面的共识协议，它必须执行工作证明（PoW2）。 分片协议在每个DS时期开始时重复。 算法2给出了PoW2的算法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Algorithm 2: PoW2 for shard membership.</span><br><span class=\"line\">Input: i: Current DS-epoch, DSi: Current DS committee</span><br><span class=\"line\">composition.</span><br><span class=\"line\">Output: nonce, mixHash: outputs of Ethash-PoW</span><br><span class=\"line\"> On each competing node:</span><br><span class=\"line\">// get epoch randomness from the DS blockchain</span><br><span class=\"line\">// DBi−1: Most recent DS-Block before start of i-th epoch</span><br><span class=\"line\"> r ← GetEpochRand(DBi)</span><br><span class=\"line\">// pk: node’s public key, IP = node’s IP address</span><br><span class=\"line\"> nonce, mixHash ← Ethash-PoW(pk, IP, r)</span><br><span class=\"line\">// IP, header is multicast to members in the DS committee</span><br><span class=\"line\"> MulticastToDSi(nonce, mixHash, pk, IP)</span><br><span class=\"line\"> return nonce, mixHash</span><br></pre></td></tr></table></figure>\n\n<p>然后将计算出的PoW2的有效随机数（和混合散列）多播到DS委员会。 DS节点将共同接受足够的PoW解决方案，以分解为L个共识委员会或分片，每个都具有n0个节点以达成共识。一旦DS委员会负责人收到足够数量的PoW2解决方案，他就启动一个协商一致的协议，以就该组有效的PoW2解决方案达成一致。在共识协议结束时，leader生成由DS节点签名的EC-Schnorr多重签名。为了进一步进行下去，超过2/3的DS节点必须同意一组可接受的PoW2解决方案。<br>Sharding利用确定性函数将节点分配给分片。让我们假设我们需要每个都有n0个节点的碎片。随机数值按升序排序，第一个有n0个节点的节点们被分配给第一个分片，下一个n0分配到下一个分片，依此类推。在碎片中提出最大随机数的矿工的身份被宣布为leader。这进一步诱导了对分片成员的严格排序。也可以表明，如果n0足够大（比如800以上），那么在每个碎片内至多有1/3个是具有高概率的拜占庭</p>\n</li>\n</ul>\n<h4 id=\"公共信道\"><a href=\"#公共信道\" class=\"headerlink\" title=\"公共信道\"></a>公共信道</h4><p>DS节点在公共信道上发布某些信息，包括DS节点的身份和连接信息，每个分片中的节点列表以及交易的分片逻辑（在第V-D节中解释）。 公共频道不可信，并假定所有节点均可访问。 在我们的实现中，我们的广播原语实现了这样的公共频道。 我们区块链的用户想要提交交易以进行接受，然后可以检查分片信息以获取负责处理其交易的碎片。 在公共频道上发布的信息预计将由任何节点或用户可验证的DS节点的2/3以上进行签名。</p>\n<h4 id=\"新节点加入ZILLIQA\"><a href=\"#新节点加入ZILLIQA\" class=\"headerlink\" title=\"新节点加入ZILLIQA\"></a>新节点加入ZILLIQA</h4><p>对于新节点加入网络，它可以尝试解决PoW1成为DS节点或PoW2成为分片的成员。 为此，它需要从区块链获得关于PoW1或PoW2所需的随机性的信息。 一旦获得了随机性信息，新节点就可以将其解决方案提交给DS委员会。</p>\n<h4 id=\"交易分片和过程\"><a href=\"#交易分片和过程\" class=\"headerlink\" title=\"交易分片和过程\"></a>交易分片和过程</h4><p>如以上所述，网络分片创建了每个能够并行处理交易的分片。 在本节中，我们将介绍特定交易如何分配给分片以及如何处理交易。 为此，我们使用以下抽象：A -ⁿ-&gt;B来指示从发件人账户A到收件人账户B的n个ZIL的交易</p>\n<ul>\n<li><p>交易分配：任何交易都表示A -ⁿ-&gt;B被单个分片处理。 假设有L个分片，编号为0到L-1，事务被分配到由发送者地址的(log₂L + 1)右边的位（bit）标识的碎片。即，实例中A的账户地址。因为账户地址是一个160位(bit)的整型数据，所以L的范围应该为<strong>log₂L + 1 ≤ 160</strong>。但实际上，它会小于100。</p>\n<p>一旦识别了分配的分片，事务就会被多播到分片中的一些节点，节点然后再进一步广播它。 一旦交易到达指定分片的领导者，它将把交易包含在TX-Block中并运行共识协议。</p>\n<p>双花（或重播攻击）可以使用每笔交易中的随机数轻松检测。 回想一下，每笔交易都有一个随机数，用于统计发件人帐户发送的交易数量。 一旦交易进入交易区块链，nonce在账户状态中更新，从而处于全局状态。 当前值小于或等于全局状态当前值的交易被矿工拒绝。 根据发件人的帐户地址本地分片交易允许分片成员检测双倍支出，因为发件人的每个交易都将在同一分片中处理。</p>\n</li>\n<li><p>交易处理：委员会内的所有节点都可以提出交易。这些交易被发送给领导者以运行一组协议，其中一组交易形成下一个TX块。由每个分片建议的块称为微块（由类型标记0x00标识）。一个微块包含EC-Schnorr多重签名，由分片中的2/3个节点组成。leader还建立一个标识签名者公钥的位图B。如果分片的第i个成员签署了TX-Block头部，则B [i] = 1。当一个分片在TX块上达成共识时，其领导者将块头和签名多播给一些DS节点。 DS节点然后在DS委员会内广播它，以便该块到达其领导者。块的数据部分可以异步发送到节点。 DS委员会然后汇集从碎片发送的所有块，并且在它们之间运行另一轮共识协议以达成最终块。最后的块是由类型标记0x01标识的TX块。最后一个块包含来自DS委员会的超过2/3个n0节点的EC-Schnorr多重签名。 DS委员会的leader还构建了一个位图B，用于标识签名者的公钥。如果DS委员会的第i个成员签署了TX-Block标题，则B [i] = 1。最后的块头和签名，然后被组播到每个分片中的一些节点。实际的TX块数据不是由DS节点发送的。</p>\n<p>在每个分片中，采取以下步骤来处理最终的块:</p>\n<ol>\n<li>分片中的每个节点使用DS节点的公钥验证EC-Schnorr多重签名。 如果签名对由位图表示的超过2/3个n0公钥有效，则节点执行下一个检查。</li>\n<li>对于包含在最终块头中的每个交易hash，节点检查其相应的交易内容是否可用。 如果相应的交易由节点所属的分片提出，则将交易数据的散列与包含在最后块header中的散列进行比较。 如果交易是由另一个分片提出的，则交易数据跨分片异步共享</li>\n<li>一旦交易数据可用，最终块的data部分被重构并且TX块被附加到本地交易区块链。 账户状态和全局状态相应地被更新。</li>\n<li>如果交易内容不可用，则节点在其本地账户视图中临时使该交易的发送账户失效，以便该账户的任何其他未决交易被拒绝，直到本地交易内容可以与全局状态同步。 这些被拒绝的事务将不得不由发送节点重试</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"共识层\"><a href=\"#共识层\" class=\"headerlink\" title=\"共识层\"></a>共识层</h3><p>如以上提到的，每个分片和DS委员会需要分别在微块和终块上跑一个共识协议。在这一块，我们将展示在每一个分片和DS委员会中定义的共识协议的共识层。在讨论中，我们将分片和DS委员会代指为共识组。</p>\n<h5 id=\"实用拜占庭容错\"><a href=\"#实用拜占庭容错\" class=\"headerlink\" title=\"实用拜占庭容错\"></a>实用拜占庭容错</h5><p>ZILLIQA共识协议的核心依赖于实用拜占庭容错(PBFT)协议。然而我们通过在PBFT中使用EC-Schnorr多签名来提升效率。EC-Schnorr多重签名的使用将正常情况下的通信延迟从O(n*n)降低为O(n)，并将签名大小从O(n)减小到O(1)，其中n是共识组的大小。 在这个部分，我们提供PBFT的概述。</p>\n<p>在PBFT中，共识组内的所有节点都按顺序排列，它有一个主节点（或领导者），其他节点称为备份节点。 每轮PBFT都有三个阶段，如下所述：</p>\n<ul>\n<li>预准备阶段:  在这个阶段，领导者宣布该小组将应该达成一致共识的下一个记录（在我们的案例中是TX-Block）</li>\n<li>准备阶段：在接收到预先准备消息后，每个节点验证其正确性并将准备消息多播给所有其他节点</li>\n<li>提交阶段：在收到超过2/3*n准备消息时，节点向组播组发送提交消息。最后，节点等待超过2/3*n的提交消息，以确保有足够数量的节点做出相同的决定。 因此，所有诚实的节点都接受相同的有效记录。</li>\n</ul>\n<p>PBFT依靠正确的领导者开始每个阶段，并在足够多节点存在时继续进行。 如果领导是拜占庭，它可能会拖延整个共识协议。 为了应对这一挑战，PBFT提供了视图更改协议来使用另一个取代拜占庭领袖。 如果节点在有限的时间内没有看到任何进展，他们可以独立宣布改变领导者的愿望。 如果超过2/3*n个节点的法定人数决定领导者有问题，那么在已知计划中的下一个领导者就会接管。</p>\n<p> 由于在准备/提交阶段每个节点的多播，正常情况下PBFT的通信复杂度为O（n*n）</p>\n<h5 id=\"提高效率\"><a href=\"#提高效率\" class=\"headerlink\" title=\"提高效率\"></a>提高效率</h5><p>经典的PBFT使用消息认证码（MAC）进行节点之间的认证通信。 由于MAC需要在每两个节点之间共享密钥，所以一个共识组中的节点可以在同一个记录上达成一致，其中每个节点的通信复杂度为O（n*n）。 由于二次复杂性，当委员会有20多个节点时，PBFT变得不切实际。</p>\n<p>为了提高效率，我们使用来源于ByzCoin的想法：</p>\n<ul>\n<li>我们用数字签名替换MAC来有效地减少O（n）的通信开销。</li>\n<li>与此同时，为了让其他节点能够验证协议，一种典型的方法是从诚实的多数收集签名并将它们附加到协议中，从而导致协商规模与协商组的大小成线性关系。 为了改善这一点，我们使用EC-Schnorr多重签名来将几个签名聚合成O（1） - 大小多重签名</li>\n</ul>\n<p>然而，我们不能直接在PBFT设置中使用经典的EC-Schnorr多重签名方案。 这是因为在古典设置中，所有签名者都同意签署给定的消息，并且签名只有在所有签名者都签名后才有效。 在PBFT设置中，我们只需要在共识组中超过2/3*n个节点签署消息。 所需的主要修改之一是为参与签名过程的签名者维护位图B. 如果第i个节点参与该过程，则B [i] = 1，否则为0。位图由领导者构建。 位图可以被任何验证者用来验证签名。 最终的协议留在附录B中。</p>\n<h5 id=\"Zilliqa共识\"><a href=\"#Zilliqa共识\" class=\"headerlink\" title=\"Zilliqa共识\"></a>Zilliqa共识</h5><p>在ZILLIQA中，我们使用PBFT作为基础共识协议，并采用两轮EC-Schnorr多重签名来替换PBFT中的准备阶段和提交阶段。 下面将解释对PBFT阶段的不同修改。</p>\n<ul>\n<li>预准备阶段: 与标准PBFT中一样，领导者将TX-Block或声明（由领导者签名）分发给共识组中的所有节点。</li>\n<li>准备阶段：所有诚实的节点检查TX块的有效性，并且领导者收集来自超过2/3*n个节点的响应。 这保证领导者提出的陈述是安全的并且与以前的所有历史一致。 签名是使用EC-Schnorr多重签名生成的。 领导者还构建签署TX块的节点的位图</li>\n<li>提交阶段：为了确保超过2/3*n的节点知道超过2/3*n节点验证了TX-Block的事实。我们进行第二轮EC-Schnorr多重签名。 正在签署的声明是上一轮生成的多重签名。</li>\n</ul>\n<p>在三个阶段结束时，就领导者提出的TX-Block将达成共识。</p>\n<h5 id=\"领导者改变\"><a href=\"#领导者改变\" class=\"headerlink\" title=\"领导者改变\"></a>领导者改变</h5><p>在我们的共识协议中，如果领导者是诚实的，它可以不断的推动共识小组中的节点就新的交易达成协议。 但是，如果领导是拜占庭，它可以有意地延迟或丢弃来自诚实节点的消息，并减慢协议。 为了惩罚这些恶意领导者，我们的协议会定期更改每个分片的领导和DS委员会。 这可以防止拜占庭领袖在无限期的时间内拖延共识协议。 由于所有节点都是有序的，下一个领导者将以循环方式选择。</p>\n<p> 事实上，每一个微块后分片的领导者都会改变，并且在每个最后一个区块之后DS委员会的领导者也会更改。 让我们假设共识组的大小为n，那么在一个DS-epoch时期内，我们允许的最终块的最大值为n，每个最终块最多在1个分片聚合1个微块。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Zilliqa网络分片篇翻译\"><a href=\"#Zilliqa网络分片篇翻译\" class=\"headerlink\" title=\"Zilliqa网络分片篇翻译\"></a>Zilliqa网络分片篇翻译</h2><p><a href=\"https://docs.zilliqa.com/whitepaper.pdf\" target=\"_blank\" rel=\"noopener\">英文版本</a></p>\n<h3 id=\"区块\"><a href=\"#区块\" class=\"headerlink\" title=\"区块\"></a>区块</h3><p>ZILLIQA协议介绍两种类型的区块（所以存在两条链）：交易区块(TX-Block)和目录服务区块（DS-Block）。TX-Block记录用户的交易，DS-Block为参与共识协议的矿工的元数据。TX-Block存储被DS-Block中的节点同意的交易，每个DS-Block与多个TX-Blocks相关。</p>\n<p>…</p>\n<h3 id=\"网络层\"><a href=\"#网络层\" class=\"headerlink\" title=\"网络层\"></a>网络层</h3><p>ZILLIQA被设计成是交易率按比例决定。主要的想法是，分片。即，将挖矿网络分成小分片，每个小分片处理交易是并行的。在本节中，我们将介绍网络和交易分片。</p>\n<h4 id=\"网络分片\"><a href=\"#网络分片\" class=\"headerlink\" title=\"网络分片\"></a>网络分片</h4><p>网络分片。将挖矿网络分成小分片是一个两个的过程，首先，一组专用的称为目录服务委员会（或DS委员会）的节点被选举出来，然后他们将将网络和节点分到他们的分片中。在下面，将具体介绍细节。</p>\n<ul>\n<li><p>目录服务委员会（Directory Service Committee）：为了促进网络的切分，我们首先会选举出一组节点，成为目录服务(DS)节点。DS节点形成一个DS委员会。DS节点的选举是基于proof-of-work1算法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//Algorithm 1: PoW1 for DS committee election.</span><br><span class=\"line\">Input: i: Current DS-epoch, DSi−1: Prev. DS committee</span><br><span class=\"line\">composition.</span><br><span class=\"line\">Output: header: DS-Block header.</span><br><span class=\"line\"> On each competing node:</span><br><span class=\"line\">// get epoch randomness from the DS blockchain</span><br><span class=\"line\">// DBi−1: Most recent DS-Block before start of i-th epoch</span><br><span class=\"line\"> r1 ← GetEpochRand(DBi−1)</span><br><span class=\"line\">// get epoch randomness from the transaction blockchain</span><br><span class=\"line\">// TBj : Most recent TX-Block before start of i-th epoch</span><br><span class=\"line\"> r2 ← GetEpochRand(TBj )</span><br><span class=\"line\">// pk: node’s public key, IP = node’s IP address</span><br><span class=\"line\"> nonce, mixHash ← Ethash-PoW(pk, IP, r1, r2)</span><br><span class=\"line\"> header ← BuildHeader(nonce, mixHash, pk)</span><br><span class=\"line\">// header includes pk and nonce among other fields</span><br><span class=\"line\">// IP, header is multicast to members in the DS committee</span><br><span class=\"line\"> MulticastToDSi−1(IP, header)</span><br><span class=\"line\"> return header</span><br></pre></td></tr></table></figure>\n\n<p>比其他节点更早成功产生一个有效的随机数的节点，将为新块提供区块头。回想一下DS-Block头和签名部分，当一个节点解决了POW1，它便可以生产仅仅1个区块头，区块头随后会被多点广播给DS委员会的所有节点，DS委员会将对产生的区块头进行共识后生成签名部分。2f个DS节点签名了区块头，这个区块便被确认添加到DS区块链中。</p>\n<p> 在成功引导阶段后，在任何时候，规定DS节点的组成为一个预定义的窗口大小n0。在最近n0节点中并成功挖掘DS-Block的节点将加入DS委员会。</p>\n<p>连续挖到两个DS-Block之间的平均时间称为DS-epoch。DS-eposh的值的设置是减小两个竞争块几率的一种方法。在DS-epoch的开始，一个新的DS节点加入DS委员然后DS委员会中最老的成员会<u>被挤出(原文为is churned out..不知道该怎么翻译比较好)</u>。这固定了在DS-eposh期间DS委员会的大小始终是n0。DS委员中最新的成员将成为leader, 并领导该时期的共识协议。 这进一步导致了DS委员会成员的严格排序。</p>\n<p>可以看到的是，如果DS委员会的规模n0足够大（比如说800），那么在n0个委员会成员中极有可能最多有1/3是拜占庭。</p>\n</li>\n<li><p>冲突解决：我们的共识协议不允许在DS区块链中分叉。  当多个节点大致同时解决难题时，可能会出现分叉。 为了解决冲突，每个DS节点从接收到的头中检索nonce字段，并按递增顺序对它们进行排序。 让我们假设第i个DS节点的最大随机数是max(nⁱ)。</p>\n<p>DS委员会的leader然后提出自己的header（对应于他所见过的最大随机数），并运行一致的协议来就DS-         Block header达成一致。 只有当相应的随机数大于或等于max(nⁱ)时，<u>第i个DS节点才同意接受建议的header（没理解上）</u>。 一旦达成共识，DS-Block的签名部分就建立起来了，然后成为领导者</p>\n</li>\n<li><p>分片生成：一旦选出DS委员会，网络的实际分片就可以开始。 为了使节点参与下面的共识协议，它必须执行工作证明（PoW2）。 分片协议在每个DS时期开始时重复。 算法2给出了PoW2的算法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Algorithm 2: PoW2 for shard membership.</span><br><span class=\"line\">Input: i: Current DS-epoch, DSi: Current DS committee</span><br><span class=\"line\">composition.</span><br><span class=\"line\">Output: nonce, mixHash: outputs of Ethash-PoW</span><br><span class=\"line\"> On each competing node:</span><br><span class=\"line\">// get epoch randomness from the DS blockchain</span><br><span class=\"line\">// DBi−1: Most recent DS-Block before start of i-th epoch</span><br><span class=\"line\"> r ← GetEpochRand(DBi)</span><br><span class=\"line\">// pk: node’s public key, IP = node’s IP address</span><br><span class=\"line\"> nonce, mixHash ← Ethash-PoW(pk, IP, r)</span><br><span class=\"line\">// IP, header is multicast to members in the DS committee</span><br><span class=\"line\"> MulticastToDSi(nonce, mixHash, pk, IP)</span><br><span class=\"line\"> return nonce, mixHash</span><br></pre></td></tr></table></figure>\n\n<p>然后将计算出的PoW2的有效随机数（和混合散列）多播到DS委员会。 DS节点将共同接受足够的PoW解决方案，以分解为L个共识委员会或分片，每个都具有n0个节点以达成共识。一旦DS委员会负责人收到足够数量的PoW2解决方案，他就启动一个协商一致的协议，以就该组有效的PoW2解决方案达成一致。在共识协议结束时，leader生成由DS节点签名的EC-Schnorr多重签名。为了进一步进行下去，超过2/3的DS节点必须同意一组可接受的PoW2解决方案。<br>Sharding利用确定性函数将节点分配给分片。让我们假设我们需要每个都有n0个节点的碎片。随机数值按升序排序，第一个有n0个节点的节点们被分配给第一个分片，下一个n0分配到下一个分片，依此类推。在碎片中提出最大随机数的矿工的身份被宣布为leader。这进一步诱导了对分片成员的严格排序。也可以表明，如果n0足够大（比如800以上），那么在每个碎片内至多有1/3个是具有高概率的拜占庭</p>\n</li>\n</ul>\n<h4 id=\"公共信道\"><a href=\"#公共信道\" class=\"headerlink\" title=\"公共信道\"></a>公共信道</h4><p>DS节点在公共信道上发布某些信息，包括DS节点的身份和连接信息，每个分片中的节点列表以及交易的分片逻辑（在第V-D节中解释）。 公共频道不可信，并假定所有节点均可访问。 在我们的实现中，我们的广播原语实现了这样的公共频道。 我们区块链的用户想要提交交易以进行接受，然后可以检查分片信息以获取负责处理其交易的碎片。 在公共频道上发布的信息预计将由任何节点或用户可验证的DS节点的2/3以上进行签名。</p>\n<h4 id=\"新节点加入ZILLIQA\"><a href=\"#新节点加入ZILLIQA\" class=\"headerlink\" title=\"新节点加入ZILLIQA\"></a>新节点加入ZILLIQA</h4><p>对于新节点加入网络，它可以尝试解决PoW1成为DS节点或PoW2成为分片的成员。 为此，它需要从区块链获得关于PoW1或PoW2所需的随机性的信息。 一旦获得了随机性信息，新节点就可以将其解决方案提交给DS委员会。</p>\n<h4 id=\"交易分片和过程\"><a href=\"#交易分片和过程\" class=\"headerlink\" title=\"交易分片和过程\"></a>交易分片和过程</h4><p>如以上所述，网络分片创建了每个能够并行处理交易的分片。 在本节中，我们将介绍特定交易如何分配给分片以及如何处理交易。 为此，我们使用以下抽象：A -ⁿ-&gt;B来指示从发件人账户A到收件人账户B的n个ZIL的交易</p>\n<ul>\n<li><p>交易分配：任何交易都表示A -ⁿ-&gt;B被单个分片处理。 假设有L个分片，编号为0到L-1，事务被分配到由发送者地址的(log₂L + 1)右边的位（bit）标识的碎片。即，实例中A的账户地址。因为账户地址是一个160位(bit)的整型数据，所以L的范围应该为<strong>log₂L + 1 ≤ 160</strong>。但实际上，它会小于100。</p>\n<p>一旦识别了分配的分片，事务就会被多播到分片中的一些节点，节点然后再进一步广播它。 一旦交易到达指定分片的领导者，它将把交易包含在TX-Block中并运行共识协议。</p>\n<p>双花（或重播攻击）可以使用每笔交易中的随机数轻松检测。 回想一下，每笔交易都有一个随机数，用于统计发件人帐户发送的交易数量。 一旦交易进入交易区块链，nonce在账户状态中更新，从而处于全局状态。 当前值小于或等于全局状态当前值的交易被矿工拒绝。 根据发件人的帐户地址本地分片交易允许分片成员检测双倍支出，因为发件人的每个交易都将在同一分片中处理。</p>\n</li>\n<li><p>交易处理：委员会内的所有节点都可以提出交易。这些交易被发送给领导者以运行一组协议，其中一组交易形成下一个TX块。由每个分片建议的块称为微块（由类型标记0x00标识）。一个微块包含EC-Schnorr多重签名，由分片中的2/3个节点组成。leader还建立一个标识签名者公钥的位图B。如果分片的第i个成员签署了TX-Block头部，则B [i] = 1。当一个分片在TX块上达成共识时，其领导者将块头和签名多播给一些DS节点。 DS节点然后在DS委员会内广播它，以便该块到达其领导者。块的数据部分可以异步发送到节点。 DS委员会然后汇集从碎片发送的所有块，并且在它们之间运行另一轮共识协议以达成最终块。最后的块是由类型标记0x01标识的TX块。最后一个块包含来自DS委员会的超过2/3个n0节点的EC-Schnorr多重签名。 DS委员会的leader还构建了一个位图B，用于标识签名者的公钥。如果DS委员会的第i个成员签署了TX-Block标题，则B [i] = 1。最后的块头和签名，然后被组播到每个分片中的一些节点。实际的TX块数据不是由DS节点发送的。</p>\n<p>在每个分片中，采取以下步骤来处理最终的块:</p>\n<ol>\n<li>分片中的每个节点使用DS节点的公钥验证EC-Schnorr多重签名。 如果签名对由位图表示的超过2/3个n0公钥有效，则节点执行下一个检查。</li>\n<li>对于包含在最终块头中的每个交易hash，节点检查其相应的交易内容是否可用。 如果相应的交易由节点所属的分片提出，则将交易数据的散列与包含在最后块header中的散列进行比较。 如果交易是由另一个分片提出的，则交易数据跨分片异步共享</li>\n<li>一旦交易数据可用，最终块的data部分被重构并且TX块被附加到本地交易区块链。 账户状态和全局状态相应地被更新。</li>\n<li>如果交易内容不可用，则节点在其本地账户视图中临时使该交易的发送账户失效，以便该账户的任何其他未决交易被拒绝，直到本地交易内容可以与全局状态同步。 这些被拒绝的事务将不得不由发送节点重试</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"共识层\"><a href=\"#共识层\" class=\"headerlink\" title=\"共识层\"></a>共识层</h3><p>如以上提到的，每个分片和DS委员会需要分别在微块和终块上跑一个共识协议。在这一块，我们将展示在每一个分片和DS委员会中定义的共识协议的共识层。在讨论中，我们将分片和DS委员会代指为共识组。</p>\n<h5 id=\"实用拜占庭容错\"><a href=\"#实用拜占庭容错\" class=\"headerlink\" title=\"实用拜占庭容错\"></a>实用拜占庭容错</h5><p>ZILLIQA共识协议的核心依赖于实用拜占庭容错(PBFT)协议。然而我们通过在PBFT中使用EC-Schnorr多签名来提升效率。EC-Schnorr多重签名的使用将正常情况下的通信延迟从O(n*n)降低为O(n)，并将签名大小从O(n)减小到O(1)，其中n是共识组的大小。 在这个部分，我们提供PBFT的概述。</p>\n<p>在PBFT中，共识组内的所有节点都按顺序排列，它有一个主节点（或领导者），其他节点称为备份节点。 每轮PBFT都有三个阶段，如下所述：</p>\n<ul>\n<li>预准备阶段:  在这个阶段，领导者宣布该小组将应该达成一致共识的下一个记录（在我们的案例中是TX-Block）</li>\n<li>准备阶段：在接收到预先准备消息后，每个节点验证其正确性并将准备消息多播给所有其他节点</li>\n<li>提交阶段：在收到超过2/3*n准备消息时，节点向组播组发送提交消息。最后，节点等待超过2/3*n的提交消息，以确保有足够数量的节点做出相同的决定。 因此，所有诚实的节点都接受相同的有效记录。</li>\n</ul>\n<p>PBFT依靠正确的领导者开始每个阶段，并在足够多节点存在时继续进行。 如果领导是拜占庭，它可能会拖延整个共识协议。 为了应对这一挑战，PBFT提供了视图更改协议来使用另一个取代拜占庭领袖。 如果节点在有限的时间内没有看到任何进展，他们可以独立宣布改变领导者的愿望。 如果超过2/3*n个节点的法定人数决定领导者有问题，那么在已知计划中的下一个领导者就会接管。</p>\n<p> 由于在准备/提交阶段每个节点的多播，正常情况下PBFT的通信复杂度为O（n*n）</p>\n<h5 id=\"提高效率\"><a href=\"#提高效率\" class=\"headerlink\" title=\"提高效率\"></a>提高效率</h5><p>经典的PBFT使用消息认证码（MAC）进行节点之间的认证通信。 由于MAC需要在每两个节点之间共享密钥，所以一个共识组中的节点可以在同一个记录上达成一致，其中每个节点的通信复杂度为O（n*n）。 由于二次复杂性，当委员会有20多个节点时，PBFT变得不切实际。</p>\n<p>为了提高效率，我们使用来源于ByzCoin的想法：</p>\n<ul>\n<li>我们用数字签名替换MAC来有效地减少O（n）的通信开销。</li>\n<li>与此同时，为了让其他节点能够验证协议，一种典型的方法是从诚实的多数收集签名并将它们附加到协议中，从而导致协商规模与协商组的大小成线性关系。 为了改善这一点，我们使用EC-Schnorr多重签名来将几个签名聚合成O（1） - 大小多重签名</li>\n</ul>\n<p>然而，我们不能直接在PBFT设置中使用经典的EC-Schnorr多重签名方案。 这是因为在古典设置中，所有签名者都同意签署给定的消息，并且签名只有在所有签名者都签名后才有效。 在PBFT设置中，我们只需要在共识组中超过2/3*n个节点签署消息。 所需的主要修改之一是为参与签名过程的签名者维护位图B. 如果第i个节点参与该过程，则B [i] = 1，否则为0。位图由领导者构建。 位图可以被任何验证者用来验证签名。 最终的协议留在附录B中。</p>\n<h5 id=\"Zilliqa共识\"><a href=\"#Zilliqa共识\" class=\"headerlink\" title=\"Zilliqa共识\"></a>Zilliqa共识</h5><p>在ZILLIQA中，我们使用PBFT作为基础共识协议，并采用两轮EC-Schnorr多重签名来替换PBFT中的准备阶段和提交阶段。 下面将解释对PBFT阶段的不同修改。</p>\n<ul>\n<li>预准备阶段: 与标准PBFT中一样，领导者将TX-Block或声明（由领导者签名）分发给共识组中的所有节点。</li>\n<li>准备阶段：所有诚实的节点检查TX块的有效性，并且领导者收集来自超过2/3*n个节点的响应。 这保证领导者提出的陈述是安全的并且与以前的所有历史一致。 签名是使用EC-Schnorr多重签名生成的。 领导者还构建签署TX块的节点的位图</li>\n<li>提交阶段：为了确保超过2/3*n的节点知道超过2/3*n节点验证了TX-Block的事实。我们进行第二轮EC-Schnorr多重签名。 正在签署的声明是上一轮生成的多重签名。</li>\n</ul>\n<p>在三个阶段结束时，就领导者提出的TX-Block将达成共识。</p>\n<h5 id=\"领导者改变\"><a href=\"#领导者改变\" class=\"headerlink\" title=\"领导者改变\"></a>领导者改变</h5><p>在我们的共识协议中，如果领导者是诚实的，它可以不断的推动共识小组中的节点就新的交易达成协议。 但是，如果领导是拜占庭，它可以有意地延迟或丢弃来自诚实节点的消息，并减慢协议。 为了惩罚这些恶意领导者，我们的协议会定期更改每个分片的领导和DS委员会。 这可以防止拜占庭领袖在无限期的时间内拖延共识协议。 由于所有节点都是有序的，下一个领导者将以循环方式选择。</p>\n<p> 事实上，每一个微块后分片的领导者都会改变，并且在每个最后一个区块之后DS委员会的领导者也会更改。 让我们假设共识组的大小为n，那么在一个DS-epoch时期内，我们允许的最终块的最大值为n，每个最终块最多在1个分片聚合1个微块。</p>\n"},{"title":"dai","date":"2019-10-14T06:52:04.000Z","_content":"\n## dai\n\n#### 合约学习\n\n从[github](https://github.com/makerdao/dss)上克隆下来源码。目录结构为\n\n```\nsrc\n    ├── cat.sol   //面向用户的清算CDP网关合约\n    ├── dai.sol   //Dai稳定币合约\n    ├── end.sol  //\n    ├── flap.sol  //当系统有盈余时，负责购买和燃烧MKR\n    ├── flip.sol\n    ├── flop.sol  //当系统有坏账时，负责发行和出售MKR\n    ├── join.sol  //负责发行和燃烧DAI的适配器(DAI? ETH抵押品？)\n    ├── jug.sol\n    ├── lib.sol\n    ├── pot.sol\n    ├── spot.sol\n    ├── test\n    ├── vat.sol  //CDP核心引擎，DAI系统记账\n    └── vow.sol\n```\n\n\n\n#### 合约词汇表\n\n##### 常用\n\n- `guy`，`usr`：一些地址\n- `wad`：一些数量的标记，通常作为一个固定点整数，十进制位数为10 ^ 18。\n- `ray`：一个固定位数整数，十进制位数为10 ^ 27。\n- `rad`：一个固定位数整数，十进制位数为10 ^ 45。\n- `file`：管理一些配置值\n\n##### 认证(auth)\n\n- `auth`：检查地址是否可以调用此方法\n- `ward`：允许调用authed方法的地址\n- `rely`：允许一个地址调用authed方法，或将一个地址添加到ward中\n- `deny`：禁止一个地址调用authed方法，或将一个地址从ward中移除\n\n##### CDP引擎 vat\n\n- `CDP`：抵押债务位置\n\n- `gem`：抵押代币，数据类型为map(byte32)map(address)uint256, 某类型抵押代币下某地址的抵押个数\n\n- `dai`：稳定代币\n\n- `sin`：antioin令牌（系统债务，不属于任何`urn`）\n\n- `ilk`：抵押品类型\n\n  - `rate`：稳定债务乘数（累计稳定费）\n  - `take`：抵押余额乘数\n  - `Ink`：抵押品总余额 ?代码里好像没了\n  - `Art`：总稳定债务\n  - `spot`：具有安全边际的抵押品价格，即每单位抵押品允许的最大稳定币\n  - `line`：特定抵押品类型的债务上限\n  - `dust`：CDP的最低可能债务\n\n- `Line`：所有抵押品类型的总债务上限\n\n- `init`：创建一个新的抵押品类型\n\n- `urn`：一个特定的CDP\n\n  - `ink`：抵押品余额\n  - `art`：未偿还稳定债务\n\n- `debt`：发行的稳定币总量\n\n- `vice`：系统债务总量\n\n- `slip`：修改用户的抵押品余额(操作gem)\n\n- `flux`：在用户之间转移抵押品(操作gem)\n\n- `move`：在用户之间转移stablecoin\n\n- `grab`：清算CDP，(只做记录，记录为抵押物减少(增加)，抵押品余额增加(减少)？)\n\n  ```\n    function grab(bytes32 i, address u, address v, address w, int dink, int dart) external note auth {\n          Urn storage urn = urns[i][u];\n          Ilk storage ilk = ilks[i];\n\n          urn.ink = add(urn.ink, dink);\n          urn.art = add(urn.art, dart);\n          ilk.Art = add(ilk.Art, dart);\n\n          int dtab = mul(ilk.rate, dart);\n\n          gem[i][v] = sub(gem[i][v], dink);\n          sin[w]    = sub(sin[w],    dtab);\n          vice      = sub(vice,      dtab);\n      }\n  ```\n\n- `heal`：创建/销毁等量的稳定币和系统债务（`vice`）\n\n- `fold`：修改债务乘数，创造/销毁相应的债务?\n\n  ```\n    function fold(bytes32 i, address u, int rate) external note auth {\n          require(live == 1);\n          Ilk storage ilk = ilks[i];\n          ilk.rate = add(ilk.rate, rate);\n          int rad  = mul(ilk.Art, rate);\n          dai[u]   = add(dai[u], rad);\n          debt     = add(debt,   rad);\n      }\n  ```\n\n- `toll`：修改抵押品乘数，创建/销毁相应的抵押品\n\n- `suck`：铸造稳定币（占比`vice`）\n\n- `frob`：修改CDP\n\n  - `lock`：将抵押品转移到CDP\n  - `free`：从CDP转移抵押品\n  - `draw`：增加CDP债务，创造Dai\n  - `wipe`：减少CDP债务，摧毁Dai\n  - `dink`：抵押品的变化\n  - `dart`：债务变动\n  - `calm`：当CDP仍处于抵押品和总债务上限时，这是真的\n  - `cool`：当稳定债务没有增加时，这是真的\n  - `firm`：当抵押品余额没有减少时为真\n  - `safe`：当CDP的抵押品与债务比率高于抵押品的清算比率时为真\n\n- `fork`：拆分CDP - 二进制批准或拆分/合并CDP\n\n  - `dink`：交换抵押品的数量\n  - `dart`：交换的稳定债务金额\n\n- `wish`：检查地址是否允许修改另一个地址的gem或dai余额\n\n  - `hope`：启用`wish`一对地址\n  - `nope`：禁用`wish`一对地址\n\n##### 稳定费用 jug\n\n- `duty`：稳定费\n- `base`：全球稳定费\n- `rho`：最后一次收集这种抵押品时间\n- `drip`：确定增加\n\n##### 清算 cat\n\n- `mat`：清算比率\n- `chop`：清算罚款\n- `lump`：清算数量，即任何一次清算事件所涵盖的固定债务数量\n- `bite`：开始清算CDP\n- `flip`：清算CDP的抵押品以支付固定数额的债务\n\n##### 结算 vow\n\n- `sin`：债务队列\n- `Sin`：队列中的总债务\n- `Woe`：非排队的非拍卖债务总额\n- `Ash`：拍卖总债务\n- `Awe`：债务总额\n- `Joy`：总盈余\n- `fess`：向队列添加债务\n- `flog`：从队列中实现债务\n- `wait`：队列的长度\n- `heal`：取消盈余和债务\n- `kiss`：取消盈余和拍卖债务\n- `sump`：债务拍卖手数，即任何一次债务拍卖所涵盖的固定债务数量\n- `bump`：剩余拍卖手数，即任何一次剩余拍卖所出售的固定剩余数量\n- `hump`：在剩余拍卖可能之前必须超过剩余缓冲\n\n##### 拍卖 flop flip flap\n\n- `flip`：抵押品拍卖（使用稳定币进行交易？）\n- `flop`：债务拍卖（通过膨胀MKR和出售稳定币来偿还债务)(以稳定币购买MKR？)\n- `flap`：剩余拍卖（出售MKR的稳定币)（以MKR来购买稳定币）\n- `lot`：拍卖数量\n- `bid`：提供的数量 `lot`\n- `tab`：总dai将被提高（`flip`拍卖中）\n- `guy`：高出价者\n- `gal`：拍卖收入的获得者\n- `ttl`：出价终身\n- `beg`：最低出价增加\n- `tau`：最长拍卖时间\n- `end`：拍卖结束时\n- `kick`：开始拍卖\n- `tick`：重新开始拍卖\n- `tend`：出价，增加出价大小\n- `dent`：出价，减少手数\n- `deal`：要求中标\n\n##### 全球结算  end\n\n- `when`：结算时间\n- `wait`：处理冷却时间长度（允许不足的CDP为`skim`med）\n- `debt`：在系统盈余/赤字被吸收后，出色的稳定供应量\n- `tag`：结算时每种抵押品的价格\n- `gap`：考虑到不合标准的CDP，每个抵押品的差额\n- `fix`：现金价格`ilk`（每稳定金额）\n- `bag`：无法转移的稳定币准备交换抵押品\n- `out`：已交换的给定地址的稳定币的数量\n- `cage`：冻结系统，取消`flip`/ `flop`拍卖，开始冷却期\n- `cage(ilk)`：设定结算价格\n- `skim`：取消CDP债务，取得抵押担保，但留下过剩\n- `skip`：可选择取消现场拍卖\n- `free`：从CDP中删除抵押品\n- `thaw`：修复了稳定币的总供应量\n- `flow`：计算`fix`同类产品的价格，可能`cage`用盈余/赤字调整价格\n- `pack`：把一些稳定的金币放入`bag`准备中`cash`\n- `cash`：交换一些`bag`给定的稳定币`gem`，与`bag`大小成比例的份额\n\n#### 基本知识点\n\n##### 用户类型\n\nMaker 主要有三种 user case。作为普通想使用稳定货币的人，他们可以在交易所用美元或者人民币购买 DAI，然后用来交易、支付甚至竞猜。\n\n第二个是比较高级的用户，他们锁定自己的抵押资产，借 DAI 进行杠杆交易。\n\n第三个是更深参与系统中的用户，他们持有 MKR 管理型货币，维护系统，同时如果管理得当获益。\n\n##### 货币\n\n在 Maker 体系中有两种主要的货币。第一个是 DAI，稳定货币。他是一种有资产背书的硬通货，在无需准许的信贷系统中生成。也就是说，任何用户可以锁定他们有价值的数字资产，然后生成 DAI。系统用动态的目标利率去调节 DAI 的价格。在第一版 DAI 里，我们会保持 DAI 的价格在 1：1 美元左右浮动。\n\n第二种代币是 MKR，也就是 Maker。MKR 是管理型代币。拥有 MKR 的用户组成一个去中心化的管理社区，他们决定哪种有价值的数字资产可以作为抵押资产，清算比例等等。作为对他们服务的回报，当用户赎回抵押物的时候，他们不仅要返还 DAI，还要加上一小部分费用，其中一部分费用会被用来购买并销毁 MKR 以关闭抵押债仓。也就是说 MKR 是信贷系统的燃料。\n\n\n\n##### 信贷系统\n\n用户如果要借 DAI，他们首先要建立一个抵押债仓（CDP），然后将数字资产作为抵押物，生成 DAI。然后他可以用 DAI 去做多他看好的资产。最后买回 DAI，偿还 DAI 和一部分费用拿回抵押资产。\n\n我们在这张图中可以看到，抵押物的价值始终大于 DAI 的价值。这是因为抵押物的价值会有波动，我们要确保 DAI 有足够的抵押。如果抵押物升值并没有太大影响，意味着 DAI 有更足够的抵押。但是如果抵押物减值，系统需要对此做出反应。\n\n当抵押物价值低于清算值，CDP 会被清算。抵押物会被强制平仓，用来回购 DAI，以保证 DAI 的偿付能力。可以想象为 margin call(追加保证金)。\n\n那么，在这一次的发布中，我们会用什么作为抵押资产呢。我们叫做 pooled-ETH，以太池。在之后的发布中，我们会引入多重资产抵押。目前我们还在开发多重资产抵押的过程中，在这一次的发布中，我们用以太池作为抵押代币。\n\n\n\n他的运行机制是：用户首先将 ETH 放入合同中，然后回收到相应比例的 ETH 兑换凭证，PETH。起初，PETH 和 ETH 的比例是一比一。但是这一比例会随着系统的表现而改变。\n\n如果系统运行良好，所有的 CDP 在偿还时会不断产生费用。一部分费用会被用来回购和销毁 PETH。销毁 PETH 意味着剩下的 PETH 可以兑换更多的 ETH。对于大多数用户来说，他们也许会抵押 PETH，用来借 DAI，然后做多资产。用户也可以选择持有 PETH，获得费用收益。\n\n\n\n当黑天鹅时间发生时，抵押物的价格大幅度下降，甚至低于 DAI 的价格，清算机制都来不及应对。这时候系统会通过增发 PETH 来回购 DAI 以支撑抵押不足的 DAI。\n\n当用户关闭 CDP 时，一部分费用会用来回购销毁 PETH，另一部分费用会用来购买 MKR，作为管理费用。\n\n\n\n##### 清算操作\n\n![img](https://img.chainnews.com/material/images/a527abfe7199a3eb00887ea7f13e8293.jpg)\n\n- 触发发生清算\n\n  预言机根据现在 PETH 的价格反馈给 Maker 平台。Maker平台需要抵押资产的实时价格信息以决定何时触动清算。也就是说需要看户机拿到这个价格，根据这个价格是否发生清算。\n\n\n\n- 发生清算\n\n  当此时发生清算了，预言机触发反馈给看户机，看护机在 CDP 清算的时候参与债务拍卖和抵押资产拍卖 。看护机也会围绕目标价格交易 Dai。当市场价格高于目标价格的时候，看护机将出售 Dai 。同理，当市场价格低于目标价格的时候，看护机将买入 Dai。这样做的是为了从市场长期价格趋同目标价格中获益。注：看户机只是做一个策略，它决定什么时候进行出售。当出售的时候他会根据系统喂价直接与以太坊使用者和看护机进行交易的智能合约。当 CDP 被清算，系统会立即回收其抵押品。CDP 持有者会收到去除债务、稳定费用和清算罚金后的剩余抵押资产。这里分两种情况：\n\n  - 第一种，正常情况\n\n    PETH 抵押资产将会在流动性供给合约中出售，看护机可以自动交易 Dai 购买 PETH。所有支付的 Dai会从流通中立即销毁，直到 CDP 债务数量被消除。如果在去除 CDP 债务后还有剩余的 Dai，这部分 Dai会被用来购买并销毁 PETH，从而提高 PETH 可兑换 ETH 的比例。这对 PETH 持有者来说将会是收益。\n\n  - 第二种，非正常的情况下\n\n    如果出售的 PETH 未能募集到足够的 Dai 以偿付整个债务，系统会连续增发并出售 PETH。以这种方式新创造出来的 PETH 会降低 PETH 可兑换ETH 的比例，从而使得 PETH 持有者收益减少。\n\n  在清算发生时，Maker 平台会购买 CDP 中的抵押物并逐渐通过自动竞卖的方式售出。竞卖的机制可以让系统即使在无法获得价格信息的时候，处理 CDP。为了能够回购 CDP 中的抵押资产并用来出售，系统会首先募集足够的 Dai 以偿付 CDP 的债务。这一过程叫做债务竞卖，通过增发 MKR的供给并以竞卖的方式出售给竞卖参与者。\n\n  与此同时，CDP 中的抵押资产会以抵押资产竞卖的方式出售，CDP 债务和清算罚金的部分会用来回购并销毁 MKR。这可以直接抵销在债务竞卖中增发的MKR。如果有足够的 Dai 用来偿付 CDP 中的债务加上清算罚金，那么抵押竞卖会转换到反向竞卖机制，竞卖最少的抵押品 - 任何剩余的抵押品都会归还给CDP 的原所有者。\n\n\n\n- 流动性供给合约 (单一抵押阶段过渡性机制)\n\n  在单一抵押资产 Dai 的阶段，清算的过程叫做流动性供给合约。根据系统喂价直接与以太坊使用者和看护机进行交易的智能合约。当 CDP被清算，系统会立即回收其抵押品。CDP 持有者会收到去除债务、稳定费用和清算罚金后的剩余抵押资产。\n\n  PETH 抵押资产将会在流动性供给合约中出售，看护机可以自动交易 Dai 购买 PETH。所有支付的 Dai 会从流通中立即销毁，直到 CDP债务数量被消除。如果在去除 CDP 债务后还有剩余的 Dai，这部分 Dai 会被用来购买并销毁 PETH ，从而提高 PETH 可兑换 ETH的比例。这对 PETH 持有者来说将会是收益。\n\n  如果出售的 PETH 未能募集到足够的 Dai 以偿付整个债务，系统会连续增发并出售 PETH。以这种方式新创造出来的 PETH 会降低 PETH 可兑换ETH 的比例，从而使得 PETH 持有者收益减少。\n\n\n\n- 债务竞卖和抵押资产竞卖（多种抵押阶段机制）\n\n  在清算发生时，Maker 平台会购买 CDP 中的抵押物并逐渐通过自动竞卖的方式售出。\n\n  竞卖的机制可以让系统即使在无法获得价格信息的时候，处理 CDP。为了能够回购 CDP 中的抵押资产并用来出售，系统会首先募集足够的 Dai 以偿付 CDP 的债务。这一过程叫做债务竞卖，通过增发 MKR的供给并以竞卖的方式出售给竞卖参与者。与此同时，CDP 中的抵押资产会以抵押资产竞卖的方式出售，CDP 债务和清算罚金的部分会用来回购并销毁 MKR 。这可以直接抵销在债务竞卖中增发的 MKR。如果有足够的 Dai 用来偿付 CDP 中的债务加上清算罚金，那么抵押竞卖会转换到反向竞卖机制，竞卖最少的抵押品 - 任何剩余的抵押品都会归还给 CDP的原所有者。\n\n\n\n- 清算期间会发生什么\n\n  当 Keeper 关闭 CDP 并将其发送到流动性提供合同（LPC）时，清算就会发生，而 LPC 又会在 Dai Dashboard 上提供 CDP资产。一旦履行了债务义务，未售出的 PETH 抵押品将返还给 CDP 所有者。\n\n  操作顺序如下：\n\n  - 违约的 CDP 已关闭。\n  - 罚款费用适用于 DAI 债务。\n  - LPC 移除了足够的 PETH 抵押品以满足当前 Oracle 价格的债务。\n  - CDP 所有者现在能够从关闭位置移除他们的剩余抵押品。\n  - 被扣押的 PETH 在 dai.makerdao.com 上出售，其激励折扣称为 Boom / Bust Spread ，适用于该值。\n  - 出售 PETH 所赚取的 DAI 被烧毁以消灭 CDP 债务。\n  - 如果销售中存在过量的 DAI ，那么它将被 PETH 出售，然后燃烧，从而增加剩余 PETH 的价值。\n  - 如果出售的 DAI 不足，那么 PETH 将被发行并出售以弥补不足。这会稀释池的总价值。\n\n\n\n- 清算后剩余多少抵押品\n\n  简化公式\n\n  ```\n  （抵押品 × Oracle 价格 × PETH / ETH 比率） - （清算罚款 × 稳定性债务） - 稳定性债务 =（剩余抵押品 ×Oracle 价格） DAI\n\n  ```\n\n  假设：\n\n  - 一个 ETH 的 Oracle 价格是 350USD\n\n  - 锁定 PETH 总数为 10 ETH\n\n  - PETH / ETH 的比率为 1.012\n\n  - 清算罚款为 13％\n\n  - CDP 的稳定债务为 1000 DAI\n\n    计算为(10 × 350 × 1.012) − (13% × 1000) − 1000 = 2412 DAI 或 6.891428571 ETH\n\n\n\n- 清算价格\n\n  可以使用以下简化公式来确定抵押品的价值必须达到多远才能触发结算：\n\n  ```\n  （稳定债务 × 清算比率）/（抵押品 × PETH / ETH 比率）= 清算价格\n  ```\n\n  例如：\n\n  - 一个 ETH 的值是 350 USD\n\n  - 总赌注 PETH 为 12\n\n  - PETH / ETH 的比率为 1.012\n\n  - 清算比率为 150％\n\n  - 稳定债务是 1000 DAI\n\n    计算为(1000 × 1.5) ÷ (12 × 1.012) = 123.51 USD\n\n    在 CDP 被认为不安全并且有被清算的风险之前，ETH 的价格需要降至 123.51 美元。\n\n\n\n- 计算抵押比率\n\n  如果希望通过查看抵押品与债务的比率来确定抵押物的健康状况，与清算价格相反，可以使用以下简化公式：\n\n  ```\n  （锁定 PETH × ETH 价格 × PETH / ETH 比率）÷ 稳定性债务 × 100 = 抵押比率\n  ```\n\n  举例：\n\n  - 一个 ETH 的值是 350 USD\n  - 总赌注 PETH 为 12\n  - PETH / ETH 的比率为 1.012\n  - 稳定债务是 1000 DAI\n\n  计算为(12 × 350 × 1.012) ÷ 1000 × 100 = 425.04%\n\n  CDP 的抵押比率为 425.04％。\n\n\n\n- 降低清算价格\n\n  CDP 所有者面临的主要挑战是在高度不可预测的市场中保持安全的杠杆状态。如果 CDP 接近清算价格，用户可以添加更多抵押品或返回 DAI以降低风险。如果用户坚信基础抵押品的未来价值，用户可以决定为他的抵押物增加更多。或者，如果用户希望降低价格波动的风险，他可以通过将 DAI 返还给自己的CDP 来偿还债务。降低清算风险的最佳方法是偿还 DAI ，因为清算价格会更有效地降低。\n\n  假设：\n\n  - 一个 ETH 的值是 350 USD\n  - 总赌注 PETH 为 12\n  - PETH / ETH 的比率为 1.012\n  - 清算比率为 150％\n  - 稳定债务是 1000 DAI\n\n  目前的清算价格：\n\n  (1000 × 1.5 ) ÷ (12 × 1.012) = 123.51 USD\n\n  清算价格变动，增加 700 美元的抵押品：\n\n  (1000 × 1.5 ) ÷ (14 × 1.012) = 105.87 USD\n\n  清算价格变动，取消 700 美元的债务：\n\n  (300 × 1.5 ) ÷ (12 × 1.012) = 37.05 USD\n\n  我们可以看到，通过返还 DAI 而不是增加更多抵押品，显着降低了清算价格。\n\n\n\n- 如何出售抵押品\n\n  当 Keeper 清算不安全的 CDP 时，流动性提供合同（LPC）确保在 Dai Dashboard 上出售抵押品。销售价格由应用了特殊修饰符的Oracle Feed确定。此修饰符通常采用折扣的形式，然后应用于必须回收的未偿还债务。这种额外的“差价”旨在通过向抵押品买方提供优于市场价格来激励系统的快速资本重组。用户可以在仪表板上购买已被 LPC 占用的 PETH 。出售的任何 DAI 盈余都可以用 PETH 购买。\n","source":"_posts/dai.md","raw":"---\ntitle: dai\ncategories:\n  - eth\ndate: 2019-10-14 14:52:04\ntags:\n---\n\n## dai\n\n#### 合约学习\n\n从[github](https://github.com/makerdao/dss)上克隆下来源码。目录结构为\n\n```\nsrc\n    ├── cat.sol   //面向用户的清算CDP网关合约\n    ├── dai.sol   //Dai稳定币合约\n    ├── end.sol  //\n    ├── flap.sol  //当系统有盈余时，负责购买和燃烧MKR\n    ├── flip.sol\n    ├── flop.sol  //当系统有坏账时，负责发行和出售MKR\n    ├── join.sol  //负责发行和燃烧DAI的适配器(DAI? ETH抵押品？)\n    ├── jug.sol\n    ├── lib.sol\n    ├── pot.sol\n    ├── spot.sol\n    ├── test\n    ├── vat.sol  //CDP核心引擎，DAI系统记账\n    └── vow.sol\n```\n\n\n\n#### 合约词汇表\n\n##### 常用\n\n- `guy`，`usr`：一些地址\n- `wad`：一些数量的标记，通常作为一个固定点整数，十进制位数为10 ^ 18。\n- `ray`：一个固定位数整数，十进制位数为10 ^ 27。\n- `rad`：一个固定位数整数，十进制位数为10 ^ 45。\n- `file`：管理一些配置值\n\n##### 认证(auth)\n\n- `auth`：检查地址是否可以调用此方法\n- `ward`：允许调用authed方法的地址\n- `rely`：允许一个地址调用authed方法，或将一个地址添加到ward中\n- `deny`：禁止一个地址调用authed方法，或将一个地址从ward中移除\n\n##### CDP引擎 vat\n\n- `CDP`：抵押债务位置\n\n- `gem`：抵押代币，数据类型为map(byte32)map(address)uint256, 某类型抵押代币下某地址的抵押个数\n\n- `dai`：稳定代币\n\n- `sin`：antioin令牌（系统债务，不属于任何`urn`）\n\n- `ilk`：抵押品类型\n\n  - `rate`：稳定债务乘数（累计稳定费）\n  - `take`：抵押余额乘数\n  - `Ink`：抵押品总余额 ?代码里好像没了\n  - `Art`：总稳定债务\n  - `spot`：具有安全边际的抵押品价格，即每单位抵押品允许的最大稳定币\n  - `line`：特定抵押品类型的债务上限\n  - `dust`：CDP的最低可能债务\n\n- `Line`：所有抵押品类型的总债务上限\n\n- `init`：创建一个新的抵押品类型\n\n- `urn`：一个特定的CDP\n\n  - `ink`：抵押品余额\n  - `art`：未偿还稳定债务\n\n- `debt`：发行的稳定币总量\n\n- `vice`：系统债务总量\n\n- `slip`：修改用户的抵押品余额(操作gem)\n\n- `flux`：在用户之间转移抵押品(操作gem)\n\n- `move`：在用户之间转移stablecoin\n\n- `grab`：清算CDP，(只做记录，记录为抵押物减少(增加)，抵押品余额增加(减少)？)\n\n  ```\n    function grab(bytes32 i, address u, address v, address w, int dink, int dart) external note auth {\n          Urn storage urn = urns[i][u];\n          Ilk storage ilk = ilks[i];\n\n          urn.ink = add(urn.ink, dink);\n          urn.art = add(urn.art, dart);\n          ilk.Art = add(ilk.Art, dart);\n\n          int dtab = mul(ilk.rate, dart);\n\n          gem[i][v] = sub(gem[i][v], dink);\n          sin[w]    = sub(sin[w],    dtab);\n          vice      = sub(vice,      dtab);\n      }\n  ```\n\n- `heal`：创建/销毁等量的稳定币和系统债务（`vice`）\n\n- `fold`：修改债务乘数，创造/销毁相应的债务?\n\n  ```\n    function fold(bytes32 i, address u, int rate) external note auth {\n          require(live == 1);\n          Ilk storage ilk = ilks[i];\n          ilk.rate = add(ilk.rate, rate);\n          int rad  = mul(ilk.Art, rate);\n          dai[u]   = add(dai[u], rad);\n          debt     = add(debt,   rad);\n      }\n  ```\n\n- `toll`：修改抵押品乘数，创建/销毁相应的抵押品\n\n- `suck`：铸造稳定币（占比`vice`）\n\n- `frob`：修改CDP\n\n  - `lock`：将抵押品转移到CDP\n  - `free`：从CDP转移抵押品\n  - `draw`：增加CDP债务，创造Dai\n  - `wipe`：减少CDP债务，摧毁Dai\n  - `dink`：抵押品的变化\n  - `dart`：债务变动\n  - `calm`：当CDP仍处于抵押品和总债务上限时，这是真的\n  - `cool`：当稳定债务没有增加时，这是真的\n  - `firm`：当抵押品余额没有减少时为真\n  - `safe`：当CDP的抵押品与债务比率高于抵押品的清算比率时为真\n\n- `fork`：拆分CDP - 二进制批准或拆分/合并CDP\n\n  - `dink`：交换抵押品的数量\n  - `dart`：交换的稳定债务金额\n\n- `wish`：检查地址是否允许修改另一个地址的gem或dai余额\n\n  - `hope`：启用`wish`一对地址\n  - `nope`：禁用`wish`一对地址\n\n##### 稳定费用 jug\n\n- `duty`：稳定费\n- `base`：全球稳定费\n- `rho`：最后一次收集这种抵押品时间\n- `drip`：确定增加\n\n##### 清算 cat\n\n- `mat`：清算比率\n- `chop`：清算罚款\n- `lump`：清算数量，即任何一次清算事件所涵盖的固定债务数量\n- `bite`：开始清算CDP\n- `flip`：清算CDP的抵押品以支付固定数额的债务\n\n##### 结算 vow\n\n- `sin`：债务队列\n- `Sin`：队列中的总债务\n- `Woe`：非排队的非拍卖债务总额\n- `Ash`：拍卖总债务\n- `Awe`：债务总额\n- `Joy`：总盈余\n- `fess`：向队列添加债务\n- `flog`：从队列中实现债务\n- `wait`：队列的长度\n- `heal`：取消盈余和债务\n- `kiss`：取消盈余和拍卖债务\n- `sump`：债务拍卖手数，即任何一次债务拍卖所涵盖的固定债务数量\n- `bump`：剩余拍卖手数，即任何一次剩余拍卖所出售的固定剩余数量\n- `hump`：在剩余拍卖可能之前必须超过剩余缓冲\n\n##### 拍卖 flop flip flap\n\n- `flip`：抵押品拍卖（使用稳定币进行交易？）\n- `flop`：债务拍卖（通过膨胀MKR和出售稳定币来偿还债务)(以稳定币购买MKR？)\n- `flap`：剩余拍卖（出售MKR的稳定币)（以MKR来购买稳定币）\n- `lot`：拍卖数量\n- `bid`：提供的数量 `lot`\n- `tab`：总dai将被提高（`flip`拍卖中）\n- `guy`：高出价者\n- `gal`：拍卖收入的获得者\n- `ttl`：出价终身\n- `beg`：最低出价增加\n- `tau`：最长拍卖时间\n- `end`：拍卖结束时\n- `kick`：开始拍卖\n- `tick`：重新开始拍卖\n- `tend`：出价，增加出价大小\n- `dent`：出价，减少手数\n- `deal`：要求中标\n\n##### 全球结算  end\n\n- `when`：结算时间\n- `wait`：处理冷却时间长度（允许不足的CDP为`skim`med）\n- `debt`：在系统盈余/赤字被吸收后，出色的稳定供应量\n- `tag`：结算时每种抵押品的价格\n- `gap`：考虑到不合标准的CDP，每个抵押品的差额\n- `fix`：现金价格`ilk`（每稳定金额）\n- `bag`：无法转移的稳定币准备交换抵押品\n- `out`：已交换的给定地址的稳定币的数量\n- `cage`：冻结系统，取消`flip`/ `flop`拍卖，开始冷却期\n- `cage(ilk)`：设定结算价格\n- `skim`：取消CDP债务，取得抵押担保，但留下过剩\n- `skip`：可选择取消现场拍卖\n- `free`：从CDP中删除抵押品\n- `thaw`：修复了稳定币的总供应量\n- `flow`：计算`fix`同类产品的价格，可能`cage`用盈余/赤字调整价格\n- `pack`：把一些稳定的金币放入`bag`准备中`cash`\n- `cash`：交换一些`bag`给定的稳定币`gem`，与`bag`大小成比例的份额\n\n#### 基本知识点\n\n##### 用户类型\n\nMaker 主要有三种 user case。作为普通想使用稳定货币的人，他们可以在交易所用美元或者人民币购买 DAI，然后用来交易、支付甚至竞猜。\n\n第二个是比较高级的用户，他们锁定自己的抵押资产，借 DAI 进行杠杆交易。\n\n第三个是更深参与系统中的用户，他们持有 MKR 管理型货币，维护系统，同时如果管理得当获益。\n\n##### 货币\n\n在 Maker 体系中有两种主要的货币。第一个是 DAI，稳定货币。他是一种有资产背书的硬通货，在无需准许的信贷系统中生成。也就是说，任何用户可以锁定他们有价值的数字资产，然后生成 DAI。系统用动态的目标利率去调节 DAI 的价格。在第一版 DAI 里，我们会保持 DAI 的价格在 1：1 美元左右浮动。\n\n第二种代币是 MKR，也就是 Maker。MKR 是管理型代币。拥有 MKR 的用户组成一个去中心化的管理社区，他们决定哪种有价值的数字资产可以作为抵押资产，清算比例等等。作为对他们服务的回报，当用户赎回抵押物的时候，他们不仅要返还 DAI，还要加上一小部分费用，其中一部分费用会被用来购买并销毁 MKR 以关闭抵押债仓。也就是说 MKR 是信贷系统的燃料。\n\n\n\n##### 信贷系统\n\n用户如果要借 DAI，他们首先要建立一个抵押债仓（CDP），然后将数字资产作为抵押物，生成 DAI。然后他可以用 DAI 去做多他看好的资产。最后买回 DAI，偿还 DAI 和一部分费用拿回抵押资产。\n\n我们在这张图中可以看到，抵押物的价值始终大于 DAI 的价值。这是因为抵押物的价值会有波动，我们要确保 DAI 有足够的抵押。如果抵押物升值并没有太大影响，意味着 DAI 有更足够的抵押。但是如果抵押物减值，系统需要对此做出反应。\n\n当抵押物价值低于清算值，CDP 会被清算。抵押物会被强制平仓，用来回购 DAI，以保证 DAI 的偿付能力。可以想象为 margin call(追加保证金)。\n\n那么，在这一次的发布中，我们会用什么作为抵押资产呢。我们叫做 pooled-ETH，以太池。在之后的发布中，我们会引入多重资产抵押。目前我们还在开发多重资产抵押的过程中，在这一次的发布中，我们用以太池作为抵押代币。\n\n\n\n他的运行机制是：用户首先将 ETH 放入合同中，然后回收到相应比例的 ETH 兑换凭证，PETH。起初，PETH 和 ETH 的比例是一比一。但是这一比例会随着系统的表现而改变。\n\n如果系统运行良好，所有的 CDP 在偿还时会不断产生费用。一部分费用会被用来回购和销毁 PETH。销毁 PETH 意味着剩下的 PETH 可以兑换更多的 ETH。对于大多数用户来说，他们也许会抵押 PETH，用来借 DAI，然后做多资产。用户也可以选择持有 PETH，获得费用收益。\n\n\n\n当黑天鹅时间发生时，抵押物的价格大幅度下降，甚至低于 DAI 的价格，清算机制都来不及应对。这时候系统会通过增发 PETH 来回购 DAI 以支撑抵押不足的 DAI。\n\n当用户关闭 CDP 时，一部分费用会用来回购销毁 PETH，另一部分费用会用来购买 MKR，作为管理费用。\n\n\n\n##### 清算操作\n\n![img](https://img.chainnews.com/material/images/a527abfe7199a3eb00887ea7f13e8293.jpg)\n\n- 触发发生清算\n\n  预言机根据现在 PETH 的价格反馈给 Maker 平台。Maker平台需要抵押资产的实时价格信息以决定何时触动清算。也就是说需要看户机拿到这个价格，根据这个价格是否发生清算。\n\n\n\n- 发生清算\n\n  当此时发生清算了，预言机触发反馈给看户机，看护机在 CDP 清算的时候参与债务拍卖和抵押资产拍卖 。看护机也会围绕目标价格交易 Dai。当市场价格高于目标价格的时候，看护机将出售 Dai 。同理，当市场价格低于目标价格的时候，看护机将买入 Dai。这样做的是为了从市场长期价格趋同目标价格中获益。注：看户机只是做一个策略，它决定什么时候进行出售。当出售的时候他会根据系统喂价直接与以太坊使用者和看护机进行交易的智能合约。当 CDP 被清算，系统会立即回收其抵押品。CDP 持有者会收到去除债务、稳定费用和清算罚金后的剩余抵押资产。这里分两种情况：\n\n  - 第一种，正常情况\n\n    PETH 抵押资产将会在流动性供给合约中出售，看护机可以自动交易 Dai 购买 PETH。所有支付的 Dai会从流通中立即销毁，直到 CDP 债务数量被消除。如果在去除 CDP 债务后还有剩余的 Dai，这部分 Dai会被用来购买并销毁 PETH，从而提高 PETH 可兑换 ETH 的比例。这对 PETH 持有者来说将会是收益。\n\n  - 第二种，非正常的情况下\n\n    如果出售的 PETH 未能募集到足够的 Dai 以偿付整个债务，系统会连续增发并出售 PETH。以这种方式新创造出来的 PETH 会降低 PETH 可兑换ETH 的比例，从而使得 PETH 持有者收益减少。\n\n  在清算发生时，Maker 平台会购买 CDP 中的抵押物并逐渐通过自动竞卖的方式售出。竞卖的机制可以让系统即使在无法获得价格信息的时候，处理 CDP。为了能够回购 CDP 中的抵押资产并用来出售，系统会首先募集足够的 Dai 以偿付 CDP 的债务。这一过程叫做债务竞卖，通过增发 MKR的供给并以竞卖的方式出售给竞卖参与者。\n\n  与此同时，CDP 中的抵押资产会以抵押资产竞卖的方式出售，CDP 债务和清算罚金的部分会用来回购并销毁 MKR。这可以直接抵销在债务竞卖中增发的MKR。如果有足够的 Dai 用来偿付 CDP 中的债务加上清算罚金，那么抵押竞卖会转换到反向竞卖机制，竞卖最少的抵押品 - 任何剩余的抵押品都会归还给CDP 的原所有者。\n\n\n\n- 流动性供给合约 (单一抵押阶段过渡性机制)\n\n  在单一抵押资产 Dai 的阶段，清算的过程叫做流动性供给合约。根据系统喂价直接与以太坊使用者和看护机进行交易的智能合约。当 CDP被清算，系统会立即回收其抵押品。CDP 持有者会收到去除债务、稳定费用和清算罚金后的剩余抵押资产。\n\n  PETH 抵押资产将会在流动性供给合约中出售，看护机可以自动交易 Dai 购买 PETH。所有支付的 Dai 会从流通中立即销毁，直到 CDP债务数量被消除。如果在去除 CDP 债务后还有剩余的 Dai，这部分 Dai 会被用来购买并销毁 PETH ，从而提高 PETH 可兑换 ETH的比例。这对 PETH 持有者来说将会是收益。\n\n  如果出售的 PETH 未能募集到足够的 Dai 以偿付整个债务，系统会连续增发并出售 PETH。以这种方式新创造出来的 PETH 会降低 PETH 可兑换ETH 的比例，从而使得 PETH 持有者收益减少。\n\n\n\n- 债务竞卖和抵押资产竞卖（多种抵押阶段机制）\n\n  在清算发生时，Maker 平台会购买 CDP 中的抵押物并逐渐通过自动竞卖的方式售出。\n\n  竞卖的机制可以让系统即使在无法获得价格信息的时候，处理 CDP。为了能够回购 CDP 中的抵押资产并用来出售，系统会首先募集足够的 Dai 以偿付 CDP 的债务。这一过程叫做债务竞卖，通过增发 MKR的供给并以竞卖的方式出售给竞卖参与者。与此同时，CDP 中的抵押资产会以抵押资产竞卖的方式出售，CDP 债务和清算罚金的部分会用来回购并销毁 MKR 。这可以直接抵销在债务竞卖中增发的 MKR。如果有足够的 Dai 用来偿付 CDP 中的债务加上清算罚金，那么抵押竞卖会转换到反向竞卖机制，竞卖最少的抵押品 - 任何剩余的抵押品都会归还给 CDP的原所有者。\n\n\n\n- 清算期间会发生什么\n\n  当 Keeper 关闭 CDP 并将其发送到流动性提供合同（LPC）时，清算就会发生，而 LPC 又会在 Dai Dashboard 上提供 CDP资产。一旦履行了债务义务，未售出的 PETH 抵押品将返还给 CDP 所有者。\n\n  操作顺序如下：\n\n  - 违约的 CDP 已关闭。\n  - 罚款费用适用于 DAI 债务。\n  - LPC 移除了足够的 PETH 抵押品以满足当前 Oracle 价格的债务。\n  - CDP 所有者现在能够从关闭位置移除他们的剩余抵押品。\n  - 被扣押的 PETH 在 dai.makerdao.com 上出售，其激励折扣称为 Boom / Bust Spread ，适用于该值。\n  - 出售 PETH 所赚取的 DAI 被烧毁以消灭 CDP 债务。\n  - 如果销售中存在过量的 DAI ，那么它将被 PETH 出售，然后燃烧，从而增加剩余 PETH 的价值。\n  - 如果出售的 DAI 不足，那么 PETH 将被发行并出售以弥补不足。这会稀释池的总价值。\n\n\n\n- 清算后剩余多少抵押品\n\n  简化公式\n\n  ```\n  （抵押品 × Oracle 价格 × PETH / ETH 比率） - （清算罚款 × 稳定性债务） - 稳定性债务 =（剩余抵押品 ×Oracle 价格） DAI\n\n  ```\n\n  假设：\n\n  - 一个 ETH 的 Oracle 价格是 350USD\n\n  - 锁定 PETH 总数为 10 ETH\n\n  - PETH / ETH 的比率为 1.012\n\n  - 清算罚款为 13％\n\n  - CDP 的稳定债务为 1000 DAI\n\n    计算为(10 × 350 × 1.012) − (13% × 1000) − 1000 = 2412 DAI 或 6.891428571 ETH\n\n\n\n- 清算价格\n\n  可以使用以下简化公式来确定抵押品的价值必须达到多远才能触发结算：\n\n  ```\n  （稳定债务 × 清算比率）/（抵押品 × PETH / ETH 比率）= 清算价格\n  ```\n\n  例如：\n\n  - 一个 ETH 的值是 350 USD\n\n  - 总赌注 PETH 为 12\n\n  - PETH / ETH 的比率为 1.012\n\n  - 清算比率为 150％\n\n  - 稳定债务是 1000 DAI\n\n    计算为(1000 × 1.5) ÷ (12 × 1.012) = 123.51 USD\n\n    在 CDP 被认为不安全并且有被清算的风险之前，ETH 的价格需要降至 123.51 美元。\n\n\n\n- 计算抵押比率\n\n  如果希望通过查看抵押品与债务的比率来确定抵押物的健康状况，与清算价格相反，可以使用以下简化公式：\n\n  ```\n  （锁定 PETH × ETH 价格 × PETH / ETH 比率）÷ 稳定性债务 × 100 = 抵押比率\n  ```\n\n  举例：\n\n  - 一个 ETH 的值是 350 USD\n  - 总赌注 PETH 为 12\n  - PETH / ETH 的比率为 1.012\n  - 稳定债务是 1000 DAI\n\n  计算为(12 × 350 × 1.012) ÷ 1000 × 100 = 425.04%\n\n  CDP 的抵押比率为 425.04％。\n\n\n\n- 降低清算价格\n\n  CDP 所有者面临的主要挑战是在高度不可预测的市场中保持安全的杠杆状态。如果 CDP 接近清算价格，用户可以添加更多抵押品或返回 DAI以降低风险。如果用户坚信基础抵押品的未来价值，用户可以决定为他的抵押物增加更多。或者，如果用户希望降低价格波动的风险，他可以通过将 DAI 返还给自己的CDP 来偿还债务。降低清算风险的最佳方法是偿还 DAI ，因为清算价格会更有效地降低。\n\n  假设：\n\n  - 一个 ETH 的值是 350 USD\n  - 总赌注 PETH 为 12\n  - PETH / ETH 的比率为 1.012\n  - 清算比率为 150％\n  - 稳定债务是 1000 DAI\n\n  目前的清算价格：\n\n  (1000 × 1.5 ) ÷ (12 × 1.012) = 123.51 USD\n\n  清算价格变动，增加 700 美元的抵押品：\n\n  (1000 × 1.5 ) ÷ (14 × 1.012) = 105.87 USD\n\n  清算价格变动，取消 700 美元的债务：\n\n  (300 × 1.5 ) ÷ (12 × 1.012) = 37.05 USD\n\n  我们可以看到，通过返还 DAI 而不是增加更多抵押品，显着降低了清算价格。\n\n\n\n- 如何出售抵押品\n\n  当 Keeper 清算不安全的 CDP 时，流动性提供合同（LPC）确保在 Dai Dashboard 上出售抵押品。销售价格由应用了特殊修饰符的Oracle Feed确定。此修饰符通常采用折扣的形式，然后应用于必须回收的未偿还债务。这种额外的“差价”旨在通过向抵押品买方提供优于市场价格来激励系统的快速资本重组。用户可以在仪表板上购买已被 LPC 占用的 PETH 。出售的任何 DAI 盈余都可以用 PETH 购买。\n","slug":"dai","published":1,"updated":"2019-10-14T06:52:45.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69xm002mt6xvlj9v35rq","content":"<h2 id=\"dai\"><a href=\"#dai\" class=\"headerlink\" title=\"dai\"></a>dai</h2><h4 id=\"合约学习\"><a href=\"#合约学习\" class=\"headerlink\" title=\"合约学习\"></a>合约学习</h4><p>从<a href=\"https://github.com/makerdao/dss\">github</a>上克隆下来源码。目录结构为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">src</span><br><span class=\"line\">    ├── cat.sol   //面向用户的清算CDP网关合约</span><br><span class=\"line\">    ├── dai.sol   //Dai稳定币合约</span><br><span class=\"line\">    ├── end.sol  //</span><br><span class=\"line\">    ├── flap.sol  //当系统有盈余时，负责购买和燃烧MKR</span><br><span class=\"line\">    ├── flip.sol</span><br><span class=\"line\">    ├── flop.sol  //当系统有坏账时，负责发行和出售MKR</span><br><span class=\"line\">    ├── join.sol  //负责发行和燃烧DAI的适配器(DAI? ETH抵押品？)</span><br><span class=\"line\">    ├── jug.sol</span><br><span class=\"line\">    ├── lib.sol</span><br><span class=\"line\">    ├── pot.sol</span><br><span class=\"line\">    ├── spot.sol</span><br><span class=\"line\">    ├── test</span><br><span class=\"line\">    ├── vat.sol  //CDP核心引擎，DAI系统记账</span><br><span class=\"line\">    └── vow.sol</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"合约词汇表\"><a href=\"#合约词汇表\" class=\"headerlink\" title=\"合约词汇表\"></a>合约词汇表</h4><h5 id=\"常用\"><a href=\"#常用\" class=\"headerlink\" title=\"常用\"></a>常用</h5><ul>\n<li><code>guy</code>，<code>usr</code>：一些地址</li>\n<li><code>wad</code>：一些数量的标记，通常作为一个固定点整数，十进制位数为10 ^ 18。</li>\n<li><code>ray</code>：一个固定位数整数，十进制位数为10 ^ 27。</li>\n<li><code>rad</code>：一个固定位数整数，十进制位数为10 ^ 45。</li>\n<li><code>file</code>：管理一些配置值</li>\n</ul>\n<h5 id=\"认证-auth\"><a href=\"#认证-auth\" class=\"headerlink\" title=\"认证(auth)\"></a>认证(auth)</h5><ul>\n<li><code>auth</code>：检查地址是否可以调用此方法</li>\n<li><code>ward</code>：允许调用authed方法的地址</li>\n<li><code>rely</code>：允许一个地址调用authed方法，或将一个地址添加到ward中</li>\n<li><code>deny</code>：禁止一个地址调用authed方法，或将一个地址从ward中移除</li>\n</ul>\n<h5 id=\"CDP引擎-vat\"><a href=\"#CDP引擎-vat\" class=\"headerlink\" title=\"CDP引擎 vat\"></a>CDP引擎 vat</h5><ul>\n<li><p><code>CDP</code>：抵押债务位置</p>\n</li>\n<li><p><code>gem</code>：抵押代币，数据类型为map(byte32)map(address)uint256, 某类型抵押代币下某地址的抵押个数</p>\n</li>\n<li><p><code>dai</code>：稳定代币</p>\n</li>\n<li><p><code>sin</code>：antioin令牌（系统债务，不属于任何<code>urn</code>）</p>\n</li>\n<li><p><code>ilk</code>：抵押品类型</p>\n<ul>\n<li><code>rate</code>：稳定债务乘数（累计稳定费）</li>\n<li><code>take</code>：抵押余额乘数</li>\n<li><code>Ink</code>：抵押品总余额 ?代码里好像没了</li>\n<li><code>Art</code>：总稳定债务</li>\n<li><code>spot</code>：具有安全边际的抵押品价格，即每单位抵押品允许的最大稳定币</li>\n<li><code>line</code>：特定抵押品类型的债务上限</li>\n<li><code>dust</code>：CDP的最低可能债务</li>\n</ul>\n</li>\n<li><p><code>Line</code>：所有抵押品类型的总债务上限</p>\n</li>\n<li><p><code>init</code>：创建一个新的抵押品类型</p>\n</li>\n<li><p><code>urn</code>：一个特定的CDP</p>\n<ul>\n<li><code>ink</code>：抵押品余额</li>\n<li><code>art</code>：未偿还稳定债务</li>\n</ul>\n</li>\n<li><p><code>debt</code>：发行的稳定币总量</p>\n</li>\n<li><p><code>vice</code>：系统债务总量</p>\n</li>\n<li><p><code>slip</code>：修改用户的抵押品余额(操作gem)</p>\n</li>\n<li><p><code>flux</code>：在用户之间转移抵押品(操作gem)</p>\n</li>\n<li><p><code>move</code>：在用户之间转移stablecoin</p>\n</li>\n<li><p><code>grab</code>：清算CDP，(只做记录，记录为抵押物减少(增加)，抵押品余额增加(减少)？)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function grab(bytes32 i, address u, address v, address w, int dink, int dart) external note auth &#123;</span><br><span class=\"line\">      Urn storage urn = urns[i][u];</span><br><span class=\"line\">      Ilk storage ilk = ilks[i];</span><br><span class=\"line\"></span><br><span class=\"line\">      urn.ink = add(urn.ink, dink);</span><br><span class=\"line\">      urn.art = add(urn.art, dart);</span><br><span class=\"line\">      ilk.Art = add(ilk.Art, dart);</span><br><span class=\"line\"></span><br><span class=\"line\">      int dtab = mul(ilk.rate, dart);</span><br><span class=\"line\"></span><br><span class=\"line\">      gem[i][v] = sub(gem[i][v], dink);</span><br><span class=\"line\">      sin[w]    = sub(sin[w],    dtab);</span><br><span class=\"line\">      vice      = sub(vice,      dtab);</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>heal</code>：创建/销毁等量的稳定币和系统债务（<code>vice</code>）</p>\n</li>\n<li><p><code>fold</code>：修改债务乘数，创造/销毁相应的债务?</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function fold(bytes32 i, address u, int rate) external note auth &#123;</span><br><span class=\"line\">      require(live == 1);</span><br><span class=\"line\">      Ilk storage ilk = ilks[i];</span><br><span class=\"line\">      ilk.rate = add(ilk.rate, rate);</span><br><span class=\"line\">      int rad  = mul(ilk.Art, rate);</span><br><span class=\"line\">      dai[u]   = add(dai[u], rad);</span><br><span class=\"line\">      debt     = add(debt,   rad);</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>toll</code>：修改抵押品乘数，创建/销毁相应的抵押品</p>\n</li>\n<li><p><code>suck</code>：铸造稳定币（占比<code>vice</code>）</p>\n</li>\n<li><p><code>frob</code>：修改CDP</p>\n<ul>\n<li><code>lock</code>：将抵押品转移到CDP</li>\n<li><code>free</code>：从CDP转移抵押品</li>\n<li><code>draw</code>：增加CDP债务，创造Dai</li>\n<li><code>wipe</code>：减少CDP债务，摧毁Dai</li>\n<li><code>dink</code>：抵押品的变化</li>\n<li><code>dart</code>：债务变动</li>\n<li><code>calm</code>：当CDP仍处于抵押品和总债务上限时，这是真的</li>\n<li><code>cool</code>：当稳定债务没有增加时，这是真的</li>\n<li><code>firm</code>：当抵押品余额没有减少时为真</li>\n<li><code>safe</code>：当CDP的抵押品与债务比率高于抵押品的清算比率时为真</li>\n</ul>\n</li>\n<li><p><code>fork</code>：拆分CDP - 二进制批准或拆分/合并CDP</p>\n<ul>\n<li><code>dink</code>：交换抵押品的数量</li>\n<li><code>dart</code>：交换的稳定债务金额</li>\n</ul>\n</li>\n<li><p><code>wish</code>：检查地址是否允许修改另一个地址的gem或dai余额</p>\n<ul>\n<li><code>hope</code>：启用<code>wish</code>一对地址</li>\n<li><code>nope</code>：禁用<code>wish</code>一对地址</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"稳定费用-jug\"><a href=\"#稳定费用-jug\" class=\"headerlink\" title=\"稳定费用 jug\"></a>稳定费用 jug</h5><ul>\n<li><code>duty</code>：稳定费</li>\n<li><code>base</code>：全球稳定费</li>\n<li><code>rho</code>：最后一次收集这种抵押品时间</li>\n<li><code>drip</code>：确定增加</li>\n</ul>\n<h5 id=\"清算-cat\"><a href=\"#清算-cat\" class=\"headerlink\" title=\"清算 cat\"></a>清算 cat</h5><ul>\n<li><code>mat</code>：清算比率</li>\n<li><code>chop</code>：清算罚款</li>\n<li><code>lump</code>：清算数量，即任何一次清算事件所涵盖的固定债务数量</li>\n<li><code>bite</code>：开始清算CDP</li>\n<li><code>flip</code>：清算CDP的抵押品以支付固定数额的债务</li>\n</ul>\n<h5 id=\"结算-vow\"><a href=\"#结算-vow\" class=\"headerlink\" title=\"结算 vow\"></a>结算 vow</h5><ul>\n<li><code>sin</code>：债务队列</li>\n<li><code>Sin</code>：队列中的总债务</li>\n<li><code>Woe</code>：非排队的非拍卖债务总额</li>\n<li><code>Ash</code>：拍卖总债务</li>\n<li><code>Awe</code>：债务总额</li>\n<li><code>Joy</code>：总盈余</li>\n<li><code>fess</code>：向队列添加债务</li>\n<li><code>flog</code>：从队列中实现债务</li>\n<li><code>wait</code>：队列的长度</li>\n<li><code>heal</code>：取消盈余和债务</li>\n<li><code>kiss</code>：取消盈余和拍卖债务</li>\n<li><code>sump</code>：债务拍卖手数，即任何一次债务拍卖所涵盖的固定债务数量</li>\n<li><code>bump</code>：剩余拍卖手数，即任何一次剩余拍卖所出售的固定剩余数量</li>\n<li><code>hump</code>：在剩余拍卖可能之前必须超过剩余缓冲</li>\n</ul>\n<h5 id=\"拍卖-flop-flip-flap\"><a href=\"#拍卖-flop-flip-flap\" class=\"headerlink\" title=\"拍卖 flop flip flap\"></a>拍卖 flop flip flap</h5><ul>\n<li><code>flip</code>：抵押品拍卖（使用稳定币进行交易？）</li>\n<li><code>flop</code>：债务拍卖（通过膨胀MKR和出售稳定币来偿还债务)(以稳定币购买MKR？)</li>\n<li><code>flap</code>：剩余拍卖（出售MKR的稳定币)（以MKR来购买稳定币）</li>\n<li><code>lot</code>：拍卖数量</li>\n<li><code>bid</code>：提供的数量 <code>lot</code></li>\n<li><code>tab</code>：总dai将被提高（<code>flip</code>拍卖中）</li>\n<li><code>guy</code>：高出价者</li>\n<li><code>gal</code>：拍卖收入的获得者</li>\n<li><code>ttl</code>：出价终身</li>\n<li><code>beg</code>：最低出价增加</li>\n<li><code>tau</code>：最长拍卖时间</li>\n<li><code>end</code>：拍卖结束时</li>\n<li><code>kick</code>：开始拍卖</li>\n<li><code>tick</code>：重新开始拍卖</li>\n<li><code>tend</code>：出价，增加出价大小</li>\n<li><code>dent</code>：出价，减少手数</li>\n<li><code>deal</code>：要求中标</li>\n</ul>\n<h5 id=\"全球结算-end\"><a href=\"#全球结算-end\" class=\"headerlink\" title=\"全球结算  end\"></a>全球结算  end</h5><ul>\n<li><code>when</code>：结算时间</li>\n<li><code>wait</code>：处理冷却时间长度（允许不足的CDP为<code>skim</code>med）</li>\n<li><code>debt</code>：在系统盈余/赤字被吸收后，出色的稳定供应量</li>\n<li><code>tag</code>：结算时每种抵押品的价格</li>\n<li><code>gap</code>：考虑到不合标准的CDP，每个抵押品的差额</li>\n<li><code>fix</code>：现金价格<code>ilk</code>（每稳定金额）</li>\n<li><code>bag</code>：无法转移的稳定币准备交换抵押品</li>\n<li><code>out</code>：已交换的给定地址的稳定币的数量</li>\n<li><code>cage</code>：冻结系统，取消<code>flip</code>/ <code>flop</code>拍卖，开始冷却期</li>\n<li><code>cage(ilk)</code>：设定结算价格</li>\n<li><code>skim</code>：取消CDP债务，取得抵押担保，但留下过剩</li>\n<li><code>skip</code>：可选择取消现场拍卖</li>\n<li><code>free</code>：从CDP中删除抵押品</li>\n<li><code>thaw</code>：修复了稳定币的总供应量</li>\n<li><code>flow</code>：计算<code>fix</code>同类产品的价格，可能<code>cage</code>用盈余/赤字调整价格</li>\n<li><code>pack</code>：把一些稳定的金币放入<code>bag</code>准备中<code>cash</code></li>\n<li><code>cash</code>：交换一些<code>bag</code>给定的稳定币<code>gem</code>，与<code>bag</code>大小成比例的份额</li>\n</ul>\n<h4 id=\"基本知识点\"><a href=\"#基本知识点\" class=\"headerlink\" title=\"基本知识点\"></a>基本知识点</h4><h5 id=\"用户类型\"><a href=\"#用户类型\" class=\"headerlink\" title=\"用户类型\"></a>用户类型</h5><p>Maker 主要有三种 user case。作为普通想使用稳定货币的人，他们可以在交易所用美元或者人民币购买 DAI，然后用来交易、支付甚至竞猜。</p>\n<p>第二个是比较高级的用户，他们锁定自己的抵押资产，借 DAI 进行杠杆交易。</p>\n<p>第三个是更深参与系统中的用户，他们持有 MKR 管理型货币，维护系统，同时如果管理得当获益。</p>\n<h5 id=\"货币\"><a href=\"#货币\" class=\"headerlink\" title=\"货币\"></a>货币</h5><p>在 Maker 体系中有两种主要的货币。第一个是 DAI，稳定货币。他是一种有资产背书的硬通货，在无需准许的信贷系统中生成。也就是说，任何用户可以锁定他们有价值的数字资产，然后生成 DAI。系统用动态的目标利率去调节 DAI 的价格。在第一版 DAI 里，我们会保持 DAI 的价格在 1：1 美元左右浮动。</p>\n<p>第二种代币是 MKR，也就是 Maker。MKR 是管理型代币。拥有 MKR 的用户组成一个去中心化的管理社区，他们决定哪种有价值的数字资产可以作为抵押资产，清算比例等等。作为对他们服务的回报，当用户赎回抵押物的时候，他们不仅要返还 DAI，还要加上一小部分费用，其中一部分费用会被用来购买并销毁 MKR 以关闭抵押债仓。也就是说 MKR 是信贷系统的燃料。</p>\n<h5 id=\"信贷系统\"><a href=\"#信贷系统\" class=\"headerlink\" title=\"信贷系统\"></a>信贷系统</h5><p>用户如果要借 DAI，他们首先要建立一个抵押债仓（CDP），然后将数字资产作为抵押物，生成 DAI。然后他可以用 DAI 去做多他看好的资产。最后买回 DAI，偿还 DAI 和一部分费用拿回抵押资产。</p>\n<p>我们在这张图中可以看到，抵押物的价值始终大于 DAI 的价值。这是因为抵押物的价值会有波动，我们要确保 DAI 有足够的抵押。如果抵押物升值并没有太大影响，意味着 DAI 有更足够的抵押。但是如果抵押物减值，系统需要对此做出反应。</p>\n<p>当抵押物价值低于清算值，CDP 会被清算。抵押物会被强制平仓，用来回购 DAI，以保证 DAI 的偿付能力。可以想象为 margin call(追加保证金)。</p>\n<p>那么，在这一次的发布中，我们会用什么作为抵押资产呢。我们叫做 pooled-ETH，以太池。在之后的发布中，我们会引入多重资产抵押。目前我们还在开发多重资产抵押的过程中，在这一次的发布中，我们用以太池作为抵押代币。</p>\n<p>他的运行机制是：用户首先将 ETH 放入合同中，然后回收到相应比例的 ETH 兑换凭证，PETH。起初，PETH 和 ETH 的比例是一比一。但是这一比例会随着系统的表现而改变。</p>\n<p>如果系统运行良好，所有的 CDP 在偿还时会不断产生费用。一部分费用会被用来回购和销毁 PETH。销毁 PETH 意味着剩下的 PETH 可以兑换更多的 ETH。对于大多数用户来说，他们也许会抵押 PETH，用来借 DAI，然后做多资产。用户也可以选择持有 PETH，获得费用收益。</p>\n<p>当黑天鹅时间发生时，抵押物的价格大幅度下降，甚至低于 DAI 的价格，清算机制都来不及应对。这时候系统会通过增发 PETH 来回购 DAI 以支撑抵押不足的 DAI。</p>\n<p>当用户关闭 CDP 时，一部分费用会用来回购销毁 PETH，另一部分费用会用来购买 MKR，作为管理费用。</p>\n<h5 id=\"清算操作\"><a href=\"#清算操作\" class=\"headerlink\" title=\"清算操作\"></a>清算操作</h5><p><img src=\"https://img.chainnews.com/material/images/a527abfe7199a3eb00887ea7f13e8293.jpg\" alt=\"img\"></p>\n<ul>\n<li><p>触发发生清算</p>\n<p>预言机根据现在 PETH 的价格反馈给 Maker 平台。Maker平台需要抵押资产的实时价格信息以决定何时触动清算。也就是说需要看户机拿到这个价格，根据这个价格是否发生清算。</p>\n</li>\n</ul>\n<ul>\n<li><p>发生清算</p>\n<p>当此时发生清算了，预言机触发反馈给看户机，看护机在 CDP 清算的时候参与债务拍卖和抵押资产拍卖 。看护机也会围绕目标价格交易 Dai。当市场价格高于目标价格的时候，看护机将出售 Dai 。同理，当市场价格低于目标价格的时候，看护机将买入 Dai。这样做的是为了从市场长期价格趋同目标价格中获益。注：看户机只是做一个策略，它决定什么时候进行出售。当出售的时候他会根据系统喂价直接与以太坊使用者和看护机进行交易的智能合约。当 CDP 被清算，系统会立即回收其抵押品。CDP 持有者会收到去除债务、稳定费用和清算罚金后的剩余抵押资产。这里分两种情况：</p>\n<ul>\n<li><p>第一种，正常情况</p>\n<p>PETH 抵押资产将会在流动性供给合约中出售，看护机可以自动交易 Dai 购买 PETH。所有支付的 Dai会从流通中立即销毁，直到 CDP 债务数量被消除。如果在去除 CDP 债务后还有剩余的 Dai，这部分 Dai会被用来购买并销毁 PETH，从而提高 PETH 可兑换 ETH 的比例。这对 PETH 持有者来说将会是收益。</p>\n</li>\n<li><p>第二种，非正常的情况下</p>\n<p>如果出售的 PETH 未能募集到足够的 Dai 以偿付整个债务，系统会连续增发并出售 PETH。以这种方式新创造出来的 PETH 会降低 PETH 可兑换ETH 的比例，从而使得 PETH 持有者收益减少。</p>\n</li>\n</ul>\n<p>在清算发生时，Maker 平台会购买 CDP 中的抵押物并逐渐通过自动竞卖的方式售出。竞卖的机制可以让系统即使在无法获得价格信息的时候，处理 CDP。为了能够回购 CDP 中的抵押资产并用来出售，系统会首先募集足够的 Dai 以偿付 CDP 的债务。这一过程叫做债务竞卖，通过增发 MKR的供给并以竞卖的方式出售给竞卖参与者。</p>\n<p>与此同时，CDP 中的抵押资产会以抵押资产竞卖的方式出售，CDP 债务和清算罚金的部分会用来回购并销毁 MKR。这可以直接抵销在债务竞卖中增发的MKR。如果有足够的 Dai 用来偿付 CDP 中的债务加上清算罚金，那么抵押竞卖会转换到反向竞卖机制，竞卖最少的抵押品 - 任何剩余的抵押品都会归还给CDP 的原所有者。</p>\n</li>\n</ul>\n<ul>\n<li><p>流动性供给合约 (单一抵押阶段过渡性机制)</p>\n<p>在单一抵押资产 Dai 的阶段，清算的过程叫做流动性供给合约。根据系统喂价直接与以太坊使用者和看护机进行交易的智能合约。当 CDP被清算，系统会立即回收其抵押品。CDP 持有者会收到去除债务、稳定费用和清算罚金后的剩余抵押资产。</p>\n<p>PETH 抵押资产将会在流动性供给合约中出售，看护机可以自动交易 Dai 购买 PETH。所有支付的 Dai 会从流通中立即销毁，直到 CDP债务数量被消除。如果在去除 CDP 债务后还有剩余的 Dai，这部分 Dai 会被用来购买并销毁 PETH ，从而提高 PETH 可兑换 ETH的比例。这对 PETH 持有者来说将会是收益。</p>\n<p>如果出售的 PETH 未能募集到足够的 Dai 以偿付整个债务，系统会连续增发并出售 PETH。以这种方式新创造出来的 PETH 会降低 PETH 可兑换ETH 的比例，从而使得 PETH 持有者收益减少。</p>\n</li>\n</ul>\n<ul>\n<li><p>债务竞卖和抵押资产竞卖（多种抵押阶段机制）</p>\n<p>在清算发生时，Maker 平台会购买 CDP 中的抵押物并逐渐通过自动竞卖的方式售出。</p>\n<p>竞卖的机制可以让系统即使在无法获得价格信息的时候，处理 CDP。为了能够回购 CDP 中的抵押资产并用来出售，系统会首先募集足够的 Dai 以偿付 CDP 的债务。这一过程叫做债务竞卖，通过增发 MKR的供给并以竞卖的方式出售给竞卖参与者。与此同时，CDP 中的抵押资产会以抵押资产竞卖的方式出售，CDP 债务和清算罚金的部分会用来回购并销毁 MKR 。这可以直接抵销在债务竞卖中增发的 MKR。如果有足够的 Dai 用来偿付 CDP 中的债务加上清算罚金，那么抵押竞卖会转换到反向竞卖机制，竞卖最少的抵押品 - 任何剩余的抵押品都会归还给 CDP的原所有者。</p>\n</li>\n</ul>\n<ul>\n<li><p>清算期间会发生什么</p>\n<p>当 Keeper 关闭 CDP 并将其发送到流动性提供合同（LPC）时，清算就会发生，而 LPC 又会在 Dai Dashboard 上提供 CDP资产。一旦履行了债务义务，未售出的 PETH 抵押品将返还给 CDP 所有者。</p>\n<p>操作顺序如下：</p>\n<ul>\n<li>违约的 CDP 已关闭。</li>\n<li>罚款费用适用于 DAI 债务。</li>\n<li>LPC 移除了足够的 PETH 抵押品以满足当前 Oracle 价格的债务。</li>\n<li>CDP 所有者现在能够从关闭位置移除他们的剩余抵押品。</li>\n<li>被扣押的 PETH 在 dai.makerdao.com 上出售，其激励折扣称为 Boom / Bust Spread ，适用于该值。</li>\n<li>出售 PETH 所赚取的 DAI 被烧毁以消灭 CDP 债务。</li>\n<li>如果销售中存在过量的 DAI ，那么它将被 PETH 出售，然后燃烧，从而增加剩余 PETH 的价值。</li>\n<li>如果出售的 DAI 不足，那么 PETH 将被发行并出售以弥补不足。这会稀释池的总价值。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>清算后剩余多少抵押品</p>\n<p>简化公式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">（抵押品 × Oracle 价格 × PETH / ETH 比率） - （清算罚款 × 稳定性债务） - 稳定性债务 =（剩余抵押品 ×Oracle 价格） DAI</span><br></pre></td></tr></table></figure>\n\n<p>假设：</p>\n<ul>\n<li><p>一个 ETH 的 Oracle 价格是 350USD</p>\n</li>\n<li><p>锁定 PETH 总数为 10 ETH</p>\n</li>\n<li><p>PETH / ETH 的比率为 1.012</p>\n</li>\n<li><p>清算罚款为 13％</p>\n</li>\n<li><p>CDP 的稳定债务为 1000 DAI</p>\n<p>计算为(10 × 350 × 1.012) − (13% × 1000) − 1000 = 2412 DAI 或 6.891428571 ETH</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>清算价格</p>\n<p>可以使用以下简化公式来确定抵押品的价值必须达到多远才能触发结算：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">（稳定债务 × 清算比率）/（抵押品 × PETH / ETH 比率）= 清算价格</span><br></pre></td></tr></table></figure>\n\n<p>例如：</p>\n<ul>\n<li><p>一个 ETH 的值是 350 USD</p>\n</li>\n<li><p>总赌注 PETH 为 12</p>\n</li>\n<li><p>PETH / ETH 的比率为 1.012</p>\n</li>\n<li><p>清算比率为 150％</p>\n</li>\n<li><p>稳定债务是 1000 DAI</p>\n<p>计算为(1000 × 1.5) ÷ (12 × 1.012) = 123.51 USD</p>\n<p>在 CDP 被认为不安全并且有被清算的风险之前，ETH 的价格需要降至 123.51 美元。</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>计算抵押比率</p>\n<p>如果希望通过查看抵押品与债务的比率来确定抵押物的健康状况，与清算价格相反，可以使用以下简化公式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">（锁定 PETH × ETH 价格 × PETH / ETH 比率）÷ 稳定性债务 × 100 = 抵押比率</span><br></pre></td></tr></table></figure>\n\n<p>举例：</p>\n<ul>\n<li>一个 ETH 的值是 350 USD</li>\n<li>总赌注 PETH 为 12</li>\n<li>PETH / ETH 的比率为 1.012</li>\n<li>稳定债务是 1000 DAI</li>\n</ul>\n<p>计算为(12 × 350 × 1.012) ÷ 1000 × 100 = 425.04%</p>\n<p>CDP 的抵押比率为 425.04％。</p>\n</li>\n</ul>\n<ul>\n<li><p>降低清算价格</p>\n<p>CDP 所有者面临的主要挑战是在高度不可预测的市场中保持安全的杠杆状态。如果 CDP 接近清算价格，用户可以添加更多抵押品或返回 DAI以降低风险。如果用户坚信基础抵押品的未来价值，用户可以决定为他的抵押物增加更多。或者，如果用户希望降低价格波动的风险，他可以通过将 DAI 返还给自己的CDP 来偿还债务。降低清算风险的最佳方法是偿还 DAI ，因为清算价格会更有效地降低。</p>\n<p>假设：</p>\n<ul>\n<li>一个 ETH 的值是 350 USD</li>\n<li>总赌注 PETH 为 12</li>\n<li>PETH / ETH 的比率为 1.012</li>\n<li>清算比率为 150％</li>\n<li>稳定债务是 1000 DAI</li>\n</ul>\n<p>目前的清算价格：</p>\n<p>(1000 × 1.5 ) ÷ (12 × 1.012) = 123.51 USD</p>\n<p>清算价格变动，增加 700 美元的抵押品：</p>\n<p>(1000 × 1.5 ) ÷ (14 × 1.012) = 105.87 USD</p>\n<p>清算价格变动，取消 700 美元的债务：</p>\n<p>(300 × 1.5 ) ÷ (12 × 1.012) = 37.05 USD</p>\n<p>我们可以看到，通过返还 DAI 而不是增加更多抵押品，显着降低了清算价格。</p>\n</li>\n</ul>\n<ul>\n<li><p>如何出售抵押品</p>\n<p>当 Keeper 清算不安全的 CDP 时，流动性提供合同（LPC）确保在 Dai Dashboard 上出售抵押品。销售价格由应用了特殊修饰符的Oracle Feed确定。此修饰符通常采用折扣的形式，然后应用于必须回收的未偿还债务。这种额外的“差价”旨在通过向抵押品买方提供优于市场价格来激励系统的快速资本重组。用户可以在仪表板上购买已被 LPC 占用的 PETH 。出售的任何 DAI 盈余都可以用 PETH 购买。</p>\n</li>\n</ul>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"dai\"><a href=\"#dai\" class=\"headerlink\" title=\"dai\"></a>dai</h2><h4 id=\"合约学习\"><a href=\"#合约学习\" class=\"headerlink\" title=\"合约学习\"></a>合约学习</h4><p>从<a href=\"https://github.com/makerdao/dss\">github</a>上克隆下来源码。目录结构为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">src</span><br><span class=\"line\">    ├── cat.sol   //面向用户的清算CDP网关合约</span><br><span class=\"line\">    ├── dai.sol   //Dai稳定币合约</span><br><span class=\"line\">    ├── end.sol  //</span><br><span class=\"line\">    ├── flap.sol  //当系统有盈余时，负责购买和燃烧MKR</span><br><span class=\"line\">    ├── flip.sol</span><br><span class=\"line\">    ├── flop.sol  //当系统有坏账时，负责发行和出售MKR</span><br><span class=\"line\">    ├── join.sol  //负责发行和燃烧DAI的适配器(DAI? ETH抵押品？)</span><br><span class=\"line\">    ├── jug.sol</span><br><span class=\"line\">    ├── lib.sol</span><br><span class=\"line\">    ├── pot.sol</span><br><span class=\"line\">    ├── spot.sol</span><br><span class=\"line\">    ├── test</span><br><span class=\"line\">    ├── vat.sol  //CDP核心引擎，DAI系统记账</span><br><span class=\"line\">    └── vow.sol</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"合约词汇表\"><a href=\"#合约词汇表\" class=\"headerlink\" title=\"合约词汇表\"></a>合约词汇表</h4><h5 id=\"常用\"><a href=\"#常用\" class=\"headerlink\" title=\"常用\"></a>常用</h5><ul>\n<li><code>guy</code>，<code>usr</code>：一些地址</li>\n<li><code>wad</code>：一些数量的标记，通常作为一个固定点整数，十进制位数为10 ^ 18。</li>\n<li><code>ray</code>：一个固定位数整数，十进制位数为10 ^ 27。</li>\n<li><code>rad</code>：一个固定位数整数，十进制位数为10 ^ 45。</li>\n<li><code>file</code>：管理一些配置值</li>\n</ul>\n<h5 id=\"认证-auth\"><a href=\"#认证-auth\" class=\"headerlink\" title=\"认证(auth)\"></a>认证(auth)</h5><ul>\n<li><code>auth</code>：检查地址是否可以调用此方法</li>\n<li><code>ward</code>：允许调用authed方法的地址</li>\n<li><code>rely</code>：允许一个地址调用authed方法，或将一个地址添加到ward中</li>\n<li><code>deny</code>：禁止一个地址调用authed方法，或将一个地址从ward中移除</li>\n</ul>\n<h5 id=\"CDP引擎-vat\"><a href=\"#CDP引擎-vat\" class=\"headerlink\" title=\"CDP引擎 vat\"></a>CDP引擎 vat</h5><ul>\n<li><p><code>CDP</code>：抵押债务位置</p>\n</li>\n<li><p><code>gem</code>：抵押代币，数据类型为map(byte32)map(address)uint256, 某类型抵押代币下某地址的抵押个数</p>\n</li>\n<li><p><code>dai</code>：稳定代币</p>\n</li>\n<li><p><code>sin</code>：antioin令牌（系统债务，不属于任何<code>urn</code>）</p>\n</li>\n<li><p><code>ilk</code>：抵押品类型</p>\n<ul>\n<li><code>rate</code>：稳定债务乘数（累计稳定费）</li>\n<li><code>take</code>：抵押余额乘数</li>\n<li><code>Ink</code>：抵押品总余额 ?代码里好像没了</li>\n<li><code>Art</code>：总稳定债务</li>\n<li><code>spot</code>：具有安全边际的抵押品价格，即每单位抵押品允许的最大稳定币</li>\n<li><code>line</code>：特定抵押品类型的债务上限</li>\n<li><code>dust</code>：CDP的最低可能债务</li>\n</ul>\n</li>\n<li><p><code>Line</code>：所有抵押品类型的总债务上限</p>\n</li>\n<li><p><code>init</code>：创建一个新的抵押品类型</p>\n</li>\n<li><p><code>urn</code>：一个特定的CDP</p>\n<ul>\n<li><code>ink</code>：抵押品余额</li>\n<li><code>art</code>：未偿还稳定债务</li>\n</ul>\n</li>\n<li><p><code>debt</code>：发行的稳定币总量</p>\n</li>\n<li><p><code>vice</code>：系统债务总量</p>\n</li>\n<li><p><code>slip</code>：修改用户的抵押品余额(操作gem)</p>\n</li>\n<li><p><code>flux</code>：在用户之间转移抵押品(操作gem)</p>\n</li>\n<li><p><code>move</code>：在用户之间转移stablecoin</p>\n</li>\n<li><p><code>grab</code>：清算CDP，(只做记录，记录为抵押物减少(增加)，抵押品余额增加(减少)？)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function grab(bytes32 i, address u, address v, address w, int dink, int dart) external note auth &#123;</span><br><span class=\"line\">      Urn storage urn = urns[i][u];</span><br><span class=\"line\">      Ilk storage ilk = ilks[i];</span><br><span class=\"line\"></span><br><span class=\"line\">      urn.ink = add(urn.ink, dink);</span><br><span class=\"line\">      urn.art = add(urn.art, dart);</span><br><span class=\"line\">      ilk.Art = add(ilk.Art, dart);</span><br><span class=\"line\"></span><br><span class=\"line\">      int dtab = mul(ilk.rate, dart);</span><br><span class=\"line\"></span><br><span class=\"line\">      gem[i][v] = sub(gem[i][v], dink);</span><br><span class=\"line\">      sin[w]    = sub(sin[w],    dtab);</span><br><span class=\"line\">      vice      = sub(vice,      dtab);</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>heal</code>：创建/销毁等量的稳定币和系统债务（<code>vice</code>）</p>\n</li>\n<li><p><code>fold</code>：修改债务乘数，创造/销毁相应的债务?</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function fold(bytes32 i, address u, int rate) external note auth &#123;</span><br><span class=\"line\">      require(live == 1);</span><br><span class=\"line\">      Ilk storage ilk = ilks[i];</span><br><span class=\"line\">      ilk.rate = add(ilk.rate, rate);</span><br><span class=\"line\">      int rad  = mul(ilk.Art, rate);</span><br><span class=\"line\">      dai[u]   = add(dai[u], rad);</span><br><span class=\"line\">      debt     = add(debt,   rad);</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>toll</code>：修改抵押品乘数，创建/销毁相应的抵押品</p>\n</li>\n<li><p><code>suck</code>：铸造稳定币（占比<code>vice</code>）</p>\n</li>\n<li><p><code>frob</code>：修改CDP</p>\n<ul>\n<li><code>lock</code>：将抵押品转移到CDP</li>\n<li><code>free</code>：从CDP转移抵押品</li>\n<li><code>draw</code>：增加CDP债务，创造Dai</li>\n<li><code>wipe</code>：减少CDP债务，摧毁Dai</li>\n<li><code>dink</code>：抵押品的变化</li>\n<li><code>dart</code>：债务变动</li>\n<li><code>calm</code>：当CDP仍处于抵押品和总债务上限时，这是真的</li>\n<li><code>cool</code>：当稳定债务没有增加时，这是真的</li>\n<li><code>firm</code>：当抵押品余额没有减少时为真</li>\n<li><code>safe</code>：当CDP的抵押品与债务比率高于抵押品的清算比率时为真</li>\n</ul>\n</li>\n<li><p><code>fork</code>：拆分CDP - 二进制批准或拆分/合并CDP</p>\n<ul>\n<li><code>dink</code>：交换抵押品的数量</li>\n<li><code>dart</code>：交换的稳定债务金额</li>\n</ul>\n</li>\n<li><p><code>wish</code>：检查地址是否允许修改另一个地址的gem或dai余额</p>\n<ul>\n<li><code>hope</code>：启用<code>wish</code>一对地址</li>\n<li><code>nope</code>：禁用<code>wish</code>一对地址</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"稳定费用-jug\"><a href=\"#稳定费用-jug\" class=\"headerlink\" title=\"稳定费用 jug\"></a>稳定费用 jug</h5><ul>\n<li><code>duty</code>：稳定费</li>\n<li><code>base</code>：全球稳定费</li>\n<li><code>rho</code>：最后一次收集这种抵押品时间</li>\n<li><code>drip</code>：确定增加</li>\n</ul>\n<h5 id=\"清算-cat\"><a href=\"#清算-cat\" class=\"headerlink\" title=\"清算 cat\"></a>清算 cat</h5><ul>\n<li><code>mat</code>：清算比率</li>\n<li><code>chop</code>：清算罚款</li>\n<li><code>lump</code>：清算数量，即任何一次清算事件所涵盖的固定债务数量</li>\n<li><code>bite</code>：开始清算CDP</li>\n<li><code>flip</code>：清算CDP的抵押品以支付固定数额的债务</li>\n</ul>\n<h5 id=\"结算-vow\"><a href=\"#结算-vow\" class=\"headerlink\" title=\"结算 vow\"></a>结算 vow</h5><ul>\n<li><code>sin</code>：债务队列</li>\n<li><code>Sin</code>：队列中的总债务</li>\n<li><code>Woe</code>：非排队的非拍卖债务总额</li>\n<li><code>Ash</code>：拍卖总债务</li>\n<li><code>Awe</code>：债务总额</li>\n<li><code>Joy</code>：总盈余</li>\n<li><code>fess</code>：向队列添加债务</li>\n<li><code>flog</code>：从队列中实现债务</li>\n<li><code>wait</code>：队列的长度</li>\n<li><code>heal</code>：取消盈余和债务</li>\n<li><code>kiss</code>：取消盈余和拍卖债务</li>\n<li><code>sump</code>：债务拍卖手数，即任何一次债务拍卖所涵盖的固定债务数量</li>\n<li><code>bump</code>：剩余拍卖手数，即任何一次剩余拍卖所出售的固定剩余数量</li>\n<li><code>hump</code>：在剩余拍卖可能之前必须超过剩余缓冲</li>\n</ul>\n<h5 id=\"拍卖-flop-flip-flap\"><a href=\"#拍卖-flop-flip-flap\" class=\"headerlink\" title=\"拍卖 flop flip flap\"></a>拍卖 flop flip flap</h5><ul>\n<li><code>flip</code>：抵押品拍卖（使用稳定币进行交易？）</li>\n<li><code>flop</code>：债务拍卖（通过膨胀MKR和出售稳定币来偿还债务)(以稳定币购买MKR？)</li>\n<li><code>flap</code>：剩余拍卖（出售MKR的稳定币)（以MKR来购买稳定币）</li>\n<li><code>lot</code>：拍卖数量</li>\n<li><code>bid</code>：提供的数量 <code>lot</code></li>\n<li><code>tab</code>：总dai将被提高（<code>flip</code>拍卖中）</li>\n<li><code>guy</code>：高出价者</li>\n<li><code>gal</code>：拍卖收入的获得者</li>\n<li><code>ttl</code>：出价终身</li>\n<li><code>beg</code>：最低出价增加</li>\n<li><code>tau</code>：最长拍卖时间</li>\n<li><code>end</code>：拍卖结束时</li>\n<li><code>kick</code>：开始拍卖</li>\n<li><code>tick</code>：重新开始拍卖</li>\n<li><code>tend</code>：出价，增加出价大小</li>\n<li><code>dent</code>：出价，减少手数</li>\n<li><code>deal</code>：要求中标</li>\n</ul>\n<h5 id=\"全球结算-end\"><a href=\"#全球结算-end\" class=\"headerlink\" title=\"全球结算  end\"></a>全球结算  end</h5><ul>\n<li><code>when</code>：结算时间</li>\n<li><code>wait</code>：处理冷却时间长度（允许不足的CDP为<code>skim</code>med）</li>\n<li><code>debt</code>：在系统盈余/赤字被吸收后，出色的稳定供应量</li>\n<li><code>tag</code>：结算时每种抵押品的价格</li>\n<li><code>gap</code>：考虑到不合标准的CDP，每个抵押品的差额</li>\n<li><code>fix</code>：现金价格<code>ilk</code>（每稳定金额）</li>\n<li><code>bag</code>：无法转移的稳定币准备交换抵押品</li>\n<li><code>out</code>：已交换的给定地址的稳定币的数量</li>\n<li><code>cage</code>：冻结系统，取消<code>flip</code>/ <code>flop</code>拍卖，开始冷却期</li>\n<li><code>cage(ilk)</code>：设定结算价格</li>\n<li><code>skim</code>：取消CDP债务，取得抵押担保，但留下过剩</li>\n<li><code>skip</code>：可选择取消现场拍卖</li>\n<li><code>free</code>：从CDP中删除抵押品</li>\n<li><code>thaw</code>：修复了稳定币的总供应量</li>\n<li><code>flow</code>：计算<code>fix</code>同类产品的价格，可能<code>cage</code>用盈余/赤字调整价格</li>\n<li><code>pack</code>：把一些稳定的金币放入<code>bag</code>准备中<code>cash</code></li>\n<li><code>cash</code>：交换一些<code>bag</code>给定的稳定币<code>gem</code>，与<code>bag</code>大小成比例的份额</li>\n</ul>\n<h4 id=\"基本知识点\"><a href=\"#基本知识点\" class=\"headerlink\" title=\"基本知识点\"></a>基本知识点</h4><h5 id=\"用户类型\"><a href=\"#用户类型\" class=\"headerlink\" title=\"用户类型\"></a>用户类型</h5><p>Maker 主要有三种 user case。作为普通想使用稳定货币的人，他们可以在交易所用美元或者人民币购买 DAI，然后用来交易、支付甚至竞猜。</p>\n<p>第二个是比较高级的用户，他们锁定自己的抵押资产，借 DAI 进行杠杆交易。</p>\n<p>第三个是更深参与系统中的用户，他们持有 MKR 管理型货币，维护系统，同时如果管理得当获益。</p>\n<h5 id=\"货币\"><a href=\"#货币\" class=\"headerlink\" title=\"货币\"></a>货币</h5><p>在 Maker 体系中有两种主要的货币。第一个是 DAI，稳定货币。他是一种有资产背书的硬通货，在无需准许的信贷系统中生成。也就是说，任何用户可以锁定他们有价值的数字资产，然后生成 DAI。系统用动态的目标利率去调节 DAI 的价格。在第一版 DAI 里，我们会保持 DAI 的价格在 1：1 美元左右浮动。</p>\n<p>第二种代币是 MKR，也就是 Maker。MKR 是管理型代币。拥有 MKR 的用户组成一个去中心化的管理社区，他们决定哪种有价值的数字资产可以作为抵押资产，清算比例等等。作为对他们服务的回报，当用户赎回抵押物的时候，他们不仅要返还 DAI，还要加上一小部分费用，其中一部分费用会被用来购买并销毁 MKR 以关闭抵押债仓。也就是说 MKR 是信贷系统的燃料。</p>\n<h5 id=\"信贷系统\"><a href=\"#信贷系统\" class=\"headerlink\" title=\"信贷系统\"></a>信贷系统</h5><p>用户如果要借 DAI，他们首先要建立一个抵押债仓（CDP），然后将数字资产作为抵押物，生成 DAI。然后他可以用 DAI 去做多他看好的资产。最后买回 DAI，偿还 DAI 和一部分费用拿回抵押资产。</p>\n<p>我们在这张图中可以看到，抵押物的价值始终大于 DAI 的价值。这是因为抵押物的价值会有波动，我们要确保 DAI 有足够的抵押。如果抵押物升值并没有太大影响，意味着 DAI 有更足够的抵押。但是如果抵押物减值，系统需要对此做出反应。</p>\n<p>当抵押物价值低于清算值，CDP 会被清算。抵押物会被强制平仓，用来回购 DAI，以保证 DAI 的偿付能力。可以想象为 margin call(追加保证金)。</p>\n<p>那么，在这一次的发布中，我们会用什么作为抵押资产呢。我们叫做 pooled-ETH，以太池。在之后的发布中，我们会引入多重资产抵押。目前我们还在开发多重资产抵押的过程中，在这一次的发布中，我们用以太池作为抵押代币。</p>\n<p>他的运行机制是：用户首先将 ETH 放入合同中，然后回收到相应比例的 ETH 兑换凭证，PETH。起初，PETH 和 ETH 的比例是一比一。但是这一比例会随着系统的表现而改变。</p>\n<p>如果系统运行良好，所有的 CDP 在偿还时会不断产生费用。一部分费用会被用来回购和销毁 PETH。销毁 PETH 意味着剩下的 PETH 可以兑换更多的 ETH。对于大多数用户来说，他们也许会抵押 PETH，用来借 DAI，然后做多资产。用户也可以选择持有 PETH，获得费用收益。</p>\n<p>当黑天鹅时间发生时，抵押物的价格大幅度下降，甚至低于 DAI 的价格，清算机制都来不及应对。这时候系统会通过增发 PETH 来回购 DAI 以支撑抵押不足的 DAI。</p>\n<p>当用户关闭 CDP 时，一部分费用会用来回购销毁 PETH，另一部分费用会用来购买 MKR，作为管理费用。</p>\n<h5 id=\"清算操作\"><a href=\"#清算操作\" class=\"headerlink\" title=\"清算操作\"></a>清算操作</h5><p><img src=\"https://img.chainnews.com/material/images/a527abfe7199a3eb00887ea7f13e8293.jpg\" alt=\"img\"></p>\n<ul>\n<li><p>触发发生清算</p>\n<p>预言机根据现在 PETH 的价格反馈给 Maker 平台。Maker平台需要抵押资产的实时价格信息以决定何时触动清算。也就是说需要看户机拿到这个价格，根据这个价格是否发生清算。</p>\n</li>\n</ul>\n<ul>\n<li><p>发生清算</p>\n<p>当此时发生清算了，预言机触发反馈给看户机，看护机在 CDP 清算的时候参与债务拍卖和抵押资产拍卖 。看护机也会围绕目标价格交易 Dai。当市场价格高于目标价格的时候，看护机将出售 Dai 。同理，当市场价格低于目标价格的时候，看护机将买入 Dai。这样做的是为了从市场长期价格趋同目标价格中获益。注：看户机只是做一个策略，它决定什么时候进行出售。当出售的时候他会根据系统喂价直接与以太坊使用者和看护机进行交易的智能合约。当 CDP 被清算，系统会立即回收其抵押品。CDP 持有者会收到去除债务、稳定费用和清算罚金后的剩余抵押资产。这里分两种情况：</p>\n<ul>\n<li><p>第一种，正常情况</p>\n<p>PETH 抵押资产将会在流动性供给合约中出售，看护机可以自动交易 Dai 购买 PETH。所有支付的 Dai会从流通中立即销毁，直到 CDP 债务数量被消除。如果在去除 CDP 债务后还有剩余的 Dai，这部分 Dai会被用来购买并销毁 PETH，从而提高 PETH 可兑换 ETH 的比例。这对 PETH 持有者来说将会是收益。</p>\n</li>\n<li><p>第二种，非正常的情况下</p>\n<p>如果出售的 PETH 未能募集到足够的 Dai 以偿付整个债务，系统会连续增发并出售 PETH。以这种方式新创造出来的 PETH 会降低 PETH 可兑换ETH 的比例，从而使得 PETH 持有者收益减少。</p>\n</li>\n</ul>\n<p>在清算发生时，Maker 平台会购买 CDP 中的抵押物并逐渐通过自动竞卖的方式售出。竞卖的机制可以让系统即使在无法获得价格信息的时候，处理 CDP。为了能够回购 CDP 中的抵押资产并用来出售，系统会首先募集足够的 Dai 以偿付 CDP 的债务。这一过程叫做债务竞卖，通过增发 MKR的供给并以竞卖的方式出售给竞卖参与者。</p>\n<p>与此同时，CDP 中的抵押资产会以抵押资产竞卖的方式出售，CDP 债务和清算罚金的部分会用来回购并销毁 MKR。这可以直接抵销在债务竞卖中增发的MKR。如果有足够的 Dai 用来偿付 CDP 中的债务加上清算罚金，那么抵押竞卖会转换到反向竞卖机制，竞卖最少的抵押品 - 任何剩余的抵押品都会归还给CDP 的原所有者。</p>\n</li>\n</ul>\n<ul>\n<li><p>流动性供给合约 (单一抵押阶段过渡性机制)</p>\n<p>在单一抵押资产 Dai 的阶段，清算的过程叫做流动性供给合约。根据系统喂价直接与以太坊使用者和看护机进行交易的智能合约。当 CDP被清算，系统会立即回收其抵押品。CDP 持有者会收到去除债务、稳定费用和清算罚金后的剩余抵押资产。</p>\n<p>PETH 抵押资产将会在流动性供给合约中出售，看护机可以自动交易 Dai 购买 PETH。所有支付的 Dai 会从流通中立即销毁，直到 CDP债务数量被消除。如果在去除 CDP 债务后还有剩余的 Dai，这部分 Dai 会被用来购买并销毁 PETH ，从而提高 PETH 可兑换 ETH的比例。这对 PETH 持有者来说将会是收益。</p>\n<p>如果出售的 PETH 未能募集到足够的 Dai 以偿付整个债务，系统会连续增发并出售 PETH。以这种方式新创造出来的 PETH 会降低 PETH 可兑换ETH 的比例，从而使得 PETH 持有者收益减少。</p>\n</li>\n</ul>\n<ul>\n<li><p>债务竞卖和抵押资产竞卖（多种抵押阶段机制）</p>\n<p>在清算发生时，Maker 平台会购买 CDP 中的抵押物并逐渐通过自动竞卖的方式售出。</p>\n<p>竞卖的机制可以让系统即使在无法获得价格信息的时候，处理 CDP。为了能够回购 CDP 中的抵押资产并用来出售，系统会首先募集足够的 Dai 以偿付 CDP 的债务。这一过程叫做债务竞卖，通过增发 MKR的供给并以竞卖的方式出售给竞卖参与者。与此同时，CDP 中的抵押资产会以抵押资产竞卖的方式出售，CDP 债务和清算罚金的部分会用来回购并销毁 MKR 。这可以直接抵销在债务竞卖中增发的 MKR。如果有足够的 Dai 用来偿付 CDP 中的债务加上清算罚金，那么抵押竞卖会转换到反向竞卖机制，竞卖最少的抵押品 - 任何剩余的抵押品都会归还给 CDP的原所有者。</p>\n</li>\n</ul>\n<ul>\n<li><p>清算期间会发生什么</p>\n<p>当 Keeper 关闭 CDP 并将其发送到流动性提供合同（LPC）时，清算就会发生，而 LPC 又会在 Dai Dashboard 上提供 CDP资产。一旦履行了债务义务，未售出的 PETH 抵押品将返还给 CDP 所有者。</p>\n<p>操作顺序如下：</p>\n<ul>\n<li>违约的 CDP 已关闭。</li>\n<li>罚款费用适用于 DAI 债务。</li>\n<li>LPC 移除了足够的 PETH 抵押品以满足当前 Oracle 价格的债务。</li>\n<li>CDP 所有者现在能够从关闭位置移除他们的剩余抵押品。</li>\n<li>被扣押的 PETH 在 dai.makerdao.com 上出售，其激励折扣称为 Boom / Bust Spread ，适用于该值。</li>\n<li>出售 PETH 所赚取的 DAI 被烧毁以消灭 CDP 债务。</li>\n<li>如果销售中存在过量的 DAI ，那么它将被 PETH 出售，然后燃烧，从而增加剩余 PETH 的价值。</li>\n<li>如果出售的 DAI 不足，那么 PETH 将被发行并出售以弥补不足。这会稀释池的总价值。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>清算后剩余多少抵押品</p>\n<p>简化公式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">（抵押品 × Oracle 价格 × PETH / ETH 比率） - （清算罚款 × 稳定性债务） - 稳定性债务 =（剩余抵押品 ×Oracle 价格） DAI</span><br></pre></td></tr></table></figure>\n\n<p>假设：</p>\n<ul>\n<li><p>一个 ETH 的 Oracle 价格是 350USD</p>\n</li>\n<li><p>锁定 PETH 总数为 10 ETH</p>\n</li>\n<li><p>PETH / ETH 的比率为 1.012</p>\n</li>\n<li><p>清算罚款为 13％</p>\n</li>\n<li><p>CDP 的稳定债务为 1000 DAI</p>\n<p>计算为(10 × 350 × 1.012) − (13% × 1000) − 1000 = 2412 DAI 或 6.891428571 ETH</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>清算价格</p>\n<p>可以使用以下简化公式来确定抵押品的价值必须达到多远才能触发结算：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">（稳定债务 × 清算比率）/（抵押品 × PETH / ETH 比率）= 清算价格</span><br></pre></td></tr></table></figure>\n\n<p>例如：</p>\n<ul>\n<li><p>一个 ETH 的值是 350 USD</p>\n</li>\n<li><p>总赌注 PETH 为 12</p>\n</li>\n<li><p>PETH / ETH 的比率为 1.012</p>\n</li>\n<li><p>清算比率为 150％</p>\n</li>\n<li><p>稳定债务是 1000 DAI</p>\n<p>计算为(1000 × 1.5) ÷ (12 × 1.012) = 123.51 USD</p>\n<p>在 CDP 被认为不安全并且有被清算的风险之前，ETH 的价格需要降至 123.51 美元。</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>计算抵押比率</p>\n<p>如果希望通过查看抵押品与债务的比率来确定抵押物的健康状况，与清算价格相反，可以使用以下简化公式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">（锁定 PETH × ETH 价格 × PETH / ETH 比率）÷ 稳定性债务 × 100 = 抵押比率</span><br></pre></td></tr></table></figure>\n\n<p>举例：</p>\n<ul>\n<li>一个 ETH 的值是 350 USD</li>\n<li>总赌注 PETH 为 12</li>\n<li>PETH / ETH 的比率为 1.012</li>\n<li>稳定债务是 1000 DAI</li>\n</ul>\n<p>计算为(12 × 350 × 1.012) ÷ 1000 × 100 = 425.04%</p>\n<p>CDP 的抵押比率为 425.04％。</p>\n</li>\n</ul>\n<ul>\n<li><p>降低清算价格</p>\n<p>CDP 所有者面临的主要挑战是在高度不可预测的市场中保持安全的杠杆状态。如果 CDP 接近清算价格，用户可以添加更多抵押品或返回 DAI以降低风险。如果用户坚信基础抵押品的未来价值，用户可以决定为他的抵押物增加更多。或者，如果用户希望降低价格波动的风险，他可以通过将 DAI 返还给自己的CDP 来偿还债务。降低清算风险的最佳方法是偿还 DAI ，因为清算价格会更有效地降低。</p>\n<p>假设：</p>\n<ul>\n<li>一个 ETH 的值是 350 USD</li>\n<li>总赌注 PETH 为 12</li>\n<li>PETH / ETH 的比率为 1.012</li>\n<li>清算比率为 150％</li>\n<li>稳定债务是 1000 DAI</li>\n</ul>\n<p>目前的清算价格：</p>\n<p>(1000 × 1.5 ) ÷ (12 × 1.012) = 123.51 USD</p>\n<p>清算价格变动，增加 700 美元的抵押品：</p>\n<p>(1000 × 1.5 ) ÷ (14 × 1.012) = 105.87 USD</p>\n<p>清算价格变动，取消 700 美元的债务：</p>\n<p>(300 × 1.5 ) ÷ (12 × 1.012) = 37.05 USD</p>\n<p>我们可以看到，通过返还 DAI 而不是增加更多抵押品，显着降低了清算价格。</p>\n</li>\n</ul>\n<ul>\n<li><p>如何出售抵押品</p>\n<p>当 Keeper 清算不安全的 CDP 时，流动性提供合同（LPC）确保在 Dai Dashboard 上出售抵押品。销售价格由应用了特殊修饰符的Oracle Feed确定。此修饰符通常采用折扣的形式，然后应用于必须回收的未偿还债务。这种额外的“差价”旨在通过向抵押品买方提供优于市场价格来激励系统的快速资本重组。用户可以在仪表板上购买已被 LPC 占用的 PETH 。出售的任何 DAI 盈余都可以用 PETH 购买。</p>\n</li>\n</ul>\n"},{"title":"eth_contract","date":"2019-10-14T06:51:05.000Z","_content":"\n## 以太坊智能合约\n\n从智能合约的代码到使用智能合约，大概包含以下步骤\n\n- 编写智能合约的代码(一般是用Solidity)\n- 编译智能合约的代码变成可在EVM上执行的bytecode(binary code)，同时可以通过编译取得智能合约的ABI\n- 部署智能合约，实际上是吧bytecode存储在链上(通过一个transaction)，并取得一个专属于这个合约的地址\n- 要调用合约，需要把信息发送到这个合约的地址，一样也是通过transaction，以太坊节点会根据输入的信息，选择要执行合约中的哪一个function和要输入的参数\n\n以下，将详细介绍以上步骤。\n\n#### 代码编写及编译部署\n\n#### 智能合约ABI\n\n如果说api，想必都知道是什么，对应的，ABI，application binary interface，顾名思义，同样是接口，但传递的是binary格式的信息。\n\nABI理解如下\n\n##### Function\n\n- `name`：a string, 方法名\n- `type`:  a string，\"function\", \"constructor\", or \"fallback\"，方法类型\n- `inputs`:  an array，方法参数，每个参数的格式为\n  - `name`：a string，参数名\n  - `type`：a string，参数的 data type(e.g. uint256)\n  - `components`：an array，如果输入的参数是 tuple(struct) type 才会有这个参数。描述 struct 中包含的参数类型\n- `outputs`：an array， 方法返回值，和 `inputs` 使用相同表示方式。如果沒有返回值可忽略，值为 `[]`\n- `payable`：`true`，function 是否可收 Ether，预设为 `false`\n- `constant`：`true`，function 是否会改写区块链状态，反之为 `false`\n- `stateMutability`：a string，其值可能为以下其中之一：\"pure\"（不会读写区块链状态）、\"view\"（只读不写区块链状态）、\"payable\" and \"nonpayable\"（会改区块链状态，且如可收 Ether 为 \"payable\"，反之为 \"nonpayable\"）\n\n仔细看会发现 `payable` 和 `constant` 这两个参数所描述的內容，似乎已包含在 `stateMutability` 中。\n\n##### Event\n\n- `name`: a string，event 的名称\n- `type`: a string，always \"event\"\n- `inputs`: an array，输入参数，包含：\n  - `name`: a string，参数名称\n  - `type`: a string，参数的 data type(e.g. uint256)\n  - `components`: an array，如果输入参数是 tuple(struct) type 才会有这个参数。描述 struct 中包含的信息类型\n  - `indexed`: `true`，如果这个参数被定义为 indexed ，反之为 `false`\n- `anonymous`: `true`，如果 event 被定义为 anonymous\n\n更新智能合约状态需要发送 transaction，transaction 需要等待验证，所以更新合约状态是非同步的，无法马上取得返回值。使用 Event 可以在状态更新成功后，将相关信息记录到 Log，并让监听这个 Event 的 DApp 或任何应用这个接口的程序收到通知。每笔 transaction 都有对应的 Log。\n\n所以简单来说，Event 可用來：1. 取得 function 更新合约状态的返回值 2. 也可作为合约另外的存储空间。\n\nEvent 的参数分为：有 `indexed`，和其他没有 `indexed` 的。有 `indexed` 的参数可以使用 filter，例如同一个 Event，我可以选择只监听从特定 address 发出来的交易。每笔 Log 的信息同样分为两个部分：Topics（长度最多为 4 的 array） 和 Data。有 `anonymous` 的参数会存储存在 Log 的 Topics，其他的存在 Data。\n\n##### 示例\n\n```\npragma solidity ^0.4.20;\ncontract SimpleStorage {\n    uint public data;\n    event Set(address indexed _from, uint value);\n    function set(uint x) public {\n        data = x;\n        Set(msg.sender, x);\n    }\n}\n\n```\n\n生成的ABI接口为\n\n```\n[{\t\t//自动生成的方法名为data的只读方法，返回data值,\"stateMutabTility\": \"view\"代表只读\n        \"constant\": true,  \n        \"inputs\": [],\n        \"name\": \"data\",\n        \"outputs\": [{\"name\": \"\",\"type\": \"uint256\"}],\n        \"payable\": false,\n        \"stateMutabTility\": \"view\",\n        \"type\": \"function\"\n    },\n    {  //set方法， \"stateMutability\": \"nonpayable\",可写方法，但不可收Ether,方法参数为uint256类型\n        \"constant\": false,\n        \"inputs\": [{\"name\": \"x\",\"type\": \"uint256\"}],\n        \"name\": \"set\",\n        \"outputs\": [],\n        \"payable\": false,\n        \"stateMutability\": \"nonpayable\",\n        \"type\": \"function\"\n\t},\n    {\n        \"anonymous\": false,\n        \"inputs\": [{\"indexed\": true,\"name\": \"_from\",\"type\": \"address\"},{\"indexed\": false,\"name\": \"value\",\"type\": \"uint256\"}],\n        \"name\": \"Set\",\n        \"type\": \"event\"\n}]\n```\n\nevent时间可监听，在web3使用时会有示例\n\n### web3\n\n关于智能合约的调用，通过命令行也是可以的，但binary的拼凑有点繁琐，web3封装的接口调用起来就方便很多。\n\n直接看例子吧。\n\n```\ncontract hello {\n    function say() constant public returns (string) {\n        return \"Hello World\";\n    }\n}\n```\n\n然后部署到了服务器上，返回合约的地址为0x43d03aaeb07e518cd975c2d67b83a7ffea3a5a51\n\nabi为编译产生的abi数组，直接复制粘贴即可。\n\n```\nvar contract = web3.eth.contract(info.abi).at(\"0x43d03aaeb07e518cd975c2d67b83a7ffea3a5a51\");\nvar account_one = web3.eth.accounts[0];\nvar result = contract.say({from: account_one})\nconsole.log(result); //Hello World\n```\n\n一个简单的调用就成功了，然后再看contract提供的接口的具体情况。\n\n智能合约方法调用方式有四种\n\n```\n//根据方法类型自动决定是使用call方式进行调用还是sendTransaction方式进行调用，call和sendTransaction的区别呢，如果方法是只读的，则不需要入链，直接调用即可，方法是可写的，则需要以交易的方法进行提交入链。参数中，param则是传入给方法的参数，后面添加别的参数\nmyContractInstance.myMethod(param1 [, param2, ...] [, transactionObject] [, defaultBlock] [, callback]);\n\n//精确使用call方式进行调用\nmyContractInstance.myMethod.call(param1 [, param2, ...] [, transactionObject] [, defaultBlock] [, callback]);\n\n//精确使用发送交易形式进行调用\nmyContractInstance.myMethod.sendTransaction(param1 [, param2, ...] [, transactionObject] [, callback]);\n\n//没看明白\n// Get the call data, so you can call the contract through some other means\n// var myCallData = myContractInstance.myMethod.request(param1 [, param2, ...]);\nvar myCallData = myContractInstance.myMethod.getData(param1 [, param2, ...]);\n// myCallData = '0x45ff3ff6000000000004545345345345..'\n\n```\n\n然后，顺便玩一下event。\n\n合约修改为\n\n```\npragma solidity ^0.4.18;\ncontract hello {\n    string public greeting;\n    event Set(address indexed _from, string value);\n\n    function set(string g) public {\n        greeting = g;\n        Set(msg.sender, g);\n    }\n\n    function get() constant public returns (string) {\n        return greeting;\n    }\n}\n```\n\n然后完整的调用脚本为\n\n```\nvar Web3 = require(\"web3\");\nvar web3 = new Web3();\nweb3.setProvider(new Web3.providers.HttpProvider(\"http://localhost:8545\"));\nif (web3.isConnected()) {\n  console.log(\"connection success!\");\n} else {\n  console.log(\"fail to connection!\");\n  return\n}\n\n\nvar contract = web3.eth.contract(abi).at(address);\nvar account_one = web3.eth.accounts[0];\nvar my_event = contract.Set();\nvar getStr = function() {\n  var str = contract.greeting({from: account_one})\n  console.log(\"the str is: \" + str);\n}\n\ngetStr()\nmy_event.watch(function(err, result) {\n    if (!err) {\n        console.log(result);\n        getStr()\n    } else {\n        console.log(err);\n    }\n    my_event.stopWatching();\n});\n\ncontract.set(\"I am Changed!\",{from: account_one})\n```\n\n查看输出\n\n```\n// connection success!\n// the str is:\n// { address: '0x8321a32f8b7bbc00a65c9e21df64948cf40bbeba',\n//   blockNumber: 785,\n//   transactionHash: '0xa90e35845cd844907f251660bce78f5cde2c968876f3a6321fbf38589d7fb476',\n//   transactionIndex: 0,\n//   blockHash: '0x742eecc3ae508b33ca5dde2ae2a32b8c0c87d321c6ab13a0cc8ad3909e579275',\n//   logIndex: 0,\n//   removed: false,\n//   event: 'Set',\n//   args:\n//    { _from: '0xc6e1feafcc44ebb1a7b0ecc06770566845eac7ac',\n//      value: 'I am Changed!' } }\n// the str is: I am Changed!\n```\n\n可以看到返回的结果中包括区块哈希等信息，还有参数\n\n\n\n\n\n#### Event\n\n在合约中定义事件，如\n\n```\nevent SendMsg(string sender, string receiver, string detail, address indexed reth);\n```\n\n注意到indexed关键字。跟event订阅有一定的关系。\n\n大致理解是，event事件犹如日志，在订阅的时候，需要确定要订阅的关键字，这个关键字可以是事件本身，也可以是某个可索引的值，如address值。如订阅某确定address值时，会取得所有含有可索引的这个地址相关的event事件。订阅事件本身的话，就只能取得这个事件的值。\n\n顺便粘贴一段在web3j中event的使用\n\n```\n   public static void test() {\n        Web3j web3j = Web3j.build(new HttpService(\"http://localhost:8545\"));\n        Event event = new Event(\"SendMsg\",\n                Arrays.<TypeReference<?>>asList(\n                        new TypeReference<Utf8String>(){},\n                        new TypeReference<Utf8String>(){},\n                        new TypeReference<Utf8String>(){},\n                        new TypeReference<Address>(true){}\n                ));\n        EthFilter filter = new EthFilter(DefaultBlockParameterName.EARLIEST,\n                DefaultBlockParameterName.LATEST, \"0x495feebd99f645a43aa63edb32d46e057e44e286\");\n        //订阅的是event事件本身\n        filter.addSingleTopic(EventEncoder.encode(event));\n\n        web3j.ethLogObservable(filter).subscribe(log -> {\n            System.out.println(log);\n            //data参数值，需要进行解码。\n            List<Type> results = FunctionReturnDecoder.decode(log.getData(), event.getNonIndexedParameters());\n            for (Type type : results) {\n                System.out.println(type);\n            }\n\n        });\n\n    }\n\n    //输出，例如，当前事件有 SendMsg(\"susan\", \"tom\", \"hi\", \"0x11a857e4d069d963c0676c53b68e9d571a3e2b26\")\n    //log输出为Log{removed=false, logIndex='0x0', transactionIndex='0x0', transactionHash='0x31aa0a485f5595fb5b5c959e94dfb511c3512e94589dfd51205c5bd07c6ba4e2', blockHash='0xc68dcd25600857642199f9ebb354b62532f8468191a85ca923c0e03e958c6398', blockNumber='0x157c', address='0x495feebd99f645a43aa63edb32d46e057e44e286', data='...', type='null', topics=[0x444f124b164dc796e3a81a1d90ea60c96a815eac0a67ad1d3d550d30afda9e1f, 0x00000000000000000000000011a857e4d069d963c0676c53b68e9d571a3e2b26]\n    //topic为两个，第一个为SendMsg事件本身，第二个为SendMsg事件定义中含有可索引值address,\n    //data解码非索引项结果为susan、tom、hi\n```\n\n\n\n#### Remix\n\nremix是基于浏览器开发的ide\n\n- 加载本地文件夹\n\n  ```\n  npm install -g remixd\n  remixd -s <absolute-path-to-the-shared-folder>\n  //会开启共享文件夹服务，通过ws\n  ```\n\n  然后在remix上点击类似于超链接的那个按钮\n\n\n\n#### bytes32、string\n\n文档上是这么说的，bytes1 ~bytes32是长度特定的类型，故花费比string和bytes小。\n\n\n\n然后记一下一般存pubkey(pubkey除掉0x长度为64，可以用两个bytes32来存)\n\n```\nbytes32 pubkey_half_pre;\nbytes32 pubkey_half_after;\n```\n\n\n\n#### 钱💰💰💰💰\n\n合约部署之后生成合约地址，地址同样可以作为普通地址使用，即转账系列。可以给合约地址转账，见[文档](https://solidity-cn.readthedocs.io/zh/develop/contracts.html#fallback)\n\n需定义一个未命名、没有参数也没有返回值函数,且为payable。如\n\n```\nfunction () payable {}\n```\n\n在ico中，转账给到合约地址，合约返回一定数量token给到转账者，就可以利用这个函数进行。\n\n\n\n或者呢，合约的某方法如果使用了payable修饰的话，也代表这个方法可以接受ether, 即msg.value，钱会存到合约地址中，通过this.balance即可获取余额。\n\n\n\n在合约中，向某地址发送ether, 使用address.transfer、address.send即可。\n\n\n\n#### 合约交互\n\n现有一合约\n\n```\npragma solidity ^0.4.18;\n\ncontract UserTest {\n    struct User {\n        string name;\n        address addr;\n        string pubkey;\n        bool isValue;\n    }\n    mapping(string => User)  users;\n    event UserChange(string uname, address addr, uint value);\n\n    function addUser(string uname, address addr, string pubkey)  public {\n         require(\n           !users[uname].isValue,\n           \"name already exist\"\n       );\n       users[uname] = User({\n           name: uname,\n           addr: addr,\n           pubkey: pubkey,\n           isValue: true\n       });\n       UserChange(uname, addr, msg.value);\n    }\n\n    function userExist(string uname) constant external returns (bool) {\n        return users[uname].isValue;\n    }\n\n}\n```\n\n然后在另一合约中调用userExist方法,首先部署上述合约，合约地址如0x123456789\n\n```\npragma solidity ^0.4.18;\n\ncontract UserTest {\n\t//要调用的方法声明需要跟原来一样\n    function userExist(string uname) constant external returns (bool);\n}\ncontract ExternalTest {\n\n    address userInstance = 0x123456789;\n    UserTest user = UserTest(userInstance); //强制类型转换\n\n    function userCheck(string uname) public returns (bool){\n        return user.userExist(uname);\n    }\n}\n```\n\n\n\n#### mapping\n\nmapping是不能遍历的，需要借助别的数据结构。\n\n```\nlibrary IterableMapping\n{\n  struct itmap\n  {\n    mapping(uint => IndexValue) data;\n    KeyFlag[] keys;\n    uint size;\n  }\n  struct IndexValue { uint keyIndex; uint value; }\n  struct KeyFlag { uint key; bool deleted; }\n  function insert(itmap storage self, uint key, uint value) returns (bool replaced)\n  {\n    uint keyIndex = self.data[key].keyIndex;\n    self.data[key].value = value;\n    if (keyIndex > 0)\n      return true;\n    else\n    {\n      keyIndex = self.keys.length++;\n      self.data[key].keyIndex = keyIndex + 1;\n      self.keys[keyIndex].key = key;\n      self.size++;\n      return false;\n    }\n  }\n  function remove(itmap storage self, uint key) returns (bool success)\n  {\n    uint keyIndex = self.data[key].keyIndex;\n    if (keyIndex == 0)\n      return false;\n    delete self.data[key];\n    self.keys[keyIndex - 1].deleted = true;\n    self.size --;\n  }\n  function contains(itmap storage self, uint key) returns (bool)\n  {\n    return self.data[key].keyIndex > 0;\n  }\n  function iterate_start(itmap storage self) returns (uint keyIndex)\n  {\n    return iterate_next(self, uint(-1));\n  }\n  function iterate_valid(itmap storage self, uint keyIndex) returns (bool)\n  {\n    return keyIndex < self.keys.length;\n  }\n  function iterate_next(itmap storage self, uint keyIndex) returns (uint r_keyIndex)\n  {\n    keyIndex++;\n    while (keyIndex < self.keys.length && self.keys[keyIndex].deleted)\n      keyIndex++;\n    return keyIndex;\n  }\n  function iterate_get(itmap storage self, uint keyIndex) returns (uint key, uint value)\n  {\n    key = self.keys[keyIndex].key;\n    value = self.data[key].value;\n  }\n}\n\n// How to use it:\ncontract User\n{\n  // Just a struct holding our data.\n  IterableMapping.itmap data;\n  // Insert something\n  function insert(uint k, uint v) returns (uint size)\n  {\n    // Actually calls itmap_impl.insert, auto-supplying the first parameter for us.\n    IterableMapping.insert(data, k, v);\n    // We can still access members of the struct - but we should take care not to mess with them.\n    return data.size;\n  }\n  // Computes the sum of all stored data.\n  function sum() returns (uint s)\n  {\n    for (var i = IterableMapping.iterate_start(data); IterableMapping.iterate_valid(data, i); i = IterableMapping.iterate_next(data, i))\n    {\n        var (key, value) = IterableMapping.iterate_get(data, i);\n        s += value;\n    }\n  }  \n}\n```\n\n\n\n\n\n\n\n#### 以太坊虚拟机(EVM)\n\n以太坊虚拟机(EVM)是智能合约的运行环境。它是一个完全独立的沙盒，合约代码在EVM内部运行，对外是完全隔离的，甚至不同合约之间也只有有限的访问权限\n\n#### 账户\n\n- 以太坊中有两种不同类型但是共享同一地址空间的账户：`外部账户`由一对公私钥控制，`合约账户`由账户内部的合约代码控制。\n- 外部账户的地址是由公钥（经过hash运算）决定的，而合约账户的地址在此合约被创建的时候决定的（由合约创建者的地址和发送到此合约地址的交易数决定，这就是所谓的“nonce”）\n- 不管是哪种类型的账户，EVM的处理方式是一样的\n- 每个账户都有一个持久的key-value类型的存储，把256字节的key映射到256字节的value\n- 此外，每个账户都有以“Wei”为单位，在交易过程中会被修改的资产(balance)信息\n\n#### 交易\n\n- 交易是一个从账户发往另一个账户（可以是同一个账户或者是special zero-account）的消息。它包含二进制数据（交易相关的数据）和 Ether。\n- 如果目标账户包含代码，代码会被执行，交易相关的数据将作为参数\n- 如果目标账户是地址为0的账户`zero-account`, 交易会创建一个新的合约。如上文提到的，合约地址不是一个地址为0的地址，而是一个由交易发送者和交易数来决定的地址。这样的一笔（到zero-account）交易的相关参数会被转化为EVM字节码\n  然后被执行，输出结果就是被永久存储的合约代码。这意味着为了创建一个合约，并不需要发送真实的合约代码，代码可以被自动创建\n\n#### gas\n\n- 创建之后，每笔交易都需要一定数量的gas，用于限制交易所消耗的工作量，即交易是需要付出代价的（避免DDoS攻击）。EVM执行交易的过程中，gas会按一个特殊规则逐渐减少\n- 费用的多少是由交易发起者设置，至少需要从发起账户支付`gas_price * gas`用费。如果交易执行完毕费用还有剩余的，将退回到发起账户。\n- 如果交易完成之前费用耗尽，将会抛出一个`out-of-gas`的异常，所有的修改都会被回滚\n\n更多关于gas的理解和讨论可以[戳这里](http://bitshuo.com/topic/5857774a2a482b0d339aab99/)\n\n#### storage,memory,stack\n\n- 每个账户都有一个持久的内存空间，称之为`storage`,`storage`以key-value形式存储，256字节的key映射到256字节value，合约内部不可能枚举`storage`(内部元素)，读取或者修改`storage`操作消耗都很大(原文是 It is not possible to enumerate storage from within a contract and it is comparatively costly to read and even more so, to modify storage. )。 合约只能读取和修改自己的`storage`里的数据。\n- 第二种内存空间称之为`memory`,里面存储着每个消息调用时合约创建的实例。`memory`是线型的，可以以字节级别来处理，但是限制为256字节宽度，写入可以是8或256字节宽度。当读取或写入一个预先未触发的指令的时候会消耗`memory`的空间，消耗空间的同时，必须支付gas。`memory`消耗的越多，需要的gas越多（按平方级增长）\n- EVM不是一个注册的机器而是一个堆栈机器，所以所有的计算指令都在`stack`空间里面执行。`stack`最多只能容纳1024个长度不超过256字节的指令元素。只能用下述方法，从顶部访问`stack`：可以拷贝最顶部的16个元素中的一个到`stack`的最顶部，或者将最顶部的那个元素与其下面的16个元素之一互换。所有其它操作从`stack`最顶部取出两个（或一个，或更多，取决于操作）元素，然后把结果push到`stack`顶端。当然将`stack`中的元素移到`memory`或者`storage`也是可以的，但是不能直接访问`stack`中间的元素（必须从头部开始访问）\n\n#### 指令集合\n\n- EVM的指令集合控制的很小，这样可以避免错误的执行引发问题。所有的指令都是操作最基本的数据类型，256字节。而且都是最常见的逻辑，算法，字节和比较运算。有条件或无条件的跳转都可以。此外，合约可以访问当前区块的属性，比如区块编号和时间戳。\n\n#### 消息调用\n\n- 合约之间可以通过消息调用的方式进行相互调用或者另一个给另一个无合约账户（外部账户）转币。消息调用很像交易，两者都有源账户，目标账户，数据（data payload），`Ether`,费用和返回数据。实际上每笔交易都由一个可创建更多调用的顶级调用组成。\n- 合约可以决定内部消息调用的时候发送多少手续费，保留多少。如果在内部消息调用的时候抛出`out-of-gas`异常（或者其它异常），这个会被一个错误值标记，放到`stack`顶部。如此，只有和消息一起发出的手续费才会被消耗。在`Solidity`中这种情形默认会引发一个异常，以便异常“冒泡”到`stack`最顶端\n- 如上所述，被调用的合约会接收到一个刚创建的`memory`实例，并且可以访问调用参数，调用参数被存储在一个被为`calldata`的隔离的区域。执行完毕后，被调用的合约将返回数据存储在调用合约预先创建的内存中。\n- 调用被限制在1024深度，这意味着复杂的操作应尽量使用循环代替递归调用。\n\n#### 代理调用/调用代码和库\n\n- 存在一种称为`delegatecall`的特殊的多样性的消息调用，which is identical to a message call apart from the fact that the code at the target address is executed in the context of the calling contract and msg.sender and msg.value do not change their values.\n- 这意味着合约可以在运行的时候动态的从另一个地址加载代码。存储、当前地址和资产仍然和调用的合约相关联，只有代码来自被调用的地址。\n- 这样可以实现Solidity库的特性:反复使用的库代码可以被应用到合约的`storage`来实现复杂的数据结构。\n\n#### 日志\n\nIt is possible to store data in a specially indexed data structure that maps all the way up to the block level. This feature called logs is used by Solidity in order to implement events. Contracts cannot access log data after it has been created, but they can be efficiently accessed from outside the blockchain. Since some part of the log data is stored in bloom filters, it is possible to search for this data in an efficient and cryptographically secure way, so network peers that do not download the whole blockchain (“light clients”) can still find these logs.\n\n#### Create\n\n- 合约甚至可以使用特殊的`opcode`创建其它的合约,`create`消息调用和普通的消息调用区别在于，`create`消息调用的data字段会被执行，执行结果以代码的形式存储，调用者可在stack上接接到新合约账户的地址\n\n\n- 示例一\n\n```\npragma solidity ^0.4.18;\n\ncontract ClassifyStorage {\n    mapping(address => string) details;\n    event AddDetailEvent(address classify, string detail);\n\n    function addDetail(address classify, string detail) public {\n        details[classify] = strConcat(details[classify], detail);\n        AddDetailEvent(classify, detail);\n    }\n\n    function getSpecificDetails(address classify) constant public returns (string) {\n        return details[classify];\n    }\n\n    function strConcat(string _a, string _b) internal returns (string){\n        bytes memory _ba = bytes(_a);\n        if(_ba.length == 0) {\n            return _b;\n        }\n        bytes memory _bb = bytes(_b);\n        string memory ret = new string(_ba.length + _bb.length + 1);\n        bytes memory bret = bytes(ret);\n        uint k = 0;\n        for (uint i = 0; i < _ba.length; i++)bret[k++] = _ba[i];\n        bret[k++] = \",\";\n        for (i = 0; i < _bb.length; i++) bret[k++] = _bb[i];\n        return string(ret);\n   }  \n}\n\n```\n","source":"_posts/eth-contract.md","raw":"---\ntitle: eth_contract\ncategories:\n  - eth\ndate: 2019-10-14 14:51:05\ntags:\n---\n\n## 以太坊智能合约\n\n从智能合约的代码到使用智能合约，大概包含以下步骤\n\n- 编写智能合约的代码(一般是用Solidity)\n- 编译智能合约的代码变成可在EVM上执行的bytecode(binary code)，同时可以通过编译取得智能合约的ABI\n- 部署智能合约，实际上是吧bytecode存储在链上(通过一个transaction)，并取得一个专属于这个合约的地址\n- 要调用合约，需要把信息发送到这个合约的地址，一样也是通过transaction，以太坊节点会根据输入的信息，选择要执行合约中的哪一个function和要输入的参数\n\n以下，将详细介绍以上步骤。\n\n#### 代码编写及编译部署\n\n#### 智能合约ABI\n\n如果说api，想必都知道是什么，对应的，ABI，application binary interface，顾名思义，同样是接口，但传递的是binary格式的信息。\n\nABI理解如下\n\n##### Function\n\n- `name`：a string, 方法名\n- `type`:  a string，\"function\", \"constructor\", or \"fallback\"，方法类型\n- `inputs`:  an array，方法参数，每个参数的格式为\n  - `name`：a string，参数名\n  - `type`：a string，参数的 data type(e.g. uint256)\n  - `components`：an array，如果输入的参数是 tuple(struct) type 才会有这个参数。描述 struct 中包含的参数类型\n- `outputs`：an array， 方法返回值，和 `inputs` 使用相同表示方式。如果沒有返回值可忽略，值为 `[]`\n- `payable`：`true`，function 是否可收 Ether，预设为 `false`\n- `constant`：`true`，function 是否会改写区块链状态，反之为 `false`\n- `stateMutability`：a string，其值可能为以下其中之一：\"pure\"（不会读写区块链状态）、\"view\"（只读不写区块链状态）、\"payable\" and \"nonpayable\"（会改区块链状态，且如可收 Ether 为 \"payable\"，反之为 \"nonpayable\"）\n\n仔细看会发现 `payable` 和 `constant` 这两个参数所描述的內容，似乎已包含在 `stateMutability` 中。\n\n##### Event\n\n- `name`: a string，event 的名称\n- `type`: a string，always \"event\"\n- `inputs`: an array，输入参数，包含：\n  - `name`: a string，参数名称\n  - `type`: a string，参数的 data type(e.g. uint256)\n  - `components`: an array，如果输入参数是 tuple(struct) type 才会有这个参数。描述 struct 中包含的信息类型\n  - `indexed`: `true`，如果这个参数被定义为 indexed ，反之为 `false`\n- `anonymous`: `true`，如果 event 被定义为 anonymous\n\n更新智能合约状态需要发送 transaction，transaction 需要等待验证，所以更新合约状态是非同步的，无法马上取得返回值。使用 Event 可以在状态更新成功后，将相关信息记录到 Log，并让监听这个 Event 的 DApp 或任何应用这个接口的程序收到通知。每笔 transaction 都有对应的 Log。\n\n所以简单来说，Event 可用來：1. 取得 function 更新合约状态的返回值 2. 也可作为合约另外的存储空间。\n\nEvent 的参数分为：有 `indexed`，和其他没有 `indexed` 的。有 `indexed` 的参数可以使用 filter，例如同一个 Event，我可以选择只监听从特定 address 发出来的交易。每笔 Log 的信息同样分为两个部分：Topics（长度最多为 4 的 array） 和 Data。有 `anonymous` 的参数会存储存在 Log 的 Topics，其他的存在 Data。\n\n##### 示例\n\n```\npragma solidity ^0.4.20;\ncontract SimpleStorage {\n    uint public data;\n    event Set(address indexed _from, uint value);\n    function set(uint x) public {\n        data = x;\n        Set(msg.sender, x);\n    }\n}\n\n```\n\n生成的ABI接口为\n\n```\n[{\t\t//自动生成的方法名为data的只读方法，返回data值,\"stateMutabTility\": \"view\"代表只读\n        \"constant\": true,  \n        \"inputs\": [],\n        \"name\": \"data\",\n        \"outputs\": [{\"name\": \"\",\"type\": \"uint256\"}],\n        \"payable\": false,\n        \"stateMutabTility\": \"view\",\n        \"type\": \"function\"\n    },\n    {  //set方法， \"stateMutability\": \"nonpayable\",可写方法，但不可收Ether,方法参数为uint256类型\n        \"constant\": false,\n        \"inputs\": [{\"name\": \"x\",\"type\": \"uint256\"}],\n        \"name\": \"set\",\n        \"outputs\": [],\n        \"payable\": false,\n        \"stateMutability\": \"nonpayable\",\n        \"type\": \"function\"\n\t},\n    {\n        \"anonymous\": false,\n        \"inputs\": [{\"indexed\": true,\"name\": \"_from\",\"type\": \"address\"},{\"indexed\": false,\"name\": \"value\",\"type\": \"uint256\"}],\n        \"name\": \"Set\",\n        \"type\": \"event\"\n}]\n```\n\nevent时间可监听，在web3使用时会有示例\n\n### web3\n\n关于智能合约的调用，通过命令行也是可以的，但binary的拼凑有点繁琐，web3封装的接口调用起来就方便很多。\n\n直接看例子吧。\n\n```\ncontract hello {\n    function say() constant public returns (string) {\n        return \"Hello World\";\n    }\n}\n```\n\n然后部署到了服务器上，返回合约的地址为0x43d03aaeb07e518cd975c2d67b83a7ffea3a5a51\n\nabi为编译产生的abi数组，直接复制粘贴即可。\n\n```\nvar contract = web3.eth.contract(info.abi).at(\"0x43d03aaeb07e518cd975c2d67b83a7ffea3a5a51\");\nvar account_one = web3.eth.accounts[0];\nvar result = contract.say({from: account_one})\nconsole.log(result); //Hello World\n```\n\n一个简单的调用就成功了，然后再看contract提供的接口的具体情况。\n\n智能合约方法调用方式有四种\n\n```\n//根据方法类型自动决定是使用call方式进行调用还是sendTransaction方式进行调用，call和sendTransaction的区别呢，如果方法是只读的，则不需要入链，直接调用即可，方法是可写的，则需要以交易的方法进行提交入链。参数中，param则是传入给方法的参数，后面添加别的参数\nmyContractInstance.myMethod(param1 [, param2, ...] [, transactionObject] [, defaultBlock] [, callback]);\n\n//精确使用call方式进行调用\nmyContractInstance.myMethod.call(param1 [, param2, ...] [, transactionObject] [, defaultBlock] [, callback]);\n\n//精确使用发送交易形式进行调用\nmyContractInstance.myMethod.sendTransaction(param1 [, param2, ...] [, transactionObject] [, callback]);\n\n//没看明白\n// Get the call data, so you can call the contract through some other means\n// var myCallData = myContractInstance.myMethod.request(param1 [, param2, ...]);\nvar myCallData = myContractInstance.myMethod.getData(param1 [, param2, ...]);\n// myCallData = '0x45ff3ff6000000000004545345345345..'\n\n```\n\n然后，顺便玩一下event。\n\n合约修改为\n\n```\npragma solidity ^0.4.18;\ncontract hello {\n    string public greeting;\n    event Set(address indexed _from, string value);\n\n    function set(string g) public {\n        greeting = g;\n        Set(msg.sender, g);\n    }\n\n    function get() constant public returns (string) {\n        return greeting;\n    }\n}\n```\n\n然后完整的调用脚本为\n\n```\nvar Web3 = require(\"web3\");\nvar web3 = new Web3();\nweb3.setProvider(new Web3.providers.HttpProvider(\"http://localhost:8545\"));\nif (web3.isConnected()) {\n  console.log(\"connection success!\");\n} else {\n  console.log(\"fail to connection!\");\n  return\n}\n\n\nvar contract = web3.eth.contract(abi).at(address);\nvar account_one = web3.eth.accounts[0];\nvar my_event = contract.Set();\nvar getStr = function() {\n  var str = contract.greeting({from: account_one})\n  console.log(\"the str is: \" + str);\n}\n\ngetStr()\nmy_event.watch(function(err, result) {\n    if (!err) {\n        console.log(result);\n        getStr()\n    } else {\n        console.log(err);\n    }\n    my_event.stopWatching();\n});\n\ncontract.set(\"I am Changed!\",{from: account_one})\n```\n\n查看输出\n\n```\n// connection success!\n// the str is:\n// { address: '0x8321a32f8b7bbc00a65c9e21df64948cf40bbeba',\n//   blockNumber: 785,\n//   transactionHash: '0xa90e35845cd844907f251660bce78f5cde2c968876f3a6321fbf38589d7fb476',\n//   transactionIndex: 0,\n//   blockHash: '0x742eecc3ae508b33ca5dde2ae2a32b8c0c87d321c6ab13a0cc8ad3909e579275',\n//   logIndex: 0,\n//   removed: false,\n//   event: 'Set',\n//   args:\n//    { _from: '0xc6e1feafcc44ebb1a7b0ecc06770566845eac7ac',\n//      value: 'I am Changed!' } }\n// the str is: I am Changed!\n```\n\n可以看到返回的结果中包括区块哈希等信息，还有参数\n\n\n\n\n\n#### Event\n\n在合约中定义事件，如\n\n```\nevent SendMsg(string sender, string receiver, string detail, address indexed reth);\n```\n\n注意到indexed关键字。跟event订阅有一定的关系。\n\n大致理解是，event事件犹如日志，在订阅的时候，需要确定要订阅的关键字，这个关键字可以是事件本身，也可以是某个可索引的值，如address值。如订阅某确定address值时，会取得所有含有可索引的这个地址相关的event事件。订阅事件本身的话，就只能取得这个事件的值。\n\n顺便粘贴一段在web3j中event的使用\n\n```\n   public static void test() {\n        Web3j web3j = Web3j.build(new HttpService(\"http://localhost:8545\"));\n        Event event = new Event(\"SendMsg\",\n                Arrays.<TypeReference<?>>asList(\n                        new TypeReference<Utf8String>(){},\n                        new TypeReference<Utf8String>(){},\n                        new TypeReference<Utf8String>(){},\n                        new TypeReference<Address>(true){}\n                ));\n        EthFilter filter = new EthFilter(DefaultBlockParameterName.EARLIEST,\n                DefaultBlockParameterName.LATEST, \"0x495feebd99f645a43aa63edb32d46e057e44e286\");\n        //订阅的是event事件本身\n        filter.addSingleTopic(EventEncoder.encode(event));\n\n        web3j.ethLogObservable(filter).subscribe(log -> {\n            System.out.println(log);\n            //data参数值，需要进行解码。\n            List<Type> results = FunctionReturnDecoder.decode(log.getData(), event.getNonIndexedParameters());\n            for (Type type : results) {\n                System.out.println(type);\n            }\n\n        });\n\n    }\n\n    //输出，例如，当前事件有 SendMsg(\"susan\", \"tom\", \"hi\", \"0x11a857e4d069d963c0676c53b68e9d571a3e2b26\")\n    //log输出为Log{removed=false, logIndex='0x0', transactionIndex='0x0', transactionHash='0x31aa0a485f5595fb5b5c959e94dfb511c3512e94589dfd51205c5bd07c6ba4e2', blockHash='0xc68dcd25600857642199f9ebb354b62532f8468191a85ca923c0e03e958c6398', blockNumber='0x157c', address='0x495feebd99f645a43aa63edb32d46e057e44e286', data='...', type='null', topics=[0x444f124b164dc796e3a81a1d90ea60c96a815eac0a67ad1d3d550d30afda9e1f, 0x00000000000000000000000011a857e4d069d963c0676c53b68e9d571a3e2b26]\n    //topic为两个，第一个为SendMsg事件本身，第二个为SendMsg事件定义中含有可索引值address,\n    //data解码非索引项结果为susan、tom、hi\n```\n\n\n\n#### Remix\n\nremix是基于浏览器开发的ide\n\n- 加载本地文件夹\n\n  ```\n  npm install -g remixd\n  remixd -s <absolute-path-to-the-shared-folder>\n  //会开启共享文件夹服务，通过ws\n  ```\n\n  然后在remix上点击类似于超链接的那个按钮\n\n\n\n#### bytes32、string\n\n文档上是这么说的，bytes1 ~bytes32是长度特定的类型，故花费比string和bytes小。\n\n\n\n然后记一下一般存pubkey(pubkey除掉0x长度为64，可以用两个bytes32来存)\n\n```\nbytes32 pubkey_half_pre;\nbytes32 pubkey_half_after;\n```\n\n\n\n#### 钱💰💰💰💰\n\n合约部署之后生成合约地址，地址同样可以作为普通地址使用，即转账系列。可以给合约地址转账，见[文档](https://solidity-cn.readthedocs.io/zh/develop/contracts.html#fallback)\n\n需定义一个未命名、没有参数也没有返回值函数,且为payable。如\n\n```\nfunction () payable {}\n```\n\n在ico中，转账给到合约地址，合约返回一定数量token给到转账者，就可以利用这个函数进行。\n\n\n\n或者呢，合约的某方法如果使用了payable修饰的话，也代表这个方法可以接受ether, 即msg.value，钱会存到合约地址中，通过this.balance即可获取余额。\n\n\n\n在合约中，向某地址发送ether, 使用address.transfer、address.send即可。\n\n\n\n#### 合约交互\n\n现有一合约\n\n```\npragma solidity ^0.4.18;\n\ncontract UserTest {\n    struct User {\n        string name;\n        address addr;\n        string pubkey;\n        bool isValue;\n    }\n    mapping(string => User)  users;\n    event UserChange(string uname, address addr, uint value);\n\n    function addUser(string uname, address addr, string pubkey)  public {\n         require(\n           !users[uname].isValue,\n           \"name already exist\"\n       );\n       users[uname] = User({\n           name: uname,\n           addr: addr,\n           pubkey: pubkey,\n           isValue: true\n       });\n       UserChange(uname, addr, msg.value);\n    }\n\n    function userExist(string uname) constant external returns (bool) {\n        return users[uname].isValue;\n    }\n\n}\n```\n\n然后在另一合约中调用userExist方法,首先部署上述合约，合约地址如0x123456789\n\n```\npragma solidity ^0.4.18;\n\ncontract UserTest {\n\t//要调用的方法声明需要跟原来一样\n    function userExist(string uname) constant external returns (bool);\n}\ncontract ExternalTest {\n\n    address userInstance = 0x123456789;\n    UserTest user = UserTest(userInstance); //强制类型转换\n\n    function userCheck(string uname) public returns (bool){\n        return user.userExist(uname);\n    }\n}\n```\n\n\n\n#### mapping\n\nmapping是不能遍历的，需要借助别的数据结构。\n\n```\nlibrary IterableMapping\n{\n  struct itmap\n  {\n    mapping(uint => IndexValue) data;\n    KeyFlag[] keys;\n    uint size;\n  }\n  struct IndexValue { uint keyIndex; uint value; }\n  struct KeyFlag { uint key; bool deleted; }\n  function insert(itmap storage self, uint key, uint value) returns (bool replaced)\n  {\n    uint keyIndex = self.data[key].keyIndex;\n    self.data[key].value = value;\n    if (keyIndex > 0)\n      return true;\n    else\n    {\n      keyIndex = self.keys.length++;\n      self.data[key].keyIndex = keyIndex + 1;\n      self.keys[keyIndex].key = key;\n      self.size++;\n      return false;\n    }\n  }\n  function remove(itmap storage self, uint key) returns (bool success)\n  {\n    uint keyIndex = self.data[key].keyIndex;\n    if (keyIndex == 0)\n      return false;\n    delete self.data[key];\n    self.keys[keyIndex - 1].deleted = true;\n    self.size --;\n  }\n  function contains(itmap storage self, uint key) returns (bool)\n  {\n    return self.data[key].keyIndex > 0;\n  }\n  function iterate_start(itmap storage self) returns (uint keyIndex)\n  {\n    return iterate_next(self, uint(-1));\n  }\n  function iterate_valid(itmap storage self, uint keyIndex) returns (bool)\n  {\n    return keyIndex < self.keys.length;\n  }\n  function iterate_next(itmap storage self, uint keyIndex) returns (uint r_keyIndex)\n  {\n    keyIndex++;\n    while (keyIndex < self.keys.length && self.keys[keyIndex].deleted)\n      keyIndex++;\n    return keyIndex;\n  }\n  function iterate_get(itmap storage self, uint keyIndex) returns (uint key, uint value)\n  {\n    key = self.keys[keyIndex].key;\n    value = self.data[key].value;\n  }\n}\n\n// How to use it:\ncontract User\n{\n  // Just a struct holding our data.\n  IterableMapping.itmap data;\n  // Insert something\n  function insert(uint k, uint v) returns (uint size)\n  {\n    // Actually calls itmap_impl.insert, auto-supplying the first parameter for us.\n    IterableMapping.insert(data, k, v);\n    // We can still access members of the struct - but we should take care not to mess with them.\n    return data.size;\n  }\n  // Computes the sum of all stored data.\n  function sum() returns (uint s)\n  {\n    for (var i = IterableMapping.iterate_start(data); IterableMapping.iterate_valid(data, i); i = IterableMapping.iterate_next(data, i))\n    {\n        var (key, value) = IterableMapping.iterate_get(data, i);\n        s += value;\n    }\n  }  \n}\n```\n\n\n\n\n\n\n\n#### 以太坊虚拟机(EVM)\n\n以太坊虚拟机(EVM)是智能合约的运行环境。它是一个完全独立的沙盒，合约代码在EVM内部运行，对外是完全隔离的，甚至不同合约之间也只有有限的访问权限\n\n#### 账户\n\n- 以太坊中有两种不同类型但是共享同一地址空间的账户：`外部账户`由一对公私钥控制，`合约账户`由账户内部的合约代码控制。\n- 外部账户的地址是由公钥（经过hash运算）决定的，而合约账户的地址在此合约被创建的时候决定的（由合约创建者的地址和发送到此合约地址的交易数决定，这就是所谓的“nonce”）\n- 不管是哪种类型的账户，EVM的处理方式是一样的\n- 每个账户都有一个持久的key-value类型的存储，把256字节的key映射到256字节的value\n- 此外，每个账户都有以“Wei”为单位，在交易过程中会被修改的资产(balance)信息\n\n#### 交易\n\n- 交易是一个从账户发往另一个账户（可以是同一个账户或者是special zero-account）的消息。它包含二进制数据（交易相关的数据）和 Ether。\n- 如果目标账户包含代码，代码会被执行，交易相关的数据将作为参数\n- 如果目标账户是地址为0的账户`zero-account`, 交易会创建一个新的合约。如上文提到的，合约地址不是一个地址为0的地址，而是一个由交易发送者和交易数来决定的地址。这样的一笔（到zero-account）交易的相关参数会被转化为EVM字节码\n  然后被执行，输出结果就是被永久存储的合约代码。这意味着为了创建一个合约，并不需要发送真实的合约代码，代码可以被自动创建\n\n#### gas\n\n- 创建之后，每笔交易都需要一定数量的gas，用于限制交易所消耗的工作量，即交易是需要付出代价的（避免DDoS攻击）。EVM执行交易的过程中，gas会按一个特殊规则逐渐减少\n- 费用的多少是由交易发起者设置，至少需要从发起账户支付`gas_price * gas`用费。如果交易执行完毕费用还有剩余的，将退回到发起账户。\n- 如果交易完成之前费用耗尽，将会抛出一个`out-of-gas`的异常，所有的修改都会被回滚\n\n更多关于gas的理解和讨论可以[戳这里](http://bitshuo.com/topic/5857774a2a482b0d339aab99/)\n\n#### storage,memory,stack\n\n- 每个账户都有一个持久的内存空间，称之为`storage`,`storage`以key-value形式存储，256字节的key映射到256字节value，合约内部不可能枚举`storage`(内部元素)，读取或者修改`storage`操作消耗都很大(原文是 It is not possible to enumerate storage from within a contract and it is comparatively costly to read and even more so, to modify storage. )。 合约只能读取和修改自己的`storage`里的数据。\n- 第二种内存空间称之为`memory`,里面存储着每个消息调用时合约创建的实例。`memory`是线型的，可以以字节级别来处理，但是限制为256字节宽度，写入可以是8或256字节宽度。当读取或写入一个预先未触发的指令的时候会消耗`memory`的空间，消耗空间的同时，必须支付gas。`memory`消耗的越多，需要的gas越多（按平方级增长）\n- EVM不是一个注册的机器而是一个堆栈机器，所以所有的计算指令都在`stack`空间里面执行。`stack`最多只能容纳1024个长度不超过256字节的指令元素。只能用下述方法，从顶部访问`stack`：可以拷贝最顶部的16个元素中的一个到`stack`的最顶部，或者将最顶部的那个元素与其下面的16个元素之一互换。所有其它操作从`stack`最顶部取出两个（或一个，或更多，取决于操作）元素，然后把结果push到`stack`顶端。当然将`stack`中的元素移到`memory`或者`storage`也是可以的，但是不能直接访问`stack`中间的元素（必须从头部开始访问）\n\n#### 指令集合\n\n- EVM的指令集合控制的很小，这样可以避免错误的执行引发问题。所有的指令都是操作最基本的数据类型，256字节。而且都是最常见的逻辑，算法，字节和比较运算。有条件或无条件的跳转都可以。此外，合约可以访问当前区块的属性，比如区块编号和时间戳。\n\n#### 消息调用\n\n- 合约之间可以通过消息调用的方式进行相互调用或者另一个给另一个无合约账户（外部账户）转币。消息调用很像交易，两者都有源账户，目标账户，数据（data payload），`Ether`,费用和返回数据。实际上每笔交易都由一个可创建更多调用的顶级调用组成。\n- 合约可以决定内部消息调用的时候发送多少手续费，保留多少。如果在内部消息调用的时候抛出`out-of-gas`异常（或者其它异常），这个会被一个错误值标记，放到`stack`顶部。如此，只有和消息一起发出的手续费才会被消耗。在`Solidity`中这种情形默认会引发一个异常，以便异常“冒泡”到`stack`最顶端\n- 如上所述，被调用的合约会接收到一个刚创建的`memory`实例，并且可以访问调用参数，调用参数被存储在一个被为`calldata`的隔离的区域。执行完毕后，被调用的合约将返回数据存储在调用合约预先创建的内存中。\n- 调用被限制在1024深度，这意味着复杂的操作应尽量使用循环代替递归调用。\n\n#### 代理调用/调用代码和库\n\n- 存在一种称为`delegatecall`的特殊的多样性的消息调用，which is identical to a message call apart from the fact that the code at the target address is executed in the context of the calling contract and msg.sender and msg.value do not change their values.\n- 这意味着合约可以在运行的时候动态的从另一个地址加载代码。存储、当前地址和资产仍然和调用的合约相关联，只有代码来自被调用的地址。\n- 这样可以实现Solidity库的特性:反复使用的库代码可以被应用到合约的`storage`来实现复杂的数据结构。\n\n#### 日志\n\nIt is possible to store data in a specially indexed data structure that maps all the way up to the block level. This feature called logs is used by Solidity in order to implement events. Contracts cannot access log data after it has been created, but they can be efficiently accessed from outside the blockchain. Since some part of the log data is stored in bloom filters, it is possible to search for this data in an efficient and cryptographically secure way, so network peers that do not download the whole blockchain (“light clients”) can still find these logs.\n\n#### Create\n\n- 合约甚至可以使用特殊的`opcode`创建其它的合约,`create`消息调用和普通的消息调用区别在于，`create`消息调用的data字段会被执行，执行结果以代码的形式存储，调用者可在stack上接接到新合约账户的地址\n\n\n- 示例一\n\n```\npragma solidity ^0.4.18;\n\ncontract ClassifyStorage {\n    mapping(address => string) details;\n    event AddDetailEvent(address classify, string detail);\n\n    function addDetail(address classify, string detail) public {\n        details[classify] = strConcat(details[classify], detail);\n        AddDetailEvent(classify, detail);\n    }\n\n    function getSpecificDetails(address classify) constant public returns (string) {\n        return details[classify];\n    }\n\n    function strConcat(string _a, string _b) internal returns (string){\n        bytes memory _ba = bytes(_a);\n        if(_ba.length == 0) {\n            return _b;\n        }\n        bytes memory _bb = bytes(_b);\n        string memory ret = new string(_ba.length + _bb.length + 1);\n        bytes memory bret = bytes(ret);\n        uint k = 0;\n        for (uint i = 0; i < _ba.length; i++)bret[k++] = _ba[i];\n        bret[k++] = \",\";\n        for (i = 0; i < _bb.length; i++) bret[k++] = _bb[i];\n        return string(ret);\n   }  \n}\n\n```\n","slug":"eth-contract","published":1,"updated":"2019-10-14T06:51:35.621Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69xn002nt6xv9knrcw58","content":"<h2 id=\"以太坊智能合约\"><a href=\"#以太坊智能合约\" class=\"headerlink\" title=\"以太坊智能合约\"></a>以太坊智能合约</h2><p>从智能合约的代码到使用智能合约，大概包含以下步骤</p>\n<ul>\n<li>编写智能合约的代码(一般是用Solidity)</li>\n<li>编译智能合约的代码变成可在EVM上执行的bytecode(binary code)，同时可以通过编译取得智能合约的ABI</li>\n<li>部署智能合约，实际上是吧bytecode存储在链上(通过一个transaction)，并取得一个专属于这个合约的地址</li>\n<li>要调用合约，需要把信息发送到这个合约的地址，一样也是通过transaction，以太坊节点会根据输入的信息，选择要执行合约中的哪一个function和要输入的参数</li>\n</ul>\n<p>以下，将详细介绍以上步骤。</p>\n<h4 id=\"代码编写及编译部署\"><a href=\"#代码编写及编译部署\" class=\"headerlink\" title=\"代码编写及编译部署\"></a>代码编写及编译部署</h4><h4 id=\"智能合约ABI\"><a href=\"#智能合约ABI\" class=\"headerlink\" title=\"智能合约ABI\"></a>智能合约ABI</h4><p>如果说api，想必都知道是什么，对应的，ABI，application binary interface，顾名思义，同样是接口，但传递的是binary格式的信息。</p>\n<p>ABI理解如下</p>\n<h5 id=\"Function\"><a href=\"#Function\" class=\"headerlink\" title=\"Function\"></a>Function</h5><ul>\n<li><code>name</code>：a string, 方法名</li>\n<li><code>type</code>:  a string，”function”, “constructor”, or “fallback”，方法类型</li>\n<li><code>inputs</code>:  an array，方法参数，每个参数的格式为<ul>\n<li><code>name</code>：a string，参数名</li>\n<li><code>type</code>：a string，参数的 data type(e.g. uint256)</li>\n<li><code>components</code>：an array，如果输入的参数是 tuple(struct) type 才会有这个参数。描述 struct 中包含的参数类型</li>\n</ul>\n</li>\n<li><code>outputs</code>：an array， 方法返回值，和 <code>inputs</code> 使用相同表示方式。如果沒有返回值可忽略，值为 <code>[]</code></li>\n<li><code>payable</code>：<code>true</code>，function 是否可收 Ether，预设为 <code>false</code></li>\n<li><code>constant</code>：<code>true</code>，function 是否会改写区块链状态，反之为 <code>false</code></li>\n<li><code>stateMutability</code>：a string，其值可能为以下其中之一：”pure”（不会读写区块链状态）、”view”（只读不写区块链状态）、”payable” and “nonpayable”（会改区块链状态，且如可收 Ether 为 “payable”，反之为 “nonpayable”）</li>\n</ul>\n<p>仔细看会发现 <code>payable</code> 和 <code>constant</code> 这两个参数所描述的內容，似乎已包含在 <code>stateMutability</code> 中。</p>\n<h5 id=\"Event\"><a href=\"#Event\" class=\"headerlink\" title=\"Event\"></a>Event</h5><ul>\n<li><code>name</code>: a string，event 的名称</li>\n<li><code>type</code>: a string，always “event”</li>\n<li><code>inputs</code>: an array，输入参数，包含：<ul>\n<li><code>name</code>: a string，参数名称</li>\n<li><code>type</code>: a string，参数的 data type(e.g. uint256)</li>\n<li><code>components</code>: an array，如果输入参数是 tuple(struct) type 才会有这个参数。描述 struct 中包含的信息类型</li>\n<li><code>indexed</code>: <code>true</code>，如果这个参数被定义为 indexed ，反之为 <code>false</code></li>\n</ul>\n</li>\n<li><code>anonymous</code>: <code>true</code>，如果 event 被定义为 anonymous</li>\n</ul>\n<p>更新智能合约状态需要发送 transaction，transaction 需要等待验证，所以更新合约状态是非同步的，无法马上取得返回值。使用 Event 可以在状态更新成功后，将相关信息记录到 Log，并让监听这个 Event 的 DApp 或任何应用这个接口的程序收到通知。每笔 transaction 都有对应的 Log。</p>\n<p>所以简单来说，Event 可用來：1. 取得 function 更新合约状态的返回值 2. 也可作为合约另外的存储空间。</p>\n<p>Event 的参数分为：有 <code>indexed</code>，和其他没有 <code>indexed</code> 的。有 <code>indexed</code> 的参数可以使用 filter，例如同一个 Event，我可以选择只监听从特定 address 发出来的交易。每笔 Log 的信息同样分为两个部分：Topics（长度最多为 4 的 array） 和 Data。有 <code>anonymous</code> 的参数会存储存在 Log 的 Topics，其他的存在 Data。</p>\n<h5 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.20;</span><br><span class=\"line\">contract SimpleStorage &#123;</span><br><span class=\"line\">    uint public data;</span><br><span class=\"line\">    event Set(address indexed _from, uint value);</span><br><span class=\"line\">    function set(uint x) public &#123;</span><br><span class=\"line\">        data = x;</span><br><span class=\"line\">        Set(msg.sender, x);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>生成的ABI接口为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&#123;\t\t//自动生成的方法名为data的只读方法，返回data值,&quot;stateMutabTility&quot;: &quot;view&quot;代表只读</span><br><span class=\"line\">        &quot;constant&quot;: true,  </span><br><span class=\"line\">        &quot;inputs&quot;: [],</span><br><span class=\"line\">        &quot;name&quot;: &quot;data&quot;,</span><br><span class=\"line\">        &quot;outputs&quot;: [&#123;&quot;name&quot;: &quot;&quot;,&quot;type&quot;: &quot;uint256&quot;&#125;],</span><br><span class=\"line\">        &quot;payable&quot;: false,</span><br><span class=\"line\">        &quot;stateMutabTility&quot;: &quot;view&quot;,</span><br><span class=\"line\">        &quot;type&quot;: &quot;function&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;  //set方法， &quot;stateMutability&quot;: &quot;nonpayable&quot;,可写方法，但不可收Ether,方法参数为uint256类型</span><br><span class=\"line\">        &quot;constant&quot;: false,</span><br><span class=\"line\">        &quot;inputs&quot;: [&#123;&quot;name&quot;: &quot;x&quot;,&quot;type&quot;: &quot;uint256&quot;&#125;],</span><br><span class=\"line\">        &quot;name&quot;: &quot;set&quot;,</span><br><span class=\"line\">        &quot;outputs&quot;: [],</span><br><span class=\"line\">        &quot;payable&quot;: false,</span><br><span class=\"line\">        &quot;stateMutability&quot;: &quot;nonpayable&quot;,</span><br><span class=\"line\">        &quot;type&quot;: &quot;function&quot;</span><br><span class=\"line\">\t&#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;anonymous&quot;: false,</span><br><span class=\"line\">        &quot;inputs&quot;: [&#123;&quot;indexed&quot;: true,&quot;name&quot;: &quot;_from&quot;,&quot;type&quot;: &quot;address&quot;&#125;,&#123;&quot;indexed&quot;: false,&quot;name&quot;: &quot;value&quot;,&quot;type&quot;: &quot;uint256&quot;&#125;],</span><br><span class=\"line\">        &quot;name&quot;: &quot;Set&quot;,</span><br><span class=\"line\">        &quot;type&quot;: &quot;event&quot;</span><br><span class=\"line\">&#125;]</span><br></pre></td></tr></table></figure>\n\n<p>event时间可监听，在web3使用时会有示例</p>\n<h3 id=\"web3\"><a href=\"#web3\" class=\"headerlink\" title=\"web3\"></a>web3</h3><p>关于智能合约的调用，通过命令行也是可以的，但binary的拼凑有点繁琐，web3封装的接口调用起来就方便很多。</p>\n<p>直接看例子吧。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">contract hello &#123;</span><br><span class=\"line\">    function say() constant public returns (string) &#123;</span><br><span class=\"line\">        return &quot;Hello World&quot;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后部署到了服务器上，返回合约的地址为0x43d03aaeb07e518cd975c2d67b83a7ffea3a5a51</p>\n<p>abi为编译产生的abi数组，直接复制粘贴即可。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var contract = web3.eth.contract(info.abi).at(&quot;0x43d03aaeb07e518cd975c2d67b83a7ffea3a5a51&quot;);</span><br><span class=\"line\">var account_one = web3.eth.accounts[0];</span><br><span class=\"line\">var result = contract.say(&#123;from: account_one&#125;)</span><br><span class=\"line\">console.log(result); //Hello World</span><br></pre></td></tr></table></figure>\n\n<p>一个简单的调用就成功了，然后再看contract提供的接口的具体情况。</p>\n<p>智能合约方法调用方式有四种</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//根据方法类型自动决定是使用call方式进行调用还是sendTransaction方式进行调用，call和sendTransaction的区别呢，如果方法是只读的，则不需要入链，直接调用即可，方法是可写的，则需要以交易的方法进行提交入链。参数中，param则是传入给方法的参数，后面添加别的参数</span><br><span class=\"line\">myContractInstance.myMethod(param1 [, param2, ...] [, transactionObject] [, defaultBlock] [, callback]);</span><br><span class=\"line\"></span><br><span class=\"line\">//精确使用call方式进行调用</span><br><span class=\"line\">myContractInstance.myMethod.call(param1 [, param2, ...] [, transactionObject] [, defaultBlock] [, callback]);</span><br><span class=\"line\"></span><br><span class=\"line\">//精确使用发送交易形式进行调用</span><br><span class=\"line\">myContractInstance.myMethod.sendTransaction(param1 [, param2, ...] [, transactionObject] [, callback]);</span><br><span class=\"line\"></span><br><span class=\"line\">//没看明白</span><br><span class=\"line\">// Get the call data, so you can call the contract through some other means</span><br><span class=\"line\">// var myCallData = myContractInstance.myMethod.request(param1 [, param2, ...]);</span><br><span class=\"line\">var myCallData = myContractInstance.myMethod.getData(param1 [, param2, ...]);</span><br><span class=\"line\">// myCallData = &apos;0x45ff3ff6000000000004545345345345..&apos;</span><br></pre></td></tr></table></figure>\n\n<p>然后，顺便玩一下event。</p>\n<p>合约修改为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.18;</span><br><span class=\"line\">contract hello &#123;</span><br><span class=\"line\">    string public greeting;</span><br><span class=\"line\">    event Set(address indexed _from, string value);</span><br><span class=\"line\"></span><br><span class=\"line\">    function set(string g) public &#123;</span><br><span class=\"line\">        greeting = g;</span><br><span class=\"line\">        Set(msg.sender, g);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    function get() constant public returns (string) &#123;</span><br><span class=\"line\">        return greeting;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后完整的调用脚本为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var Web3 = require(&quot;web3&quot;);</span><br><span class=\"line\">var web3 = new Web3();</span><br><span class=\"line\">web3.setProvider(new Web3.providers.HttpProvider(&quot;http://localhost:8545&quot;));</span><br><span class=\"line\">if (web3.isConnected()) &#123;</span><br><span class=\"line\">  console.log(&quot;connection success!&quot;);</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">  console.log(&quot;fail to connection!&quot;);</span><br><span class=\"line\">  return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">var contract = web3.eth.contract(abi).at(address);</span><br><span class=\"line\">var account_one = web3.eth.accounts[0];</span><br><span class=\"line\">var my_event = contract.Set();</span><br><span class=\"line\">var getStr = function() &#123;</span><br><span class=\"line\">  var str = contract.greeting(&#123;from: account_one&#125;)</span><br><span class=\"line\">  console.log(&quot;the str is: &quot; + str);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">getStr()</span><br><span class=\"line\">my_event.watch(function(err, result) &#123;</span><br><span class=\"line\">    if (!err) &#123;</span><br><span class=\"line\">        console.log(result);</span><br><span class=\"line\">        getStr()</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        console.log(err);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    my_event.stopWatching();</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">contract.set(&quot;I am Changed!&quot;,&#123;from: account_one&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>查看输出</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// connection success!</span><br><span class=\"line\">// the str is:</span><br><span class=\"line\">// &#123; address: &apos;0x8321a32f8b7bbc00a65c9e21df64948cf40bbeba&apos;,</span><br><span class=\"line\">//   blockNumber: 785,</span><br><span class=\"line\">//   transactionHash: &apos;0xa90e35845cd844907f251660bce78f5cde2c968876f3a6321fbf38589d7fb476&apos;,</span><br><span class=\"line\">//   transactionIndex: 0,</span><br><span class=\"line\">//   blockHash: &apos;0x742eecc3ae508b33ca5dde2ae2a32b8c0c87d321c6ab13a0cc8ad3909e579275&apos;,</span><br><span class=\"line\">//   logIndex: 0,</span><br><span class=\"line\">//   removed: false,</span><br><span class=\"line\">//   event: &apos;Set&apos;,</span><br><span class=\"line\">//   args:</span><br><span class=\"line\">//    &#123; _from: &apos;0xc6e1feafcc44ebb1a7b0ecc06770566845eac7ac&apos;,</span><br><span class=\"line\">//      value: &apos;I am Changed!&apos; &#125; &#125;</span><br><span class=\"line\">// the str is: I am Changed!</span><br></pre></td></tr></table></figure>\n\n<p>可以看到返回的结果中包括区块哈希等信息，还有参数</p>\n<h4 id=\"Event-1\"><a href=\"#Event-1\" class=\"headerlink\" title=\"Event\"></a>Event</h4><p>在合约中定义事件，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">event SendMsg(string sender, string receiver, string detail, address indexed reth);</span><br></pre></td></tr></table></figure>\n\n<p>注意到indexed关键字。跟event订阅有一定的关系。</p>\n<p>大致理解是，event事件犹如日志，在订阅的时候，需要确定要订阅的关键字，这个关键字可以是事件本身，也可以是某个可索引的值，如address值。如订阅某确定address值时，会取得所有含有可索引的这个地址相关的event事件。订阅事件本身的话，就只能取得这个事件的值。</p>\n<p>顺便粘贴一段在web3j中event的使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void test() &#123;</span><br><span class=\"line\">     Web3j web3j = Web3j.build(new HttpService(&quot;http://localhost:8545&quot;));</span><br><span class=\"line\">     Event event = new Event(&quot;SendMsg&quot;,</span><br><span class=\"line\">             Arrays.&lt;TypeReference&lt;?&gt;&gt;asList(</span><br><span class=\"line\">                     new TypeReference&lt;Utf8String&gt;()&#123;&#125;,</span><br><span class=\"line\">                     new TypeReference&lt;Utf8String&gt;()&#123;&#125;,</span><br><span class=\"line\">                     new TypeReference&lt;Utf8String&gt;()&#123;&#125;,</span><br><span class=\"line\">                     new TypeReference&lt;Address&gt;(true)&#123;&#125;</span><br><span class=\"line\">             ));</span><br><span class=\"line\">     EthFilter filter = new EthFilter(DefaultBlockParameterName.EARLIEST,</span><br><span class=\"line\">             DefaultBlockParameterName.LATEST, &quot;0x495feebd99f645a43aa63edb32d46e057e44e286&quot;);</span><br><span class=\"line\">     //订阅的是event事件本身</span><br><span class=\"line\">     filter.addSingleTopic(EventEncoder.encode(event));</span><br><span class=\"line\"></span><br><span class=\"line\">     web3j.ethLogObservable(filter).subscribe(log -&gt; &#123;</span><br><span class=\"line\">         System.out.println(log);</span><br><span class=\"line\">         //data参数值，需要进行解码。</span><br><span class=\"line\">         List&lt;Type&gt; results = FunctionReturnDecoder.decode(log.getData(), event.getNonIndexedParameters());</span><br><span class=\"line\">         for (Type type : results) &#123;</span><br><span class=\"line\">             System.out.println(type);</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">     &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> //输出，例如，当前事件有 SendMsg(&quot;susan&quot;, &quot;tom&quot;, &quot;hi&quot;, &quot;0x11a857e4d069d963c0676c53b68e9d571a3e2b26&quot;)</span><br><span class=\"line\"> //log输出为Log&#123;removed=false, logIndex=&apos;0x0&apos;, transactionIndex=&apos;0x0&apos;, transactionHash=&apos;0x31aa0a485f5595fb5b5c959e94dfb511c3512e94589dfd51205c5bd07c6ba4e2&apos;, blockHash=&apos;0xc68dcd25600857642199f9ebb354b62532f8468191a85ca923c0e03e958c6398&apos;, blockNumber=&apos;0x157c&apos;, address=&apos;0x495feebd99f645a43aa63edb32d46e057e44e286&apos;, data=&apos;...&apos;, type=&apos;null&apos;, topics=[0x444f124b164dc796e3a81a1d90ea60c96a815eac0a67ad1d3d550d30afda9e1f, 0x00000000000000000000000011a857e4d069d963c0676c53b68e9d571a3e2b26]</span><br><span class=\"line\"> //topic为两个，第一个为SendMsg事件本身，第二个为SendMsg事件定义中含有可索引值address,</span><br><span class=\"line\"> //data解码非索引项结果为susan、tom、hi</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Remix\"><a href=\"#Remix\" class=\"headerlink\" title=\"Remix\"></a>Remix</h4><p>remix是基于浏览器开发的ide</p>\n<ul>\n<li><p>加载本地文件夹</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g remixd</span><br><span class=\"line\">remixd -s &lt;absolute-path-to-the-shared-folder&gt;</span><br><span class=\"line\">//会开启共享文件夹服务，通过ws</span><br></pre></td></tr></table></figure>\n\n<p>然后在remix上点击类似于超链接的那个按钮</p>\n</li>\n</ul>\n<h4 id=\"bytes32、string\"><a href=\"#bytes32、string\" class=\"headerlink\" title=\"bytes32、string\"></a>bytes32、string</h4><p>文档上是这么说的，bytes1 ~bytes32是长度特定的类型，故花费比string和bytes小。</p>\n<p>然后记一下一般存pubkey(pubkey除掉0x长度为64，可以用两个bytes32来存)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bytes32 pubkey_half_pre;</span><br><span class=\"line\">bytes32 pubkey_half_after;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"钱💰💰💰💰\"><a href=\"#钱💰💰💰💰\" class=\"headerlink\" title=\"钱💰💰💰💰\"></a>钱💰💰💰💰</h4><p>合约部署之后生成合约地址，地址同样可以作为普通地址使用，即转账系列。可以给合约地址转账，见<a href=\"https://solidity-cn.readthedocs.io/zh/develop/contracts.html#fallback\" target=\"_blank\" rel=\"noopener\">文档</a></p>\n<p>需定义一个未命名、没有参数也没有返回值函数,且为payable。如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function () payable &#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在ico中，转账给到合约地址，合约返回一定数量token给到转账者，就可以利用这个函数进行。</p>\n<p>或者呢，合约的某方法如果使用了payable修饰的话，也代表这个方法可以接受ether, 即msg.value，钱会存到合约地址中，通过this.balance即可获取余额。</p>\n<p>在合约中，向某地址发送ether, 使用address.transfer、address.send即可。</p>\n<h4 id=\"合约交互\"><a href=\"#合约交互\" class=\"headerlink\" title=\"合约交互\"></a>合约交互</h4><p>现有一合约</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.18;</span><br><span class=\"line\"></span><br><span class=\"line\">contract UserTest &#123;</span><br><span class=\"line\">    struct User &#123;</span><br><span class=\"line\">        string name;</span><br><span class=\"line\">        address addr;</span><br><span class=\"line\">        string pubkey;</span><br><span class=\"line\">        bool isValue;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    mapping(string =&gt; User)  users;</span><br><span class=\"line\">    event UserChange(string uname, address addr, uint value);</span><br><span class=\"line\"></span><br><span class=\"line\">    function addUser(string uname, address addr, string pubkey)  public &#123;</span><br><span class=\"line\">         require(</span><br><span class=\"line\">           !users[uname].isValue,</span><br><span class=\"line\">           &quot;name already exist&quot;</span><br><span class=\"line\">       );</span><br><span class=\"line\">       users[uname] = User(&#123;</span><br><span class=\"line\">           name: uname,</span><br><span class=\"line\">           addr: addr,</span><br><span class=\"line\">           pubkey: pubkey,</span><br><span class=\"line\">           isValue: true</span><br><span class=\"line\">       &#125;);</span><br><span class=\"line\">       UserChange(uname, addr, msg.value);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    function userExist(string uname) constant external returns (bool) &#123;</span><br><span class=\"line\">        return users[uname].isValue;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后在另一合约中调用userExist方法,首先部署上述合约，合约地址如0x123456789</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.18;</span><br><span class=\"line\"></span><br><span class=\"line\">contract UserTest &#123;</span><br><span class=\"line\">\t//要调用的方法声明需要跟原来一样</span><br><span class=\"line\">    function userExist(string uname) constant external returns (bool);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">contract ExternalTest &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    address userInstance = 0x123456789;</span><br><span class=\"line\">    UserTest user = UserTest(userInstance); //强制类型转换</span><br><span class=\"line\"></span><br><span class=\"line\">    function userCheck(string uname) public returns (bool)&#123;</span><br><span class=\"line\">        return user.userExist(uname);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"mapping\"><a href=\"#mapping\" class=\"headerlink\" title=\"mapping\"></a>mapping</h4><p>mapping是不能遍历的，需要借助别的数据结构。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">library IterableMapping</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  struct itmap</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    mapping(uint =&gt; IndexValue) data;</span><br><span class=\"line\">    KeyFlag[] keys;</span><br><span class=\"line\">    uint size;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  struct IndexValue &#123; uint keyIndex; uint value; &#125;</span><br><span class=\"line\">  struct KeyFlag &#123; uint key; bool deleted; &#125;</span><br><span class=\"line\">  function insert(itmap storage self, uint key, uint value) returns (bool replaced)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    uint keyIndex = self.data[key].keyIndex;</span><br><span class=\"line\">    self.data[key].value = value;</span><br><span class=\"line\">    if (keyIndex &gt; 0)</span><br><span class=\"line\">      return true;</span><br><span class=\"line\">    else</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      keyIndex = self.keys.length++;</span><br><span class=\"line\">      self.data[key].keyIndex = keyIndex + 1;</span><br><span class=\"line\">      self.keys[keyIndex].key = key;</span><br><span class=\"line\">      self.size++;</span><br><span class=\"line\">      return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function remove(itmap storage self, uint key) returns (bool success)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    uint keyIndex = self.data[key].keyIndex;</span><br><span class=\"line\">    if (keyIndex == 0)</span><br><span class=\"line\">      return false;</span><br><span class=\"line\">    delete self.data[key];</span><br><span class=\"line\">    self.keys[keyIndex - 1].deleted = true;</span><br><span class=\"line\">    self.size --;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function contains(itmap storage self, uint key) returns (bool)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    return self.data[key].keyIndex &gt; 0;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function iterate_start(itmap storage self) returns (uint keyIndex)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    return iterate_next(self, uint(-1));</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function iterate_valid(itmap storage self, uint keyIndex) returns (bool)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    return keyIndex &lt; self.keys.length;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function iterate_next(itmap storage self, uint keyIndex) returns (uint r_keyIndex)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    keyIndex++;</span><br><span class=\"line\">    while (keyIndex &lt; self.keys.length &amp;&amp; self.keys[keyIndex].deleted)</span><br><span class=\"line\">      keyIndex++;</span><br><span class=\"line\">    return keyIndex;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function iterate_get(itmap storage self, uint keyIndex) returns (uint key, uint value)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    key = self.keys[keyIndex].key;</span><br><span class=\"line\">    value = self.data[key].value;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// How to use it:</span><br><span class=\"line\">contract User</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  // Just a struct holding our data.</span><br><span class=\"line\">  IterableMapping.itmap data;</span><br><span class=\"line\">  // Insert something</span><br><span class=\"line\">  function insert(uint k, uint v) returns (uint size)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    // Actually calls itmap_impl.insert, auto-supplying the first parameter for us.</span><br><span class=\"line\">    IterableMapping.insert(data, k, v);</span><br><span class=\"line\">    // We can still access members of the struct - but we should take care not to mess with them.</span><br><span class=\"line\">    return data.size;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  // Computes the sum of all stored data.</span><br><span class=\"line\">  function sum() returns (uint s)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    for (var i = IterableMapping.iterate_start(data); IterableMapping.iterate_valid(data, i); i = IterableMapping.iterate_next(data, i))</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        var (key, value) = IterableMapping.iterate_get(data, i);</span><br><span class=\"line\">        s += value;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"以太坊虚拟机-EVM\"><a href=\"#以太坊虚拟机-EVM\" class=\"headerlink\" title=\"以太坊虚拟机(EVM)\"></a>以太坊虚拟机(EVM)</h4><p>以太坊虚拟机(EVM)是智能合约的运行环境。它是一个完全独立的沙盒，合约代码在EVM内部运行，对外是完全隔离的，甚至不同合约之间也只有有限的访问权限</p>\n<h4 id=\"账户\"><a href=\"#账户\" class=\"headerlink\" title=\"账户\"></a>账户</h4><ul>\n<li>以太坊中有两种不同类型但是共享同一地址空间的账户：<code>外部账户</code>由一对公私钥控制，<code>合约账户</code>由账户内部的合约代码控制。</li>\n<li>外部账户的地址是由公钥（经过hash运算）决定的，而合约账户的地址在此合约被创建的时候决定的（由合约创建者的地址和发送到此合约地址的交易数决定，这就是所谓的“nonce”）</li>\n<li>不管是哪种类型的账户，EVM的处理方式是一样的</li>\n<li>每个账户都有一个持久的key-value类型的存储，把256字节的key映射到256字节的value</li>\n<li>此外，每个账户都有以“Wei”为单位，在交易过程中会被修改的资产(balance)信息</li>\n</ul>\n<h4 id=\"交易\"><a href=\"#交易\" class=\"headerlink\" title=\"交易\"></a>交易</h4><ul>\n<li>交易是一个从账户发往另一个账户（可以是同一个账户或者是special zero-account）的消息。它包含二进制数据（交易相关的数据）和 Ether。</li>\n<li>如果目标账户包含代码，代码会被执行，交易相关的数据将作为参数</li>\n<li>如果目标账户是地址为0的账户<code>zero-account</code>, 交易会创建一个新的合约。如上文提到的，合约地址不是一个地址为0的地址，而是一个由交易发送者和交易数来决定的地址。这样的一笔（到zero-account）交易的相关参数会被转化为EVM字节码<br>然后被执行，输出结果就是被永久存储的合约代码。这意味着为了创建一个合约，并不需要发送真实的合约代码，代码可以被自动创建</li>\n</ul>\n<h4 id=\"gas\"><a href=\"#gas\" class=\"headerlink\" title=\"gas\"></a>gas</h4><ul>\n<li>创建之后，每笔交易都需要一定数量的gas，用于限制交易所消耗的工作量，即交易是需要付出代价的（避免DDoS攻击）。EVM执行交易的过程中，gas会按一个特殊规则逐渐减少</li>\n<li>费用的多少是由交易发起者设置，至少需要从发起账户支付<code>gas_price * gas</code>用费。如果交易执行完毕费用还有剩余的，将退回到发起账户。</li>\n<li>如果交易完成之前费用耗尽，将会抛出一个<code>out-of-gas</code>的异常，所有的修改都会被回滚</li>\n</ul>\n<p>更多关于gas的理解和讨论可以<a href=\"http://bitshuo.com/topic/5857774a2a482b0d339aab99/\" target=\"_blank\" rel=\"noopener\">戳这里</a></p>\n<h4 id=\"storage-memory-stack\"><a href=\"#storage-memory-stack\" class=\"headerlink\" title=\"storage,memory,stack\"></a>storage,memory,stack</h4><ul>\n<li>每个账户都有一个持久的内存空间，称之为<code>storage</code>,<code>storage</code>以key-value形式存储，256字节的key映射到256字节value，合约内部不可能枚举<code>storage</code>(内部元素)，读取或者修改<code>storage</code>操作消耗都很大(原文是 It is not possible to enumerate storage from within a contract and it is comparatively costly to read and even more so, to modify storage. )。 合约只能读取和修改自己的<code>storage</code>里的数据。</li>\n<li>第二种内存空间称之为<code>memory</code>,里面存储着每个消息调用时合约创建的实例。<code>memory</code>是线型的，可以以字节级别来处理，但是限制为256字节宽度，写入可以是8或256字节宽度。当读取或写入一个预先未触发的指令的时候会消耗<code>memory</code>的空间，消耗空间的同时，必须支付gas。<code>memory</code>消耗的越多，需要的gas越多（按平方级增长）</li>\n<li>EVM不是一个注册的机器而是一个堆栈机器，所以所有的计算指令都在<code>stack</code>空间里面执行。<code>stack</code>最多只能容纳1024个长度不超过256字节的指令元素。只能用下述方法，从顶部访问<code>stack</code>：可以拷贝最顶部的16个元素中的一个到<code>stack</code>的最顶部，或者将最顶部的那个元素与其下面的16个元素之一互换。所有其它操作从<code>stack</code>最顶部取出两个（或一个，或更多，取决于操作）元素，然后把结果push到<code>stack</code>顶端。当然将<code>stack</code>中的元素移到<code>memory</code>或者<code>storage</code>也是可以的，但是不能直接访问<code>stack</code>中间的元素（必须从头部开始访问）</li>\n</ul>\n<h4 id=\"指令集合\"><a href=\"#指令集合\" class=\"headerlink\" title=\"指令集合\"></a>指令集合</h4><ul>\n<li>EVM的指令集合控制的很小，这样可以避免错误的执行引发问题。所有的指令都是操作最基本的数据类型，256字节。而且都是最常见的逻辑，算法，字节和比较运算。有条件或无条件的跳转都可以。此外，合约可以访问当前区块的属性，比如区块编号和时间戳。</li>\n</ul>\n<h4 id=\"消息调用\"><a href=\"#消息调用\" class=\"headerlink\" title=\"消息调用\"></a>消息调用</h4><ul>\n<li>合约之间可以通过消息调用的方式进行相互调用或者另一个给另一个无合约账户（外部账户）转币。消息调用很像交易，两者都有源账户，目标账户，数据（data payload），<code>Ether</code>,费用和返回数据。实际上每笔交易都由一个可创建更多调用的顶级调用组成。</li>\n<li>合约可以决定内部消息调用的时候发送多少手续费，保留多少。如果在内部消息调用的时候抛出<code>out-of-gas</code>异常（或者其它异常），这个会被一个错误值标记，放到<code>stack</code>顶部。如此，只有和消息一起发出的手续费才会被消耗。在<code>Solidity</code>中这种情形默认会引发一个异常，以便异常“冒泡”到<code>stack</code>最顶端</li>\n<li>如上所述，被调用的合约会接收到一个刚创建的<code>memory</code>实例，并且可以访问调用参数，调用参数被存储在一个被为<code>calldata</code>的隔离的区域。执行完毕后，被调用的合约将返回数据存储在调用合约预先创建的内存中。</li>\n<li>调用被限制在1024深度，这意味着复杂的操作应尽量使用循环代替递归调用。</li>\n</ul>\n<h4 id=\"代理调用-调用代码和库\"><a href=\"#代理调用-调用代码和库\" class=\"headerlink\" title=\"代理调用/调用代码和库\"></a>代理调用/调用代码和库</h4><ul>\n<li>存在一种称为<code>delegatecall</code>的特殊的多样性的消息调用，which is identical to a message call apart from the fact that the code at the target address is executed in the context of the calling contract and msg.sender and msg.value do not change their values.</li>\n<li>这意味着合约可以在运行的时候动态的从另一个地址加载代码。存储、当前地址和资产仍然和调用的合约相关联，只有代码来自被调用的地址。</li>\n<li>这样可以实现Solidity库的特性:反复使用的库代码可以被应用到合约的<code>storage</code>来实现复杂的数据结构。</li>\n</ul>\n<h4 id=\"日志\"><a href=\"#日志\" class=\"headerlink\" title=\"日志\"></a>日志</h4><p>It is possible to store data in a specially indexed data structure that maps all the way up to the block level. This feature called logs is used by Solidity in order to implement events. Contracts cannot access log data after it has been created, but they can be efficiently accessed from outside the blockchain. Since some part of the log data is stored in bloom filters, it is possible to search for this data in an efficient and cryptographically secure way, so network peers that do not download the whole blockchain (“light clients”) can still find these logs.</p>\n<h4 id=\"Create\"><a href=\"#Create\" class=\"headerlink\" title=\"Create\"></a>Create</h4><ul>\n<li>合约甚至可以使用特殊的<code>opcode</code>创建其它的合约,<code>create</code>消息调用和普通的消息调用区别在于，<code>create</code>消息调用的data字段会被执行，执行结果以代码的形式存储，调用者可在stack上接接到新合约账户的地址</li>\n</ul>\n<ul>\n<li>示例一</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.18;</span><br><span class=\"line\"></span><br><span class=\"line\">contract ClassifyStorage &#123;</span><br><span class=\"line\">    mapping(address =&gt; string) details;</span><br><span class=\"line\">    event AddDetailEvent(address classify, string detail);</span><br><span class=\"line\"></span><br><span class=\"line\">    function addDetail(address classify, string detail) public &#123;</span><br><span class=\"line\">        details[classify] = strConcat(details[classify], detail);</span><br><span class=\"line\">        AddDetailEvent(classify, detail);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    function getSpecificDetails(address classify) constant public returns (string) &#123;</span><br><span class=\"line\">        return details[classify];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    function strConcat(string _a, string _b) internal returns (string)&#123;</span><br><span class=\"line\">        bytes memory _ba = bytes(_a);</span><br><span class=\"line\">        if(_ba.length == 0) &#123;</span><br><span class=\"line\">            return _b;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        bytes memory _bb = bytes(_b);</span><br><span class=\"line\">        string memory ret = new string(_ba.length + _bb.length + 1);</span><br><span class=\"line\">        bytes memory bret = bytes(ret);</span><br><span class=\"line\">        uint k = 0;</span><br><span class=\"line\">        for (uint i = 0; i &lt; _ba.length; i++)bret[k++] = _ba[i];</span><br><span class=\"line\">        bret[k++] = &quot;,&quot;;</span><br><span class=\"line\">        for (i = 0; i &lt; _bb.length; i++) bret[k++] = _bb[i];</span><br><span class=\"line\">        return string(ret);</span><br><span class=\"line\">   &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"以太坊智能合约\"><a href=\"#以太坊智能合约\" class=\"headerlink\" title=\"以太坊智能合约\"></a>以太坊智能合约</h2><p>从智能合约的代码到使用智能合约，大概包含以下步骤</p>\n<ul>\n<li>编写智能合约的代码(一般是用Solidity)</li>\n<li>编译智能合约的代码变成可在EVM上执行的bytecode(binary code)，同时可以通过编译取得智能合约的ABI</li>\n<li>部署智能合约，实际上是吧bytecode存储在链上(通过一个transaction)，并取得一个专属于这个合约的地址</li>\n<li>要调用合约，需要把信息发送到这个合约的地址，一样也是通过transaction，以太坊节点会根据输入的信息，选择要执行合约中的哪一个function和要输入的参数</li>\n</ul>\n<p>以下，将详细介绍以上步骤。</p>\n<h4 id=\"代码编写及编译部署\"><a href=\"#代码编写及编译部署\" class=\"headerlink\" title=\"代码编写及编译部署\"></a>代码编写及编译部署</h4><h4 id=\"智能合约ABI\"><a href=\"#智能合约ABI\" class=\"headerlink\" title=\"智能合约ABI\"></a>智能合约ABI</h4><p>如果说api，想必都知道是什么，对应的，ABI，application binary interface，顾名思义，同样是接口，但传递的是binary格式的信息。</p>\n<p>ABI理解如下</p>\n<h5 id=\"Function\"><a href=\"#Function\" class=\"headerlink\" title=\"Function\"></a>Function</h5><ul>\n<li><code>name</code>：a string, 方法名</li>\n<li><code>type</code>:  a string，”function”, “constructor”, or “fallback”，方法类型</li>\n<li><code>inputs</code>:  an array，方法参数，每个参数的格式为<ul>\n<li><code>name</code>：a string，参数名</li>\n<li><code>type</code>：a string，参数的 data type(e.g. uint256)</li>\n<li><code>components</code>：an array，如果输入的参数是 tuple(struct) type 才会有这个参数。描述 struct 中包含的参数类型</li>\n</ul>\n</li>\n<li><code>outputs</code>：an array， 方法返回值，和 <code>inputs</code> 使用相同表示方式。如果沒有返回值可忽略，值为 <code>[]</code></li>\n<li><code>payable</code>：<code>true</code>，function 是否可收 Ether，预设为 <code>false</code></li>\n<li><code>constant</code>：<code>true</code>，function 是否会改写区块链状态，反之为 <code>false</code></li>\n<li><code>stateMutability</code>：a string，其值可能为以下其中之一：”pure”（不会读写区块链状态）、”view”（只读不写区块链状态）、”payable” and “nonpayable”（会改区块链状态，且如可收 Ether 为 “payable”，反之为 “nonpayable”）</li>\n</ul>\n<p>仔细看会发现 <code>payable</code> 和 <code>constant</code> 这两个参数所描述的內容，似乎已包含在 <code>stateMutability</code> 中。</p>\n<h5 id=\"Event\"><a href=\"#Event\" class=\"headerlink\" title=\"Event\"></a>Event</h5><ul>\n<li><code>name</code>: a string，event 的名称</li>\n<li><code>type</code>: a string，always “event”</li>\n<li><code>inputs</code>: an array，输入参数，包含：<ul>\n<li><code>name</code>: a string，参数名称</li>\n<li><code>type</code>: a string，参数的 data type(e.g. uint256)</li>\n<li><code>components</code>: an array，如果输入参数是 tuple(struct) type 才会有这个参数。描述 struct 中包含的信息类型</li>\n<li><code>indexed</code>: <code>true</code>，如果这个参数被定义为 indexed ，反之为 <code>false</code></li>\n</ul>\n</li>\n<li><code>anonymous</code>: <code>true</code>，如果 event 被定义为 anonymous</li>\n</ul>\n<p>更新智能合约状态需要发送 transaction，transaction 需要等待验证，所以更新合约状态是非同步的，无法马上取得返回值。使用 Event 可以在状态更新成功后，将相关信息记录到 Log，并让监听这个 Event 的 DApp 或任何应用这个接口的程序收到通知。每笔 transaction 都有对应的 Log。</p>\n<p>所以简单来说，Event 可用來：1. 取得 function 更新合约状态的返回值 2. 也可作为合约另外的存储空间。</p>\n<p>Event 的参数分为：有 <code>indexed</code>，和其他没有 <code>indexed</code> 的。有 <code>indexed</code> 的参数可以使用 filter，例如同一个 Event，我可以选择只监听从特定 address 发出来的交易。每笔 Log 的信息同样分为两个部分：Topics（长度最多为 4 的 array） 和 Data。有 <code>anonymous</code> 的参数会存储存在 Log 的 Topics，其他的存在 Data。</p>\n<h5 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.20;</span><br><span class=\"line\">contract SimpleStorage &#123;</span><br><span class=\"line\">    uint public data;</span><br><span class=\"line\">    event Set(address indexed _from, uint value);</span><br><span class=\"line\">    function set(uint x) public &#123;</span><br><span class=\"line\">        data = x;</span><br><span class=\"line\">        Set(msg.sender, x);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>生成的ABI接口为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&#123;\t\t//自动生成的方法名为data的只读方法，返回data值,&quot;stateMutabTility&quot;: &quot;view&quot;代表只读</span><br><span class=\"line\">        &quot;constant&quot;: true,  </span><br><span class=\"line\">        &quot;inputs&quot;: [],</span><br><span class=\"line\">        &quot;name&quot;: &quot;data&quot;,</span><br><span class=\"line\">        &quot;outputs&quot;: [&#123;&quot;name&quot;: &quot;&quot;,&quot;type&quot;: &quot;uint256&quot;&#125;],</span><br><span class=\"line\">        &quot;payable&quot;: false,</span><br><span class=\"line\">        &quot;stateMutabTility&quot;: &quot;view&quot;,</span><br><span class=\"line\">        &quot;type&quot;: &quot;function&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;  //set方法， &quot;stateMutability&quot;: &quot;nonpayable&quot;,可写方法，但不可收Ether,方法参数为uint256类型</span><br><span class=\"line\">        &quot;constant&quot;: false,</span><br><span class=\"line\">        &quot;inputs&quot;: [&#123;&quot;name&quot;: &quot;x&quot;,&quot;type&quot;: &quot;uint256&quot;&#125;],</span><br><span class=\"line\">        &quot;name&quot;: &quot;set&quot;,</span><br><span class=\"line\">        &quot;outputs&quot;: [],</span><br><span class=\"line\">        &quot;payable&quot;: false,</span><br><span class=\"line\">        &quot;stateMutability&quot;: &quot;nonpayable&quot;,</span><br><span class=\"line\">        &quot;type&quot;: &quot;function&quot;</span><br><span class=\"line\">\t&#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;anonymous&quot;: false,</span><br><span class=\"line\">        &quot;inputs&quot;: [&#123;&quot;indexed&quot;: true,&quot;name&quot;: &quot;_from&quot;,&quot;type&quot;: &quot;address&quot;&#125;,&#123;&quot;indexed&quot;: false,&quot;name&quot;: &quot;value&quot;,&quot;type&quot;: &quot;uint256&quot;&#125;],</span><br><span class=\"line\">        &quot;name&quot;: &quot;Set&quot;,</span><br><span class=\"line\">        &quot;type&quot;: &quot;event&quot;</span><br><span class=\"line\">&#125;]</span><br></pre></td></tr></table></figure>\n\n<p>event时间可监听，在web3使用时会有示例</p>\n<h3 id=\"web3\"><a href=\"#web3\" class=\"headerlink\" title=\"web3\"></a>web3</h3><p>关于智能合约的调用，通过命令行也是可以的，但binary的拼凑有点繁琐，web3封装的接口调用起来就方便很多。</p>\n<p>直接看例子吧。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">contract hello &#123;</span><br><span class=\"line\">    function say() constant public returns (string) &#123;</span><br><span class=\"line\">        return &quot;Hello World&quot;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后部署到了服务器上，返回合约的地址为0x43d03aaeb07e518cd975c2d67b83a7ffea3a5a51</p>\n<p>abi为编译产生的abi数组，直接复制粘贴即可。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var contract = web3.eth.contract(info.abi).at(&quot;0x43d03aaeb07e518cd975c2d67b83a7ffea3a5a51&quot;);</span><br><span class=\"line\">var account_one = web3.eth.accounts[0];</span><br><span class=\"line\">var result = contract.say(&#123;from: account_one&#125;)</span><br><span class=\"line\">console.log(result); //Hello World</span><br></pre></td></tr></table></figure>\n\n<p>一个简单的调用就成功了，然后再看contract提供的接口的具体情况。</p>\n<p>智能合约方法调用方式有四种</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//根据方法类型自动决定是使用call方式进行调用还是sendTransaction方式进行调用，call和sendTransaction的区别呢，如果方法是只读的，则不需要入链，直接调用即可，方法是可写的，则需要以交易的方法进行提交入链。参数中，param则是传入给方法的参数，后面添加别的参数</span><br><span class=\"line\">myContractInstance.myMethod(param1 [, param2, ...] [, transactionObject] [, defaultBlock] [, callback]);</span><br><span class=\"line\"></span><br><span class=\"line\">//精确使用call方式进行调用</span><br><span class=\"line\">myContractInstance.myMethod.call(param1 [, param2, ...] [, transactionObject] [, defaultBlock] [, callback]);</span><br><span class=\"line\"></span><br><span class=\"line\">//精确使用发送交易形式进行调用</span><br><span class=\"line\">myContractInstance.myMethod.sendTransaction(param1 [, param2, ...] [, transactionObject] [, callback]);</span><br><span class=\"line\"></span><br><span class=\"line\">//没看明白</span><br><span class=\"line\">// Get the call data, so you can call the contract through some other means</span><br><span class=\"line\">// var myCallData = myContractInstance.myMethod.request(param1 [, param2, ...]);</span><br><span class=\"line\">var myCallData = myContractInstance.myMethod.getData(param1 [, param2, ...]);</span><br><span class=\"line\">// myCallData = &apos;0x45ff3ff6000000000004545345345345..&apos;</span><br></pre></td></tr></table></figure>\n\n<p>然后，顺便玩一下event。</p>\n<p>合约修改为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.18;</span><br><span class=\"line\">contract hello &#123;</span><br><span class=\"line\">    string public greeting;</span><br><span class=\"line\">    event Set(address indexed _from, string value);</span><br><span class=\"line\"></span><br><span class=\"line\">    function set(string g) public &#123;</span><br><span class=\"line\">        greeting = g;</span><br><span class=\"line\">        Set(msg.sender, g);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    function get() constant public returns (string) &#123;</span><br><span class=\"line\">        return greeting;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后完整的调用脚本为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var Web3 = require(&quot;web3&quot;);</span><br><span class=\"line\">var web3 = new Web3();</span><br><span class=\"line\">web3.setProvider(new Web3.providers.HttpProvider(&quot;http://localhost:8545&quot;));</span><br><span class=\"line\">if (web3.isConnected()) &#123;</span><br><span class=\"line\">  console.log(&quot;connection success!&quot;);</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">  console.log(&quot;fail to connection!&quot;);</span><br><span class=\"line\">  return</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">var contract = web3.eth.contract(abi).at(address);</span><br><span class=\"line\">var account_one = web3.eth.accounts[0];</span><br><span class=\"line\">var my_event = contract.Set();</span><br><span class=\"line\">var getStr = function() &#123;</span><br><span class=\"line\">  var str = contract.greeting(&#123;from: account_one&#125;)</span><br><span class=\"line\">  console.log(&quot;the str is: &quot; + str);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">getStr()</span><br><span class=\"line\">my_event.watch(function(err, result) &#123;</span><br><span class=\"line\">    if (!err) &#123;</span><br><span class=\"line\">        console.log(result);</span><br><span class=\"line\">        getStr()</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        console.log(err);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    my_event.stopWatching();</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">contract.set(&quot;I am Changed!&quot;,&#123;from: account_one&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>查看输出</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// connection success!</span><br><span class=\"line\">// the str is:</span><br><span class=\"line\">// &#123; address: &apos;0x8321a32f8b7bbc00a65c9e21df64948cf40bbeba&apos;,</span><br><span class=\"line\">//   blockNumber: 785,</span><br><span class=\"line\">//   transactionHash: &apos;0xa90e35845cd844907f251660bce78f5cde2c968876f3a6321fbf38589d7fb476&apos;,</span><br><span class=\"line\">//   transactionIndex: 0,</span><br><span class=\"line\">//   blockHash: &apos;0x742eecc3ae508b33ca5dde2ae2a32b8c0c87d321c6ab13a0cc8ad3909e579275&apos;,</span><br><span class=\"line\">//   logIndex: 0,</span><br><span class=\"line\">//   removed: false,</span><br><span class=\"line\">//   event: &apos;Set&apos;,</span><br><span class=\"line\">//   args:</span><br><span class=\"line\">//    &#123; _from: &apos;0xc6e1feafcc44ebb1a7b0ecc06770566845eac7ac&apos;,</span><br><span class=\"line\">//      value: &apos;I am Changed!&apos; &#125; &#125;</span><br><span class=\"line\">// the str is: I am Changed!</span><br></pre></td></tr></table></figure>\n\n<p>可以看到返回的结果中包括区块哈希等信息，还有参数</p>\n<h4 id=\"Event-1\"><a href=\"#Event-1\" class=\"headerlink\" title=\"Event\"></a>Event</h4><p>在合约中定义事件，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">event SendMsg(string sender, string receiver, string detail, address indexed reth);</span><br></pre></td></tr></table></figure>\n\n<p>注意到indexed关键字。跟event订阅有一定的关系。</p>\n<p>大致理解是，event事件犹如日志，在订阅的时候，需要确定要订阅的关键字，这个关键字可以是事件本身，也可以是某个可索引的值，如address值。如订阅某确定address值时，会取得所有含有可索引的这个地址相关的event事件。订阅事件本身的话，就只能取得这个事件的值。</p>\n<p>顺便粘贴一段在web3j中event的使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void test() &#123;</span><br><span class=\"line\">     Web3j web3j = Web3j.build(new HttpService(&quot;http://localhost:8545&quot;));</span><br><span class=\"line\">     Event event = new Event(&quot;SendMsg&quot;,</span><br><span class=\"line\">             Arrays.&lt;TypeReference&lt;?&gt;&gt;asList(</span><br><span class=\"line\">                     new TypeReference&lt;Utf8String&gt;()&#123;&#125;,</span><br><span class=\"line\">                     new TypeReference&lt;Utf8String&gt;()&#123;&#125;,</span><br><span class=\"line\">                     new TypeReference&lt;Utf8String&gt;()&#123;&#125;,</span><br><span class=\"line\">                     new TypeReference&lt;Address&gt;(true)&#123;&#125;</span><br><span class=\"line\">             ));</span><br><span class=\"line\">     EthFilter filter = new EthFilter(DefaultBlockParameterName.EARLIEST,</span><br><span class=\"line\">             DefaultBlockParameterName.LATEST, &quot;0x495feebd99f645a43aa63edb32d46e057e44e286&quot;);</span><br><span class=\"line\">     //订阅的是event事件本身</span><br><span class=\"line\">     filter.addSingleTopic(EventEncoder.encode(event));</span><br><span class=\"line\"></span><br><span class=\"line\">     web3j.ethLogObservable(filter).subscribe(log -&gt; &#123;</span><br><span class=\"line\">         System.out.println(log);</span><br><span class=\"line\">         //data参数值，需要进行解码。</span><br><span class=\"line\">         List&lt;Type&gt; results = FunctionReturnDecoder.decode(log.getData(), event.getNonIndexedParameters());</span><br><span class=\"line\">         for (Type type : results) &#123;</span><br><span class=\"line\">             System.out.println(type);</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">     &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> //输出，例如，当前事件有 SendMsg(&quot;susan&quot;, &quot;tom&quot;, &quot;hi&quot;, &quot;0x11a857e4d069d963c0676c53b68e9d571a3e2b26&quot;)</span><br><span class=\"line\"> //log输出为Log&#123;removed=false, logIndex=&apos;0x0&apos;, transactionIndex=&apos;0x0&apos;, transactionHash=&apos;0x31aa0a485f5595fb5b5c959e94dfb511c3512e94589dfd51205c5bd07c6ba4e2&apos;, blockHash=&apos;0xc68dcd25600857642199f9ebb354b62532f8468191a85ca923c0e03e958c6398&apos;, blockNumber=&apos;0x157c&apos;, address=&apos;0x495feebd99f645a43aa63edb32d46e057e44e286&apos;, data=&apos;...&apos;, type=&apos;null&apos;, topics=[0x444f124b164dc796e3a81a1d90ea60c96a815eac0a67ad1d3d550d30afda9e1f, 0x00000000000000000000000011a857e4d069d963c0676c53b68e9d571a3e2b26]</span><br><span class=\"line\"> //topic为两个，第一个为SendMsg事件本身，第二个为SendMsg事件定义中含有可索引值address,</span><br><span class=\"line\"> //data解码非索引项结果为susan、tom、hi</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Remix\"><a href=\"#Remix\" class=\"headerlink\" title=\"Remix\"></a>Remix</h4><p>remix是基于浏览器开发的ide</p>\n<ul>\n<li><p>加载本地文件夹</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g remixd</span><br><span class=\"line\">remixd -s &lt;absolute-path-to-the-shared-folder&gt;</span><br><span class=\"line\">//会开启共享文件夹服务，通过ws</span><br></pre></td></tr></table></figure>\n\n<p>然后在remix上点击类似于超链接的那个按钮</p>\n</li>\n</ul>\n<h4 id=\"bytes32、string\"><a href=\"#bytes32、string\" class=\"headerlink\" title=\"bytes32、string\"></a>bytes32、string</h4><p>文档上是这么说的，bytes1 ~bytes32是长度特定的类型，故花费比string和bytes小。</p>\n<p>然后记一下一般存pubkey(pubkey除掉0x长度为64，可以用两个bytes32来存)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bytes32 pubkey_half_pre;</span><br><span class=\"line\">bytes32 pubkey_half_after;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"钱💰💰💰💰\"><a href=\"#钱💰💰💰💰\" class=\"headerlink\" title=\"钱💰💰💰💰\"></a>钱💰💰💰💰</h4><p>合约部署之后生成合约地址，地址同样可以作为普通地址使用，即转账系列。可以给合约地址转账，见<a href=\"https://solidity-cn.readthedocs.io/zh/develop/contracts.html#fallback\" target=\"_blank\" rel=\"noopener\">文档</a></p>\n<p>需定义一个未命名、没有参数也没有返回值函数,且为payable。如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function () payable &#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在ico中，转账给到合约地址，合约返回一定数量token给到转账者，就可以利用这个函数进行。</p>\n<p>或者呢，合约的某方法如果使用了payable修饰的话，也代表这个方法可以接受ether, 即msg.value，钱会存到合约地址中，通过this.balance即可获取余额。</p>\n<p>在合约中，向某地址发送ether, 使用address.transfer、address.send即可。</p>\n<h4 id=\"合约交互\"><a href=\"#合约交互\" class=\"headerlink\" title=\"合约交互\"></a>合约交互</h4><p>现有一合约</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.18;</span><br><span class=\"line\"></span><br><span class=\"line\">contract UserTest &#123;</span><br><span class=\"line\">    struct User &#123;</span><br><span class=\"line\">        string name;</span><br><span class=\"line\">        address addr;</span><br><span class=\"line\">        string pubkey;</span><br><span class=\"line\">        bool isValue;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    mapping(string =&gt; User)  users;</span><br><span class=\"line\">    event UserChange(string uname, address addr, uint value);</span><br><span class=\"line\"></span><br><span class=\"line\">    function addUser(string uname, address addr, string pubkey)  public &#123;</span><br><span class=\"line\">         require(</span><br><span class=\"line\">           !users[uname].isValue,</span><br><span class=\"line\">           &quot;name already exist&quot;</span><br><span class=\"line\">       );</span><br><span class=\"line\">       users[uname] = User(&#123;</span><br><span class=\"line\">           name: uname,</span><br><span class=\"line\">           addr: addr,</span><br><span class=\"line\">           pubkey: pubkey,</span><br><span class=\"line\">           isValue: true</span><br><span class=\"line\">       &#125;);</span><br><span class=\"line\">       UserChange(uname, addr, msg.value);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    function userExist(string uname) constant external returns (bool) &#123;</span><br><span class=\"line\">        return users[uname].isValue;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后在另一合约中调用userExist方法,首先部署上述合约，合约地址如0x123456789</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.18;</span><br><span class=\"line\"></span><br><span class=\"line\">contract UserTest &#123;</span><br><span class=\"line\">\t//要调用的方法声明需要跟原来一样</span><br><span class=\"line\">    function userExist(string uname) constant external returns (bool);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">contract ExternalTest &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    address userInstance = 0x123456789;</span><br><span class=\"line\">    UserTest user = UserTest(userInstance); //强制类型转换</span><br><span class=\"line\"></span><br><span class=\"line\">    function userCheck(string uname) public returns (bool)&#123;</span><br><span class=\"line\">        return user.userExist(uname);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"mapping\"><a href=\"#mapping\" class=\"headerlink\" title=\"mapping\"></a>mapping</h4><p>mapping是不能遍历的，需要借助别的数据结构。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">library IterableMapping</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  struct itmap</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    mapping(uint =&gt; IndexValue) data;</span><br><span class=\"line\">    KeyFlag[] keys;</span><br><span class=\"line\">    uint size;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  struct IndexValue &#123; uint keyIndex; uint value; &#125;</span><br><span class=\"line\">  struct KeyFlag &#123; uint key; bool deleted; &#125;</span><br><span class=\"line\">  function insert(itmap storage self, uint key, uint value) returns (bool replaced)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    uint keyIndex = self.data[key].keyIndex;</span><br><span class=\"line\">    self.data[key].value = value;</span><br><span class=\"line\">    if (keyIndex &gt; 0)</span><br><span class=\"line\">      return true;</span><br><span class=\"line\">    else</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      keyIndex = self.keys.length++;</span><br><span class=\"line\">      self.data[key].keyIndex = keyIndex + 1;</span><br><span class=\"line\">      self.keys[keyIndex].key = key;</span><br><span class=\"line\">      self.size++;</span><br><span class=\"line\">      return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function remove(itmap storage self, uint key) returns (bool success)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    uint keyIndex = self.data[key].keyIndex;</span><br><span class=\"line\">    if (keyIndex == 0)</span><br><span class=\"line\">      return false;</span><br><span class=\"line\">    delete self.data[key];</span><br><span class=\"line\">    self.keys[keyIndex - 1].deleted = true;</span><br><span class=\"line\">    self.size --;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function contains(itmap storage self, uint key) returns (bool)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    return self.data[key].keyIndex &gt; 0;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function iterate_start(itmap storage self) returns (uint keyIndex)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    return iterate_next(self, uint(-1));</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function iterate_valid(itmap storage self, uint keyIndex) returns (bool)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    return keyIndex &lt; self.keys.length;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function iterate_next(itmap storage self, uint keyIndex) returns (uint r_keyIndex)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    keyIndex++;</span><br><span class=\"line\">    while (keyIndex &lt; self.keys.length &amp;&amp; self.keys[keyIndex].deleted)</span><br><span class=\"line\">      keyIndex++;</span><br><span class=\"line\">    return keyIndex;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  function iterate_get(itmap storage self, uint keyIndex) returns (uint key, uint value)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    key = self.keys[keyIndex].key;</span><br><span class=\"line\">    value = self.data[key].value;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// How to use it:</span><br><span class=\"line\">contract User</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  // Just a struct holding our data.</span><br><span class=\"line\">  IterableMapping.itmap data;</span><br><span class=\"line\">  // Insert something</span><br><span class=\"line\">  function insert(uint k, uint v) returns (uint size)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    // Actually calls itmap_impl.insert, auto-supplying the first parameter for us.</span><br><span class=\"line\">    IterableMapping.insert(data, k, v);</span><br><span class=\"line\">    // We can still access members of the struct - but we should take care not to mess with them.</span><br><span class=\"line\">    return data.size;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  // Computes the sum of all stored data.</span><br><span class=\"line\">  function sum() returns (uint s)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    for (var i = IterableMapping.iterate_start(data); IterableMapping.iterate_valid(data, i); i = IterableMapping.iterate_next(data, i))</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        var (key, value) = IterableMapping.iterate_get(data, i);</span><br><span class=\"line\">        s += value;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"以太坊虚拟机-EVM\"><a href=\"#以太坊虚拟机-EVM\" class=\"headerlink\" title=\"以太坊虚拟机(EVM)\"></a>以太坊虚拟机(EVM)</h4><p>以太坊虚拟机(EVM)是智能合约的运行环境。它是一个完全独立的沙盒，合约代码在EVM内部运行，对外是完全隔离的，甚至不同合约之间也只有有限的访问权限</p>\n<h4 id=\"账户\"><a href=\"#账户\" class=\"headerlink\" title=\"账户\"></a>账户</h4><ul>\n<li>以太坊中有两种不同类型但是共享同一地址空间的账户：<code>外部账户</code>由一对公私钥控制，<code>合约账户</code>由账户内部的合约代码控制。</li>\n<li>外部账户的地址是由公钥（经过hash运算）决定的，而合约账户的地址在此合约被创建的时候决定的（由合约创建者的地址和发送到此合约地址的交易数决定，这就是所谓的“nonce”）</li>\n<li>不管是哪种类型的账户，EVM的处理方式是一样的</li>\n<li>每个账户都有一个持久的key-value类型的存储，把256字节的key映射到256字节的value</li>\n<li>此外，每个账户都有以“Wei”为单位，在交易过程中会被修改的资产(balance)信息</li>\n</ul>\n<h4 id=\"交易\"><a href=\"#交易\" class=\"headerlink\" title=\"交易\"></a>交易</h4><ul>\n<li>交易是一个从账户发往另一个账户（可以是同一个账户或者是special zero-account）的消息。它包含二进制数据（交易相关的数据）和 Ether。</li>\n<li>如果目标账户包含代码，代码会被执行，交易相关的数据将作为参数</li>\n<li>如果目标账户是地址为0的账户<code>zero-account</code>, 交易会创建一个新的合约。如上文提到的，合约地址不是一个地址为0的地址，而是一个由交易发送者和交易数来决定的地址。这样的一笔（到zero-account）交易的相关参数会被转化为EVM字节码<br>然后被执行，输出结果就是被永久存储的合约代码。这意味着为了创建一个合约，并不需要发送真实的合约代码，代码可以被自动创建</li>\n</ul>\n<h4 id=\"gas\"><a href=\"#gas\" class=\"headerlink\" title=\"gas\"></a>gas</h4><ul>\n<li>创建之后，每笔交易都需要一定数量的gas，用于限制交易所消耗的工作量，即交易是需要付出代价的（避免DDoS攻击）。EVM执行交易的过程中，gas会按一个特殊规则逐渐减少</li>\n<li>费用的多少是由交易发起者设置，至少需要从发起账户支付<code>gas_price * gas</code>用费。如果交易执行完毕费用还有剩余的，将退回到发起账户。</li>\n<li>如果交易完成之前费用耗尽，将会抛出一个<code>out-of-gas</code>的异常，所有的修改都会被回滚</li>\n</ul>\n<p>更多关于gas的理解和讨论可以<a href=\"http://bitshuo.com/topic/5857774a2a482b0d339aab99/\" target=\"_blank\" rel=\"noopener\">戳这里</a></p>\n<h4 id=\"storage-memory-stack\"><a href=\"#storage-memory-stack\" class=\"headerlink\" title=\"storage,memory,stack\"></a>storage,memory,stack</h4><ul>\n<li>每个账户都有一个持久的内存空间，称之为<code>storage</code>,<code>storage</code>以key-value形式存储，256字节的key映射到256字节value，合约内部不可能枚举<code>storage</code>(内部元素)，读取或者修改<code>storage</code>操作消耗都很大(原文是 It is not possible to enumerate storage from within a contract and it is comparatively costly to read and even more so, to modify storage. )。 合约只能读取和修改自己的<code>storage</code>里的数据。</li>\n<li>第二种内存空间称之为<code>memory</code>,里面存储着每个消息调用时合约创建的实例。<code>memory</code>是线型的，可以以字节级别来处理，但是限制为256字节宽度，写入可以是8或256字节宽度。当读取或写入一个预先未触发的指令的时候会消耗<code>memory</code>的空间，消耗空间的同时，必须支付gas。<code>memory</code>消耗的越多，需要的gas越多（按平方级增长）</li>\n<li>EVM不是一个注册的机器而是一个堆栈机器，所以所有的计算指令都在<code>stack</code>空间里面执行。<code>stack</code>最多只能容纳1024个长度不超过256字节的指令元素。只能用下述方法，从顶部访问<code>stack</code>：可以拷贝最顶部的16个元素中的一个到<code>stack</code>的最顶部，或者将最顶部的那个元素与其下面的16个元素之一互换。所有其它操作从<code>stack</code>最顶部取出两个（或一个，或更多，取决于操作）元素，然后把结果push到<code>stack</code>顶端。当然将<code>stack</code>中的元素移到<code>memory</code>或者<code>storage</code>也是可以的，但是不能直接访问<code>stack</code>中间的元素（必须从头部开始访问）</li>\n</ul>\n<h4 id=\"指令集合\"><a href=\"#指令集合\" class=\"headerlink\" title=\"指令集合\"></a>指令集合</h4><ul>\n<li>EVM的指令集合控制的很小，这样可以避免错误的执行引发问题。所有的指令都是操作最基本的数据类型，256字节。而且都是最常见的逻辑，算法，字节和比较运算。有条件或无条件的跳转都可以。此外，合约可以访问当前区块的属性，比如区块编号和时间戳。</li>\n</ul>\n<h4 id=\"消息调用\"><a href=\"#消息调用\" class=\"headerlink\" title=\"消息调用\"></a>消息调用</h4><ul>\n<li>合约之间可以通过消息调用的方式进行相互调用或者另一个给另一个无合约账户（外部账户）转币。消息调用很像交易，两者都有源账户，目标账户，数据（data payload），<code>Ether</code>,费用和返回数据。实际上每笔交易都由一个可创建更多调用的顶级调用组成。</li>\n<li>合约可以决定内部消息调用的时候发送多少手续费，保留多少。如果在内部消息调用的时候抛出<code>out-of-gas</code>异常（或者其它异常），这个会被一个错误值标记，放到<code>stack</code>顶部。如此，只有和消息一起发出的手续费才会被消耗。在<code>Solidity</code>中这种情形默认会引发一个异常，以便异常“冒泡”到<code>stack</code>最顶端</li>\n<li>如上所述，被调用的合约会接收到一个刚创建的<code>memory</code>实例，并且可以访问调用参数，调用参数被存储在一个被为<code>calldata</code>的隔离的区域。执行完毕后，被调用的合约将返回数据存储在调用合约预先创建的内存中。</li>\n<li>调用被限制在1024深度，这意味着复杂的操作应尽量使用循环代替递归调用。</li>\n</ul>\n<h4 id=\"代理调用-调用代码和库\"><a href=\"#代理调用-调用代码和库\" class=\"headerlink\" title=\"代理调用/调用代码和库\"></a>代理调用/调用代码和库</h4><ul>\n<li>存在一种称为<code>delegatecall</code>的特殊的多样性的消息调用，which is identical to a message call apart from the fact that the code at the target address is executed in the context of the calling contract and msg.sender and msg.value do not change their values.</li>\n<li>这意味着合约可以在运行的时候动态的从另一个地址加载代码。存储、当前地址和资产仍然和调用的合约相关联，只有代码来自被调用的地址。</li>\n<li>这样可以实现Solidity库的特性:反复使用的库代码可以被应用到合约的<code>storage</code>来实现复杂的数据结构。</li>\n</ul>\n<h4 id=\"日志\"><a href=\"#日志\" class=\"headerlink\" title=\"日志\"></a>日志</h4><p>It is possible to store data in a specially indexed data structure that maps all the way up to the block level. This feature called logs is used by Solidity in order to implement events. Contracts cannot access log data after it has been created, but they can be efficiently accessed from outside the blockchain. Since some part of the log data is stored in bloom filters, it is possible to search for this data in an efficient and cryptographically secure way, so network peers that do not download the whole blockchain (“light clients”) can still find these logs.</p>\n<h4 id=\"Create\"><a href=\"#Create\" class=\"headerlink\" title=\"Create\"></a>Create</h4><ul>\n<li>合约甚至可以使用特殊的<code>opcode</code>创建其它的合约,<code>create</code>消息调用和普通的消息调用区别在于，<code>create</code>消息调用的data字段会被执行，执行结果以代码的形式存储，调用者可在stack上接接到新合约账户的地址</li>\n</ul>\n<ul>\n<li>示例一</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma solidity ^0.4.18;</span><br><span class=\"line\"></span><br><span class=\"line\">contract ClassifyStorage &#123;</span><br><span class=\"line\">    mapping(address =&gt; string) details;</span><br><span class=\"line\">    event AddDetailEvent(address classify, string detail);</span><br><span class=\"line\"></span><br><span class=\"line\">    function addDetail(address classify, string detail) public &#123;</span><br><span class=\"line\">        details[classify] = strConcat(details[classify], detail);</span><br><span class=\"line\">        AddDetailEvent(classify, detail);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    function getSpecificDetails(address classify) constant public returns (string) &#123;</span><br><span class=\"line\">        return details[classify];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    function strConcat(string _a, string _b) internal returns (string)&#123;</span><br><span class=\"line\">        bytes memory _ba = bytes(_a);</span><br><span class=\"line\">        if(_ba.length == 0) &#123;</span><br><span class=\"line\">            return _b;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        bytes memory _bb = bytes(_b);</span><br><span class=\"line\">        string memory ret = new string(_ba.length + _bb.length + 1);</span><br><span class=\"line\">        bytes memory bret = bytes(ret);</span><br><span class=\"line\">        uint k = 0;</span><br><span class=\"line\">        for (uint i = 0; i &lt; _ba.length; i++)bret[k++] = _ba[i];</span><br><span class=\"line\">        bret[k++] = &quot;,&quot;;</span><br><span class=\"line\">        for (i = 0; i &lt; _bb.length; i++) bret[k++] = _bb[i];</span><br><span class=\"line\">        return string(ret);</span><br><span class=\"line\">   &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"fabric","date":"2019-10-14T06:56:49.000Z","_content":"\n## Fabric基本认识\n\n\n\n### 基本架构\n\n\n\n[官方文档](http://hyperledger-fabric.readthedocs.io/en/master/arch-deep-dive.html)\n\n\n\n![宏观图](./fabric_macro.jpg)\n\n上图为fabric的基本结构图，以下解释各名词含义。\n\n- application: 提供各种语言的SDK接口\n- membership： 也就是fabric-ca，提供成员服务，用来管理身份，提供授权和认证\n- peer: 负责模拟交易和记账\n  - Endorser(背书)，peer执行交易并返回yes/no\n  - Committer，将验证过的区块追加到通道上各个账本的副本\n  - Ledger，账本\n  - chaincode，用来编写业务逻辑，交易指令用来修改资产，可以理解为fabric网络对外提供的一个交易接口（智能合约）\n  - Event是fabric提供的一个事件框架，比如链代码事件，拒绝事件，注册事件等，在编写代码的时候可以订阅这些事件来实现自己的业务逻辑。\n- o-service用来实现共识\n\n\n\n区块链运行称之为链码（chaincode）的程序，保存状态、账本数据，并执行交易。链码是中央元素，因为交易是在链码上调用的操作。交易必须被“endorsed”，而且只有被“endorsed”后的交易才能被提交。管理方法和参数可能存在一个或多个特殊链码，统称为系统链码。\n\n**交易**可能有两种类型：\n\n- 部署事务，创建新的链接代码并将程序作为参数。当部署事务成功执行时，链代码已经安装在区块链上。\n- 调用事务，在先前部署的链式代码的上下文中执行操作。一个invoke事务引用了一个chaincode和它提供的函数之一。成功时，chaincode执行指定的功能 - 可能涉及修改相应的状态并返回输出。\n\n如后面所述，部署事务是调用事务的特例，其中创建新链代码的部署事务对应于系统链代码上的调用事务。\n\n**State**，区块链的最新state被建模为版本化的键值存储（KVS），修改由运行在区块链上的链码（applications）调用KVS的put,get操作。详细的操作与版本化暂时略，看文档有点没看懂..State由peers进行维护，而不是orders和clients。KVS中的Keys可以从它们的名称中识别出属于特定的链码，因此只有特定链码的交易可以修改这个链码上的keys，但原则上，任何链码都可读别的链码的keys，即读取方便，但修改需特权。\n\n\n\n**Ledger, 账本**，账本提供了发生在系统运行时的所有成功和不成功交易的历史。账本，作为总的区块总的哈希链（成功或不成功），由订阅服务构造。哈希链强制要求在账本中所有的有序区块以及每个块包含1个完全有序的交易，这在所有交易中强制要求所有的订阅。账本保存在所有的peer中，并可选择性的存放在orders中。在orders中，我们指的账本是OrdererLedger(总账)；在peers中，我们指的是PeerLedger（分账），分账和总账的区别在于peers本地会维护一个位掩码，这个位掩码会将有效的事务从无效的当中分离出来。peers可能会对分账进行修剪，orders负责维护总账的容错性和可用性并且可以随时修剪，前提是ordering服务的属性得到维护。账本允许peers重播所有交易的历史以及重建state,所以state是一个可选的数据结构。\n\n\n\n**节点**，节点是区块链中的通信实体，节点只是一个逻辑功能，因为不同类型的多个节点可以在同一台物理服务器上运行，重要的是节点在“信任域”中如何分组并与控制它们的逻辑实体相关联。节点分为3种类型：\n\n- Client 或 submitting-client: 提交真正交易给endorsers的客户，并且广播交易申请给ordering服务\n- Peer：提交交易并维护state和账本的备份，除此之外，peers还有一个特殊的endorser角色\n- Ordering-service-node或者order：通信服务 -> 实现传递保证，例如原子性或者所有的order广播\n\n\n\n订阅服务提供了一个共享的通信通道给clients和peers, 提供的是一个包含交易信息的广播服务。client连接到通道，在通道中广播消息，消息将会送达给所有的peers。通道支持所有消息的原子性传递，即，消息通信是按序传递和可靠的。换句话说，通道给所有连接的peers输出的是相同消息，且是相同的逻辑顺序。这种原子性的通信保证在分布式系统中也被称为全序广播，原子广播，或者是共识。传递的消息是包含在区块链状态中的候选交易。\n\n\n\n#### 交易流程\n\n交易过程如下：\n\n1. Application向一个或多个peer节点发送对交易的背书请求。\n2. Peer的endorse执行背书，但并不将结果提交到本地账本，只是将结果返回给应用。\n3. 应用收集所有背书节点的结果后，将结果广播给orderers，orderers执行共识，生成block，通过消息通道批量的将block发布给peer节点，更新lerdger。\n\n交易过程可如下图\n\n![交易过程](./fabric_peer.jpg)\n\n\n\n#### channel\n\nchannel是构建在Fabric网络上的私有区块链，实现了数据的隔离和保密。channel是由特定的peer所共享的，并且交易方必须通过该通道的正确验证才能与账本进行交互。\n\n可以看到不同颜色的channel隔离了不同的peer之间的通信。\n\n\n\nFabric提供了一个first-network的<u>demo</u>来学习整个流程。要学哦! 入手做一个~等理论搞定，明天能不能搞定理论 fabric的~\n\n今天理论到一半了吧.. 然而又读不下去了，真的超枯燥...我先搞一下别的。\n\nfirst-network有两个组织，每个组织各有两个个peer节点，以及一个排序服务。两个peer节点无法达成共识，三个peer节点无法容错，四个peer节点刚好完成演示。\n\n\n\n### fabric 理解\n\n#### 问题记录\n\n```\nPolicy for [Groups] /Channel/Application not satisfied: Failed to reach implicit threshold of 1 sub-policies, required [Admins]...\n```\n\n创建通道时，报错。\n\n创建通道，根据通道定义的策略，传入相关成员签名/证书。如果策略是or1.admin和org2.admin，就需要两个一起授权(数组..)\n\n首先检查是否是传入了相关用户，然后检查SigningIdentity是否正确，可打印出来对比`fmt.Println(string(identity.EnrollmentCertificate()))`\n\n使用go-sdk的话会在tmp目录下有相关的数据目录，我的情况是先使用ca注册了一个admin..就会生成一个由ca签名的admin证书，但这个admin并不是org1.admin，所以我(⊙x⊙;)…删除了目录..  就还是不要注册admin这种敏感名字的用户了吧...\n\n\n\n\n\n`peer chaincode instantiate -p git.wokoworks.com/blockchain/fabric-thread/multipeer/chaincode/go/test  -n mytest -v 0`\n\n之后，在peer的`/var/hyperledger/production/chaincodes`目录下会有`mycc.0`的二进制？不晓得\n\n?好奇怪  这个是要peer安装的意思？\n\n安装和部署的区别\n\n\n```\n  cli:\n    container_name: cli\n    image: hyperledger/fabric-tools\n    tty: true\n    environment:\n      - GOPATH=/opt/gopath\n      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\n      - FABRIC_LOGGING_SPEC=DEBUG\n      - CORE_PEER_ID=cli\n      - CORE_PEER_ADDRESS=peer:7051\n      - CORE_PEER_LOCALMSPID=DEFAULT\n      - CORE_PEER_MSPCONFIGPATH=/etc/hyperledger/msp\n    working_dir: /opt/gopath/src/chaincodedev\n#    command: /bin/bash -c './script.sh'\n    volumes:\n      - /var/run/:/host/var/run/\n      - ./nodes/peer1/msp:/etc/hyperledger/msp\n      - /Users/xiaoxuez/go/src/github.com/hyperledger/fabric/examples/chaincode/go:/opt/gopath/src/chaincodedev/chaincode\n      - ./:/opt/gopath/src/chaincodedev/\n    depends_on:\n      - orderer\n      - peer1\n```\n\n\n\n```\nCORE_PEER_ADDRESS=peer1:7051 peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0\n```\n\n\n\n```\nconfigure.sh \"mychannel\" \"channel.tx anchor.tx\" \"peer1 peer2 peer3 peer4\" false\n```\n\n\n\n------\n\n#### 1. 生成公私钥和证书\n\n```\ncryptogen generate  --config ./crypto-config.yaml --output crypto-config\n```\n\n—output 为生成后的文件夹\n\ncrypto-config.yaml为\n\n```\nOrdererOrgs:\n  - Name: Orderer\n    Domain: orderer.net\n    CA:\n      Country: US\n      Province: California\n      Locality: San Francisco\n    Specs:\n      - Hostname: orderer\n\nPeerOrgs:\n  - Name: Org1\n    Domain: org1.net\n    CA:\n      Country: US\n      Province: California\n      Locality: San Francisco\n    Template:\n      Count: 4\n      Start: 1\n    Users:\n      Count: 1\n\n```\n\n有两个组织，为Orderer和Org1。使用命令后生成文件为\n\n```\ncrypto-config\n├── ordererOrganizations\n│   └── orderer.net\n│       ├── ca\n│       ├── msp\n│       ├── orderers\n│       ├── tlsca\n│       └── users\n└── peerOrganizations\n    └── org1.net\n        ├── ca\n        ├── msp\n        ├── peers //count为4所以peers下面会有4个\n        ├── tlsca\n        └── users\n\n```\n\n\n\n关于证书，稍微说明一下看到的源码。\n\n首先，是两个组织，从cryptogen的角度上来讲，这两个组织的一切证书和公私钥生成方式是一样的。只是名字什么的是由配置文件决定的。\n\n其次，一组证书和公私钥的生成方式呢，分为几个步骤\n\n1. 生成公私钥，由私钥对包含公钥的等信息进行签名可得证书。\n2. 一个组织的证书链，包含一个root ca，可其签发的一系列证书。首先，会产生一对公私钥，这个私钥会作为root ca的私钥，config中定义的ca的其他属性会作为root ca的元数据(签名时应该会用到)，然后就会生成一个私钥文件，和一个root ca的证书(证书链中的顶级证书)，这两个文件位于ca文件夹。\n3. 另外，因为fabric中需要两套证书，另外一套为tls，用于通信传输.. 所以会生成两套(生成逻辑是一毛一样的)，一套位于ca文件夹，一套位于tlsca文件夹。\n4. msp文件夹内的内容主要是ca和tlsca中的证书的拷贝(不包含私钥)，另外是有一个admin的用户证书(拷贝自用户目录)\n5. users目录和peers目录中，每个peer和user的逻辑都是生成了一对公私钥，随后，使用root ca和tlsca对公钥d等信息进行签名颁发证书，同样也包含两套证书，同时，还包括root ca和tlsca的自带证书\n\n关于证书验证的问题，启动ca服务端时会将root ca作为其签发证书的私钥，当用户注册并申请证书后获得证书，其实ca server返回的x509格式的证书申请结果中是含有证书和签发者的公钥信息的，但在fabric-sdk-go的使用中，enroll的结果返回只有证书，在封装的内层代码中将签发者的公钥信息直接忽略了。当用户拿到证书，进行交易发送到peer，peer如何验证证书呢.. peer目前只有两个签发者，一个是自己，一个是root ca(具有root ca的证书，所以就可以使用公钥验证)，所以应该是使用这两者进行验证吧。但是，再想想，其实正常的情况，构成了证书链的话，如果a -> b -> c的证书链的话，应该是用户提交的证书中，就会包含整个证书链，以后待考证？\n\n\n\n#### 2. 生成初始块和配置的交易\n\n```\nconfigtxgen -profile SampleOrg -outputBlock ./channel-artifacts/genesis.block\n```\n\n这个命令会自动加载当前文件夹下的`configtx.yaml`配置文件，该文件配置了哪些\n\n\n\n```\nCORE_PEER_ADDRESS=peer1:7051 peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0\n//-p  Path to chaincode,\n//  \t默认路径是从gopath下进行搜索，即上例中的路径为gopath/chaincodedev/chaincode/sacc, sacc为文件夹名称，只配置到文件夹即可\n//-n, --name string                    Name of the chaincode\n```\n\n\n\n```\npeer chaincode instantiate -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c '{\"Args\":[\"init\",\"a\", \"100\", \"b\",\"200\"]}' -P \"OR ('Org1MSP.admin','Org1MSP.member')\"\n```\n\n\n\n\n\n```\npeer chaincode instantiate -o orderer.example.com:7050  --tls true --cafile  /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n marbles02 -v 0 -c '{\"Args\":[\"\"]}' -P \"OR ('Org1MSP.admin','Org1MSP.member')\"\n//没有配tsl的话就不虚要--tls true --cafile  -o也有默认值orderer.example.com:7050  -P默认值？\n```\n\n\n\n\n\n大概看了下，没怎么看透。基本的说一下，在configtx.yaml中，定义了初始组织的基本信息。其中Profiles提供了一些组合，这些组合可以提供生成genesis块(包含order信息组织和财团(Consortiums = =应该就是权限最大的组织))，可以生成新建channel的交易(包含一个Consortium和Application定义)。\n\n首先，会使用configtx.yaml生成创世块，OneOrgOrdererGenesis为Profiles中的定义的组合段落。\n\n```\nconfigtxgen -profile OneOrgOrdererGenesis -outputBlock ./config/genesis.block\n```\n\n\n\n其次，生成相应的通道，同理OneOrgChannel也是Profiles中的定义的组合段落。\n\n```\nconfigtxgen -profile  OneOrgChannel -outputCreateChannelTx ./config/channel.tx -channelID $CHANNEL_NAME\n```\n\n\n\n要新建通道的话，就要先使用上述生成通道的命令生成一个.tx的文件，然后再调用新建通道的命令传入这个文件。\n\n\n\n### go-sdk\n\n#### config.yaml\n\n初始化sdk的时候需要传入config.yaml，所以这个配置文件是最关键的。\n\n在这个文件中，主要包含几个大块。\n\n- client，客户端配置，即对自己的一些配置，包括自己所属组织，自己的msp文件(keys和certs)。BCCSP定义了加密的相关算法，还有就是tls证书配置\n- channel, 配置通道，即当访问某通道时通过哪些peer(peer_name)，以及这个peer具有的权限，还有就是性能相关的配置。程序要访问不同的通道，这个就需要有相应的配置项。不然就会报` could not get chConfig reference`\n- organizations,配置网络中的参与者(org -> peer_name 和 orderorg)\n- orderers, 配置orderer的name和相关rpc的配置，tls配置\n- peers，配置peers的name和相关rpc的配置，tls配置\n- certificateAuthorities， 配置ca的name和相关rpc的配置，tls配置\n- entityMatchers，这个是匹配替换，用于集中替换，可匹配正则的name，满足的实体(peer、orderer、ca)都会进行相应的替换，可用于替换url..\n\n#### 源码分析\n\n- fabsdk.New(config)\n\n  - defPkgSuite，包管理工具，根据config提供相应的包，defaultPkgSuite提供的每个包都是工厂模式，根据config可提供对应的具体的包。\n    - Core(corefactory)，提供了BCCSP、signing manager和fabric primitives的实现包。\n      - BCCSP即区块链加密服务提供者，提供加密标准和算法的实现。目前支持两种实现，sw和pkcs11。\n        - sw即software-based，基于软件实现的BCCSP，通过调用go原生支持的密码算法实现，并提供keystore来保存密钥\n        - pkcs11，通过调用pkcs11接口实现相关加密操作，仅支持ecdsa、rsa以及aes算法，密码保存在pkcs11通过pin口令保护的数据库或者硬件设备中。\n    - MSP，成员管理提供实现，如本地成员管理(从配置文件读入用户..本地存储用户等)，主要实现位于msppvdr包下。\n    - Service，服务提供实现，如channel服务、discovery服务等..\n    - Logger\n\n  所以，其实fabsdk.new就是提供了一大堆的provide。\n\n  ```\n  //update sdk providers list since all required providers are initialized\n  \tsdk.provider = context.NewProvider(context.WithCryptoSuiteConfig(cfg.cryptoSuiteConfig),\n  \t\tcontext.WithEndpointConfig(cfg.endpointConfig),\n  \t\tcontext.WithIdentityConfig(cfg.identityConfig),\n  \t\tcontext.WithCryptoSuite(sdk.cryptoSuite),\n  \t\tcontext.WithSigningManager(signingManager),\n  \t\tcontext.WithUserStore(userStore),\n  \t\tcontext.WithLocalDiscoveryProvider(localDiscoveryProvider),\n  \t\tcontext.WithIdentityManagerProvider(identityManagerProvider),\n  \t\tcontext.WithInfraProvider(infraProvider),\n  \t\tcontext.WithChannelProvider(channelProvider),\n  \t\tcontext.WithClientMetrics(sdk.clientMetrics),\n  \t)\n  \t...\n  ```\n\n\n\n总的来说，go-sdk是封装的rpc。所以有了sdk的相关上下文，就可以进行实例化相关的rpc client了。在pkg包下的client里，目录如下\n\n```\n├── channel   //通道相关的rpc\n├── common\n├── event\t//事件监听，如区块、链码、或交易状态\n├── ledger\t//账本相关rpc,如查询区块、交易等\n├── msp\t\t//成员相关rpc,与ca交互，提供注册查询等api\n└── resmgmt\t//resouce manager clinet\n```\n\n\n\n#### msp\n\nmsp包提供了与ca相关的rpc调用，如注册等。同时也提供了查询本地identify功能，即访问本地文件，查询出具体的私钥和相关证书(msppvdr包)。\n\nrpc相关调用包括以下功能\n\n```\n1. 身份注册；\n2. 颁发登录证书(ECerts)；\n3. 颁发交易证书(TCerts)，保证链上交易的匿名性与不可连接性；\n4. 证书续期与撤销\n```\n\n首先，只有已经登录了的身份才能发起注册的请求，而且必须有相应的权限来注册想要注册的身份类型。所以要注册用户，首先要使用一个已有的身份，然后再进行注册新用户和密码。\n\n- Enroll方法，内容包括，生成新的私钥(存于config.credentialStore.cryptoStore/)，然后将公钥等信息作为参数，进行http请求ca服务器，ca服务器将返回对公钥等信息进行签名完的证书(存于config.credentialStore.path/)。\n  - 提到这里，多嘴一句，证书的存储文件名为name@Org1MSP-cert.pem，在进行查询时，可使用name或Org1MSP皆可查询到证书，然后通过对证书进行解析出公钥pubKey，name和pubKey.SKI()组成了私钥的文件名，从而可索引到私钥。\n\n​        总的来说就是一次Enroll，就会更新一次私钥和证书。\n\n- Register方法，进行注册，上文提到，要注册，首先要登录一个已有的身份(用户名)，获取证书，然后再使用证书进行注册别的身份。\n\n  - 注册时可传属性，如\n\n    ```\n    attributes:\n            - name: hf.Revoker\n            value: true\n            ECert: true\n            - name: anotherAttrName\n            value: anotherAttrValue\n    ```\n\n    这个应该是跟LDAP…相关的吧..暂时不知道是啥\n\n\n\n#### channel\n\n通道相关api，如链码的调用。\n\n这里先对链码的调用简单分析一下。\n\nchannel的客户端提供了两个方法`Query`和`Execute`\n\n先说二者的共同流程。两个方法都是负责组装参数(handlers…opts..)后调用`chclinet.InvokeHandler`。在`InvokeHandler`里可以看到流程是准备参数，准备上下文，然后启动一个协程运行handlers，本方法堵塞直到complete或reqCtx.Done()通道读出消息，当handlers运行完毕后会向通道complete写入消息(成功或失败都会写入)，reqCtx.Done()则是超时。所以重点是运行Handler。Handler的组装类似于生产线，如a -> b ->c按顺序执行，且将上一个执行的结果也传递给下一位。\n\n- Query\n\n  - ProposalProcessorHandler\n\n    首先，检查targets参数长度是否为0，targets为进行背书的节点们。如果没有提供targets，将会查询背书的节点，opts参数中的filter将会在这里使用到，就是按需求筛选节点(如是查询还是背书...)\n\n  - EndorsementHandler\n\n    其次，会将proposal发送到各个targets，返回的responses会传递下去\n\n  - EndorsementValidationHandler\n\n    再次，验证各个target返回的结果，状态码是否正常，reponse是否一样\n\n  - SignatureValidationHandler\n\n    最后，验证各个节点返回的response的签名/证书是否正确\n\n  到此为止，query请求就完成了，最后将reponse返回给上层\n\n- Execute\n\n  - SelectAndEndorseHandler\n\n    首先检查targets，其次调用EndorsementHandler发送proposal，然后根据链码策略向另外的peer发起proposal，返回的responses一起传递下去\n\n  - EndorsementValidationHandler\n\n    同上\n\n  - SignatureValidationHandler\n\n    同上\n\n  - CommitHandler\n\n    拿到所有peer的背书后，首先向order发送交易。然后订阅这笔交易状态，接收到新状态，方法执行结束，继续向下执行\n\nresponse结构体中包含有Payload，ChaincodeStatus，TxValidationCode。\n\n在github.com/hyperledger/fabric/protos/peer下有TxValidationCode的所有码，可判断如下\n\n```\nswitch pb.TxValidationCode(response.TxValidationCode) {\n\tcase pb.TxValidationCode_VALID:\n\t\tcliconfig.Config().Logger().Debugf(\"(%s) - Successfully committed transaction [%s] ...\\n\", t.id, response.TransactionID)\n\t\treturn nil\n\tcase pb.TxValidationCode_DUPLICATE_TXID, pb.TxValidationCode_MVCC_READ_CONFLICT, pb.TxValidationCode_PHANTOM_READ_CONFLICT:\n\t\tcliconfig.Config().Logger().Debugf(\"(%s) - Transaction commit failed for [%s] with code [%s]. This is most likely a transient error.\\n\", t.id, response.TransactionID, response.TxValidationCode)\n\t\treturn invokeerror.Wrapf(invokeerror.TransientError, errors.New(\"Duplicate TxID\"), \"invoke Error received from eventhub for TxID [%s]. Code: %s\", response.TransactionID, response.TxValidationCode)\n\tdefault:\n\t\tcliconfig.Config().Logger().Debugf(\"(%s) - Transaction commit failed for [%s] with code [%s].\\n\", t.id, response.TransactionID, response.TxValidationCode)\n\t\treturn invokeerror.Wrapf(invokeerror.PersistentError, errors.New(\"error\"), \"invoke Error received from eventhub for TxID [%s]. Code: %s\", response.TransactionID, response.TxValidationCode)\n\t}\n```\n\n#### sdk example\n\n[Sdk example ](https://github.com/securekey/fabric-examples/tree/master/fabric-cli)\n\n\n\n\n\n## couchdb\n\n#### 查询索引\n\n```\nhttp://localhost:5984/mychannel_mycc/_index\n```\n\n查询结果如\n\n```\n{\n    \"total_rows\":2,\n    \"indexes\":[\n        {\n            \"ddoc\":null,\n            \"name\":\"_all_docs\",\n            \"type\":\"special\",\n            \"def\":{\n                \"fields\":[\n                    {\n                        \"_id\":\"asc\"\n                    }\n                ]\n            }\n        },\n        {\n            \"ddoc\":\"_design/indexOwnerDoc\",\n            \"name\":\"indexOwner\",\n            \"type\":\"json\",\n            \"def\":{\n                \"fields\":[\n                    {\n                        \"docType\":\"asc\"\n                    },\n                    {\n                        \"owner\":\"asc\"\n                    }\n                ]\n            }\n        }\n    ]\n}\n```\n\n\n\n这个是在我刚启动好链码容器时，什么操作都没做。为什么会建了一个索引呢.\n\n另外，在这个文档下，发现存在一条记录(一打开就有一条记录)。\n\n```\n{\n    \"_id\":\"_design/indexOwnerDoc\",\n    \"_rev\":\"1-56c3e9386cb19531f6731afa88281caa\",\n    \"language\":\"query\",\n    \"views\":{\n        \"indexOwner\":{\n            \"map\":{\n                \"fields\":{\n                    \"docType\":\"asc\",\n                    \"owner\":\"asc\"\n                },\n                \"partial_filter_selector\":{\n\n                }\n            },\n            \"reduce\":\"_count\",\n            \"options\":{\n                \"def\":{\n                    \"fields\":[\n                        \"docType\",\n                        \"owner\"\n                    ]\n                }\n            }\n        }\n    }\n}\n```\n\n\n\n猜测，索引应该是由这条记录引起的，似乎是创建时的自动的索引？不对！是在我的链码里，有个文件夹叫META-INF下定义的。\n\n果然，这下面有个json文件，内容为\n\n```\n{\n\t\"index\":{\"fields\":[\"docType\",\"owner\"]},\n\t\"ddoc\":\"indexOwnerDoc\",\n\t\"name\":\"indexOwner\",\n\t\"type\":\"json\"\n}\n```\n\n完全吻合。所以定义索引是可以通过这个配置文件！\n\n定义的索引对于查询的意义，似乎是如果要查询相应的字段(字段相关，如大于啥小于啥)，就要定义包含其中的字段的索引\n\n默认情况下，会建立一个id的索引。\n\n```\n{\n \"type\": \"special\",\n \"def\": {\n  \"fields\": [\n   {\n    \"_id\": \"asc\"\n   }\n  ]\n }\n}\n```\n\n\n\n如新建一个索引视图\n\n```\ncurl -i -X POST -H \"Content-Type: application/json\" -d \"{\\\"index\\\":{\\\"fields\\\":[\\\"size\\\",\\\"docType\\\",\\\"owner\\\"]},\\\"ddoc\\\":\\\"indexSizeSortDoc1\\\", \\\"name\\\":\\\"indexSizeSortDesc1\\\",\\\"type\\\":\\\"json\\\"}\" http://localhost:5984/mychannel_mycc/_index\n```\n\n\n\n重新查询索引，多了一个\n\n```\n{\n    \"total_rows\":3,\n    \"indexes\":[\n        {\n         ...\n        },\n        {\n         ...\n        },\n        {\n            \"ddoc\":\"_design/indexSizeSortDoc\",\n            \"name\":\"indexSizeSortDesc\",\n            \"type\":\"json\",\n            \"def\":{\n                \"fields\":[\n                    {\n                        \"size\":\"desc\"\n                    },\n                    {\n                        \"docType\":\"desc\"\n                    },\n                    {\n                        \"owner\":\"desc\"\n                    }\n                ]\n            }\n        }\n    ]\n}\n```\n\n建立了这个索引后，就可以进行size相关的查询，如\n\n```\n\"{\\\"selector\\\":{\\\"docType\\\":{\\\"$eq\\\":\\\"marble\\\"},\\\"owner\\\":{\\\"$eq\\\":\\\"tom\\\"},\\\"size\\\":{\\\"$gt\\\":0}},\\\"fields\\\":[\\\"docType\\\",\\\"owner\\\",\\\"size\\\"],\\\"sort\\\":[{\\\"size\\\":\\\"desc\\\"}],\\\"use_index\\\":\\\"_design/indexSizeSortDoc\\\"}\"\n```\n\n**啊！！**就是建立的这个索引视图是包括size、docType、owner这三个的，然后我使用查询的时候，如果少传一个，就是我只查询docType和size，就会报错`Error running query. Reason: (no_usable_index) No index exists for this sort, try indexing by the sort fields.`\n\n几经挣扎和尝试，确定下来几个结论。\n\n1. 如果不适用sort，selector中的field都随意查询，使用的默认index(id asc排序)\n2. 如果使用了sort，那么需要一个index包含 在selector中的field + sort中的field组成的field ，并且index中定义的field集合必须是selector中的field + sort中的field组成的field的子集，即index中出现过的，在查询时一定要出现，在selector和在sort中都无所谓，但sort中的一定要出现在index中\n","source":"_posts/fabric.md","raw":"---\ntitle: fabric\ncategories:\n  - fabric\ndate: 2019-10-14 14:56:49\ntags:\n---\n\n## Fabric基本认识\n\n\n\n### 基本架构\n\n\n\n[官方文档](http://hyperledger-fabric.readthedocs.io/en/master/arch-deep-dive.html)\n\n\n\n![宏观图](./fabric_macro.jpg)\n\n上图为fabric的基本结构图，以下解释各名词含义。\n\n- application: 提供各种语言的SDK接口\n- membership： 也就是fabric-ca，提供成员服务，用来管理身份，提供授权和认证\n- peer: 负责模拟交易和记账\n  - Endorser(背书)，peer执行交易并返回yes/no\n  - Committer，将验证过的区块追加到通道上各个账本的副本\n  - Ledger，账本\n  - chaincode，用来编写业务逻辑，交易指令用来修改资产，可以理解为fabric网络对外提供的一个交易接口（智能合约）\n  - Event是fabric提供的一个事件框架，比如链代码事件，拒绝事件，注册事件等，在编写代码的时候可以订阅这些事件来实现自己的业务逻辑。\n- o-service用来实现共识\n\n\n\n区块链运行称之为链码（chaincode）的程序，保存状态、账本数据，并执行交易。链码是中央元素，因为交易是在链码上调用的操作。交易必须被“endorsed”，而且只有被“endorsed”后的交易才能被提交。管理方法和参数可能存在一个或多个特殊链码，统称为系统链码。\n\n**交易**可能有两种类型：\n\n- 部署事务，创建新的链接代码并将程序作为参数。当部署事务成功执行时，链代码已经安装在区块链上。\n- 调用事务，在先前部署的链式代码的上下文中执行操作。一个invoke事务引用了一个chaincode和它提供的函数之一。成功时，chaincode执行指定的功能 - 可能涉及修改相应的状态并返回输出。\n\n如后面所述，部署事务是调用事务的特例，其中创建新链代码的部署事务对应于系统链代码上的调用事务。\n\n**State**，区块链的最新state被建模为版本化的键值存储（KVS），修改由运行在区块链上的链码（applications）调用KVS的put,get操作。详细的操作与版本化暂时略，看文档有点没看懂..State由peers进行维护，而不是orders和clients。KVS中的Keys可以从它们的名称中识别出属于特定的链码，因此只有特定链码的交易可以修改这个链码上的keys，但原则上，任何链码都可读别的链码的keys，即读取方便，但修改需特权。\n\n\n\n**Ledger, 账本**，账本提供了发生在系统运行时的所有成功和不成功交易的历史。账本，作为总的区块总的哈希链（成功或不成功），由订阅服务构造。哈希链强制要求在账本中所有的有序区块以及每个块包含1个完全有序的交易，这在所有交易中强制要求所有的订阅。账本保存在所有的peer中，并可选择性的存放在orders中。在orders中，我们指的账本是OrdererLedger(总账)；在peers中，我们指的是PeerLedger（分账），分账和总账的区别在于peers本地会维护一个位掩码，这个位掩码会将有效的事务从无效的当中分离出来。peers可能会对分账进行修剪，orders负责维护总账的容错性和可用性并且可以随时修剪，前提是ordering服务的属性得到维护。账本允许peers重播所有交易的历史以及重建state,所以state是一个可选的数据结构。\n\n\n\n**节点**，节点是区块链中的通信实体，节点只是一个逻辑功能，因为不同类型的多个节点可以在同一台物理服务器上运行，重要的是节点在“信任域”中如何分组并与控制它们的逻辑实体相关联。节点分为3种类型：\n\n- Client 或 submitting-client: 提交真正交易给endorsers的客户，并且广播交易申请给ordering服务\n- Peer：提交交易并维护state和账本的备份，除此之外，peers还有一个特殊的endorser角色\n- Ordering-service-node或者order：通信服务 -> 实现传递保证，例如原子性或者所有的order广播\n\n\n\n订阅服务提供了一个共享的通信通道给clients和peers, 提供的是一个包含交易信息的广播服务。client连接到通道，在通道中广播消息，消息将会送达给所有的peers。通道支持所有消息的原子性传递，即，消息通信是按序传递和可靠的。换句话说，通道给所有连接的peers输出的是相同消息，且是相同的逻辑顺序。这种原子性的通信保证在分布式系统中也被称为全序广播，原子广播，或者是共识。传递的消息是包含在区块链状态中的候选交易。\n\n\n\n#### 交易流程\n\n交易过程如下：\n\n1. Application向一个或多个peer节点发送对交易的背书请求。\n2. Peer的endorse执行背书，但并不将结果提交到本地账本，只是将结果返回给应用。\n3. 应用收集所有背书节点的结果后，将结果广播给orderers，orderers执行共识，生成block，通过消息通道批量的将block发布给peer节点，更新lerdger。\n\n交易过程可如下图\n\n![交易过程](./fabric_peer.jpg)\n\n\n\n#### channel\n\nchannel是构建在Fabric网络上的私有区块链，实现了数据的隔离和保密。channel是由特定的peer所共享的，并且交易方必须通过该通道的正确验证才能与账本进行交互。\n\n可以看到不同颜色的channel隔离了不同的peer之间的通信。\n\n\n\nFabric提供了一个first-network的<u>demo</u>来学习整个流程。要学哦! 入手做一个~等理论搞定，明天能不能搞定理论 fabric的~\n\n今天理论到一半了吧.. 然而又读不下去了，真的超枯燥...我先搞一下别的。\n\nfirst-network有两个组织，每个组织各有两个个peer节点，以及一个排序服务。两个peer节点无法达成共识，三个peer节点无法容错，四个peer节点刚好完成演示。\n\n\n\n### fabric 理解\n\n#### 问题记录\n\n```\nPolicy for [Groups] /Channel/Application not satisfied: Failed to reach implicit threshold of 1 sub-policies, required [Admins]...\n```\n\n创建通道时，报错。\n\n创建通道，根据通道定义的策略，传入相关成员签名/证书。如果策略是or1.admin和org2.admin，就需要两个一起授权(数组..)\n\n首先检查是否是传入了相关用户，然后检查SigningIdentity是否正确，可打印出来对比`fmt.Println(string(identity.EnrollmentCertificate()))`\n\n使用go-sdk的话会在tmp目录下有相关的数据目录，我的情况是先使用ca注册了一个admin..就会生成一个由ca签名的admin证书，但这个admin并不是org1.admin，所以我(⊙x⊙;)…删除了目录..  就还是不要注册admin这种敏感名字的用户了吧...\n\n\n\n\n\n`peer chaincode instantiate -p git.wokoworks.com/blockchain/fabric-thread/multipeer/chaincode/go/test  -n mytest -v 0`\n\n之后，在peer的`/var/hyperledger/production/chaincodes`目录下会有`mycc.0`的二进制？不晓得\n\n?好奇怪  这个是要peer安装的意思？\n\n安装和部署的区别\n\n\n```\n  cli:\n    container_name: cli\n    image: hyperledger/fabric-tools\n    tty: true\n    environment:\n      - GOPATH=/opt/gopath\n      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\n      - FABRIC_LOGGING_SPEC=DEBUG\n      - CORE_PEER_ID=cli\n      - CORE_PEER_ADDRESS=peer:7051\n      - CORE_PEER_LOCALMSPID=DEFAULT\n      - CORE_PEER_MSPCONFIGPATH=/etc/hyperledger/msp\n    working_dir: /opt/gopath/src/chaincodedev\n#    command: /bin/bash -c './script.sh'\n    volumes:\n      - /var/run/:/host/var/run/\n      - ./nodes/peer1/msp:/etc/hyperledger/msp\n      - /Users/xiaoxuez/go/src/github.com/hyperledger/fabric/examples/chaincode/go:/opt/gopath/src/chaincodedev/chaincode\n      - ./:/opt/gopath/src/chaincodedev/\n    depends_on:\n      - orderer\n      - peer1\n```\n\n\n\n```\nCORE_PEER_ADDRESS=peer1:7051 peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0\n```\n\n\n\n```\nconfigure.sh \"mychannel\" \"channel.tx anchor.tx\" \"peer1 peer2 peer3 peer4\" false\n```\n\n\n\n------\n\n#### 1. 生成公私钥和证书\n\n```\ncryptogen generate  --config ./crypto-config.yaml --output crypto-config\n```\n\n—output 为生成后的文件夹\n\ncrypto-config.yaml为\n\n```\nOrdererOrgs:\n  - Name: Orderer\n    Domain: orderer.net\n    CA:\n      Country: US\n      Province: California\n      Locality: San Francisco\n    Specs:\n      - Hostname: orderer\n\nPeerOrgs:\n  - Name: Org1\n    Domain: org1.net\n    CA:\n      Country: US\n      Province: California\n      Locality: San Francisco\n    Template:\n      Count: 4\n      Start: 1\n    Users:\n      Count: 1\n\n```\n\n有两个组织，为Orderer和Org1。使用命令后生成文件为\n\n```\ncrypto-config\n├── ordererOrganizations\n│   └── orderer.net\n│       ├── ca\n│       ├── msp\n│       ├── orderers\n│       ├── tlsca\n│       └── users\n└── peerOrganizations\n    └── org1.net\n        ├── ca\n        ├── msp\n        ├── peers //count为4所以peers下面会有4个\n        ├── tlsca\n        └── users\n\n```\n\n\n\n关于证书，稍微说明一下看到的源码。\n\n首先，是两个组织，从cryptogen的角度上来讲，这两个组织的一切证书和公私钥生成方式是一样的。只是名字什么的是由配置文件决定的。\n\n其次，一组证书和公私钥的生成方式呢，分为几个步骤\n\n1. 生成公私钥，由私钥对包含公钥的等信息进行签名可得证书。\n2. 一个组织的证书链，包含一个root ca，可其签发的一系列证书。首先，会产生一对公私钥，这个私钥会作为root ca的私钥，config中定义的ca的其他属性会作为root ca的元数据(签名时应该会用到)，然后就会生成一个私钥文件，和一个root ca的证书(证书链中的顶级证书)，这两个文件位于ca文件夹。\n3. 另外，因为fabric中需要两套证书，另外一套为tls，用于通信传输.. 所以会生成两套(生成逻辑是一毛一样的)，一套位于ca文件夹，一套位于tlsca文件夹。\n4. msp文件夹内的内容主要是ca和tlsca中的证书的拷贝(不包含私钥)，另外是有一个admin的用户证书(拷贝自用户目录)\n5. users目录和peers目录中，每个peer和user的逻辑都是生成了一对公私钥，随后，使用root ca和tlsca对公钥d等信息进行签名颁发证书，同样也包含两套证书，同时，还包括root ca和tlsca的自带证书\n\n关于证书验证的问题，启动ca服务端时会将root ca作为其签发证书的私钥，当用户注册并申请证书后获得证书，其实ca server返回的x509格式的证书申请结果中是含有证书和签发者的公钥信息的，但在fabric-sdk-go的使用中，enroll的结果返回只有证书，在封装的内层代码中将签发者的公钥信息直接忽略了。当用户拿到证书，进行交易发送到peer，peer如何验证证书呢.. peer目前只有两个签发者，一个是自己，一个是root ca(具有root ca的证书，所以就可以使用公钥验证)，所以应该是使用这两者进行验证吧。但是，再想想，其实正常的情况，构成了证书链的话，如果a -> b -> c的证书链的话，应该是用户提交的证书中，就会包含整个证书链，以后待考证？\n\n\n\n#### 2. 生成初始块和配置的交易\n\n```\nconfigtxgen -profile SampleOrg -outputBlock ./channel-artifacts/genesis.block\n```\n\n这个命令会自动加载当前文件夹下的`configtx.yaml`配置文件，该文件配置了哪些\n\n\n\n```\nCORE_PEER_ADDRESS=peer1:7051 peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0\n//-p  Path to chaincode,\n//  \t默认路径是从gopath下进行搜索，即上例中的路径为gopath/chaincodedev/chaincode/sacc, sacc为文件夹名称，只配置到文件夹即可\n//-n, --name string                    Name of the chaincode\n```\n\n\n\n```\npeer chaincode instantiate -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c '{\"Args\":[\"init\",\"a\", \"100\", \"b\",\"200\"]}' -P \"OR ('Org1MSP.admin','Org1MSP.member')\"\n```\n\n\n\n\n\n```\npeer chaincode instantiate -o orderer.example.com:7050  --tls true --cafile  /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n marbles02 -v 0 -c '{\"Args\":[\"\"]}' -P \"OR ('Org1MSP.admin','Org1MSP.member')\"\n//没有配tsl的话就不虚要--tls true --cafile  -o也有默认值orderer.example.com:7050  -P默认值？\n```\n\n\n\n\n\n大概看了下，没怎么看透。基本的说一下，在configtx.yaml中，定义了初始组织的基本信息。其中Profiles提供了一些组合，这些组合可以提供生成genesis块(包含order信息组织和财团(Consortiums = =应该就是权限最大的组织))，可以生成新建channel的交易(包含一个Consortium和Application定义)。\n\n首先，会使用configtx.yaml生成创世块，OneOrgOrdererGenesis为Profiles中的定义的组合段落。\n\n```\nconfigtxgen -profile OneOrgOrdererGenesis -outputBlock ./config/genesis.block\n```\n\n\n\n其次，生成相应的通道，同理OneOrgChannel也是Profiles中的定义的组合段落。\n\n```\nconfigtxgen -profile  OneOrgChannel -outputCreateChannelTx ./config/channel.tx -channelID $CHANNEL_NAME\n```\n\n\n\n要新建通道的话，就要先使用上述生成通道的命令生成一个.tx的文件，然后再调用新建通道的命令传入这个文件。\n\n\n\n### go-sdk\n\n#### config.yaml\n\n初始化sdk的时候需要传入config.yaml，所以这个配置文件是最关键的。\n\n在这个文件中，主要包含几个大块。\n\n- client，客户端配置，即对自己的一些配置，包括自己所属组织，自己的msp文件(keys和certs)。BCCSP定义了加密的相关算法，还有就是tls证书配置\n- channel, 配置通道，即当访问某通道时通过哪些peer(peer_name)，以及这个peer具有的权限，还有就是性能相关的配置。程序要访问不同的通道，这个就需要有相应的配置项。不然就会报` could not get chConfig reference`\n- organizations,配置网络中的参与者(org -> peer_name 和 orderorg)\n- orderers, 配置orderer的name和相关rpc的配置，tls配置\n- peers，配置peers的name和相关rpc的配置，tls配置\n- certificateAuthorities， 配置ca的name和相关rpc的配置，tls配置\n- entityMatchers，这个是匹配替换，用于集中替换，可匹配正则的name，满足的实体(peer、orderer、ca)都会进行相应的替换，可用于替换url..\n\n#### 源码分析\n\n- fabsdk.New(config)\n\n  - defPkgSuite，包管理工具，根据config提供相应的包，defaultPkgSuite提供的每个包都是工厂模式，根据config可提供对应的具体的包。\n    - Core(corefactory)，提供了BCCSP、signing manager和fabric primitives的实现包。\n      - BCCSP即区块链加密服务提供者，提供加密标准和算法的实现。目前支持两种实现，sw和pkcs11。\n        - sw即software-based，基于软件实现的BCCSP，通过调用go原生支持的密码算法实现，并提供keystore来保存密钥\n        - pkcs11，通过调用pkcs11接口实现相关加密操作，仅支持ecdsa、rsa以及aes算法，密码保存在pkcs11通过pin口令保护的数据库或者硬件设备中。\n    - MSP，成员管理提供实现，如本地成员管理(从配置文件读入用户..本地存储用户等)，主要实现位于msppvdr包下。\n    - Service，服务提供实现，如channel服务、discovery服务等..\n    - Logger\n\n  所以，其实fabsdk.new就是提供了一大堆的provide。\n\n  ```\n  //update sdk providers list since all required providers are initialized\n  \tsdk.provider = context.NewProvider(context.WithCryptoSuiteConfig(cfg.cryptoSuiteConfig),\n  \t\tcontext.WithEndpointConfig(cfg.endpointConfig),\n  \t\tcontext.WithIdentityConfig(cfg.identityConfig),\n  \t\tcontext.WithCryptoSuite(sdk.cryptoSuite),\n  \t\tcontext.WithSigningManager(signingManager),\n  \t\tcontext.WithUserStore(userStore),\n  \t\tcontext.WithLocalDiscoveryProvider(localDiscoveryProvider),\n  \t\tcontext.WithIdentityManagerProvider(identityManagerProvider),\n  \t\tcontext.WithInfraProvider(infraProvider),\n  \t\tcontext.WithChannelProvider(channelProvider),\n  \t\tcontext.WithClientMetrics(sdk.clientMetrics),\n  \t)\n  \t...\n  ```\n\n\n\n总的来说，go-sdk是封装的rpc。所以有了sdk的相关上下文，就可以进行实例化相关的rpc client了。在pkg包下的client里，目录如下\n\n```\n├── channel   //通道相关的rpc\n├── common\n├── event\t//事件监听，如区块、链码、或交易状态\n├── ledger\t//账本相关rpc,如查询区块、交易等\n├── msp\t\t//成员相关rpc,与ca交互，提供注册查询等api\n└── resmgmt\t//resouce manager clinet\n```\n\n\n\n#### msp\n\nmsp包提供了与ca相关的rpc调用，如注册等。同时也提供了查询本地identify功能，即访问本地文件，查询出具体的私钥和相关证书(msppvdr包)。\n\nrpc相关调用包括以下功能\n\n```\n1. 身份注册；\n2. 颁发登录证书(ECerts)；\n3. 颁发交易证书(TCerts)，保证链上交易的匿名性与不可连接性；\n4. 证书续期与撤销\n```\n\n首先，只有已经登录了的身份才能发起注册的请求，而且必须有相应的权限来注册想要注册的身份类型。所以要注册用户，首先要使用一个已有的身份，然后再进行注册新用户和密码。\n\n- Enroll方法，内容包括，生成新的私钥(存于config.credentialStore.cryptoStore/)，然后将公钥等信息作为参数，进行http请求ca服务器，ca服务器将返回对公钥等信息进行签名完的证书(存于config.credentialStore.path/)。\n  - 提到这里，多嘴一句，证书的存储文件名为name@Org1MSP-cert.pem，在进行查询时，可使用name或Org1MSP皆可查询到证书，然后通过对证书进行解析出公钥pubKey，name和pubKey.SKI()组成了私钥的文件名，从而可索引到私钥。\n\n​        总的来说就是一次Enroll，就会更新一次私钥和证书。\n\n- Register方法，进行注册，上文提到，要注册，首先要登录一个已有的身份(用户名)，获取证书，然后再使用证书进行注册别的身份。\n\n  - 注册时可传属性，如\n\n    ```\n    attributes:\n            - name: hf.Revoker\n            value: true\n            ECert: true\n            - name: anotherAttrName\n            value: anotherAttrValue\n    ```\n\n    这个应该是跟LDAP…相关的吧..暂时不知道是啥\n\n\n\n#### channel\n\n通道相关api，如链码的调用。\n\n这里先对链码的调用简单分析一下。\n\nchannel的客户端提供了两个方法`Query`和`Execute`\n\n先说二者的共同流程。两个方法都是负责组装参数(handlers…opts..)后调用`chclinet.InvokeHandler`。在`InvokeHandler`里可以看到流程是准备参数，准备上下文，然后启动一个协程运行handlers，本方法堵塞直到complete或reqCtx.Done()通道读出消息，当handlers运行完毕后会向通道complete写入消息(成功或失败都会写入)，reqCtx.Done()则是超时。所以重点是运行Handler。Handler的组装类似于生产线，如a -> b ->c按顺序执行，且将上一个执行的结果也传递给下一位。\n\n- Query\n\n  - ProposalProcessorHandler\n\n    首先，检查targets参数长度是否为0，targets为进行背书的节点们。如果没有提供targets，将会查询背书的节点，opts参数中的filter将会在这里使用到，就是按需求筛选节点(如是查询还是背书...)\n\n  - EndorsementHandler\n\n    其次，会将proposal发送到各个targets，返回的responses会传递下去\n\n  - EndorsementValidationHandler\n\n    再次，验证各个target返回的结果，状态码是否正常，reponse是否一样\n\n  - SignatureValidationHandler\n\n    最后，验证各个节点返回的response的签名/证书是否正确\n\n  到此为止，query请求就完成了，最后将reponse返回给上层\n\n- Execute\n\n  - SelectAndEndorseHandler\n\n    首先检查targets，其次调用EndorsementHandler发送proposal，然后根据链码策略向另外的peer发起proposal，返回的responses一起传递下去\n\n  - EndorsementValidationHandler\n\n    同上\n\n  - SignatureValidationHandler\n\n    同上\n\n  - CommitHandler\n\n    拿到所有peer的背书后，首先向order发送交易。然后订阅这笔交易状态，接收到新状态，方法执行结束，继续向下执行\n\nresponse结构体中包含有Payload，ChaincodeStatus，TxValidationCode。\n\n在github.com/hyperledger/fabric/protos/peer下有TxValidationCode的所有码，可判断如下\n\n```\nswitch pb.TxValidationCode(response.TxValidationCode) {\n\tcase pb.TxValidationCode_VALID:\n\t\tcliconfig.Config().Logger().Debugf(\"(%s) - Successfully committed transaction [%s] ...\\n\", t.id, response.TransactionID)\n\t\treturn nil\n\tcase pb.TxValidationCode_DUPLICATE_TXID, pb.TxValidationCode_MVCC_READ_CONFLICT, pb.TxValidationCode_PHANTOM_READ_CONFLICT:\n\t\tcliconfig.Config().Logger().Debugf(\"(%s) - Transaction commit failed for [%s] with code [%s]. This is most likely a transient error.\\n\", t.id, response.TransactionID, response.TxValidationCode)\n\t\treturn invokeerror.Wrapf(invokeerror.TransientError, errors.New(\"Duplicate TxID\"), \"invoke Error received from eventhub for TxID [%s]. Code: %s\", response.TransactionID, response.TxValidationCode)\n\tdefault:\n\t\tcliconfig.Config().Logger().Debugf(\"(%s) - Transaction commit failed for [%s] with code [%s].\\n\", t.id, response.TransactionID, response.TxValidationCode)\n\t\treturn invokeerror.Wrapf(invokeerror.PersistentError, errors.New(\"error\"), \"invoke Error received from eventhub for TxID [%s]. Code: %s\", response.TransactionID, response.TxValidationCode)\n\t}\n```\n\n#### sdk example\n\n[Sdk example ](https://github.com/securekey/fabric-examples/tree/master/fabric-cli)\n\n\n\n\n\n## couchdb\n\n#### 查询索引\n\n```\nhttp://localhost:5984/mychannel_mycc/_index\n```\n\n查询结果如\n\n```\n{\n    \"total_rows\":2,\n    \"indexes\":[\n        {\n            \"ddoc\":null,\n            \"name\":\"_all_docs\",\n            \"type\":\"special\",\n            \"def\":{\n                \"fields\":[\n                    {\n                        \"_id\":\"asc\"\n                    }\n                ]\n            }\n        },\n        {\n            \"ddoc\":\"_design/indexOwnerDoc\",\n            \"name\":\"indexOwner\",\n            \"type\":\"json\",\n            \"def\":{\n                \"fields\":[\n                    {\n                        \"docType\":\"asc\"\n                    },\n                    {\n                        \"owner\":\"asc\"\n                    }\n                ]\n            }\n        }\n    ]\n}\n```\n\n\n\n这个是在我刚启动好链码容器时，什么操作都没做。为什么会建了一个索引呢.\n\n另外，在这个文档下，发现存在一条记录(一打开就有一条记录)。\n\n```\n{\n    \"_id\":\"_design/indexOwnerDoc\",\n    \"_rev\":\"1-56c3e9386cb19531f6731afa88281caa\",\n    \"language\":\"query\",\n    \"views\":{\n        \"indexOwner\":{\n            \"map\":{\n                \"fields\":{\n                    \"docType\":\"asc\",\n                    \"owner\":\"asc\"\n                },\n                \"partial_filter_selector\":{\n\n                }\n            },\n            \"reduce\":\"_count\",\n            \"options\":{\n                \"def\":{\n                    \"fields\":[\n                        \"docType\",\n                        \"owner\"\n                    ]\n                }\n            }\n        }\n    }\n}\n```\n\n\n\n猜测，索引应该是由这条记录引起的，似乎是创建时的自动的索引？不对！是在我的链码里，有个文件夹叫META-INF下定义的。\n\n果然，这下面有个json文件，内容为\n\n```\n{\n\t\"index\":{\"fields\":[\"docType\",\"owner\"]},\n\t\"ddoc\":\"indexOwnerDoc\",\n\t\"name\":\"indexOwner\",\n\t\"type\":\"json\"\n}\n```\n\n完全吻合。所以定义索引是可以通过这个配置文件！\n\n定义的索引对于查询的意义，似乎是如果要查询相应的字段(字段相关，如大于啥小于啥)，就要定义包含其中的字段的索引\n\n默认情况下，会建立一个id的索引。\n\n```\n{\n \"type\": \"special\",\n \"def\": {\n  \"fields\": [\n   {\n    \"_id\": \"asc\"\n   }\n  ]\n }\n}\n```\n\n\n\n如新建一个索引视图\n\n```\ncurl -i -X POST -H \"Content-Type: application/json\" -d \"{\\\"index\\\":{\\\"fields\\\":[\\\"size\\\",\\\"docType\\\",\\\"owner\\\"]},\\\"ddoc\\\":\\\"indexSizeSortDoc1\\\", \\\"name\\\":\\\"indexSizeSortDesc1\\\",\\\"type\\\":\\\"json\\\"}\" http://localhost:5984/mychannel_mycc/_index\n```\n\n\n\n重新查询索引，多了一个\n\n```\n{\n    \"total_rows\":3,\n    \"indexes\":[\n        {\n         ...\n        },\n        {\n         ...\n        },\n        {\n            \"ddoc\":\"_design/indexSizeSortDoc\",\n            \"name\":\"indexSizeSortDesc\",\n            \"type\":\"json\",\n            \"def\":{\n                \"fields\":[\n                    {\n                        \"size\":\"desc\"\n                    },\n                    {\n                        \"docType\":\"desc\"\n                    },\n                    {\n                        \"owner\":\"desc\"\n                    }\n                ]\n            }\n        }\n    ]\n}\n```\n\n建立了这个索引后，就可以进行size相关的查询，如\n\n```\n\"{\\\"selector\\\":{\\\"docType\\\":{\\\"$eq\\\":\\\"marble\\\"},\\\"owner\\\":{\\\"$eq\\\":\\\"tom\\\"},\\\"size\\\":{\\\"$gt\\\":0}},\\\"fields\\\":[\\\"docType\\\",\\\"owner\\\",\\\"size\\\"],\\\"sort\\\":[{\\\"size\\\":\\\"desc\\\"}],\\\"use_index\\\":\\\"_design/indexSizeSortDoc\\\"}\"\n```\n\n**啊！！**就是建立的这个索引视图是包括size、docType、owner这三个的，然后我使用查询的时候，如果少传一个，就是我只查询docType和size，就会报错`Error running query. Reason: (no_usable_index) No index exists for this sort, try indexing by the sort fields.`\n\n几经挣扎和尝试，确定下来几个结论。\n\n1. 如果不适用sort，selector中的field都随意查询，使用的默认index(id asc排序)\n2. 如果使用了sort，那么需要一个index包含 在selector中的field + sort中的field组成的field ，并且index中定义的field集合必须是selector中的field + sort中的field组成的field的子集，即index中出现过的，在查询时一定要出现，在selector和在sort中都无所谓，但sort中的一定要出现在index中\n","slug":"fabric","published":1,"updated":"2019-10-14T07:04:57.064Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69xv002qt6xvqekde64h","content":"<h2 id=\"Fabric基本认识\"><a href=\"#Fabric基本认识\" class=\"headerlink\" title=\"Fabric基本认识\"></a>Fabric基本认识</h2><h3 id=\"基本架构\"><a href=\"#基本架构\" class=\"headerlink\" title=\"基本架构\"></a>基本架构</h3><p><a href=\"http://hyperledger-fabric.readthedocs.io/en/master/arch-deep-dive.html\" target=\"_blank\" rel=\"noopener\">官方文档</a></p>\n<p><img src=\"./fabric_macro.jpg\" alt=\"宏观图\"></p>\n<p>上图为fabric的基本结构图，以下解释各名词含义。</p>\n<ul>\n<li>application: 提供各种语言的SDK接口</li>\n<li>membership： 也就是fabric-ca，提供成员服务，用来管理身份，提供授权和认证</li>\n<li>peer: 负责模拟交易和记账<ul>\n<li>Endorser(背书)，peer执行交易并返回yes/no</li>\n<li>Committer，将验证过的区块追加到通道上各个账本的副本</li>\n<li>Ledger，账本</li>\n<li>chaincode，用来编写业务逻辑，交易指令用来修改资产，可以理解为fabric网络对外提供的一个交易接口（智能合约）</li>\n<li>Event是fabric提供的一个事件框架，比如链代码事件，拒绝事件，注册事件等，在编写代码的时候可以订阅这些事件来实现自己的业务逻辑。</li>\n</ul>\n</li>\n<li>o-service用来实现共识</li>\n</ul>\n<p>区块链运行称之为链码（chaincode）的程序，保存状态、账本数据，并执行交易。链码是中央元素，因为交易是在链码上调用的操作。交易必须被“endorsed”，而且只有被“endorsed”后的交易才能被提交。管理方法和参数可能存在一个或多个特殊链码，统称为系统链码。</p>\n<p><strong>交易</strong>可能有两种类型：</p>\n<ul>\n<li>部署事务，创建新的链接代码并将程序作为参数。当部署事务成功执行时，链代码已经安装在区块链上。</li>\n<li>调用事务，在先前部署的链式代码的上下文中执行操作。一个invoke事务引用了一个chaincode和它提供的函数之一。成功时，chaincode执行指定的功能 - 可能涉及修改相应的状态并返回输出。</li>\n</ul>\n<p>如后面所述，部署事务是调用事务的特例，其中创建新链代码的部署事务对应于系统链代码上的调用事务。</p>\n<p><strong>State</strong>，区块链的最新state被建模为版本化的键值存储（KVS），修改由运行在区块链上的链码（applications）调用KVS的put,get操作。详细的操作与版本化暂时略，看文档有点没看懂..State由peers进行维护，而不是orders和clients。KVS中的Keys可以从它们的名称中识别出属于特定的链码，因此只有特定链码的交易可以修改这个链码上的keys，但原则上，任何链码都可读别的链码的keys，即读取方便，但修改需特权。</p>\n<p><strong>Ledger, 账本</strong>，账本提供了发生在系统运行时的所有成功和不成功交易的历史。账本，作为总的区块总的哈希链（成功或不成功），由订阅服务构造。哈希链强制要求在账本中所有的有序区块以及每个块包含1个完全有序的交易，这在所有交易中强制要求所有的订阅。账本保存在所有的peer中，并可选择性的存放在orders中。在orders中，我们指的账本是OrdererLedger(总账)；在peers中，我们指的是PeerLedger（分账），分账和总账的区别在于peers本地会维护一个位掩码，这个位掩码会将有效的事务从无效的当中分离出来。peers可能会对分账进行修剪，orders负责维护总账的容错性和可用性并且可以随时修剪，前提是ordering服务的属性得到维护。账本允许peers重播所有交易的历史以及重建state,所以state是一个可选的数据结构。</p>\n<p><strong>节点</strong>，节点是区块链中的通信实体，节点只是一个逻辑功能，因为不同类型的多个节点可以在同一台物理服务器上运行，重要的是节点在“信任域”中如何分组并与控制它们的逻辑实体相关联。节点分为3种类型：</p>\n<ul>\n<li>Client 或 submitting-client: 提交真正交易给endorsers的客户，并且广播交易申请给ordering服务</li>\n<li>Peer：提交交易并维护state和账本的备份，除此之外，peers还有一个特殊的endorser角色</li>\n<li>Ordering-service-node或者order：通信服务 -&gt; 实现传递保证，例如原子性或者所有的order广播</li>\n</ul>\n<p>订阅服务提供了一个共享的通信通道给clients和peers, 提供的是一个包含交易信息的广播服务。client连接到通道，在通道中广播消息，消息将会送达给所有的peers。通道支持所有消息的原子性传递，即，消息通信是按序传递和可靠的。换句话说，通道给所有连接的peers输出的是相同消息，且是相同的逻辑顺序。这种原子性的通信保证在分布式系统中也被称为全序广播，原子广播，或者是共识。传递的消息是包含在区块链状态中的候选交易。</p>\n<h4 id=\"交易流程\"><a href=\"#交易流程\" class=\"headerlink\" title=\"交易流程\"></a>交易流程</h4><p>交易过程如下：</p>\n<ol>\n<li>Application向一个或多个peer节点发送对交易的背书请求。</li>\n<li>Peer的endorse执行背书，但并不将结果提交到本地账本，只是将结果返回给应用。</li>\n<li>应用收集所有背书节点的结果后，将结果广播给orderers，orderers执行共识，生成block，通过消息通道批量的将block发布给peer节点，更新lerdger。</li>\n</ol>\n<p>交易过程可如下图</p>\n<p><img src=\"./fabric_peer.jpg\" alt=\"交易过程\"></p>\n<h4 id=\"channel\"><a href=\"#channel\" class=\"headerlink\" title=\"channel\"></a>channel</h4><p>channel是构建在Fabric网络上的私有区块链，实现了数据的隔离和保密。channel是由特定的peer所共享的，并且交易方必须通过该通道的正确验证才能与账本进行交互。</p>\n<p>可以看到不同颜色的channel隔离了不同的peer之间的通信。</p>\n<p>Fabric提供了一个first-network的<u>demo</u>来学习整个流程。要学哦! 入手做一个<del>等理论搞定，明天能不能搞定理论 fabric的</del></p>\n<p>今天理论到一半了吧.. 然而又读不下去了，真的超枯燥…我先搞一下别的。</p>\n<p>first-network有两个组织，每个组织各有两个个peer节点，以及一个排序服务。两个peer节点无法达成共识，三个peer节点无法容错，四个peer节点刚好完成演示。</p>\n<h3 id=\"fabric-理解\"><a href=\"#fabric-理解\" class=\"headerlink\" title=\"fabric 理解\"></a>fabric 理解</h3><h4 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Policy for [Groups] /Channel/Application not satisfied: Failed to reach implicit threshold of 1 sub-policies, required [Admins]...</span><br></pre></td></tr></table></figure>\n\n<p>创建通道时，报错。</p>\n<p>创建通道，根据通道定义的策略，传入相关成员签名/证书。如果策略是or1.admin和org2.admin，就需要两个一起授权(数组..)</p>\n<p>首先检查是否是传入了相关用户，然后检查SigningIdentity是否正确，可打印出来对比<code>fmt.Println(string(identity.EnrollmentCertificate()))</code></p>\n<p>使用go-sdk的话会在tmp目录下有相关的数据目录，我的情况是先使用ca注册了一个admin..就会生成一个由ca签名的admin证书，但这个admin并不是org1.admin，所以我(⊙x⊙;)…删除了目录..  就还是不要注册admin这种敏感名字的用户了吧…</p>\n<p><code>peer chaincode instantiate -p git.wokoworks.com/blockchain/fabric-thread/multipeer/chaincode/go/test  -n mytest -v 0</code></p>\n<p>之后，在peer的<code>/var/hyperledger/production/chaincodes</code>目录下会有<code>mycc.0</code>的二进制？不晓得</p>\n<p>?好奇怪  这个是要peer安装的意思？</p>\n<p>安装和部署的区别</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  cli:</span><br><span class=\"line\">    container_name: cli</span><br><span class=\"line\">    image: hyperledger/fabric-tools</span><br><span class=\"line\">    tty: true</span><br><span class=\"line\">    environment:</span><br><span class=\"line\">      - GOPATH=/opt/gopath</span><br><span class=\"line\">      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock</span><br><span class=\"line\">      - FABRIC_LOGGING_SPEC=DEBUG</span><br><span class=\"line\">      - CORE_PEER_ID=cli</span><br><span class=\"line\">      - CORE_PEER_ADDRESS=peer:7051</span><br><span class=\"line\">      - CORE_PEER_LOCALMSPID=DEFAULT</span><br><span class=\"line\">      - CORE_PEER_MSPCONFIGPATH=/etc/hyperledger/msp</span><br><span class=\"line\">    working_dir: /opt/gopath/src/chaincodedev</span><br><span class=\"line\">#    command: /bin/bash -c &apos;./script.sh&apos;</span><br><span class=\"line\">    volumes:</span><br><span class=\"line\">      - /var/run/:/host/var/run/</span><br><span class=\"line\">      - ./nodes/peer1/msp:/etc/hyperledger/msp</span><br><span class=\"line\">      - /Users/xiaoxuez/go/src/github.com/hyperledger/fabric/examples/chaincode/go:/opt/gopath/src/chaincodedev/chaincode</span><br><span class=\"line\">      - ./:/opt/gopath/src/chaincodedev/</span><br><span class=\"line\">    depends_on:</span><br><span class=\"line\">      - orderer</span><br><span class=\"line\">      - peer1</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CORE_PEER_ADDRESS=peer1:7051 peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure.sh &quot;mychannel&quot; &quot;channel.tx anchor.tx&quot; &quot;peer1 peer2 peer3 peer4&quot; false</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"1-生成公私钥和证书\"><a href=\"#1-生成公私钥和证书\" class=\"headerlink\" title=\"1. 生成公私钥和证书\"></a>1. 生成公私钥和证书</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cryptogen generate  --config ./crypto-config.yaml --output crypto-config</span><br></pre></td></tr></table></figure>\n\n<p>—output 为生成后的文件夹</p>\n<p>crypto-config.yaml为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">OrdererOrgs:</span><br><span class=\"line\">  - Name: Orderer</span><br><span class=\"line\">    Domain: orderer.net</span><br><span class=\"line\">    CA:</span><br><span class=\"line\">      Country: US</span><br><span class=\"line\">      Province: California</span><br><span class=\"line\">      Locality: San Francisco</span><br><span class=\"line\">    Specs:</span><br><span class=\"line\">      - Hostname: orderer</span><br><span class=\"line\"></span><br><span class=\"line\">PeerOrgs:</span><br><span class=\"line\">  - Name: Org1</span><br><span class=\"line\">    Domain: org1.net</span><br><span class=\"line\">    CA:</span><br><span class=\"line\">      Country: US</span><br><span class=\"line\">      Province: California</span><br><span class=\"line\">      Locality: San Francisco</span><br><span class=\"line\">    Template:</span><br><span class=\"line\">      Count: 4</span><br><span class=\"line\">      Start: 1</span><br><span class=\"line\">    Users:</span><br><span class=\"line\">      Count: 1</span><br></pre></td></tr></table></figure>\n\n<p>有两个组织，为Orderer和Org1。使用命令后生成文件为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crypto-config</span><br><span class=\"line\">├── ordererOrganizations</span><br><span class=\"line\">│   └── orderer.net</span><br><span class=\"line\">│       ├── ca</span><br><span class=\"line\">│       ├── msp</span><br><span class=\"line\">│       ├── orderers</span><br><span class=\"line\">│       ├── tlsca</span><br><span class=\"line\">│       └── users</span><br><span class=\"line\">└── peerOrganizations</span><br><span class=\"line\">    └── org1.net</span><br><span class=\"line\">        ├── ca</span><br><span class=\"line\">        ├── msp</span><br><span class=\"line\">        ├── peers //count为4所以peers下面会有4个</span><br><span class=\"line\">        ├── tlsca</span><br><span class=\"line\">        └── users</span><br></pre></td></tr></table></figure>\n\n<p>关于证书，稍微说明一下看到的源码。</p>\n<p>首先，是两个组织，从cryptogen的角度上来讲，这两个组织的一切证书和公私钥生成方式是一样的。只是名字什么的是由配置文件决定的。</p>\n<p>其次，一组证书和公私钥的生成方式呢，分为几个步骤</p>\n<ol>\n<li>生成公私钥，由私钥对包含公钥的等信息进行签名可得证书。</li>\n<li>一个组织的证书链，包含一个root ca，可其签发的一系列证书。首先，会产生一对公私钥，这个私钥会作为root ca的私钥，config中定义的ca的其他属性会作为root ca的元数据(签名时应该会用到)，然后就会生成一个私钥文件，和一个root ca的证书(证书链中的顶级证书)，这两个文件位于ca文件夹。</li>\n<li>另外，因为fabric中需要两套证书，另外一套为tls，用于通信传输.. 所以会生成两套(生成逻辑是一毛一样的)，一套位于ca文件夹，一套位于tlsca文件夹。</li>\n<li>msp文件夹内的内容主要是ca和tlsca中的证书的拷贝(不包含私钥)，另外是有一个admin的用户证书(拷贝自用户目录)</li>\n<li>users目录和peers目录中，每个peer和user的逻辑都是生成了一对公私钥，随后，使用root ca和tlsca对公钥d等信息进行签名颁发证书，同样也包含两套证书，同时，还包括root ca和tlsca的自带证书</li>\n</ol>\n<p>关于证书验证的问题，启动ca服务端时会将root ca作为其签发证书的私钥，当用户注册并申请证书后获得证书，其实ca server返回的x509格式的证书申请结果中是含有证书和签发者的公钥信息的，但在fabric-sdk-go的使用中，enroll的结果返回只有证书，在封装的内层代码中将签发者的公钥信息直接忽略了。当用户拿到证书，进行交易发送到peer，peer如何验证证书呢.. peer目前只有两个签发者，一个是自己，一个是root ca(具有root ca的证书，所以就可以使用公钥验证)，所以应该是使用这两者进行验证吧。但是，再想想，其实正常的情况，构成了证书链的话，如果a -&gt; b -&gt; c的证书链的话，应该是用户提交的证书中，就会包含整个证书链，以后待考证？</p>\n<h4 id=\"2-生成初始块和配置的交易\"><a href=\"#2-生成初始块和配置的交易\" class=\"headerlink\" title=\"2. 生成初始块和配置的交易\"></a>2. 生成初始块和配置的交易</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configtxgen -profile SampleOrg -outputBlock ./channel-artifacts/genesis.block</span><br></pre></td></tr></table></figure>\n\n<p>这个命令会自动加载当前文件夹下的<code>configtx.yaml</code>配置文件，该文件配置了哪些</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CORE_PEER_ADDRESS=peer1:7051 peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0</span><br><span class=\"line\">//-p  Path to chaincode,</span><br><span class=\"line\">//  \t默认路径是从gopath下进行搜索，即上例中的路径为gopath/chaincodedev/chaincode/sacc, sacc为文件夹名称，只配置到文件夹即可</span><br><span class=\"line\">//-n, --name string                    Name of the chaincode</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">peer chaincode instantiate -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.admin&apos;,&apos;Org1MSP.member&apos;)&quot;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">peer chaincode instantiate -o orderer.example.com:7050  --tls true --cafile  /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n marbles02 -v 0 -c &apos;&#123;&quot;Args&quot;:[&quot;&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.admin&apos;,&apos;Org1MSP.member&apos;)&quot;</span><br><span class=\"line\">//没有配tsl的话就不虚要--tls true --cafile  -o也有默认值orderer.example.com:7050  -P默认值？</span><br></pre></td></tr></table></figure>\n\n<p>大概看了下，没怎么看透。基本的说一下，在configtx.yaml中，定义了初始组织的基本信息。其中Profiles提供了一些组合，这些组合可以提供生成genesis块(包含order信息组织和财团(Consortiums = =应该就是权限最大的组织))，可以生成新建channel的交易(包含一个Consortium和Application定义)。</p>\n<p>首先，会使用configtx.yaml生成创世块，OneOrgOrdererGenesis为Profiles中的定义的组合段落。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configtxgen -profile OneOrgOrdererGenesis -outputBlock ./config/genesis.block</span><br></pre></td></tr></table></figure>\n\n<p>其次，生成相应的通道，同理OneOrgChannel也是Profiles中的定义的组合段落。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configtxgen -profile  OneOrgChannel -outputCreateChannelTx ./config/channel.tx -channelID $CHANNEL_NAME</span><br></pre></td></tr></table></figure>\n\n<p>要新建通道的话，就要先使用上述生成通道的命令生成一个.tx的文件，然后再调用新建通道的命令传入这个文件。</p>\n<h3 id=\"go-sdk\"><a href=\"#go-sdk\" class=\"headerlink\" title=\"go-sdk\"></a>go-sdk</h3><h4 id=\"config-yaml\"><a href=\"#config-yaml\" class=\"headerlink\" title=\"config.yaml\"></a>config.yaml</h4><p>初始化sdk的时候需要传入config.yaml，所以这个配置文件是最关键的。</p>\n<p>在这个文件中，主要包含几个大块。</p>\n<ul>\n<li>client，客户端配置，即对自己的一些配置，包括自己所属组织，自己的msp文件(keys和certs)。BCCSP定义了加密的相关算法，还有就是tls证书配置</li>\n<li>channel, 配置通道，即当访问某通道时通过哪些peer(peer_name)，以及这个peer具有的权限，还有就是性能相关的配置。程序要访问不同的通道，这个就需要有相应的配置项。不然就会报<code>could not get chConfig reference</code></li>\n<li>organizations,配置网络中的参与者(org -&gt; peer_name 和 orderorg)</li>\n<li>orderers, 配置orderer的name和相关rpc的配置，tls配置</li>\n<li>peers，配置peers的name和相关rpc的配置，tls配置</li>\n<li>certificateAuthorities， 配置ca的name和相关rpc的配置，tls配置</li>\n<li>entityMatchers，这个是匹配替换，用于集中替换，可匹配正则的name，满足的实体(peer、orderer、ca)都会进行相应的替换，可用于替换url..</li>\n</ul>\n<h4 id=\"源码分析\"><a href=\"#源码分析\" class=\"headerlink\" title=\"源码分析\"></a>源码分析</h4><ul>\n<li><p>fabsdk.New(config)</p>\n<ul>\n<li>defPkgSuite，包管理工具，根据config提供相应的包，defaultPkgSuite提供的每个包都是工厂模式，根据config可提供对应的具体的包。<ul>\n<li>Core(corefactory)，提供了BCCSP、signing manager和fabric primitives的实现包。<ul>\n<li>BCCSP即区块链加密服务提供者，提供加密标准和算法的实现。目前支持两种实现，sw和pkcs11。<ul>\n<li>sw即software-based，基于软件实现的BCCSP，通过调用go原生支持的密码算法实现，并提供keystore来保存密钥</li>\n<li>pkcs11，通过调用pkcs11接口实现相关加密操作，仅支持ecdsa、rsa以及aes算法，密码保存在pkcs11通过pin口令保护的数据库或者硬件设备中。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>MSP，成员管理提供实现，如本地成员管理(从配置文件读入用户..本地存储用户等)，主要实现位于msppvdr包下。</li>\n<li>Service，服务提供实现，如channel服务、discovery服务等..</li>\n<li>Logger</li>\n</ul>\n</li>\n</ul>\n<p>所以，其实fabsdk.new就是提供了一大堆的provide。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//update sdk providers list since all required providers are initialized</span><br><span class=\"line\">\tsdk.provider = context.NewProvider(context.WithCryptoSuiteConfig(cfg.cryptoSuiteConfig),</span><br><span class=\"line\">\t\tcontext.WithEndpointConfig(cfg.endpointConfig),</span><br><span class=\"line\">\t\tcontext.WithIdentityConfig(cfg.identityConfig),</span><br><span class=\"line\">\t\tcontext.WithCryptoSuite(sdk.cryptoSuite),</span><br><span class=\"line\">\t\tcontext.WithSigningManager(signingManager),</span><br><span class=\"line\">\t\tcontext.WithUserStore(userStore),</span><br><span class=\"line\">\t\tcontext.WithLocalDiscoveryProvider(localDiscoveryProvider),</span><br><span class=\"line\">\t\tcontext.WithIdentityManagerProvider(identityManagerProvider),</span><br><span class=\"line\">\t\tcontext.WithInfraProvider(infraProvider),</span><br><span class=\"line\">\t\tcontext.WithChannelProvider(channelProvider),</span><br><span class=\"line\">\t\tcontext.WithClientMetrics(sdk.clientMetrics),</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\t...</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>总的来说，go-sdk是封装的rpc。所以有了sdk的相关上下文，就可以进行实例化相关的rpc client了。在pkg包下的client里，目录如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">├── channel   //通道相关的rpc</span><br><span class=\"line\">├── common</span><br><span class=\"line\">├── event\t//事件监听，如区块、链码、或交易状态</span><br><span class=\"line\">├── ledger\t//账本相关rpc,如查询区块、交易等</span><br><span class=\"line\">├── msp\t\t//成员相关rpc,与ca交互，提供注册查询等api</span><br><span class=\"line\">└── resmgmt\t//resouce manager clinet</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"msp\"><a href=\"#msp\" class=\"headerlink\" title=\"msp\"></a>msp</h4><p>msp包提供了与ca相关的rpc调用，如注册等。同时也提供了查询本地identify功能，即访问本地文件，查询出具体的私钥和相关证书(msppvdr包)。</p>\n<p>rpc相关调用包括以下功能</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 身份注册；</span><br><span class=\"line\">2. 颁发登录证书(ECerts)；</span><br><span class=\"line\">3. 颁发交易证书(TCerts)，保证链上交易的匿名性与不可连接性；</span><br><span class=\"line\">4. 证书续期与撤销</span><br></pre></td></tr></table></figure>\n\n<p>首先，只有已经登录了的身份才能发起注册的请求，而且必须有相应的权限来注册想要注册的身份类型。所以要注册用户，首先要使用一个已有的身份，然后再进行注册新用户和密码。</p>\n<ul>\n<li>Enroll方法，内容包括，生成新的私钥(存于config.credentialStore.cryptoStore/)，然后将公钥等信息作为参数，进行http请求ca服务器，ca服务器将返回对公钥等信息进行签名完的证书(存于config.credentialStore.path/)。<ul>\n<li>提到这里，多嘴一句，证书的存储文件名为<a href=\"mailto:name@Org1MSP-cert.pem\" target=\"_blank\" rel=\"noopener\">name@Org1MSP-cert.pem</a>，在进行查询时，可使用name或Org1MSP皆可查询到证书，然后通过对证书进行解析出公钥pubKey，name和pubKey.SKI()组成了私钥的文件名，从而可索引到私钥。</li>\n</ul>\n</li>\n</ul>\n<p>​        总的来说就是一次Enroll，就会更新一次私钥和证书。</p>\n<ul>\n<li><p>Register方法，进行注册，上文提到，要注册，首先要登录一个已有的身份(用户名)，获取证书，然后再使用证书进行注册别的身份。</p>\n<ul>\n<li><p>注册时可传属性，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">attributes:</span><br><span class=\"line\">        - name: hf.Revoker</span><br><span class=\"line\">        value: true</span><br><span class=\"line\">        ECert: true</span><br><span class=\"line\">        - name: anotherAttrName</span><br><span class=\"line\">        value: anotherAttrValue</span><br></pre></td></tr></table></figure>\n\n<p>这个应该是跟LDAP…相关的吧..暂时不知道是啥</p>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"channel-1\"><a href=\"#channel-1\" class=\"headerlink\" title=\"channel\"></a>channel</h4><p>通道相关api，如链码的调用。</p>\n<p>这里先对链码的调用简单分析一下。</p>\n<p>channel的客户端提供了两个方法<code>Query</code>和<code>Execute</code></p>\n<p>先说二者的共同流程。两个方法都是负责组装参数(handlers…opts..)后调用<code>chclinet.InvokeHandler</code>。在<code>InvokeHandler</code>里可以看到流程是准备参数，准备上下文，然后启动一个协程运行handlers，本方法堵塞直到complete或reqCtx.Done()通道读出消息，当handlers运行完毕后会向通道complete写入消息(成功或失败都会写入)，reqCtx.Done()则是超时。所以重点是运行Handler。Handler的组装类似于生产线，如a -&gt; b -&gt;c按顺序执行，且将上一个执行的结果也传递给下一位。</p>\n<ul>\n<li><p>Query</p>\n<ul>\n<li><p>ProposalProcessorHandler</p>\n<p>首先，检查targets参数长度是否为0，targets为进行背书的节点们。如果没有提供targets，将会查询背书的节点，opts参数中的filter将会在这里使用到，就是按需求筛选节点(如是查询还是背书…)</p>\n</li>\n<li><p>EndorsementHandler</p>\n<p>其次，会将proposal发送到各个targets，返回的responses会传递下去</p>\n</li>\n<li><p>EndorsementValidationHandler</p>\n<p>再次，验证各个target返回的结果，状态码是否正常，reponse是否一样</p>\n</li>\n<li><p>SignatureValidationHandler</p>\n<p>最后，验证各个节点返回的response的签名/证书是否正确</p>\n</li>\n</ul>\n<p>到此为止，query请求就完成了，最后将reponse返回给上层</p>\n</li>\n<li><p>Execute</p>\n<ul>\n<li><p>SelectAndEndorseHandler</p>\n<p>首先检查targets，其次调用EndorsementHandler发送proposal，然后根据链码策略向另外的peer发起proposal，返回的responses一起传递下去</p>\n</li>\n<li><p>EndorsementValidationHandler</p>\n<p>同上</p>\n</li>\n<li><p>SignatureValidationHandler</p>\n<p>同上</p>\n</li>\n<li><p>CommitHandler</p>\n<p>拿到所有peer的背书后，首先向order发送交易。然后订阅这笔交易状态，接收到新状态，方法执行结束，继续向下执行</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>response结构体中包含有Payload，ChaincodeStatus，TxValidationCode。</p>\n<p>在github.com/hyperledger/fabric/protos/peer下有TxValidationCode的所有码，可判断如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">switch pb.TxValidationCode(response.TxValidationCode) &#123;</span><br><span class=\"line\">\tcase pb.TxValidationCode_VALID:</span><br><span class=\"line\">\t\tcliconfig.Config().Logger().Debugf(&quot;(%s) - Successfully committed transaction [%s] ...\\n&quot;, t.id, response.TransactionID)</span><br><span class=\"line\">\t\treturn nil</span><br><span class=\"line\">\tcase pb.TxValidationCode_DUPLICATE_TXID, pb.TxValidationCode_MVCC_READ_CONFLICT, pb.TxValidationCode_PHANTOM_READ_CONFLICT:</span><br><span class=\"line\">\t\tcliconfig.Config().Logger().Debugf(&quot;(%s) - Transaction commit failed for [%s] with code [%s]. This is most likely a transient error.\\n&quot;, t.id, response.TransactionID, response.TxValidationCode)</span><br><span class=\"line\">\t\treturn invokeerror.Wrapf(invokeerror.TransientError, errors.New(&quot;Duplicate TxID&quot;), &quot;invoke Error received from eventhub for TxID [%s]. Code: %s&quot;, response.TransactionID, response.TxValidationCode)</span><br><span class=\"line\">\tdefault:</span><br><span class=\"line\">\t\tcliconfig.Config().Logger().Debugf(&quot;(%s) - Transaction commit failed for [%s] with code [%s].\\n&quot;, t.id, response.TransactionID, response.TxValidationCode)</span><br><span class=\"line\">\t\treturn invokeerror.Wrapf(invokeerror.PersistentError, errors.New(&quot;error&quot;), &quot;invoke Error received from eventhub for TxID [%s]. Code: %s&quot;, response.TransactionID, response.TxValidationCode)</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"sdk-example\"><a href=\"#sdk-example\" class=\"headerlink\" title=\"sdk example\"></a>sdk example</h4><p><a href=\"https://github.com/securekey/fabric-examples/tree/master/fabric-cli\">Sdk example </a></p>\n<h2 id=\"couchdb\"><a href=\"#couchdb\" class=\"headerlink\" title=\"couchdb\"></a>couchdb</h2><h4 id=\"查询索引\"><a href=\"#查询索引\" class=\"headerlink\" title=\"查询索引\"></a>查询索引</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost:5984/mychannel_mycc/_index</span><br></pre></td></tr></table></figure>\n\n<p>查询结果如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;total_rows&quot;:2,</span><br><span class=\"line\">    &quot;indexes&quot;:[</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;ddoc&quot;:null,</span><br><span class=\"line\">            &quot;name&quot;:&quot;_all_docs&quot;,</span><br><span class=\"line\">            &quot;type&quot;:&quot;special&quot;,</span><br><span class=\"line\">            &quot;def&quot;:&#123;</span><br><span class=\"line\">                &quot;fields&quot;:[</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;_id&quot;:&quot;asc&quot;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;ddoc&quot;:&quot;_design/indexOwnerDoc&quot;,</span><br><span class=\"line\">            &quot;name&quot;:&quot;indexOwner&quot;,</span><br><span class=\"line\">            &quot;type&quot;:&quot;json&quot;,</span><br><span class=\"line\">            &quot;def&quot;:&#123;</span><br><span class=\"line\">                &quot;fields&quot;:[</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;docType&quot;:&quot;asc&quot;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;owner&quot;:&quot;asc&quot;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这个是在我刚启动好链码容器时，什么操作都没做。为什么会建了一个索引呢.</p>\n<p>另外，在这个文档下，发现存在一条记录(一打开就有一条记录)。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;_id&quot;:&quot;_design/indexOwnerDoc&quot;,</span><br><span class=\"line\">    &quot;_rev&quot;:&quot;1-56c3e9386cb19531f6731afa88281caa&quot;,</span><br><span class=\"line\">    &quot;language&quot;:&quot;query&quot;,</span><br><span class=\"line\">    &quot;views&quot;:&#123;</span><br><span class=\"line\">        &quot;indexOwner&quot;:&#123;</span><br><span class=\"line\">            &quot;map&quot;:&#123;</span><br><span class=\"line\">                &quot;fields&quot;:&#123;</span><br><span class=\"line\">                    &quot;docType&quot;:&quot;asc&quot;,</span><br><span class=\"line\">                    &quot;owner&quot;:&quot;asc&quot;</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                &quot;partial_filter_selector&quot;:&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;reduce&quot;:&quot;_count&quot;,</span><br><span class=\"line\">            &quot;options&quot;:&#123;</span><br><span class=\"line\">                &quot;def&quot;:&#123;</span><br><span class=\"line\">                    &quot;fields&quot;:[</span><br><span class=\"line\">                        &quot;docType&quot;,</span><br><span class=\"line\">                        &quot;owner&quot;</span><br><span class=\"line\">                    ]</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>猜测，索引应该是由这条记录引起的，似乎是创建时的自动的索引？不对！是在我的链码里，有个文件夹叫META-INF下定义的。</p>\n<p>果然，这下面有个json文件，内容为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">\t&quot;index&quot;:&#123;&quot;fields&quot;:[&quot;docType&quot;,&quot;owner&quot;]&#125;,</span><br><span class=\"line\">\t&quot;ddoc&quot;:&quot;indexOwnerDoc&quot;,</span><br><span class=\"line\">\t&quot;name&quot;:&quot;indexOwner&quot;,</span><br><span class=\"line\">\t&quot;type&quot;:&quot;json&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>完全吻合。所以定义索引是可以通过这个配置文件！</p>\n<p>定义的索引对于查询的意义，似乎是如果要查询相应的字段(字段相关，如大于啥小于啥)，就要定义包含其中的字段的索引</p>\n<p>默认情况下，会建立一个id的索引。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\"> &quot;type&quot;: &quot;special&quot;,</span><br><span class=\"line\"> &quot;def&quot;: &#123;</span><br><span class=\"line\">  &quot;fields&quot;: [</span><br><span class=\"line\">   &#123;</span><br><span class=\"line\">    &quot;_id&quot;: &quot;asc&quot;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如新建一个索引视图</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -i -X POST -H &quot;Content-Type: application/json&quot; -d &quot;&#123;\\&quot;index\\&quot;:&#123;\\&quot;fields\\&quot;:[\\&quot;size\\&quot;,\\&quot;docType\\&quot;,\\&quot;owner\\&quot;]&#125;,\\&quot;ddoc\\&quot;:\\&quot;indexSizeSortDoc1\\&quot;, \\&quot;name\\&quot;:\\&quot;indexSizeSortDesc1\\&quot;,\\&quot;type\\&quot;:\\&quot;json\\&quot;&#125;&quot; http://localhost:5984/mychannel_mycc/_index</span><br></pre></td></tr></table></figure>\n\n<p>重新查询索引，多了一个</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;total_rows&quot;:3,</span><br><span class=\"line\">    &quot;indexes&quot;:[</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">         ...</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">         ...</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;ddoc&quot;:&quot;_design/indexSizeSortDoc&quot;,</span><br><span class=\"line\">            &quot;name&quot;:&quot;indexSizeSortDesc&quot;,</span><br><span class=\"line\">            &quot;type&quot;:&quot;json&quot;,</span><br><span class=\"line\">            &quot;def&quot;:&#123;</span><br><span class=\"line\">                &quot;fields&quot;:[</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;size&quot;:&quot;desc&quot;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;docType&quot;:&quot;desc&quot;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;owner&quot;:&quot;desc&quot;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>建立了这个索引后，就可以进行size相关的查询，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;&#123;\\&quot;selector\\&quot;:&#123;\\&quot;docType\\&quot;:&#123;\\&quot;$eq\\&quot;:\\&quot;marble\\&quot;&#125;,\\&quot;owner\\&quot;:&#123;\\&quot;$eq\\&quot;:\\&quot;tom\\&quot;&#125;,\\&quot;size\\&quot;:&#123;\\&quot;$gt\\&quot;:0&#125;&#125;,\\&quot;fields\\&quot;:[\\&quot;docType\\&quot;,\\&quot;owner\\&quot;,\\&quot;size\\&quot;],\\&quot;sort\\&quot;:[&#123;\\&quot;size\\&quot;:\\&quot;desc\\&quot;&#125;],\\&quot;use_index\\&quot;:\\&quot;_design/indexSizeSortDoc\\&quot;&#125;&quot;</span><br></pre></td></tr></table></figure>\n\n<p><strong>啊！！</strong>就是建立的这个索引视图是包括size、docType、owner这三个的，然后我使用查询的时候，如果少传一个，就是我只查询docType和size，就会报错<code>Error running query. Reason: (no_usable_index) No index exists for this sort, try indexing by the sort fields.</code></p>\n<p>几经挣扎和尝试，确定下来几个结论。</p>\n<ol>\n<li>如果不适用sort，selector中的field都随意查询，使用的默认index(id asc排序)</li>\n<li>如果使用了sort，那么需要一个index包含 在selector中的field + sort中的field组成的field ，并且index中定义的field集合必须是selector中的field + sort中的field组成的field的子集，即index中出现过的，在查询时一定要出现，在selector和在sort中都无所谓，但sort中的一定要出现在index中</li>\n</ol>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Fabric基本认识\"><a href=\"#Fabric基本认识\" class=\"headerlink\" title=\"Fabric基本认识\"></a>Fabric基本认识</h2><h3 id=\"基本架构\"><a href=\"#基本架构\" class=\"headerlink\" title=\"基本架构\"></a>基本架构</h3><p><a href=\"http://hyperledger-fabric.readthedocs.io/en/master/arch-deep-dive.html\" target=\"_blank\" rel=\"noopener\">官方文档</a></p>\n<p><img src=\"./fabric_macro.jpg\" alt=\"宏观图\"></p>\n<p>上图为fabric的基本结构图，以下解释各名词含义。</p>\n<ul>\n<li>application: 提供各种语言的SDK接口</li>\n<li>membership： 也就是fabric-ca，提供成员服务，用来管理身份，提供授权和认证</li>\n<li>peer: 负责模拟交易和记账<ul>\n<li>Endorser(背书)，peer执行交易并返回yes/no</li>\n<li>Committer，将验证过的区块追加到通道上各个账本的副本</li>\n<li>Ledger，账本</li>\n<li>chaincode，用来编写业务逻辑，交易指令用来修改资产，可以理解为fabric网络对外提供的一个交易接口（智能合约）</li>\n<li>Event是fabric提供的一个事件框架，比如链代码事件，拒绝事件，注册事件等，在编写代码的时候可以订阅这些事件来实现自己的业务逻辑。</li>\n</ul>\n</li>\n<li>o-service用来实现共识</li>\n</ul>\n<p>区块链运行称之为链码（chaincode）的程序，保存状态、账本数据，并执行交易。链码是中央元素，因为交易是在链码上调用的操作。交易必须被“endorsed”，而且只有被“endorsed”后的交易才能被提交。管理方法和参数可能存在一个或多个特殊链码，统称为系统链码。</p>\n<p><strong>交易</strong>可能有两种类型：</p>\n<ul>\n<li>部署事务，创建新的链接代码并将程序作为参数。当部署事务成功执行时，链代码已经安装在区块链上。</li>\n<li>调用事务，在先前部署的链式代码的上下文中执行操作。一个invoke事务引用了一个chaincode和它提供的函数之一。成功时，chaincode执行指定的功能 - 可能涉及修改相应的状态并返回输出。</li>\n</ul>\n<p>如后面所述，部署事务是调用事务的特例，其中创建新链代码的部署事务对应于系统链代码上的调用事务。</p>\n<p><strong>State</strong>，区块链的最新state被建模为版本化的键值存储（KVS），修改由运行在区块链上的链码（applications）调用KVS的put,get操作。详细的操作与版本化暂时略，看文档有点没看懂..State由peers进行维护，而不是orders和clients。KVS中的Keys可以从它们的名称中识别出属于特定的链码，因此只有特定链码的交易可以修改这个链码上的keys，但原则上，任何链码都可读别的链码的keys，即读取方便，但修改需特权。</p>\n<p><strong>Ledger, 账本</strong>，账本提供了发生在系统运行时的所有成功和不成功交易的历史。账本，作为总的区块总的哈希链（成功或不成功），由订阅服务构造。哈希链强制要求在账本中所有的有序区块以及每个块包含1个完全有序的交易，这在所有交易中强制要求所有的订阅。账本保存在所有的peer中，并可选择性的存放在orders中。在orders中，我们指的账本是OrdererLedger(总账)；在peers中，我们指的是PeerLedger（分账），分账和总账的区别在于peers本地会维护一个位掩码，这个位掩码会将有效的事务从无效的当中分离出来。peers可能会对分账进行修剪，orders负责维护总账的容错性和可用性并且可以随时修剪，前提是ordering服务的属性得到维护。账本允许peers重播所有交易的历史以及重建state,所以state是一个可选的数据结构。</p>\n<p><strong>节点</strong>，节点是区块链中的通信实体，节点只是一个逻辑功能，因为不同类型的多个节点可以在同一台物理服务器上运行，重要的是节点在“信任域”中如何分组并与控制它们的逻辑实体相关联。节点分为3种类型：</p>\n<ul>\n<li>Client 或 submitting-client: 提交真正交易给endorsers的客户，并且广播交易申请给ordering服务</li>\n<li>Peer：提交交易并维护state和账本的备份，除此之外，peers还有一个特殊的endorser角色</li>\n<li>Ordering-service-node或者order：通信服务 -&gt; 实现传递保证，例如原子性或者所有的order广播</li>\n</ul>\n<p>订阅服务提供了一个共享的通信通道给clients和peers, 提供的是一个包含交易信息的广播服务。client连接到通道，在通道中广播消息，消息将会送达给所有的peers。通道支持所有消息的原子性传递，即，消息通信是按序传递和可靠的。换句话说，通道给所有连接的peers输出的是相同消息，且是相同的逻辑顺序。这种原子性的通信保证在分布式系统中也被称为全序广播，原子广播，或者是共识。传递的消息是包含在区块链状态中的候选交易。</p>\n<h4 id=\"交易流程\"><a href=\"#交易流程\" class=\"headerlink\" title=\"交易流程\"></a>交易流程</h4><p>交易过程如下：</p>\n<ol>\n<li>Application向一个或多个peer节点发送对交易的背书请求。</li>\n<li>Peer的endorse执行背书，但并不将结果提交到本地账本，只是将结果返回给应用。</li>\n<li>应用收集所有背书节点的结果后，将结果广播给orderers，orderers执行共识，生成block，通过消息通道批量的将block发布给peer节点，更新lerdger。</li>\n</ol>\n<p>交易过程可如下图</p>\n<p><img src=\"./fabric_peer.jpg\" alt=\"交易过程\"></p>\n<h4 id=\"channel\"><a href=\"#channel\" class=\"headerlink\" title=\"channel\"></a>channel</h4><p>channel是构建在Fabric网络上的私有区块链，实现了数据的隔离和保密。channel是由特定的peer所共享的，并且交易方必须通过该通道的正确验证才能与账本进行交互。</p>\n<p>可以看到不同颜色的channel隔离了不同的peer之间的通信。</p>\n<p>Fabric提供了一个first-network的<u>demo</u>来学习整个流程。要学哦! 入手做一个<del>等理论搞定，明天能不能搞定理论 fabric的</del></p>\n<p>今天理论到一半了吧.. 然而又读不下去了，真的超枯燥…我先搞一下别的。</p>\n<p>first-network有两个组织，每个组织各有两个个peer节点，以及一个排序服务。两个peer节点无法达成共识，三个peer节点无法容错，四个peer节点刚好完成演示。</p>\n<h3 id=\"fabric-理解\"><a href=\"#fabric-理解\" class=\"headerlink\" title=\"fabric 理解\"></a>fabric 理解</h3><h4 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Policy for [Groups] /Channel/Application not satisfied: Failed to reach implicit threshold of 1 sub-policies, required [Admins]...</span><br></pre></td></tr></table></figure>\n\n<p>创建通道时，报错。</p>\n<p>创建通道，根据通道定义的策略，传入相关成员签名/证书。如果策略是or1.admin和org2.admin，就需要两个一起授权(数组..)</p>\n<p>首先检查是否是传入了相关用户，然后检查SigningIdentity是否正确，可打印出来对比<code>fmt.Println(string(identity.EnrollmentCertificate()))</code></p>\n<p>使用go-sdk的话会在tmp目录下有相关的数据目录，我的情况是先使用ca注册了一个admin..就会生成一个由ca签名的admin证书，但这个admin并不是org1.admin，所以我(⊙x⊙;)…删除了目录..  就还是不要注册admin这种敏感名字的用户了吧…</p>\n<p><code>peer chaincode instantiate -p git.wokoworks.com/blockchain/fabric-thread/multipeer/chaincode/go/test  -n mytest -v 0</code></p>\n<p>之后，在peer的<code>/var/hyperledger/production/chaincodes</code>目录下会有<code>mycc.0</code>的二进制？不晓得</p>\n<p>?好奇怪  这个是要peer安装的意思？</p>\n<p>安装和部署的区别</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  cli:</span><br><span class=\"line\">    container_name: cli</span><br><span class=\"line\">    image: hyperledger/fabric-tools</span><br><span class=\"line\">    tty: true</span><br><span class=\"line\">    environment:</span><br><span class=\"line\">      - GOPATH=/opt/gopath</span><br><span class=\"line\">      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock</span><br><span class=\"line\">      - FABRIC_LOGGING_SPEC=DEBUG</span><br><span class=\"line\">      - CORE_PEER_ID=cli</span><br><span class=\"line\">      - CORE_PEER_ADDRESS=peer:7051</span><br><span class=\"line\">      - CORE_PEER_LOCALMSPID=DEFAULT</span><br><span class=\"line\">      - CORE_PEER_MSPCONFIGPATH=/etc/hyperledger/msp</span><br><span class=\"line\">    working_dir: /opt/gopath/src/chaincodedev</span><br><span class=\"line\">#    command: /bin/bash -c &apos;./script.sh&apos;</span><br><span class=\"line\">    volumes:</span><br><span class=\"line\">      - /var/run/:/host/var/run/</span><br><span class=\"line\">      - ./nodes/peer1/msp:/etc/hyperledger/msp</span><br><span class=\"line\">      - /Users/xiaoxuez/go/src/github.com/hyperledger/fabric/examples/chaincode/go:/opt/gopath/src/chaincodedev/chaincode</span><br><span class=\"line\">      - ./:/opt/gopath/src/chaincodedev/</span><br><span class=\"line\">    depends_on:</span><br><span class=\"line\">      - orderer</span><br><span class=\"line\">      - peer1</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CORE_PEER_ADDRESS=peer1:7051 peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure.sh &quot;mychannel&quot; &quot;channel.tx anchor.tx&quot; &quot;peer1 peer2 peer3 peer4&quot; false</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"1-生成公私钥和证书\"><a href=\"#1-生成公私钥和证书\" class=\"headerlink\" title=\"1. 生成公私钥和证书\"></a>1. 生成公私钥和证书</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cryptogen generate  --config ./crypto-config.yaml --output crypto-config</span><br></pre></td></tr></table></figure>\n\n<p>—output 为生成后的文件夹</p>\n<p>crypto-config.yaml为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">OrdererOrgs:</span><br><span class=\"line\">  - Name: Orderer</span><br><span class=\"line\">    Domain: orderer.net</span><br><span class=\"line\">    CA:</span><br><span class=\"line\">      Country: US</span><br><span class=\"line\">      Province: California</span><br><span class=\"line\">      Locality: San Francisco</span><br><span class=\"line\">    Specs:</span><br><span class=\"line\">      - Hostname: orderer</span><br><span class=\"line\"></span><br><span class=\"line\">PeerOrgs:</span><br><span class=\"line\">  - Name: Org1</span><br><span class=\"line\">    Domain: org1.net</span><br><span class=\"line\">    CA:</span><br><span class=\"line\">      Country: US</span><br><span class=\"line\">      Province: California</span><br><span class=\"line\">      Locality: San Francisco</span><br><span class=\"line\">    Template:</span><br><span class=\"line\">      Count: 4</span><br><span class=\"line\">      Start: 1</span><br><span class=\"line\">    Users:</span><br><span class=\"line\">      Count: 1</span><br></pre></td></tr></table></figure>\n\n<p>有两个组织，为Orderer和Org1。使用命令后生成文件为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crypto-config</span><br><span class=\"line\">├── ordererOrganizations</span><br><span class=\"line\">│   └── orderer.net</span><br><span class=\"line\">│       ├── ca</span><br><span class=\"line\">│       ├── msp</span><br><span class=\"line\">│       ├── orderers</span><br><span class=\"line\">│       ├── tlsca</span><br><span class=\"line\">│       └── users</span><br><span class=\"line\">└── peerOrganizations</span><br><span class=\"line\">    └── org1.net</span><br><span class=\"line\">        ├── ca</span><br><span class=\"line\">        ├── msp</span><br><span class=\"line\">        ├── peers //count为4所以peers下面会有4个</span><br><span class=\"line\">        ├── tlsca</span><br><span class=\"line\">        └── users</span><br></pre></td></tr></table></figure>\n\n<p>关于证书，稍微说明一下看到的源码。</p>\n<p>首先，是两个组织，从cryptogen的角度上来讲，这两个组织的一切证书和公私钥生成方式是一样的。只是名字什么的是由配置文件决定的。</p>\n<p>其次，一组证书和公私钥的生成方式呢，分为几个步骤</p>\n<ol>\n<li>生成公私钥，由私钥对包含公钥的等信息进行签名可得证书。</li>\n<li>一个组织的证书链，包含一个root ca，可其签发的一系列证书。首先，会产生一对公私钥，这个私钥会作为root ca的私钥，config中定义的ca的其他属性会作为root ca的元数据(签名时应该会用到)，然后就会生成一个私钥文件，和一个root ca的证书(证书链中的顶级证书)，这两个文件位于ca文件夹。</li>\n<li>另外，因为fabric中需要两套证书，另外一套为tls，用于通信传输.. 所以会生成两套(生成逻辑是一毛一样的)，一套位于ca文件夹，一套位于tlsca文件夹。</li>\n<li>msp文件夹内的内容主要是ca和tlsca中的证书的拷贝(不包含私钥)，另外是有一个admin的用户证书(拷贝自用户目录)</li>\n<li>users目录和peers目录中，每个peer和user的逻辑都是生成了一对公私钥，随后，使用root ca和tlsca对公钥d等信息进行签名颁发证书，同样也包含两套证书，同时，还包括root ca和tlsca的自带证书</li>\n</ol>\n<p>关于证书验证的问题，启动ca服务端时会将root ca作为其签发证书的私钥，当用户注册并申请证书后获得证书，其实ca server返回的x509格式的证书申请结果中是含有证书和签发者的公钥信息的，但在fabric-sdk-go的使用中，enroll的结果返回只有证书，在封装的内层代码中将签发者的公钥信息直接忽略了。当用户拿到证书，进行交易发送到peer，peer如何验证证书呢.. peer目前只有两个签发者，一个是自己，一个是root ca(具有root ca的证书，所以就可以使用公钥验证)，所以应该是使用这两者进行验证吧。但是，再想想，其实正常的情况，构成了证书链的话，如果a -&gt; b -&gt; c的证书链的话，应该是用户提交的证书中，就会包含整个证书链，以后待考证？</p>\n<h4 id=\"2-生成初始块和配置的交易\"><a href=\"#2-生成初始块和配置的交易\" class=\"headerlink\" title=\"2. 生成初始块和配置的交易\"></a>2. 生成初始块和配置的交易</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configtxgen -profile SampleOrg -outputBlock ./channel-artifacts/genesis.block</span><br></pre></td></tr></table></figure>\n\n<p>这个命令会自动加载当前文件夹下的<code>configtx.yaml</code>配置文件，该文件配置了哪些</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CORE_PEER_ADDRESS=peer1:7051 peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0</span><br><span class=\"line\">//-p  Path to chaincode,</span><br><span class=\"line\">//  \t默认路径是从gopath下进行搜索，即上例中的路径为gopath/chaincodedev/chaincode/sacc, sacc为文件夹名称，只配置到文件夹即可</span><br><span class=\"line\">//-n, --name string                    Name of the chaincode</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">peer chaincode instantiate -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.admin&apos;,&apos;Org1MSP.member&apos;)&quot;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">peer chaincode instantiate -o orderer.example.com:7050  --tls true --cafile  /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n marbles02 -v 0 -c &apos;&#123;&quot;Args&quot;:[&quot;&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.admin&apos;,&apos;Org1MSP.member&apos;)&quot;</span><br><span class=\"line\">//没有配tsl的话就不虚要--tls true --cafile  -o也有默认值orderer.example.com:7050  -P默认值？</span><br></pre></td></tr></table></figure>\n\n<p>大概看了下，没怎么看透。基本的说一下，在configtx.yaml中，定义了初始组织的基本信息。其中Profiles提供了一些组合，这些组合可以提供生成genesis块(包含order信息组织和财团(Consortiums = =应该就是权限最大的组织))，可以生成新建channel的交易(包含一个Consortium和Application定义)。</p>\n<p>首先，会使用configtx.yaml生成创世块，OneOrgOrdererGenesis为Profiles中的定义的组合段落。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configtxgen -profile OneOrgOrdererGenesis -outputBlock ./config/genesis.block</span><br></pre></td></tr></table></figure>\n\n<p>其次，生成相应的通道，同理OneOrgChannel也是Profiles中的定义的组合段落。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configtxgen -profile  OneOrgChannel -outputCreateChannelTx ./config/channel.tx -channelID $CHANNEL_NAME</span><br></pre></td></tr></table></figure>\n\n<p>要新建通道的话，就要先使用上述生成通道的命令生成一个.tx的文件，然后再调用新建通道的命令传入这个文件。</p>\n<h3 id=\"go-sdk\"><a href=\"#go-sdk\" class=\"headerlink\" title=\"go-sdk\"></a>go-sdk</h3><h4 id=\"config-yaml\"><a href=\"#config-yaml\" class=\"headerlink\" title=\"config.yaml\"></a>config.yaml</h4><p>初始化sdk的时候需要传入config.yaml，所以这个配置文件是最关键的。</p>\n<p>在这个文件中，主要包含几个大块。</p>\n<ul>\n<li>client，客户端配置，即对自己的一些配置，包括自己所属组织，自己的msp文件(keys和certs)。BCCSP定义了加密的相关算法，还有就是tls证书配置</li>\n<li>channel, 配置通道，即当访问某通道时通过哪些peer(peer_name)，以及这个peer具有的权限，还有就是性能相关的配置。程序要访问不同的通道，这个就需要有相应的配置项。不然就会报<code>could not get chConfig reference</code></li>\n<li>organizations,配置网络中的参与者(org -&gt; peer_name 和 orderorg)</li>\n<li>orderers, 配置orderer的name和相关rpc的配置，tls配置</li>\n<li>peers，配置peers的name和相关rpc的配置，tls配置</li>\n<li>certificateAuthorities， 配置ca的name和相关rpc的配置，tls配置</li>\n<li>entityMatchers，这个是匹配替换，用于集中替换，可匹配正则的name，满足的实体(peer、orderer、ca)都会进行相应的替换，可用于替换url..</li>\n</ul>\n<h4 id=\"源码分析\"><a href=\"#源码分析\" class=\"headerlink\" title=\"源码分析\"></a>源码分析</h4><ul>\n<li><p>fabsdk.New(config)</p>\n<ul>\n<li>defPkgSuite，包管理工具，根据config提供相应的包，defaultPkgSuite提供的每个包都是工厂模式，根据config可提供对应的具体的包。<ul>\n<li>Core(corefactory)，提供了BCCSP、signing manager和fabric primitives的实现包。<ul>\n<li>BCCSP即区块链加密服务提供者，提供加密标准和算法的实现。目前支持两种实现，sw和pkcs11。<ul>\n<li>sw即software-based，基于软件实现的BCCSP，通过调用go原生支持的密码算法实现，并提供keystore来保存密钥</li>\n<li>pkcs11，通过调用pkcs11接口实现相关加密操作，仅支持ecdsa、rsa以及aes算法，密码保存在pkcs11通过pin口令保护的数据库或者硬件设备中。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>MSP，成员管理提供实现，如本地成员管理(从配置文件读入用户..本地存储用户等)，主要实现位于msppvdr包下。</li>\n<li>Service，服务提供实现，如channel服务、discovery服务等..</li>\n<li>Logger</li>\n</ul>\n</li>\n</ul>\n<p>所以，其实fabsdk.new就是提供了一大堆的provide。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//update sdk providers list since all required providers are initialized</span><br><span class=\"line\">\tsdk.provider = context.NewProvider(context.WithCryptoSuiteConfig(cfg.cryptoSuiteConfig),</span><br><span class=\"line\">\t\tcontext.WithEndpointConfig(cfg.endpointConfig),</span><br><span class=\"line\">\t\tcontext.WithIdentityConfig(cfg.identityConfig),</span><br><span class=\"line\">\t\tcontext.WithCryptoSuite(sdk.cryptoSuite),</span><br><span class=\"line\">\t\tcontext.WithSigningManager(signingManager),</span><br><span class=\"line\">\t\tcontext.WithUserStore(userStore),</span><br><span class=\"line\">\t\tcontext.WithLocalDiscoveryProvider(localDiscoveryProvider),</span><br><span class=\"line\">\t\tcontext.WithIdentityManagerProvider(identityManagerProvider),</span><br><span class=\"line\">\t\tcontext.WithInfraProvider(infraProvider),</span><br><span class=\"line\">\t\tcontext.WithChannelProvider(channelProvider),</span><br><span class=\"line\">\t\tcontext.WithClientMetrics(sdk.clientMetrics),</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\t...</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>总的来说，go-sdk是封装的rpc。所以有了sdk的相关上下文，就可以进行实例化相关的rpc client了。在pkg包下的client里，目录如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">├── channel   //通道相关的rpc</span><br><span class=\"line\">├── common</span><br><span class=\"line\">├── event\t//事件监听，如区块、链码、或交易状态</span><br><span class=\"line\">├── ledger\t//账本相关rpc,如查询区块、交易等</span><br><span class=\"line\">├── msp\t\t//成员相关rpc,与ca交互，提供注册查询等api</span><br><span class=\"line\">└── resmgmt\t//resouce manager clinet</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"msp\"><a href=\"#msp\" class=\"headerlink\" title=\"msp\"></a>msp</h4><p>msp包提供了与ca相关的rpc调用，如注册等。同时也提供了查询本地identify功能，即访问本地文件，查询出具体的私钥和相关证书(msppvdr包)。</p>\n<p>rpc相关调用包括以下功能</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 身份注册；</span><br><span class=\"line\">2. 颁发登录证书(ECerts)；</span><br><span class=\"line\">3. 颁发交易证书(TCerts)，保证链上交易的匿名性与不可连接性；</span><br><span class=\"line\">4. 证书续期与撤销</span><br></pre></td></tr></table></figure>\n\n<p>首先，只有已经登录了的身份才能发起注册的请求，而且必须有相应的权限来注册想要注册的身份类型。所以要注册用户，首先要使用一个已有的身份，然后再进行注册新用户和密码。</p>\n<ul>\n<li>Enroll方法，内容包括，生成新的私钥(存于config.credentialStore.cryptoStore/)，然后将公钥等信息作为参数，进行http请求ca服务器，ca服务器将返回对公钥等信息进行签名完的证书(存于config.credentialStore.path/)。<ul>\n<li>提到这里，多嘴一句，证书的存储文件名为<a href=\"mailto:name@Org1MSP-cert.pem\" target=\"_blank\" rel=\"noopener\">name@Org1MSP-cert.pem</a>，在进行查询时，可使用name或Org1MSP皆可查询到证书，然后通过对证书进行解析出公钥pubKey，name和pubKey.SKI()组成了私钥的文件名，从而可索引到私钥。</li>\n</ul>\n</li>\n</ul>\n<p>​        总的来说就是一次Enroll，就会更新一次私钥和证书。</p>\n<ul>\n<li><p>Register方法，进行注册，上文提到，要注册，首先要登录一个已有的身份(用户名)，获取证书，然后再使用证书进行注册别的身份。</p>\n<ul>\n<li><p>注册时可传属性，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">attributes:</span><br><span class=\"line\">        - name: hf.Revoker</span><br><span class=\"line\">        value: true</span><br><span class=\"line\">        ECert: true</span><br><span class=\"line\">        - name: anotherAttrName</span><br><span class=\"line\">        value: anotherAttrValue</span><br></pre></td></tr></table></figure>\n\n<p>这个应该是跟LDAP…相关的吧..暂时不知道是啥</p>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"channel-1\"><a href=\"#channel-1\" class=\"headerlink\" title=\"channel\"></a>channel</h4><p>通道相关api，如链码的调用。</p>\n<p>这里先对链码的调用简单分析一下。</p>\n<p>channel的客户端提供了两个方法<code>Query</code>和<code>Execute</code></p>\n<p>先说二者的共同流程。两个方法都是负责组装参数(handlers…opts..)后调用<code>chclinet.InvokeHandler</code>。在<code>InvokeHandler</code>里可以看到流程是准备参数，准备上下文，然后启动一个协程运行handlers，本方法堵塞直到complete或reqCtx.Done()通道读出消息，当handlers运行完毕后会向通道complete写入消息(成功或失败都会写入)，reqCtx.Done()则是超时。所以重点是运行Handler。Handler的组装类似于生产线，如a -&gt; b -&gt;c按顺序执行，且将上一个执行的结果也传递给下一位。</p>\n<ul>\n<li><p>Query</p>\n<ul>\n<li><p>ProposalProcessorHandler</p>\n<p>首先，检查targets参数长度是否为0，targets为进行背书的节点们。如果没有提供targets，将会查询背书的节点，opts参数中的filter将会在这里使用到，就是按需求筛选节点(如是查询还是背书…)</p>\n</li>\n<li><p>EndorsementHandler</p>\n<p>其次，会将proposal发送到各个targets，返回的responses会传递下去</p>\n</li>\n<li><p>EndorsementValidationHandler</p>\n<p>再次，验证各个target返回的结果，状态码是否正常，reponse是否一样</p>\n</li>\n<li><p>SignatureValidationHandler</p>\n<p>最后，验证各个节点返回的response的签名/证书是否正确</p>\n</li>\n</ul>\n<p>到此为止，query请求就完成了，最后将reponse返回给上层</p>\n</li>\n<li><p>Execute</p>\n<ul>\n<li><p>SelectAndEndorseHandler</p>\n<p>首先检查targets，其次调用EndorsementHandler发送proposal，然后根据链码策略向另外的peer发起proposal，返回的responses一起传递下去</p>\n</li>\n<li><p>EndorsementValidationHandler</p>\n<p>同上</p>\n</li>\n<li><p>SignatureValidationHandler</p>\n<p>同上</p>\n</li>\n<li><p>CommitHandler</p>\n<p>拿到所有peer的背书后，首先向order发送交易。然后订阅这笔交易状态，接收到新状态，方法执行结束，继续向下执行</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>response结构体中包含有Payload，ChaincodeStatus，TxValidationCode。</p>\n<p>在github.com/hyperledger/fabric/protos/peer下有TxValidationCode的所有码，可判断如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">switch pb.TxValidationCode(response.TxValidationCode) &#123;</span><br><span class=\"line\">\tcase pb.TxValidationCode_VALID:</span><br><span class=\"line\">\t\tcliconfig.Config().Logger().Debugf(&quot;(%s) - Successfully committed transaction [%s] ...\\n&quot;, t.id, response.TransactionID)</span><br><span class=\"line\">\t\treturn nil</span><br><span class=\"line\">\tcase pb.TxValidationCode_DUPLICATE_TXID, pb.TxValidationCode_MVCC_READ_CONFLICT, pb.TxValidationCode_PHANTOM_READ_CONFLICT:</span><br><span class=\"line\">\t\tcliconfig.Config().Logger().Debugf(&quot;(%s) - Transaction commit failed for [%s] with code [%s]. This is most likely a transient error.\\n&quot;, t.id, response.TransactionID, response.TxValidationCode)</span><br><span class=\"line\">\t\treturn invokeerror.Wrapf(invokeerror.TransientError, errors.New(&quot;Duplicate TxID&quot;), &quot;invoke Error received from eventhub for TxID [%s]. Code: %s&quot;, response.TransactionID, response.TxValidationCode)</span><br><span class=\"line\">\tdefault:</span><br><span class=\"line\">\t\tcliconfig.Config().Logger().Debugf(&quot;(%s) - Transaction commit failed for [%s] with code [%s].\\n&quot;, t.id, response.TransactionID, response.TxValidationCode)</span><br><span class=\"line\">\t\treturn invokeerror.Wrapf(invokeerror.PersistentError, errors.New(&quot;error&quot;), &quot;invoke Error received from eventhub for TxID [%s]. Code: %s&quot;, response.TransactionID, response.TxValidationCode)</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"sdk-example\"><a href=\"#sdk-example\" class=\"headerlink\" title=\"sdk example\"></a>sdk example</h4><p><a href=\"https://github.com/securekey/fabric-examples/tree/master/fabric-cli\">Sdk example </a></p>\n<h2 id=\"couchdb\"><a href=\"#couchdb\" class=\"headerlink\" title=\"couchdb\"></a>couchdb</h2><h4 id=\"查询索引\"><a href=\"#查询索引\" class=\"headerlink\" title=\"查询索引\"></a>查询索引</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost:5984/mychannel_mycc/_index</span><br></pre></td></tr></table></figure>\n\n<p>查询结果如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;total_rows&quot;:2,</span><br><span class=\"line\">    &quot;indexes&quot;:[</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;ddoc&quot;:null,</span><br><span class=\"line\">            &quot;name&quot;:&quot;_all_docs&quot;,</span><br><span class=\"line\">            &quot;type&quot;:&quot;special&quot;,</span><br><span class=\"line\">            &quot;def&quot;:&#123;</span><br><span class=\"line\">                &quot;fields&quot;:[</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;_id&quot;:&quot;asc&quot;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;ddoc&quot;:&quot;_design/indexOwnerDoc&quot;,</span><br><span class=\"line\">            &quot;name&quot;:&quot;indexOwner&quot;,</span><br><span class=\"line\">            &quot;type&quot;:&quot;json&quot;,</span><br><span class=\"line\">            &quot;def&quot;:&#123;</span><br><span class=\"line\">                &quot;fields&quot;:[</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;docType&quot;:&quot;asc&quot;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;owner&quot;:&quot;asc&quot;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这个是在我刚启动好链码容器时，什么操作都没做。为什么会建了一个索引呢.</p>\n<p>另外，在这个文档下，发现存在一条记录(一打开就有一条记录)。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;_id&quot;:&quot;_design/indexOwnerDoc&quot;,</span><br><span class=\"line\">    &quot;_rev&quot;:&quot;1-56c3e9386cb19531f6731afa88281caa&quot;,</span><br><span class=\"line\">    &quot;language&quot;:&quot;query&quot;,</span><br><span class=\"line\">    &quot;views&quot;:&#123;</span><br><span class=\"line\">        &quot;indexOwner&quot;:&#123;</span><br><span class=\"line\">            &quot;map&quot;:&#123;</span><br><span class=\"line\">                &quot;fields&quot;:&#123;</span><br><span class=\"line\">                    &quot;docType&quot;:&quot;asc&quot;,</span><br><span class=\"line\">                    &quot;owner&quot;:&quot;asc&quot;</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                &quot;partial_filter_selector&quot;:&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;reduce&quot;:&quot;_count&quot;,</span><br><span class=\"line\">            &quot;options&quot;:&#123;</span><br><span class=\"line\">                &quot;def&quot;:&#123;</span><br><span class=\"line\">                    &quot;fields&quot;:[</span><br><span class=\"line\">                        &quot;docType&quot;,</span><br><span class=\"line\">                        &quot;owner&quot;</span><br><span class=\"line\">                    ]</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>猜测，索引应该是由这条记录引起的，似乎是创建时的自动的索引？不对！是在我的链码里，有个文件夹叫META-INF下定义的。</p>\n<p>果然，这下面有个json文件，内容为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">\t&quot;index&quot;:&#123;&quot;fields&quot;:[&quot;docType&quot;,&quot;owner&quot;]&#125;,</span><br><span class=\"line\">\t&quot;ddoc&quot;:&quot;indexOwnerDoc&quot;,</span><br><span class=\"line\">\t&quot;name&quot;:&quot;indexOwner&quot;,</span><br><span class=\"line\">\t&quot;type&quot;:&quot;json&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>完全吻合。所以定义索引是可以通过这个配置文件！</p>\n<p>定义的索引对于查询的意义，似乎是如果要查询相应的字段(字段相关，如大于啥小于啥)，就要定义包含其中的字段的索引</p>\n<p>默认情况下，会建立一个id的索引。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\"> &quot;type&quot;: &quot;special&quot;,</span><br><span class=\"line\"> &quot;def&quot;: &#123;</span><br><span class=\"line\">  &quot;fields&quot;: [</span><br><span class=\"line\">   &#123;</span><br><span class=\"line\">    &quot;_id&quot;: &quot;asc&quot;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如新建一个索引视图</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -i -X POST -H &quot;Content-Type: application/json&quot; -d &quot;&#123;\\&quot;index\\&quot;:&#123;\\&quot;fields\\&quot;:[\\&quot;size\\&quot;,\\&quot;docType\\&quot;,\\&quot;owner\\&quot;]&#125;,\\&quot;ddoc\\&quot;:\\&quot;indexSizeSortDoc1\\&quot;, \\&quot;name\\&quot;:\\&quot;indexSizeSortDesc1\\&quot;,\\&quot;type\\&quot;:\\&quot;json\\&quot;&#125;&quot; http://localhost:5984/mychannel_mycc/_index</span><br></pre></td></tr></table></figure>\n\n<p>重新查询索引，多了一个</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;total_rows&quot;:3,</span><br><span class=\"line\">    &quot;indexes&quot;:[</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">         ...</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">         ...</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;ddoc&quot;:&quot;_design/indexSizeSortDoc&quot;,</span><br><span class=\"line\">            &quot;name&quot;:&quot;indexSizeSortDesc&quot;,</span><br><span class=\"line\">            &quot;type&quot;:&quot;json&quot;,</span><br><span class=\"line\">            &quot;def&quot;:&#123;</span><br><span class=\"line\">                &quot;fields&quot;:[</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;size&quot;:&quot;desc&quot;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;docType&quot;:&quot;desc&quot;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    &#123;</span><br><span class=\"line\">                        &quot;owner&quot;:&quot;desc&quot;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>建立了这个索引后，就可以进行size相关的查询，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;&#123;\\&quot;selector\\&quot;:&#123;\\&quot;docType\\&quot;:&#123;\\&quot;$eq\\&quot;:\\&quot;marble\\&quot;&#125;,\\&quot;owner\\&quot;:&#123;\\&quot;$eq\\&quot;:\\&quot;tom\\&quot;&#125;,\\&quot;size\\&quot;:&#123;\\&quot;$gt\\&quot;:0&#125;&#125;,\\&quot;fields\\&quot;:[\\&quot;docType\\&quot;,\\&quot;owner\\&quot;,\\&quot;size\\&quot;],\\&quot;sort\\&quot;:[&#123;\\&quot;size\\&quot;:\\&quot;desc\\&quot;&#125;],\\&quot;use_index\\&quot;:\\&quot;_design/indexSizeSortDoc\\&quot;&#125;&quot;</span><br></pre></td></tr></table></figure>\n\n<p><strong>啊！！</strong>就是建立的这个索引视图是包括size、docType、owner这三个的，然后我使用查询的时候，如果少传一个，就是我只查询docType和size，就会报错<code>Error running query. Reason: (no_usable_index) No index exists for this sort, try indexing by the sort fields.</code></p>\n<p>几经挣扎和尝试，确定下来几个结论。</p>\n<ol>\n<li>如果不适用sort，selector中的field都随意查询，使用的默认index(id asc排序)</li>\n<li>如果使用了sort，那么需要一个index包含 在selector中的field + sort中的field组成的field ，并且index中定义的field集合必须是selector中的field + sort中的field组成的field的子集，即index中出现过的，在查询时一定要出现，在selector和在sort中都无所谓，但sort中的一定要出现在index中</li>\n</ol>\n"},{"title":"kibana-plugin","date":"2017-10-14T05:54:55.000Z","_content":"## Kibana插件第一视角\n\n### Kibana插件大概类型有\n\n- visTypes 视图组件，Visualize\n- app 应用组件，如timeline\n- hacks, Any module that should be included in every application\n- chromeNavControls,\n- [更多](https://www.elastic.co/guide/en/kibana/current/development-uiexports.html)...\n\n#### 首要目标是visTypes\n\n------\n\n### 全军出击\n\n- git clone kibana，切换到与es对应的版本\n\n- npm install,\n\n  - git切换 http\n\n  ```\n  git config --global url.\"https://\".insteadOf \"git://\"\n  ```\n\n  - chromedriver失败\n\n  ```\n  npm ERR! chromedriver@2.32.3 install: `node install.js`\n  ```\n\n   解决方法\n\n  ```\n  npm install chromedriver --chromedriver_cdnurl=https://npm.taobao.org/mirrors/chromedriver\n  ```\n\n  - 默认dev 启动方式会使用ssl,所以是https,如果需要修改的话，可以修改\\kibana\\src\\cli\\serve\\serve.js文件。\n\n  ```\n    if (opts.dev) {\n      set('env', 'development');\n      set('optimize.lazy', true);\n\n      // if (opts.ssl) {\n      //   set('server.ssl.enabled', true);\n      // }\n\n      // if (opts.ssl && !has('server.ssl.certificate') && !has('server.ssl.key')) {\n      //   set('server.ssl.certificate', DEV_SSL_CERT_PATH);\n      //   set('server.ssl.key', DEV_SSL_KEY_PATH);\n      // }\n    }\n\n  ```\n\n- npm start\n\n### First Blood\n\n自定义visTypes的话，在kibana/plugins下新建文件夹，在新建的文件夹下执行\n\n```\nsao kibana-plugin\n```\n\n可生成对应文件夹格式，如果是visTypes的话，app component，translation files，an hack component， a server API都选no就好了\n\n- new TemplateVisType参数解析\n\n```\nreturn new TemplateVisType({\n    name: 'extended_metric',\n    title: 'Extended Metric',\n    description: 'Based on the core Metric-Plugin but gives you the ability' +\n      'to output custom aggregates on metric-results.',\n    icon: 'fa-calculator',\n    template: extendedMetricVisTemplate, //视图模板\n    params: { //Options选项\n      defaults: {\n        handleNoResults: true,\n        fontSize: 60,\n        outputs: [\n          {\n            formula: 'metrics[0].value * metrics[0].value',\n            label: 'Count squared',\n            enabled: true\n          }\n        ]\n      },\n      editor: metricVisParamsTemplate //Options视图模板\n    },\n    schemas: new Schemas([ //Data相关\n      {\n        group: 'metrics',\n        name: 'metric',\n        title: 'Metric',\n        min: 1,\n        defaults: [\n          { type: 'count', schema: 'metric' }\n        ]\n      }\n    ])\n  });\n```\n\n上面的例子来源于[地址](https://github.com/ommsolutions/kibana_ext_metrics_vis)，一个vis插件。\n\n看着AngularJS的语法，我想静静。\n\n目前看起来，vis包括主要的内容包括\n\n- schema, 为左边栏Data部分，选择已有的组件即可。一般来说，metric 数值聚合肯定是 Y 轴；bucket 聚合肯定是 X 轴；而在此基础上，Kibana4 还可以让 bucket 有不同效果，也就是 Schema 里的 segment(默认), group 和 split。根据效果不同，这里是各有增减的，比如饼图就不会有 group。\n- Options(params),为左边栏Options部分，包括渲染html\n- 显示可视化视图html\n- controller, 为html的逻辑部分, V <-> C是双向绑定的。\n\n先梳理一下需求，最好是在es聚合数据拿到之后，到view的那层中间将数据做修改。然后我需要找到数据处理的代码。既然这样，去看看原始vis组件吧。[参考](https://sunyonggang.gitbooks.io/elkstack-guide-cn/content/kibana/v4/source-code-analysis/visualize_app.html)\n\n- src/core\\_plugins/kbn\\_vislib\\_vis\\_types下方是各组件的定义部分\n- src/ui/public/vislib是vis具体渲染，vis组件的controller和html渲染主要就是在这个文件下，然而我没找到比较明显的controller,渲染主要是d3进行渲染\n\n感觉很茫然..\n\n走不下去的时候，又倒回来重新走。解析一下上面粘的代码，首先是TemplateVisType。\n\n```\nexport default function TemplateVisTypeFactory(Private) {\n  const VisType = Private(VisVisTypeProvider);\n  const TemplateRenderbot = Private(TemplateVisTypeTemplateRenderbotProvider);\n\n\t// ·。第一，继承VisType，增加了template检测\n  _.class(TemplateVisType).inherits(VisType);\n  function TemplateVisType(opts = {}) {\n    TemplateVisType.Super.call(this, opts);\n\n    this.template = opts.template;\n    if (!this.template) {\n      throw new Error('Missing template for TemplateVisType');\n    }\n  }\n\t// ·。第二，增加了createRenderbot，下面会对比看看，重写的意义\n  TemplateVisType.prototype.createRenderbot = function (vis, $el, uiState) {\n    return new TemplateRenderbot(vis, $el, uiState);\n  };\n\n  return TemplateVisType;\n}\n\n```\n\n然后是看看VislibVisType，基本vis继承的是这个，跟TemplateVisType应该是差不多的\n\n```\nexport default function VislibVisTypeFactory(Private) {\n\t...\n\tconst updateParams = function (params) {\n\t\tconst updateIfSet = (from, to, prop, func) => {\n\t      if (from[prop]) {\n\t        to[prop] = func ? func(from[prop]) : from[prop];\n\t      }\n\t    };\n\t    ...\n\t})\n\t...\n\t// ·。第一，继承VisType，看到responseConverter默认是转换为点线图数组的。\n\t_.class(VislibVisType).inherits(VisType);\n   function VislibVisType(opts = {}) {\n     VislibVisType.Super.call(this, opts);\n\n     if (this.responseConverter == null) {\n       this.responseConverter = pointSeries;\n     }\n\n     this.listeners = opts.listeners || {};\n   }\n\t// ·。第二，增加了createRenderbot\n\t   VislibVisType.prototype.createRenderbot = function (vis, $el, uiState) {\n\t   // 在返回新VislibRenderbot对象之前，对vis.params进行了相应的转换和判断，比如把一些params下的属性对应移到params.seriesParams[0]或者params.valueAxes[0]，params.categoryAxes[0]下\n\t    updateParams(vis.params);\n\t    return new VislibRenderbot(vis, $el, uiState);\n\t};\n}\n```\n\n好啦，再看看他们都实现的VisType的庐山真面目\n\n```\nexport default function VisTypeFactory(Private) {\n  /**\n   * Provides the visualizations for the vislib 👈官方注释很重要。大概意思是输入参数为angular module,输出为vis的class\n   *\n   * @module vislib\n   * @submodule VisTypeFactory\n   * @param Private {Object} Loads any function as an angular module\n   * @return {Function} Returns an Object of Visualization classes\n   */\n  return {\n    pie: Private(VislibVisualizationsPieChartProvider),\n    point_series: Private(VislibVisualizationsPointSeriesProvider)\n  };\n}\n\n```\n\n好，其实一点没看到，比如继承那个语法就很蒙圈...不过暂时连蒙带猜的总结下吧。就是讲一个angular module搞到vis的class的过程。具体是怎么搞的，可能一会会看到，可能不会。接下来看看VislibRenderbot的代码。\n\n```\n\t//具体就不贴了，主要定义了几个类似生命周期的方法，如\n\tVislibRenderbot.prototype._createVis\n\tVislibRenderbot.prototype._getVislibParams\n\tVislibRenderbot.prototype.destroy\n\tVislibRenderbot.prototype.updateParams\n\t//看到render方法了，贴一下具体的代码，看起来重要的是，buildChartData方法和vislibVis对象\n\tVislibRenderbot.prototype.render = function (esResponse) {\n\t    this.chartData = this.buildChartData(esResponse);\n\t    return AngularPromise.delay(1).then(() => {\n\t      this.vislibVis.render(this.chartData, this.uiState);\n\t      this.refreshLegend++;\n\t    });\n\t  };\n\n```\n\n好吧..再往下追，很多很多..就不挨着解释了，大概说一下，vislibVis类中主要是选择和绘制图。在src/ui/visualization下是各个组件确切的绘图代码，他们都继承自_chart.js,在_chart.js中看到render方法调用自身draw方法，故实现_chart的类实现draw方法即可。好啦，源码分析在这里就差不多了，其实还是没有找到自己想找的东西。这个时候在github上看到了另一个vis的插件。\n\nVis类中是渲染了，然后render的参数，data -> {Object} Elasticsearch query results, 要找data从哪里来的话，就开始找类似vis.render的调用，搜了下，调用位置在VislibRenderbot的\\_createVis方法中，恩，这就跟一开始联系起来了，又回到了VislibRenderbot上了。然后继续找vislibrenderbot实例化的位置，来到了src/ui/public/visualize/visualize.js，看起来这像是高地了。\n\n```\n  $scope.$watch('esResp', prereq(function (resp) {\n    if (!resp) return;\n    $scope.renderbot.render(resp); //es请求回来的结果传给了renderbot\n  }));\n```\n\n倒回去看看VislibRenderbot的代码\n\n```\n  VislibRenderbot.prototype.render = function (esResponse) {\n    this.chartData = this.buildChartData(esResponse);\n    return AngularPromise.delay(1).then(() => {\n      this.vislibVis.render(this.chartData, this.uiState);\n      this.refreshLegend++;\n    });\n  };\n```\n\n好! 好像稍微有点眉目了。通过render方法把es的数据传给了renderbot，renderbot通过buildChartData进行搞事完了就是最后的chartData了，也就是vis.render中的data了。\n\n恩! 仔细一想，好像还是有点乱，再捋捋。VislibVisType的方法createRenderbot返回的是VislibRenderbot,然后VislibRenderbot的是跟visualize连接的核心，在visualize中，VislibRenderbot进行初始化，传入vislibVis的html元素，和es返回的data,然后在VislibRenderbot内部进行绘制。默认的VislibRenderbot内部data会进行buildChartData转换。\n\n#### 示例extended_metric\n\n然后再看TemplateVisType, 这个是自定义时候的VislibVisType，对应的renderbot为TemplateRenderbot,定义的render为，就是裸数据，在$scope中。\n\n```\n  TemplateRenderbot.prototype.render = function (esResponse) {\n    this.$scope.esResponse = esResponse;\n  };\n```\n\n最开始提到了extended_metric插件，然后以这个为例，看看数据的流向。在controller中\n\n```\n  // watches\n  $scope.$watch('esResponse', function (resp) {\n    if (resp) {\n      calcOutputs.length = 0;\n      metrics.length = 0;\n      for (let key in metrics) {\n        if (metrics.hasOwnProperty(key)) {\n          delete metrics[key];\n        }\n      }\n      $scope.processTableGroups(tabifyAggResponse($scope.vis, resp));\n    }\n  });\n\n```\n\n啊虽然是找到了数据的来源和流向，可是，又是Angular.. Angular基础为零的我心好累...不过也算是了然了。然后具体看看extended_metric插件拿到数据之后做的事\n\n```\n  $scope.processTableGroups = function (tableGroups) {\n    tableGroups.tables.forEach(function (table) {\n      table.columns.forEach(function (column, i) {\n        const fieldFormatter = table.aggConfig(column).fieldFormatter();\n        let value = table.rows[0][i]; //es数据存在table.rows内\n        let formattedValue = isInvalid(value) ? '?' : fieldFormatter(value);     //数据转换后拿出label, formattedValue\n        const metric = {\n          label: column.title,\n          value: value,\n          formattedValue: formattedValue\n        };\n        metrics.push(metric);\n        metrics[column.title] = metric;\n      });\n    });\n    updateOutputs();\n  };\n```\n\n上面两段代码是相连的，首先processTableGroups的参数是tabifyAggResponse($scope.vis, resp)，tabifyAggResponse是一个内部已有的方法，主要是把es返回的已知结构的数据，转换成标准格式，这里选择的是table,如果是line的话，可以看看point_series.js。转换包括参数包括数据之外，还有vis,转换完成得到的数据中包含es数据之外，还包括选项卡中的数据，如设置的label等。\n\n#### 示例line\\_sg\n\n示例[地址](https://github.com/sbeyn/kibana-plugin-line-sg)\n\n然后分析一下，顺便巩固一下上面的知识。\n\n在line\\_sg.js中，熟悉的控件，TemplateVisType，包含params和schemas。\n\n在视图line\\_sg.html中,使用c3绘制，只有几行代码，看似很简单，我想控制绘制的代码应该在controller中，然后看看\\_params.html,是Option的选项卡，主要应该是视图的配置相关。然后看看controller,在视图controller中，前面很大一部分是关于要画的准备工作，以数据流向为接入点\n\n```\n  $scope.$watch('esResponse', function (resp) {\n      if (resp) {\n        console.log(resp);\n        metrics.length = 0; //重置metrics，重置数组的方式是修改length,emmm学到了\n        $scope.processTableGroups(tabifyAggResponse($scope.vis, resp)); //还是使用的数据表格形式，为什么大家都选这个转换形式？我猜可能是因为数据比较好拿出来..数据还是集中的，数据拿出来搞成自己格式的，与视图相关的数据都在metrics中，\n        $scope.showGraph(); //从metrics中拿出数据，做图\n      }\n    });\n```\n\n这个是示例是使用c3来完成绘制的示例，因为和需求的方波刚好可以吻合，就具体细节学习下吧。首先将代码拷入plugins文件夹，启动kibana,查看效果。发现不怎么好看，另外选择chart_types=step似乎不工作，看看代码吧。\n\n首先尝试是，设置params之后，点击重绘，没有效果。\n\n仔细看了看插件的绘制和c3的使用，看了看线上的kibana，发现line是真的可以有step..而且图形没有错...其实本来line画图就有方波。好吧，还是先看看这个插件为什么设置params之后，点击重绘，没有触发重绘吧。结论是没有监听变量的变化..$scope.$watch、$watchController等监听方法，虽然没有看到具体代码，大概是，侧边栏部分没有修改的话，那个重绘的按钮就无法点击，那个按钮的点击事件应该是触发watch的监听事件的，有修改，就会触发监听事件，要重绘的话其实就是在监听事件的回调中加入视图重绘的部分，其实数据会自动绑定，只是需要个刷新机制。\n\n\n\n\n\n\n\n\n\n------\n\n\n\n```\n                                                 /===-_---~~~~~~~~~------____\n                                                |===-~___                _,-'\n                 -==\\\\                         `//~\\\\   ~~~~`---.___.-~~\n             ______-==|                         | |  \\\\           _-~`\n       __--~~~  ,-/-==\\\\                        | |   `\\        ,'\n    _-~       /'    |  \\\\                      / /      \\      /\n  .'        /       |   \\\\                   /' /        \\   /'\n /  ____  /         |    \\`\\.__/-~~ ~ \\ _ _/'  /          \\/'\n/-'~    ~~~~~---__  |     ~-/~         ( )   /'        _--~`\n                  \\_|      /        _)   ;  ),   __--~~\n                    '~~--_/      _-~/-  / \\   '-~ \\\n                   {\\__--_/}    / \\\\_>- )<__\\      \\\n                   /'   (_/  _-~  | |__>--<__|      |\n                  |0  0 _/) )-~     | |__>--<__|      |\n                  / /~ ,_/       / /__>---<__/      |\n                 o o _//        /-~_>---<__-~      /\n                 (^(~          /~_>---<__-      _-~\n                ,/|           /__>--<__/     _-~\n             ,//('(          |__>--<__|     /                  .----_\n            ( ( '))          |__>--<__|    |                 /' _---_~\\\n         `-)) )) (           |__>--<__|    |               /'  /     ~\\`\\\n        ,/,'//( (             \\__>--<__\\    \\            /'  //        ||\n      ,( ( ((, ))              ~-__>--<_~-_  ~--____---~' _/'/        /'\n    `~/  )` ) ,/|                 ~-_~>--<_/-__       __-~ _/\n  ._-~//( )/ )) `                    ~~-'_/_/ /~~~~~~~__--~\n   ;'( ')/ ,)(                              ~~~~~~~~~~\n  ' ') '( (/\n    '   '  `\n\n\n```\n\n\n\n------\n\n后面整理了下，思路稍微清晰一点的。\n\n开发插件的话，都需要一定的模板，官方推荐的生成模板的脚手架[sao](https://github.com/saojs/sao),具体使用[样例](https://github.com/elastic/template-kibana-plugin)。还有插件开发的[教程](https://www.gitbook.com/book/trumandu/kibana-plugin-development-tutorial/details)。篇幅原因，就省去教程系列，主要看看结构，源码什么的..\n\n### visTypes\n\nVisualize插件的开发，组成主要是es6,angular(听说angular1和2完全没关系，特地指出kibana采用的是angular1)。kibana的Visualize组件的绘制主要是通过[d3](https://d3js.org/)这个伟大的可视化库。\n\n#### 插件样例\n\n从众多优秀的vis插件中选择了一个比较简单的[样例](https://github.com/ommsolutions/kibana_ext_metrics_vis)来做分析(主要是人家有图)。效果如gif图，用文字来说明的话，就是实现了一个可计算的插件，选择metric值，然后填入计算公式，得出值。(因为见识有限，以前总说在kibana中实现计算很复杂，现在看来真是啪啪(*10)打脸)。\n\nextended\\_metric\\_vis.js很明显，是这个插件的大头。稍微粘一点代码。\n\n```\n\treturn new TemplateVisType({\n\t    name: 'extended_metric',\n\t    title: 'Extended Metric',\n\t    description: 'Based on the core Metric-Plugin but gives you the ability' +\n\t      'to output custom aggregates on metric-results.',\n\t    icon: 'fa-calculator',\n\t    template: extendedMetricVisTemplate, //视图模板.html\n\t    params: { //Options选项，预定义的Options选项及值，在对应视图中会有具体使用\n\t      defaults: {\n\t        handleNoResults: true,\n\t        fontSize: 60,\n\t        outputs: [\n\t          {\n\t            formula: 'metrics[0].value * metrics[0].value',\n\t            label: 'Count squared',\n\t            enabled: true\n\t          }\n\t        ]\n\t      },\n\t      editor: metricVisParamsTemplate //Options选项卡视图模板.html\n\t    },\n\t    schemas: new Schemas([ //Data相关，这里就不是自由发挥的地界了，属于半命题类型，根据自己需要的数据选择对应类型，基本\n\t    \t\t\t\t\t//就是metric，bucket的组合，一般来说，metric 数值聚合肯定是 Y 轴；bucket 聚合肯定是 X 轴；\n\t      {           //而在此基础上，还可以让 bucket 有不同效果，也就是 Schema 里的 segment(默认), group 和 split。\n\t        group: 'metrics',\n\t        name: 'metric',\n\t        title: 'Metric',\n\t        min: 1,\n\t        defaults: [\n\t          { type: 'count', schema: 'metric' }\n\t        ]\n\t      }\n\t    ])\n\t  });\n\n```\n\n如果稍微看了下vis插件的教程的话，就会很熟悉，因为模板就差不多是这样，利用TemplateVisType生成对应实例，基本备注都在代码里了，就不再啰嗦了。\n\n然后根据上面的代码直接的找到两个html，extended\\_metric\\_vis.html和extended\\_metric\\_vis\\_params.html, 很显示，就是view,会看到伟大的angular进行mvc的管理，然后去看c => extended\\_metric\\_vis\\_controller.js。这个代码里，主要是angular与其控制器的绑定，跳过这个，进到方法里。\n\n```\n$scope.$watch('esResponse', function (resp) {\n    if (resp) {\n      calcOutputs.length = 0;\n      metrics.length = 0;\n      //清空metrics\n      for (let key in metrics) {\n        if (metrics.hasOwnProperty(key)) {\n          delete metrics[key];\n        }\n      }\n      $scope.processTableGroups(tabifyAggResponse($scope.vis, resp));\n    }\n  });\n\n```\n\n很明显，这里是接受es查询结果的代码，结论很明显是，获得es查询结果只需要监听esResponse变量就可以。然后看看拿到结果的处理processTableGroups方法。首先是tabifyAggResponse是按照已知的es查询结果结构生成与视图(data选项卡)强相关的数据结构，为什么说强相关呢，比如tabifyAggResponse后的结果主要包括columns和rows，分别是data选项卡的分组和对应的数据，就拿这个例子来说，如果新建了两个metric, columns里就是这两个metric的属性，包含title(即输入的label)等，对应index的rows里的数据就是对应metric的结果。转换之后，在processTableGroups方法里，只需要把对应的数据拿出来组合下，比如，例子里就是以columns中的title为键，以metric的结果为值，组成数据到metrics(装数据的对象，下方会用到)中。\n\nview有了，数据也有了，还差最后一步，就是怎么把公式套进去？在这里，我不得不再次感叹下js的伟大。\n\n```\n  try {\n    const func = Function(\"metrics\", \"return \" + output.formula); //<<<<=这里是亮点\n    output.value = func(metrics) || \"?\";\n  } catch (e) {\n    output.value = '?';\n  }\n\n```\n\noutput.formula为输入的公式，类型为string，然后一句string的字符串就变成方法了？！是的。很神奇。有了方法，把数据套进去，答案就出来了。\n\n大概内容就是这样，可能还有些细节需要注意，比如，修改了data/option点击那么重绘的按钮，重新计算，需要监听对应数据，如\n\n```\n\t//updateOutputs为计算的过程\n\t$scope.$watchCollection('vis.params.outputs', updateOutputs);\n\n```\n\n#### 源码样例\n\n接下来就看看稍微肤浅点的源码，时间和能力确实有限啊。比如上面出现过的TemplateVisType，整体理解下结构和运作。\n\n- src/core\\_plugins/kbn\\_vislib\\_vis\\_types\n\n  自带的vis组件定义的地方。还包括options选项卡的html,js等等，看看line.js的部分代码\n\n  ```\n  return new VislibVisType({\n    name: 'line',\n    title: 'Line',\n    image,\n    description: 'Emphasize trends',\n    category: VisType.CATEGORY.BASIC,\n    params: {\n      defaults: {\n        grid: {\n          categoryLines: false,\n          style: {\n            color: '#eee'\n          }\n        },\n        ...\n      },\n      positions: ['top', 'left', 'right', 'bottom'],\n      ...\n      editor: pointSeriesTemplate,\n      ...\n      schemas: new Schemas([\n      {\n        group: 'metrics',\n        name: 'metric',\n        title: 'Y-Axis',\n        min: 1,\n        aggFilter: ['!geo_centroid'],\n        defaults: [\n          { schema: 'metric', type: 'count' }\n        ]\n      },\n     \t....\n    ])\n\n\n  ```\n\n 和上方extended\\_metric\\_vis.js粘出来的代码很相似吧，只不过一个是使用的TemplateVisType，一个是VislibVisType，其实这两个类也很相似，都是继承vis\\_type。不过从这点上来看，定义vis组件的套路其实差不多，区别呢，就是官方的组件的话视图绘制的部分应该是内定的，直接选择出来绘制就好了(在后面会看到选择的代码)，但是自定义vis组件的话，视图部分是需要自己自定义的，而不是选择原有的，所以自定义需要TemplateVisType对象，传入template视图。\n\n- src/public/ui/vis/vis\\_type\n\n  定义基本属性和方法createRenderbot。继承这个的话需要实现createRenderbot方法返回Renderbot对象。\n\n- src/public/ui/vislib\\_vis\\_type/vislib\\_vis\\_type\n\n  继承vis_type。\n\n  ```\n  \t...\n  \tconst updateParams = function (params) {\n  \t\tconst updateIfSet = (from, to, prop, func) => {\n  \t      if (from[prop]) {\n  \t        to[prop] = func ? func(from[prop]) : from[prop];\n  \t      }\n  \t    };\n  \t    ...\n  \t})\n  \t...\n  \t// ·。第一，继承VisType，看到responseConverter默认是转换为点线图数组的。\n  \t_.class(VislibVisType).inherits(VisType);\n     function VislibVisType(opts = {}) {\n       VislibVisType.Super.call(this, opts);\n\n       if (this.responseConverter == null) {\n         this.responseConverter = pointSeries;\n       }\n\n       this.listeners = opts.listeners || {};\n     }\n  \t// ·。第二，实现createRenderbot\n  \t   VislibVisType.prototype.createRenderbot = function (vis, $el, uiState) {\n  \t   // 在返回新VislibRenderbot对象之前，对vis.params进行了相应的转换和判断，比如把一些params下的属性对应移到params.seriesParams[0]或者params.valueAxes[0]，params.categoryAxes[0]下\n  \t    updateParams(vis.params);\n  \t    return new VislibRenderbot(vis, $el, uiState);\n  \t};\n\n\n  ```\n\n  可以看到基本就是params的转换，和返回VislibRenderbot作为Renderbot对象，那么，久闻的Renderbot的作用？预知后事如何，请看后面..\n\n- src/public/ui/vislib\\_vis\\_type/vislib\\_renderbot\n\n  恩，Renderbot中定义了需实现的一些方法，VislibRenderbot就继承Renderbot，故就直接看VislibRenderbot的代码了。\n\n  ```\n    VislibRenderbot.prototype.render = function (esResponse) {\n      this.chartData = this.buildChartData(esResponse);\n      return AngularPromise.delay(1).then(() => {\n        this.vislibVis.render(this.chartData, this.uiState); //绘制\n        this.refreshLegend++;\n      });\n    };\n\n\n  ```\n\n  例如render方法,通过调用vislibRenderbot.render方法实现绘制。\n  看到这里，不知道有没有看到加了注释那句代码，绘制的主要工作应该就在这行代码，那么好奇一下this.vislibVis又是什么呢？找到this.vislibVis的初始化\n\n  ```\n  this.vislibVis = new vislib.Vis(this.$el[0], this.vislibParams);\n\n  ```\n\n  在Vis中，主要是visConfig和handler, handler绘制，visConfig选择生成相应的数据结构。对于visConfig的代码\n\n  ```\n  //src/public/ui/vislib/vis_config.js\n  const visType = visTypes[visConfigArgs.type];\n  const typeDefaults = visType(visConfigArgs, this.data); // <= 数据结构更改\n\n  //visTypes => src/public/ui/vislib/types\n    return {\n      histogram: pointSeries.column,\n      horizontal_bar: pointSeries.column,\n      line: pointSeries.line,\n      pie: Private(VislibLibTypesPieProvider),\n      area: pointSeries.area,\n      point_series: pointSeries.line,\n      heatmap: pointSeries.heatmap,\n    };\n\n  ```\n\n  handler绘制,handler的render方法中,可以看到chart.render\n\n  ```\n  // render in handler\n  render() {\n  \t...\n  \tconst chart = new self.ChartClass(self, this, chartData);\n  \t...\n  \tchart.render();\n  }\n\n  //ChartClass in handler\n  this.ChartClass = chartTypes[visConfig.get('type')];\n\n  //chartTypes from src/public/ui/vislib/visualizations/vis_types\n  //这里面是进行可视化的地方，可视化对象都继承自Chart类，components/vislib/visualizations/_chart\n    Chart.prototype.render = function () {\n        var selection = d3.select(this.chartEl);\n        selection.selectAll('*').remove();\n        selection.call(this.draw());\n     };\n    //也就是说，各个可视化对象，只需要用 d3.js 或者其他绘图库，完成自己的 draw() 函数，就可以了！可以在本文件夹下查看具体一些绘制代码\n\n  ```\n\n- src/public/visualize/visualize\n\n  ```\n    $scope.$watch('esResp', prereq(function (resp) {\n        if (!resp) return;\n        $scope.renderbot.render(resp);\n      }));\n\n  ```\n\n   很明显，visualize.js是Visualization的大Boss，通过代码可以看出，visualize与vis_types交互主要通过调用renderbot的各种方法，包括render。\n\n大致总结一下，要定义vis组件的话，返回VislibVisType或TemplateVisType对象，这两个类内部都会生成对应的renderbot对象，visualize与通过调用renderbot对象进行一系列的操作，如果是自定义组件的话，返回的TemplateVisType对象需要具有template属性，为图表视图模板(html), 官方自带的组件的话，会根据类型进行选择视图。对于视图的绘制(包括修改选项卡，重绘)，visualize会调用renderbot.render方法，VisRenderbot的render方法即重绘..在上方粘贴的代码也可以看到，TemplateRenderbot的render方法是将esResponse数据绑定到当前作用域的esResponse变量上，所以自定义插件中要完成绘制的话，需要监听当前作用域的esResponse变量。\n\n好啦，官方自带的组件的代码介绍和自开发插件的代码介绍就到这里就结束啦。\n","source":"_posts/kibana-plugin.md","raw":"---\ntitle: kibana-plugin\ndate: 2017-10-14 13:54:55\ncategories:\n- elk\n---\n## Kibana插件第一视角\n\n### Kibana插件大概类型有\n\n- visTypes 视图组件，Visualize\n- app 应用组件，如timeline\n- hacks, Any module that should be included in every application\n- chromeNavControls,\n- [更多](https://www.elastic.co/guide/en/kibana/current/development-uiexports.html)...\n\n#### 首要目标是visTypes\n\n------\n\n### 全军出击\n\n- git clone kibana，切换到与es对应的版本\n\n- npm install,\n\n  - git切换 http\n\n  ```\n  git config --global url.\"https://\".insteadOf \"git://\"\n  ```\n\n  - chromedriver失败\n\n  ```\n  npm ERR! chromedriver@2.32.3 install: `node install.js`\n  ```\n\n   解决方法\n\n  ```\n  npm install chromedriver --chromedriver_cdnurl=https://npm.taobao.org/mirrors/chromedriver\n  ```\n\n  - 默认dev 启动方式会使用ssl,所以是https,如果需要修改的话，可以修改\\kibana\\src\\cli\\serve\\serve.js文件。\n\n  ```\n    if (opts.dev) {\n      set('env', 'development');\n      set('optimize.lazy', true);\n\n      // if (opts.ssl) {\n      //   set('server.ssl.enabled', true);\n      // }\n\n      // if (opts.ssl && !has('server.ssl.certificate') && !has('server.ssl.key')) {\n      //   set('server.ssl.certificate', DEV_SSL_CERT_PATH);\n      //   set('server.ssl.key', DEV_SSL_KEY_PATH);\n      // }\n    }\n\n  ```\n\n- npm start\n\n### First Blood\n\n自定义visTypes的话，在kibana/plugins下新建文件夹，在新建的文件夹下执行\n\n```\nsao kibana-plugin\n```\n\n可生成对应文件夹格式，如果是visTypes的话，app component，translation files，an hack component， a server API都选no就好了\n\n- new TemplateVisType参数解析\n\n```\nreturn new TemplateVisType({\n    name: 'extended_metric',\n    title: 'Extended Metric',\n    description: 'Based on the core Metric-Plugin but gives you the ability' +\n      'to output custom aggregates on metric-results.',\n    icon: 'fa-calculator',\n    template: extendedMetricVisTemplate, //视图模板\n    params: { //Options选项\n      defaults: {\n        handleNoResults: true,\n        fontSize: 60,\n        outputs: [\n          {\n            formula: 'metrics[0].value * metrics[0].value',\n            label: 'Count squared',\n            enabled: true\n          }\n        ]\n      },\n      editor: metricVisParamsTemplate //Options视图模板\n    },\n    schemas: new Schemas([ //Data相关\n      {\n        group: 'metrics',\n        name: 'metric',\n        title: 'Metric',\n        min: 1,\n        defaults: [\n          { type: 'count', schema: 'metric' }\n        ]\n      }\n    ])\n  });\n```\n\n上面的例子来源于[地址](https://github.com/ommsolutions/kibana_ext_metrics_vis)，一个vis插件。\n\n看着AngularJS的语法，我想静静。\n\n目前看起来，vis包括主要的内容包括\n\n- schema, 为左边栏Data部分，选择已有的组件即可。一般来说，metric 数值聚合肯定是 Y 轴；bucket 聚合肯定是 X 轴；而在此基础上，Kibana4 还可以让 bucket 有不同效果，也就是 Schema 里的 segment(默认), group 和 split。根据效果不同，这里是各有增减的，比如饼图就不会有 group。\n- Options(params),为左边栏Options部分，包括渲染html\n- 显示可视化视图html\n- controller, 为html的逻辑部分, V <-> C是双向绑定的。\n\n先梳理一下需求，最好是在es聚合数据拿到之后，到view的那层中间将数据做修改。然后我需要找到数据处理的代码。既然这样，去看看原始vis组件吧。[参考](https://sunyonggang.gitbooks.io/elkstack-guide-cn/content/kibana/v4/source-code-analysis/visualize_app.html)\n\n- src/core\\_plugins/kbn\\_vislib\\_vis\\_types下方是各组件的定义部分\n- src/ui/public/vislib是vis具体渲染，vis组件的controller和html渲染主要就是在这个文件下，然而我没找到比较明显的controller,渲染主要是d3进行渲染\n\n感觉很茫然..\n\n走不下去的时候，又倒回来重新走。解析一下上面粘的代码，首先是TemplateVisType。\n\n```\nexport default function TemplateVisTypeFactory(Private) {\n  const VisType = Private(VisVisTypeProvider);\n  const TemplateRenderbot = Private(TemplateVisTypeTemplateRenderbotProvider);\n\n\t// ·。第一，继承VisType，增加了template检测\n  _.class(TemplateVisType).inherits(VisType);\n  function TemplateVisType(opts = {}) {\n    TemplateVisType.Super.call(this, opts);\n\n    this.template = opts.template;\n    if (!this.template) {\n      throw new Error('Missing template for TemplateVisType');\n    }\n  }\n\t// ·。第二，增加了createRenderbot，下面会对比看看，重写的意义\n  TemplateVisType.prototype.createRenderbot = function (vis, $el, uiState) {\n    return new TemplateRenderbot(vis, $el, uiState);\n  };\n\n  return TemplateVisType;\n}\n\n```\n\n然后是看看VislibVisType，基本vis继承的是这个，跟TemplateVisType应该是差不多的\n\n```\nexport default function VislibVisTypeFactory(Private) {\n\t...\n\tconst updateParams = function (params) {\n\t\tconst updateIfSet = (from, to, prop, func) => {\n\t      if (from[prop]) {\n\t        to[prop] = func ? func(from[prop]) : from[prop];\n\t      }\n\t    };\n\t    ...\n\t})\n\t...\n\t// ·。第一，继承VisType，看到responseConverter默认是转换为点线图数组的。\n\t_.class(VislibVisType).inherits(VisType);\n   function VislibVisType(opts = {}) {\n     VislibVisType.Super.call(this, opts);\n\n     if (this.responseConverter == null) {\n       this.responseConverter = pointSeries;\n     }\n\n     this.listeners = opts.listeners || {};\n   }\n\t// ·。第二，增加了createRenderbot\n\t   VislibVisType.prototype.createRenderbot = function (vis, $el, uiState) {\n\t   // 在返回新VislibRenderbot对象之前，对vis.params进行了相应的转换和判断，比如把一些params下的属性对应移到params.seriesParams[0]或者params.valueAxes[0]，params.categoryAxes[0]下\n\t    updateParams(vis.params);\n\t    return new VislibRenderbot(vis, $el, uiState);\n\t};\n}\n```\n\n好啦，再看看他们都实现的VisType的庐山真面目\n\n```\nexport default function VisTypeFactory(Private) {\n  /**\n   * Provides the visualizations for the vislib 👈官方注释很重要。大概意思是输入参数为angular module,输出为vis的class\n   *\n   * @module vislib\n   * @submodule VisTypeFactory\n   * @param Private {Object} Loads any function as an angular module\n   * @return {Function} Returns an Object of Visualization classes\n   */\n  return {\n    pie: Private(VislibVisualizationsPieChartProvider),\n    point_series: Private(VislibVisualizationsPointSeriesProvider)\n  };\n}\n\n```\n\n好，其实一点没看到，比如继承那个语法就很蒙圈...不过暂时连蒙带猜的总结下吧。就是讲一个angular module搞到vis的class的过程。具体是怎么搞的，可能一会会看到，可能不会。接下来看看VislibRenderbot的代码。\n\n```\n\t//具体就不贴了，主要定义了几个类似生命周期的方法，如\n\tVislibRenderbot.prototype._createVis\n\tVislibRenderbot.prototype._getVislibParams\n\tVislibRenderbot.prototype.destroy\n\tVislibRenderbot.prototype.updateParams\n\t//看到render方法了，贴一下具体的代码，看起来重要的是，buildChartData方法和vislibVis对象\n\tVislibRenderbot.prototype.render = function (esResponse) {\n\t    this.chartData = this.buildChartData(esResponse);\n\t    return AngularPromise.delay(1).then(() => {\n\t      this.vislibVis.render(this.chartData, this.uiState);\n\t      this.refreshLegend++;\n\t    });\n\t  };\n\n```\n\n好吧..再往下追，很多很多..就不挨着解释了，大概说一下，vislibVis类中主要是选择和绘制图。在src/ui/visualization下是各个组件确切的绘图代码，他们都继承自_chart.js,在_chart.js中看到render方法调用自身draw方法，故实现_chart的类实现draw方法即可。好啦，源码分析在这里就差不多了，其实还是没有找到自己想找的东西。这个时候在github上看到了另一个vis的插件。\n\nVis类中是渲染了，然后render的参数，data -> {Object} Elasticsearch query results, 要找data从哪里来的话，就开始找类似vis.render的调用，搜了下，调用位置在VislibRenderbot的\\_createVis方法中，恩，这就跟一开始联系起来了，又回到了VislibRenderbot上了。然后继续找vislibrenderbot实例化的位置，来到了src/ui/public/visualize/visualize.js，看起来这像是高地了。\n\n```\n  $scope.$watch('esResp', prereq(function (resp) {\n    if (!resp) return;\n    $scope.renderbot.render(resp); //es请求回来的结果传给了renderbot\n  }));\n```\n\n倒回去看看VislibRenderbot的代码\n\n```\n  VislibRenderbot.prototype.render = function (esResponse) {\n    this.chartData = this.buildChartData(esResponse);\n    return AngularPromise.delay(1).then(() => {\n      this.vislibVis.render(this.chartData, this.uiState);\n      this.refreshLegend++;\n    });\n  };\n```\n\n好! 好像稍微有点眉目了。通过render方法把es的数据传给了renderbot，renderbot通过buildChartData进行搞事完了就是最后的chartData了，也就是vis.render中的data了。\n\n恩! 仔细一想，好像还是有点乱，再捋捋。VislibVisType的方法createRenderbot返回的是VislibRenderbot,然后VislibRenderbot的是跟visualize连接的核心，在visualize中，VislibRenderbot进行初始化，传入vislibVis的html元素，和es返回的data,然后在VislibRenderbot内部进行绘制。默认的VislibRenderbot内部data会进行buildChartData转换。\n\n#### 示例extended_metric\n\n然后再看TemplateVisType, 这个是自定义时候的VislibVisType，对应的renderbot为TemplateRenderbot,定义的render为，就是裸数据，在$scope中。\n\n```\n  TemplateRenderbot.prototype.render = function (esResponse) {\n    this.$scope.esResponse = esResponse;\n  };\n```\n\n最开始提到了extended_metric插件，然后以这个为例，看看数据的流向。在controller中\n\n```\n  // watches\n  $scope.$watch('esResponse', function (resp) {\n    if (resp) {\n      calcOutputs.length = 0;\n      metrics.length = 0;\n      for (let key in metrics) {\n        if (metrics.hasOwnProperty(key)) {\n          delete metrics[key];\n        }\n      }\n      $scope.processTableGroups(tabifyAggResponse($scope.vis, resp));\n    }\n  });\n\n```\n\n啊虽然是找到了数据的来源和流向，可是，又是Angular.. Angular基础为零的我心好累...不过也算是了然了。然后具体看看extended_metric插件拿到数据之后做的事\n\n```\n  $scope.processTableGroups = function (tableGroups) {\n    tableGroups.tables.forEach(function (table) {\n      table.columns.forEach(function (column, i) {\n        const fieldFormatter = table.aggConfig(column).fieldFormatter();\n        let value = table.rows[0][i]; //es数据存在table.rows内\n        let formattedValue = isInvalid(value) ? '?' : fieldFormatter(value);     //数据转换后拿出label, formattedValue\n        const metric = {\n          label: column.title,\n          value: value,\n          formattedValue: formattedValue\n        };\n        metrics.push(metric);\n        metrics[column.title] = metric;\n      });\n    });\n    updateOutputs();\n  };\n```\n\n上面两段代码是相连的，首先processTableGroups的参数是tabifyAggResponse($scope.vis, resp)，tabifyAggResponse是一个内部已有的方法，主要是把es返回的已知结构的数据，转换成标准格式，这里选择的是table,如果是line的话，可以看看point_series.js。转换包括参数包括数据之外，还有vis,转换完成得到的数据中包含es数据之外，还包括选项卡中的数据，如设置的label等。\n\n#### 示例line\\_sg\n\n示例[地址](https://github.com/sbeyn/kibana-plugin-line-sg)\n\n然后分析一下，顺便巩固一下上面的知识。\n\n在line\\_sg.js中，熟悉的控件，TemplateVisType，包含params和schemas。\n\n在视图line\\_sg.html中,使用c3绘制，只有几行代码，看似很简单，我想控制绘制的代码应该在controller中，然后看看\\_params.html,是Option的选项卡，主要应该是视图的配置相关。然后看看controller,在视图controller中，前面很大一部分是关于要画的准备工作，以数据流向为接入点\n\n```\n  $scope.$watch('esResponse', function (resp) {\n      if (resp) {\n        console.log(resp);\n        metrics.length = 0; //重置metrics，重置数组的方式是修改length,emmm学到了\n        $scope.processTableGroups(tabifyAggResponse($scope.vis, resp)); //还是使用的数据表格形式，为什么大家都选这个转换形式？我猜可能是因为数据比较好拿出来..数据还是集中的，数据拿出来搞成自己格式的，与视图相关的数据都在metrics中，\n        $scope.showGraph(); //从metrics中拿出数据，做图\n      }\n    });\n```\n\n这个是示例是使用c3来完成绘制的示例，因为和需求的方波刚好可以吻合，就具体细节学习下吧。首先将代码拷入plugins文件夹，启动kibana,查看效果。发现不怎么好看，另外选择chart_types=step似乎不工作，看看代码吧。\n\n首先尝试是，设置params之后，点击重绘，没有效果。\n\n仔细看了看插件的绘制和c3的使用，看了看线上的kibana，发现line是真的可以有step..而且图形没有错...其实本来line画图就有方波。好吧，还是先看看这个插件为什么设置params之后，点击重绘，没有触发重绘吧。结论是没有监听变量的变化..$scope.$watch、$watchController等监听方法，虽然没有看到具体代码，大概是，侧边栏部分没有修改的话，那个重绘的按钮就无法点击，那个按钮的点击事件应该是触发watch的监听事件的，有修改，就会触发监听事件，要重绘的话其实就是在监听事件的回调中加入视图重绘的部分，其实数据会自动绑定，只是需要个刷新机制。\n\n\n\n\n\n\n\n\n\n------\n\n\n\n```\n                                                 /===-_---~~~~~~~~~------____\n                                                |===-~___                _,-'\n                 -==\\\\                         `//~\\\\   ~~~~`---.___.-~~\n             ______-==|                         | |  \\\\           _-~`\n       __--~~~  ,-/-==\\\\                        | |   `\\        ,'\n    _-~       /'    |  \\\\                      / /      \\      /\n  .'        /       |   \\\\                   /' /        \\   /'\n /  ____  /         |    \\`\\.__/-~~ ~ \\ _ _/'  /          \\/'\n/-'~    ~~~~~---__  |     ~-/~         ( )   /'        _--~`\n                  \\_|      /        _)   ;  ),   __--~~\n                    '~~--_/      _-~/-  / \\   '-~ \\\n                   {\\__--_/}    / \\\\_>- )<__\\      \\\n                   /'   (_/  _-~  | |__>--<__|      |\n                  |0  0 _/) )-~     | |__>--<__|      |\n                  / /~ ,_/       / /__>---<__/      |\n                 o o _//        /-~_>---<__-~      /\n                 (^(~          /~_>---<__-      _-~\n                ,/|           /__>--<__/     _-~\n             ,//('(          |__>--<__|     /                  .----_\n            ( ( '))          |__>--<__|    |                 /' _---_~\\\n         `-)) )) (           |__>--<__|    |               /'  /     ~\\`\\\n        ,/,'//( (             \\__>--<__\\    \\            /'  //        ||\n      ,( ( ((, ))              ~-__>--<_~-_  ~--____---~' _/'/        /'\n    `~/  )` ) ,/|                 ~-_~>--<_/-__       __-~ _/\n  ._-~//( )/ )) `                    ~~-'_/_/ /~~~~~~~__--~\n   ;'( ')/ ,)(                              ~~~~~~~~~~\n  ' ') '( (/\n    '   '  `\n\n\n```\n\n\n\n------\n\n后面整理了下，思路稍微清晰一点的。\n\n开发插件的话，都需要一定的模板，官方推荐的生成模板的脚手架[sao](https://github.com/saojs/sao),具体使用[样例](https://github.com/elastic/template-kibana-plugin)。还有插件开发的[教程](https://www.gitbook.com/book/trumandu/kibana-plugin-development-tutorial/details)。篇幅原因，就省去教程系列，主要看看结构，源码什么的..\n\n### visTypes\n\nVisualize插件的开发，组成主要是es6,angular(听说angular1和2完全没关系，特地指出kibana采用的是angular1)。kibana的Visualize组件的绘制主要是通过[d3](https://d3js.org/)这个伟大的可视化库。\n\n#### 插件样例\n\n从众多优秀的vis插件中选择了一个比较简单的[样例](https://github.com/ommsolutions/kibana_ext_metrics_vis)来做分析(主要是人家有图)。效果如gif图，用文字来说明的话，就是实现了一个可计算的插件，选择metric值，然后填入计算公式，得出值。(因为见识有限，以前总说在kibana中实现计算很复杂，现在看来真是啪啪(*10)打脸)。\n\nextended\\_metric\\_vis.js很明显，是这个插件的大头。稍微粘一点代码。\n\n```\n\treturn new TemplateVisType({\n\t    name: 'extended_metric',\n\t    title: 'Extended Metric',\n\t    description: 'Based on the core Metric-Plugin but gives you the ability' +\n\t      'to output custom aggregates on metric-results.',\n\t    icon: 'fa-calculator',\n\t    template: extendedMetricVisTemplate, //视图模板.html\n\t    params: { //Options选项，预定义的Options选项及值，在对应视图中会有具体使用\n\t      defaults: {\n\t        handleNoResults: true,\n\t        fontSize: 60,\n\t        outputs: [\n\t          {\n\t            formula: 'metrics[0].value * metrics[0].value',\n\t            label: 'Count squared',\n\t            enabled: true\n\t          }\n\t        ]\n\t      },\n\t      editor: metricVisParamsTemplate //Options选项卡视图模板.html\n\t    },\n\t    schemas: new Schemas([ //Data相关，这里就不是自由发挥的地界了，属于半命题类型，根据自己需要的数据选择对应类型，基本\n\t    \t\t\t\t\t//就是metric，bucket的组合，一般来说，metric 数值聚合肯定是 Y 轴；bucket 聚合肯定是 X 轴；\n\t      {           //而在此基础上，还可以让 bucket 有不同效果，也就是 Schema 里的 segment(默认), group 和 split。\n\t        group: 'metrics',\n\t        name: 'metric',\n\t        title: 'Metric',\n\t        min: 1,\n\t        defaults: [\n\t          { type: 'count', schema: 'metric' }\n\t        ]\n\t      }\n\t    ])\n\t  });\n\n```\n\n如果稍微看了下vis插件的教程的话，就会很熟悉，因为模板就差不多是这样，利用TemplateVisType生成对应实例，基本备注都在代码里了，就不再啰嗦了。\n\n然后根据上面的代码直接的找到两个html，extended\\_metric\\_vis.html和extended\\_metric\\_vis\\_params.html, 很显示，就是view,会看到伟大的angular进行mvc的管理，然后去看c => extended\\_metric\\_vis\\_controller.js。这个代码里，主要是angular与其控制器的绑定，跳过这个，进到方法里。\n\n```\n$scope.$watch('esResponse', function (resp) {\n    if (resp) {\n      calcOutputs.length = 0;\n      metrics.length = 0;\n      //清空metrics\n      for (let key in metrics) {\n        if (metrics.hasOwnProperty(key)) {\n          delete metrics[key];\n        }\n      }\n      $scope.processTableGroups(tabifyAggResponse($scope.vis, resp));\n    }\n  });\n\n```\n\n很明显，这里是接受es查询结果的代码，结论很明显是，获得es查询结果只需要监听esResponse变量就可以。然后看看拿到结果的处理processTableGroups方法。首先是tabifyAggResponse是按照已知的es查询结果结构生成与视图(data选项卡)强相关的数据结构，为什么说强相关呢，比如tabifyAggResponse后的结果主要包括columns和rows，分别是data选项卡的分组和对应的数据，就拿这个例子来说，如果新建了两个metric, columns里就是这两个metric的属性，包含title(即输入的label)等，对应index的rows里的数据就是对应metric的结果。转换之后，在processTableGroups方法里，只需要把对应的数据拿出来组合下，比如，例子里就是以columns中的title为键，以metric的结果为值，组成数据到metrics(装数据的对象，下方会用到)中。\n\nview有了，数据也有了，还差最后一步，就是怎么把公式套进去？在这里，我不得不再次感叹下js的伟大。\n\n```\n  try {\n    const func = Function(\"metrics\", \"return \" + output.formula); //<<<<=这里是亮点\n    output.value = func(metrics) || \"?\";\n  } catch (e) {\n    output.value = '?';\n  }\n\n```\n\noutput.formula为输入的公式，类型为string，然后一句string的字符串就变成方法了？！是的。很神奇。有了方法，把数据套进去，答案就出来了。\n\n大概内容就是这样，可能还有些细节需要注意，比如，修改了data/option点击那么重绘的按钮，重新计算，需要监听对应数据，如\n\n```\n\t//updateOutputs为计算的过程\n\t$scope.$watchCollection('vis.params.outputs', updateOutputs);\n\n```\n\n#### 源码样例\n\n接下来就看看稍微肤浅点的源码，时间和能力确实有限啊。比如上面出现过的TemplateVisType，整体理解下结构和运作。\n\n- src/core\\_plugins/kbn\\_vislib\\_vis\\_types\n\n  自带的vis组件定义的地方。还包括options选项卡的html,js等等，看看line.js的部分代码\n\n  ```\n  return new VislibVisType({\n    name: 'line',\n    title: 'Line',\n    image,\n    description: 'Emphasize trends',\n    category: VisType.CATEGORY.BASIC,\n    params: {\n      defaults: {\n        grid: {\n          categoryLines: false,\n          style: {\n            color: '#eee'\n          }\n        },\n        ...\n      },\n      positions: ['top', 'left', 'right', 'bottom'],\n      ...\n      editor: pointSeriesTemplate,\n      ...\n      schemas: new Schemas([\n      {\n        group: 'metrics',\n        name: 'metric',\n        title: 'Y-Axis',\n        min: 1,\n        aggFilter: ['!geo_centroid'],\n        defaults: [\n          { schema: 'metric', type: 'count' }\n        ]\n      },\n     \t....\n    ])\n\n\n  ```\n\n 和上方extended\\_metric\\_vis.js粘出来的代码很相似吧，只不过一个是使用的TemplateVisType，一个是VislibVisType，其实这两个类也很相似，都是继承vis\\_type。不过从这点上来看，定义vis组件的套路其实差不多，区别呢，就是官方的组件的话视图绘制的部分应该是内定的，直接选择出来绘制就好了(在后面会看到选择的代码)，但是自定义vis组件的话，视图部分是需要自己自定义的，而不是选择原有的，所以自定义需要TemplateVisType对象，传入template视图。\n\n- src/public/ui/vis/vis\\_type\n\n  定义基本属性和方法createRenderbot。继承这个的话需要实现createRenderbot方法返回Renderbot对象。\n\n- src/public/ui/vislib\\_vis\\_type/vislib\\_vis\\_type\n\n  继承vis_type。\n\n  ```\n  \t...\n  \tconst updateParams = function (params) {\n  \t\tconst updateIfSet = (from, to, prop, func) => {\n  \t      if (from[prop]) {\n  \t        to[prop] = func ? func(from[prop]) : from[prop];\n  \t      }\n  \t    };\n  \t    ...\n  \t})\n  \t...\n  \t// ·。第一，继承VisType，看到responseConverter默认是转换为点线图数组的。\n  \t_.class(VislibVisType).inherits(VisType);\n     function VislibVisType(opts = {}) {\n       VislibVisType.Super.call(this, opts);\n\n       if (this.responseConverter == null) {\n         this.responseConverter = pointSeries;\n       }\n\n       this.listeners = opts.listeners || {};\n     }\n  \t// ·。第二，实现createRenderbot\n  \t   VislibVisType.prototype.createRenderbot = function (vis, $el, uiState) {\n  \t   // 在返回新VislibRenderbot对象之前，对vis.params进行了相应的转换和判断，比如把一些params下的属性对应移到params.seriesParams[0]或者params.valueAxes[0]，params.categoryAxes[0]下\n  \t    updateParams(vis.params);\n  \t    return new VislibRenderbot(vis, $el, uiState);\n  \t};\n\n\n  ```\n\n  可以看到基本就是params的转换，和返回VislibRenderbot作为Renderbot对象，那么，久闻的Renderbot的作用？预知后事如何，请看后面..\n\n- src/public/ui/vislib\\_vis\\_type/vislib\\_renderbot\n\n  恩，Renderbot中定义了需实现的一些方法，VislibRenderbot就继承Renderbot，故就直接看VislibRenderbot的代码了。\n\n  ```\n    VislibRenderbot.prototype.render = function (esResponse) {\n      this.chartData = this.buildChartData(esResponse);\n      return AngularPromise.delay(1).then(() => {\n        this.vislibVis.render(this.chartData, this.uiState); //绘制\n        this.refreshLegend++;\n      });\n    };\n\n\n  ```\n\n  例如render方法,通过调用vislibRenderbot.render方法实现绘制。\n  看到这里，不知道有没有看到加了注释那句代码，绘制的主要工作应该就在这行代码，那么好奇一下this.vislibVis又是什么呢？找到this.vislibVis的初始化\n\n  ```\n  this.vislibVis = new vislib.Vis(this.$el[0], this.vislibParams);\n\n  ```\n\n  在Vis中，主要是visConfig和handler, handler绘制，visConfig选择生成相应的数据结构。对于visConfig的代码\n\n  ```\n  //src/public/ui/vislib/vis_config.js\n  const visType = visTypes[visConfigArgs.type];\n  const typeDefaults = visType(visConfigArgs, this.data); // <= 数据结构更改\n\n  //visTypes => src/public/ui/vislib/types\n    return {\n      histogram: pointSeries.column,\n      horizontal_bar: pointSeries.column,\n      line: pointSeries.line,\n      pie: Private(VislibLibTypesPieProvider),\n      area: pointSeries.area,\n      point_series: pointSeries.line,\n      heatmap: pointSeries.heatmap,\n    };\n\n  ```\n\n  handler绘制,handler的render方法中,可以看到chart.render\n\n  ```\n  // render in handler\n  render() {\n  \t...\n  \tconst chart = new self.ChartClass(self, this, chartData);\n  \t...\n  \tchart.render();\n  }\n\n  //ChartClass in handler\n  this.ChartClass = chartTypes[visConfig.get('type')];\n\n  //chartTypes from src/public/ui/vislib/visualizations/vis_types\n  //这里面是进行可视化的地方，可视化对象都继承自Chart类，components/vislib/visualizations/_chart\n    Chart.prototype.render = function () {\n        var selection = d3.select(this.chartEl);\n        selection.selectAll('*').remove();\n        selection.call(this.draw());\n     };\n    //也就是说，各个可视化对象，只需要用 d3.js 或者其他绘图库，完成自己的 draw() 函数，就可以了！可以在本文件夹下查看具体一些绘制代码\n\n  ```\n\n- src/public/visualize/visualize\n\n  ```\n    $scope.$watch('esResp', prereq(function (resp) {\n        if (!resp) return;\n        $scope.renderbot.render(resp);\n      }));\n\n  ```\n\n   很明显，visualize.js是Visualization的大Boss，通过代码可以看出，visualize与vis_types交互主要通过调用renderbot的各种方法，包括render。\n\n大致总结一下，要定义vis组件的话，返回VislibVisType或TemplateVisType对象，这两个类内部都会生成对应的renderbot对象，visualize与通过调用renderbot对象进行一系列的操作，如果是自定义组件的话，返回的TemplateVisType对象需要具有template属性，为图表视图模板(html), 官方自带的组件的话，会根据类型进行选择视图。对于视图的绘制(包括修改选项卡，重绘)，visualize会调用renderbot.render方法，VisRenderbot的render方法即重绘..在上方粘贴的代码也可以看到，TemplateRenderbot的render方法是将esResponse数据绑定到当前作用域的esResponse变量上，所以自定义插件中要完成绘制的话，需要监听当前作用域的esResponse变量。\n\n好啦，官方自带的组件的代码介绍和自开发插件的代码介绍就到这里就结束啦。\n","slug":"kibana-plugin","published":1,"updated":"2019-10-14T06:22:04.369Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69xw002rt6xvusmkhjt4","content":"<h2 id=\"Kibana插件第一视角\"><a href=\"#Kibana插件第一视角\" class=\"headerlink\" title=\"Kibana插件第一视角\"></a>Kibana插件第一视角</h2><h3 id=\"Kibana插件大概类型有\"><a href=\"#Kibana插件大概类型有\" class=\"headerlink\" title=\"Kibana插件大概类型有\"></a>Kibana插件大概类型有</h3><ul>\n<li>visTypes 视图组件，Visualize</li>\n<li>app 应用组件，如timeline</li>\n<li>hacks, Any module that should be included in every application</li>\n<li>chromeNavControls,</li>\n<li><a href=\"https://www.elastic.co/guide/en/kibana/current/development-uiexports.html\" target=\"_blank\" rel=\"noopener\">更多</a>…</li>\n</ul>\n<h4 id=\"首要目标是visTypes\"><a href=\"#首要目标是visTypes\" class=\"headerlink\" title=\"首要目标是visTypes\"></a>首要目标是visTypes</h4><hr>\n<h3 id=\"全军出击\"><a href=\"#全军出击\" class=\"headerlink\" title=\"全军出击\"></a>全军出击</h3><ul>\n<li><p>git clone kibana，切换到与es对应的版本</p>\n</li>\n<li><p>npm install,</p>\n<ul>\n<li>git切换 http</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global url.&quot;https://&quot;.insteadOf &quot;git://&quot;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>chromedriver失败</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm ERR! chromedriver@2.32.3 install: `node install.js`</span><br></pre></td></tr></table></figure>\n\n<p> 解决方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install chromedriver --chromedriver_cdnurl=https://npm.taobao.org/mirrors/chromedriver</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>默认dev 启动方式会使用ssl,所以是https,如果需要修改的话，可以修改\\kibana\\src\\cli\\serve\\serve.js文件。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (opts.dev) &#123;</span><br><span class=\"line\">  set(&apos;env&apos;, &apos;development&apos;);</span><br><span class=\"line\">  set(&apos;optimize.lazy&apos;, true);</span><br><span class=\"line\"></span><br><span class=\"line\">  // if (opts.ssl) &#123;</span><br><span class=\"line\">  //   set(&apos;server.ssl.enabled&apos;, true);</span><br><span class=\"line\">  // &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // if (opts.ssl &amp;&amp; !has(&apos;server.ssl.certificate&apos;) &amp;&amp; !has(&apos;server.ssl.key&apos;)) &#123;</span><br><span class=\"line\">  //   set(&apos;server.ssl.certificate&apos;, DEV_SSL_CERT_PATH);</span><br><span class=\"line\">  //   set(&apos;server.ssl.key&apos;, DEV_SSL_KEY_PATH);</span><br><span class=\"line\">  // &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>npm start</p>\n</li>\n</ul>\n<h3 id=\"First-Blood\"><a href=\"#First-Blood\" class=\"headerlink\" title=\"First Blood\"></a>First Blood</h3><p>自定义visTypes的话，在kibana/plugins下新建文件夹，在新建的文件夹下执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sao kibana-plugin</span><br></pre></td></tr></table></figure>\n\n<p>可生成对应文件夹格式，如果是visTypes的话，app component，translation files，an hack component， a server API都选no就好了</p>\n<ul>\n<li>new TemplateVisType参数解析</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return new TemplateVisType(&#123;</span><br><span class=\"line\">    name: &apos;extended_metric&apos;,</span><br><span class=\"line\">    title: &apos;Extended Metric&apos;,</span><br><span class=\"line\">    description: &apos;Based on the core Metric-Plugin but gives you the ability&apos; +</span><br><span class=\"line\">      &apos;to output custom aggregates on metric-results.&apos;,</span><br><span class=\"line\">    icon: &apos;fa-calculator&apos;,</span><br><span class=\"line\">    template: extendedMetricVisTemplate, //视图模板</span><br><span class=\"line\">    params: &#123; //Options选项</span><br><span class=\"line\">      defaults: &#123;</span><br><span class=\"line\">        handleNoResults: true,</span><br><span class=\"line\">        fontSize: 60,</span><br><span class=\"line\">        outputs: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            formula: &apos;metrics[0].value * metrics[0].value&apos;,</span><br><span class=\"line\">            label: &apos;Count squared&apos;,</span><br><span class=\"line\">            enabled: true</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      editor: metricVisParamsTemplate //Options视图模板</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    schemas: new Schemas([ //Data相关</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        group: &apos;metrics&apos;,</span><br><span class=\"line\">        name: &apos;metric&apos;,</span><br><span class=\"line\">        title: &apos;Metric&apos;,</span><br><span class=\"line\">        min: 1,</span><br><span class=\"line\">        defaults: [</span><br><span class=\"line\">          &#123; type: &apos;count&apos;, schema: &apos;metric&apos; &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    ])</span><br><span class=\"line\">  &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>上面的例子来源于<a href=\"https://github.com/ommsolutions/kibana_ext_metrics_vis\">地址</a>，一个vis插件。</p>\n<p>看着AngularJS的语法，我想静静。</p>\n<p>目前看起来，vis包括主要的内容包括</p>\n<ul>\n<li>schema, 为左边栏Data部分，选择已有的组件即可。一般来说，metric 数值聚合肯定是 Y 轴；bucket 聚合肯定是 X 轴；而在此基础上，Kibana4 还可以让 bucket 有不同效果，也就是 Schema 里的 segment(默认), group 和 split。根据效果不同，这里是各有增减的，比如饼图就不会有 group。</li>\n<li>Options(params),为左边栏Options部分，包括渲染html</li>\n<li>显示可视化视图html</li>\n<li>controller, 为html的逻辑部分, V &lt;-&gt; C是双向绑定的。</li>\n</ul>\n<p>先梳理一下需求，最好是在es聚合数据拿到之后，到view的那层中间将数据做修改。然后我需要找到数据处理的代码。既然这样，去看看原始vis组件吧。<a href=\"https://sunyonggang.gitbooks.io/elkstack-guide-cn/content/kibana/v4/source-code-analysis/visualize_app.html\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n<ul>\n<li>src/core_plugins/kbn_vislib_vis_types下方是各组件的定义部分</li>\n<li>src/ui/public/vislib是vis具体渲染，vis组件的controller和html渲染主要就是在这个文件下，然而我没找到比较明显的controller,渲染主要是d3进行渲染</li>\n</ul>\n<p>感觉很茫然..</p>\n<p>走不下去的时候，又倒回来重新走。解析一下上面粘的代码，首先是TemplateVisType。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export default function TemplateVisTypeFactory(Private) &#123;</span><br><span class=\"line\">  const VisType = Private(VisVisTypeProvider);</span><br><span class=\"line\">  const TemplateRenderbot = Private(TemplateVisTypeTemplateRenderbotProvider);</span><br><span class=\"line\"></span><br><span class=\"line\">\t// ·。第一，继承VisType，增加了template检测</span><br><span class=\"line\">  _.class(TemplateVisType).inherits(VisType);</span><br><span class=\"line\">  function TemplateVisType(opts = &#123;&#125;) &#123;</span><br><span class=\"line\">    TemplateVisType.Super.call(this, opts);</span><br><span class=\"line\"></span><br><span class=\"line\">    this.template = opts.template;</span><br><span class=\"line\">    if (!this.template) &#123;</span><br><span class=\"line\">      throw new Error(&apos;Missing template for TemplateVisType&apos;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">\t// ·。第二，增加了createRenderbot，下面会对比看看，重写的意义</span><br><span class=\"line\">  TemplateVisType.prototype.createRenderbot = function (vis, $el, uiState) &#123;</span><br><span class=\"line\">    return new TemplateRenderbot(vis, $el, uiState);</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">  return TemplateVisType;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后是看看VislibVisType，基本vis继承的是这个，跟TemplateVisType应该是差不多的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export default function VislibVisTypeFactory(Private) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tconst updateParams = function (params) &#123;</span><br><span class=\"line\">\t\tconst updateIfSet = (from, to, prop, func) =&gt; &#123;</span><br><span class=\"line\">\t      if (from[prop]) &#123;</span><br><span class=\"line\">\t        to[prop] = func ? func(from[prop]) : from[prop];</span><br><span class=\"line\">\t      &#125;</span><br><span class=\"line\">\t    &#125;;</span><br><span class=\"line\">\t    ...</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t// ·。第一，继承VisType，看到responseConverter默认是转换为点线图数组的。</span><br><span class=\"line\">\t_.class(VislibVisType).inherits(VisType);</span><br><span class=\"line\">   function VislibVisType(opts = &#123;&#125;) &#123;</span><br><span class=\"line\">     VislibVisType.Super.call(this, opts);</span><br><span class=\"line\"></span><br><span class=\"line\">     if (this.responseConverter == null) &#123;</span><br><span class=\"line\">       this.responseConverter = pointSeries;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">     this.listeners = opts.listeners || &#123;&#125;;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">\t// ·。第二，增加了createRenderbot</span><br><span class=\"line\">\t   VislibVisType.prototype.createRenderbot = function (vis, $el, uiState) &#123;</span><br><span class=\"line\">\t   // 在返回新VislibRenderbot对象之前，对vis.params进行了相应的转换和判断，比如把一些params下的属性对应移到params.seriesParams[0]或者params.valueAxes[0]，params.categoryAxes[0]下</span><br><span class=\"line\">\t    updateParams(vis.params);</span><br><span class=\"line\">\t    return new VislibRenderbot(vis, $el, uiState);</span><br><span class=\"line\">\t&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>好啦，再看看他们都实现的VisType的庐山真面目</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export default function VisTypeFactory(Private) &#123;</span><br><span class=\"line\">  /**</span><br><span class=\"line\">   * Provides the visualizations for the vislib 👈官方注释很重要。大概意思是输入参数为angular module,输出为vis的class</span><br><span class=\"line\">   *</span><br><span class=\"line\">   * @module vislib</span><br><span class=\"line\">   * @submodule VisTypeFactory</span><br><span class=\"line\">   * @param Private &#123;Object&#125; Loads any function as an angular module</span><br><span class=\"line\">   * @return &#123;Function&#125; Returns an Object of Visualization classes</span><br><span class=\"line\">   */</span><br><span class=\"line\">  return &#123;</span><br><span class=\"line\">    pie: Private(VislibVisualizationsPieChartProvider),</span><br><span class=\"line\">    point_series: Private(VislibVisualizationsPointSeriesProvider)</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>好，其实一点没看到，比如继承那个语法就很蒙圈…不过暂时连蒙带猜的总结下吧。就是讲一个angular module搞到vis的class的过程。具体是怎么搞的，可能一会会看到，可能不会。接下来看看VislibRenderbot的代码。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//具体就不贴了，主要定义了几个类似生命周期的方法，如</span><br><span class=\"line\">VislibRenderbot.prototype._createVis</span><br><span class=\"line\">VislibRenderbot.prototype._getVislibParams</span><br><span class=\"line\">VislibRenderbot.prototype.destroy</span><br><span class=\"line\">VislibRenderbot.prototype.updateParams</span><br><span class=\"line\">//看到render方法了，贴一下具体的代码，看起来重要的是，buildChartData方法和vislibVis对象</span><br><span class=\"line\">VislibRenderbot.prototype.render = function (esResponse) &#123;</span><br><span class=\"line\">    this.chartData = this.buildChartData(esResponse);</span><br><span class=\"line\">    return AngularPromise.delay(1).then(() =&gt; &#123;</span><br><span class=\"line\">      this.vislibVis.render(this.chartData, this.uiState);</span><br><span class=\"line\">      this.refreshLegend++;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">  &#125;;</span><br></pre></td></tr></table></figure>\n\n<p>好吧..再往下追，很多很多..就不挨着解释了，大概说一下，vislibVis类中主要是选择和绘制图。在src/ui/visualization下是各个组件确切的绘图代码，他们都继承自_chart.js,在_chart.js中看到render方法调用自身draw方法，故实现_chart的类实现draw方法即可。好啦，源码分析在这里就差不多了，其实还是没有找到自己想找的东西。这个时候在github上看到了另一个vis的插件。</p>\n<p>Vis类中是渲染了，然后render的参数，data -&gt; {Object} Elasticsearch query results, 要找data从哪里来的话，就开始找类似vis.render的调用，搜了下，调用位置在VislibRenderbot的_createVis方法中，恩，这就跟一开始联系起来了，又回到了VislibRenderbot上了。然后继续找vislibrenderbot实例化的位置，来到了src/ui/public/visualize/visualize.js，看起来这像是高地了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.$watch(&apos;esResp&apos;, prereq(function (resp) &#123;</span><br><span class=\"line\">  if (!resp) return;</span><br><span class=\"line\">  $scope.renderbot.render(resp); //es请求回来的结果传给了renderbot</span><br><span class=\"line\">&#125;));</span><br></pre></td></tr></table></figure>\n\n<p>倒回去看看VislibRenderbot的代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VislibRenderbot.prototype.render = function (esResponse) &#123;</span><br><span class=\"line\">  this.chartData = this.buildChartData(esResponse);</span><br><span class=\"line\">  return AngularPromise.delay(1).then(() =&gt; &#123;</span><br><span class=\"line\">    this.vislibVis.render(this.chartData, this.uiState);</span><br><span class=\"line\">    this.refreshLegend++;</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>好! 好像稍微有点眉目了。通过render方法把es的数据传给了renderbot，renderbot通过buildChartData进行搞事完了就是最后的chartData了，也就是vis.render中的data了。</p>\n<p>恩! 仔细一想，好像还是有点乱，再捋捋。VislibVisType的方法createRenderbot返回的是VislibRenderbot,然后VislibRenderbot的是跟visualize连接的核心，在visualize中，VislibRenderbot进行初始化，传入vislibVis的html元素，和es返回的data,然后在VislibRenderbot内部进行绘制。默认的VislibRenderbot内部data会进行buildChartData转换。</p>\n<h4 id=\"示例extended-metric\"><a href=\"#示例extended-metric\" class=\"headerlink\" title=\"示例extended_metric\"></a>示例extended_metric</h4><p>然后再看TemplateVisType, 这个是自定义时候的VislibVisType，对应的renderbot为TemplateRenderbot,定义的render为，就是裸数据，在$scope中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TemplateRenderbot.prototype.render = function (esResponse) &#123;</span><br><span class=\"line\">  this.$scope.esResponse = esResponse;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>最开始提到了extended_metric插件，然后以这个为例，看看数据的流向。在controller中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// watches</span><br><span class=\"line\">$scope.$watch(&apos;esResponse&apos;, function (resp) &#123;</span><br><span class=\"line\">  if (resp) &#123;</span><br><span class=\"line\">    calcOutputs.length = 0;</span><br><span class=\"line\">    metrics.length = 0;</span><br><span class=\"line\">    for (let key in metrics) &#123;</span><br><span class=\"line\">      if (metrics.hasOwnProperty(key)) &#123;</span><br><span class=\"line\">        delete metrics[key];</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    $scope.processTableGroups(tabifyAggResponse($scope.vis, resp));</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<p>啊虽然是找到了数据的来源和流向，可是，又是Angular.. Angular基础为零的我心好累…不过也算是了然了。然后具体看看extended_metric插件拿到数据之后做的事</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.processTableGroups = function (tableGroups) &#123;</span><br><span class=\"line\">  tableGroups.tables.forEach(function (table) &#123;</span><br><span class=\"line\">    table.columns.forEach(function (column, i) &#123;</span><br><span class=\"line\">      const fieldFormatter = table.aggConfig(column).fieldFormatter();</span><br><span class=\"line\">      let value = table.rows[0][i]; //es数据存在table.rows内</span><br><span class=\"line\">      let formattedValue = isInvalid(value) ? &apos;?&apos; : fieldFormatter(value);     //数据转换后拿出label, formattedValue</span><br><span class=\"line\">      const metric = &#123;</span><br><span class=\"line\">        label: column.title,</span><br><span class=\"line\">        value: value,</span><br><span class=\"line\">        formattedValue: formattedValue</span><br><span class=\"line\">      &#125;;</span><br><span class=\"line\">      metrics.push(metric);</span><br><span class=\"line\">      metrics[column.title] = metric;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">  updateOutputs();</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>上面两段代码是相连的，首先processTableGroups的参数是tabifyAggResponse($scope.vis, resp)，tabifyAggResponse是一个内部已有的方法，主要是把es返回的已知结构的数据，转换成标准格式，这里选择的是table,如果是line的话，可以看看point_series.js。转换包括参数包括数据之外，还有vis,转换完成得到的数据中包含es数据之外，还包括选项卡中的数据，如设置的label等。</p>\n<h4 id=\"示例line-sg\"><a href=\"#示例line-sg\" class=\"headerlink\" title=\"示例line_sg\"></a>示例line_sg</h4><p>示例<a href=\"https://github.com/sbeyn/kibana-plugin-line-sg\">地址</a></p>\n<p>然后分析一下，顺便巩固一下上面的知识。</p>\n<p>在line_sg.js中，熟悉的控件，TemplateVisType，包含params和schemas。</p>\n<p>在视图line_sg.html中,使用c3绘制，只有几行代码，看似很简单，我想控制绘制的代码应该在controller中，然后看看_params.html,是Option的选项卡，主要应该是视图的配置相关。然后看看controller,在视图controller中，前面很大一部分是关于要画的准备工作，以数据流向为接入点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.$watch(&apos;esResponse&apos;, function (resp) &#123;</span><br><span class=\"line\">    if (resp) &#123;</span><br><span class=\"line\">      console.log(resp);</span><br><span class=\"line\">      metrics.length = 0; //重置metrics，重置数组的方式是修改length,emmm学到了</span><br><span class=\"line\">      $scope.processTableGroups(tabifyAggResponse($scope.vis, resp)); //还是使用的数据表格形式，为什么大家都选这个转换形式？我猜可能是因为数据比较好拿出来..数据还是集中的，数据拿出来搞成自己格式的，与视图相关的数据都在metrics中，</span><br><span class=\"line\">      $scope.showGraph(); //从metrics中拿出数据，做图</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>这个是示例是使用c3来完成绘制的示例，因为和需求的方波刚好可以吻合，就具体细节学习下吧。首先将代码拷入plugins文件夹，启动kibana,查看效果。发现不怎么好看，另外选择chart_types=step似乎不工作，看看代码吧。</p>\n<p>首先尝试是，设置params之后，点击重绘，没有效果。</p>\n<p>仔细看了看插件的绘制和c3的使用，看了看线上的kibana，发现line是真的可以有step..而且图形没有错…其实本来line画图就有方波。好吧，还是先看看这个插件为什么设置params之后，点击重绘，没有触发重绘吧。结论是没有监听变量的变化..$scope.$watch、$watchController等监听方法，虽然没有看到具体代码，大概是，侧边栏部分没有修改的话，那个重绘的按钮就无法点击，那个按钮的点击事件应该是触发watch的监听事件的，有修改，就会触发监听事件，要重绘的话其实就是在监听事件的回调中加入视图重绘的部分，其实数据会自动绑定，只是需要个刷新机制。</p>\n<hr>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">                                                 /===-_---~~~~~~~~~------____</span><br><span class=\"line\">                                                |===-~___                _,-&apos;</span><br><span class=\"line\">                 -==\\\\                         `//~\\\\   ~~~~`---.___.-~~</span><br><span class=\"line\">             ______-==|                         | |  \\\\           _-~`</span><br><span class=\"line\">       __--~~~  ,-/-==\\\\                        | |   `\\        ,&apos;</span><br><span class=\"line\">    _-~       /&apos;    |  \\\\                      / /      \\      /</span><br><span class=\"line\">  .&apos;        /       |   \\\\                   /&apos; /        \\   /&apos;</span><br><span class=\"line\"> /  ____  /         |    \\`\\.__/-~~ ~ \\ _ _/&apos;  /          \\/&apos;</span><br><span class=\"line\">/-&apos;~    ~~~~~---__  |     ~-/~         ( )   /&apos;        _--~`</span><br><span class=\"line\">                  \\_|      /        _)   ;  ),   __--~~</span><br><span class=\"line\">                    &apos;~~--_/      _-~/-  / \\   &apos;-~ \\</span><br><span class=\"line\">                   &#123;\\__--_/&#125;    / \\\\_&gt;- )&lt;__\\      \\</span><br><span class=\"line\">                   /&apos;   (_/  _-~  | |__&gt;--&lt;__|      |</span><br><span class=\"line\">                  |0  0 _/) )-~     | |__&gt;--&lt;__|      |</span><br><span class=\"line\">                  / /~ ,_/       / /__&gt;---&lt;__/      |</span><br><span class=\"line\">                 o o _//        /-~_&gt;---&lt;__-~      /</span><br><span class=\"line\">                 (^(~          /~_&gt;---&lt;__-      _-~</span><br><span class=\"line\">                ,/|           /__&gt;--&lt;__/     _-~</span><br><span class=\"line\">             ,//(&apos;(          |__&gt;--&lt;__|     /                  .----_</span><br><span class=\"line\">            ( ( &apos;))          |__&gt;--&lt;__|    |                 /&apos; _---_~\\</span><br><span class=\"line\">         `-)) )) (           |__&gt;--&lt;__|    |               /&apos;  /     ~\\`\\</span><br><span class=\"line\">        ,/,&apos;//( (             \\__&gt;--&lt;__\\    \\            /&apos;  //        ||</span><br><span class=\"line\">      ,( ( ((, ))              ~-__&gt;--&lt;_~-_  ~--____---~&apos; _/&apos;/        /&apos;</span><br><span class=\"line\">    `~/  )` ) ,/|                 ~-_~&gt;--&lt;_/-__       __-~ _/</span><br><span class=\"line\">  ._-~//( )/ )) `                    ~~-&apos;_/_/ /~~~~~~~__--~</span><br><span class=\"line\">   ;&apos;( &apos;)/ ,)(                              ~~~~~~~~~~</span><br><span class=\"line\">  &apos; &apos;) &apos;( (/</span><br><span class=\"line\">    &apos;   &apos;  `</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>后面整理了下，思路稍微清晰一点的。</p>\n<p>开发插件的话，都需要一定的模板，官方推荐的生成模板的脚手架<a href=\"https://github.com/saojs/sao\">sao</a>,具体使用<a href=\"https://github.com/elastic/template-kibana-plugin\">样例</a>。还有插件开发的<a href=\"https://www.gitbook.com/book/trumandu/kibana-plugin-development-tutorial/details\" target=\"_blank\" rel=\"noopener\">教程</a>。篇幅原因，就省去教程系列，主要看看结构，源码什么的..</p>\n<h3 id=\"visTypes\"><a href=\"#visTypes\" class=\"headerlink\" title=\"visTypes\"></a>visTypes</h3><p>Visualize插件的开发，组成主要是es6,angular(听说angular1和2完全没关系，特地指出kibana采用的是angular1)。kibana的Visualize组件的绘制主要是通过<a href=\"https://d3js.org/\" target=\"_blank\" rel=\"noopener\">d3</a>这个伟大的可视化库。</p>\n<h4 id=\"插件样例\"><a href=\"#插件样例\" class=\"headerlink\" title=\"插件样例\"></a>插件样例</h4><p>从众多优秀的vis插件中选择了一个比较简单的<a href=\"https://github.com/ommsolutions/kibana_ext_metrics_vis\">样例</a>来做分析(主要是人家有图)。效果如gif图，用文字来说明的话，就是实现了一个可计算的插件，选择metric值，然后填入计算公式，得出值。(因为见识有限，以前总说在kibana中实现计算很复杂，现在看来真是啪啪(*10)打脸)。</p>\n<p>extended_metric_vis.js很明显，是这个插件的大头。稍微粘一点代码。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return new TemplateVisType(&#123;</span><br><span class=\"line\">    name: &apos;extended_metric&apos;,</span><br><span class=\"line\">    title: &apos;Extended Metric&apos;,</span><br><span class=\"line\">    description: &apos;Based on the core Metric-Plugin but gives you the ability&apos; +</span><br><span class=\"line\">      &apos;to output custom aggregates on metric-results.&apos;,</span><br><span class=\"line\">    icon: &apos;fa-calculator&apos;,</span><br><span class=\"line\">    template: extendedMetricVisTemplate, //视图模板.html</span><br><span class=\"line\">    params: &#123; //Options选项，预定义的Options选项及值，在对应视图中会有具体使用</span><br><span class=\"line\">      defaults: &#123;</span><br><span class=\"line\">        handleNoResults: true,</span><br><span class=\"line\">        fontSize: 60,</span><br><span class=\"line\">        outputs: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            formula: &apos;metrics[0].value * metrics[0].value&apos;,</span><br><span class=\"line\">            label: &apos;Count squared&apos;,</span><br><span class=\"line\">            enabled: true</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      editor: metricVisParamsTemplate //Options选项卡视图模板.html</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    schemas: new Schemas([ //Data相关，这里就不是自由发挥的地界了，属于半命题类型，根据自己需要的数据选择对应类型，基本</span><br><span class=\"line\">    \t\t\t\t\t//就是metric，bucket的组合，一般来说，metric 数值聚合肯定是 Y 轴；bucket 聚合肯定是 X 轴；</span><br><span class=\"line\">      &#123;           //而在此基础上，还可以让 bucket 有不同效果，也就是 Schema 里的 segment(默认), group 和 split。</span><br><span class=\"line\">        group: &apos;metrics&apos;,</span><br><span class=\"line\">        name: &apos;metric&apos;,</span><br><span class=\"line\">        title: &apos;Metric&apos;,</span><br><span class=\"line\">        min: 1,</span><br><span class=\"line\">        defaults: [</span><br><span class=\"line\">          &#123; type: &apos;count&apos;, schema: &apos;metric&apos; &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    ])</span><br><span class=\"line\">  &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>如果稍微看了下vis插件的教程的话，就会很熟悉，因为模板就差不多是这样，利用TemplateVisType生成对应实例，基本备注都在代码里了，就不再啰嗦了。</p>\n<p>然后根据上面的代码直接的找到两个html，extended_metric_vis.html和extended_metric_vis_params.html, 很显示，就是view,会看到伟大的angular进行mvc的管理，然后去看c =&gt; extended_metric_vis_controller.js。这个代码里，主要是angular与其控制器的绑定，跳过这个，进到方法里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.$watch(&apos;esResponse&apos;, function (resp) &#123;</span><br><span class=\"line\">    if (resp) &#123;</span><br><span class=\"line\">      calcOutputs.length = 0;</span><br><span class=\"line\">      metrics.length = 0;</span><br><span class=\"line\">      //清空metrics</span><br><span class=\"line\">      for (let key in metrics) &#123;</span><br><span class=\"line\">        if (metrics.hasOwnProperty(key)) &#123;</span><br><span class=\"line\">          delete metrics[key];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      $scope.processTableGroups(tabifyAggResponse($scope.vis, resp));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>很明显，这里是接受es查询结果的代码，结论很明显是，获得es查询结果只需要监听esResponse变量就可以。然后看看拿到结果的处理processTableGroups方法。首先是tabifyAggResponse是按照已知的es查询结果结构生成与视图(data选项卡)强相关的数据结构，为什么说强相关呢，比如tabifyAggResponse后的结果主要包括columns和rows，分别是data选项卡的分组和对应的数据，就拿这个例子来说，如果新建了两个metric, columns里就是这两个metric的属性，包含title(即输入的label)等，对应index的rows里的数据就是对应metric的结果。转换之后，在processTableGroups方法里，只需要把对应的数据拿出来组合下，比如，例子里就是以columns中的title为键，以metric的结果为值，组成数据到metrics(装数据的对象，下方会用到)中。</p>\n<p>view有了，数据也有了，还差最后一步，就是怎么把公式套进去？在这里，我不得不再次感叹下js的伟大。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">try &#123;</span><br><span class=\"line\">  const func = Function(&quot;metrics&quot;, &quot;return &quot; + output.formula); //&lt;&lt;&lt;&lt;=这里是亮点</span><br><span class=\"line\">  output.value = func(metrics) || &quot;?&quot;;</span><br><span class=\"line\">&#125; catch (e) &#123;</span><br><span class=\"line\">  output.value = &apos;?&apos;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>output.formula为输入的公式，类型为string，然后一句string的字符串就变成方法了？！是的。很神奇。有了方法，把数据套进去，答案就出来了。</p>\n<p>大概内容就是这样，可能还有些细节需要注意，比如，修改了data/option点击那么重绘的按钮，重新计算，需要监听对应数据，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//updateOutputs为计算的过程</span><br><span class=\"line\">$scope.$watchCollection(&apos;vis.params.outputs&apos;, updateOutputs);</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"源码样例\"><a href=\"#源码样例\" class=\"headerlink\" title=\"源码样例\"></a>源码样例</h4><p>接下来就看看稍微肤浅点的源码，时间和能力确实有限啊。比如上面出现过的TemplateVisType，整体理解下结构和运作。</p>\n<ul>\n<li><p>src/core_plugins/kbn_vislib_vis_types</p>\n<p>自带的vis组件定义的地方。还包括options选项卡的html,js等等，看看line.js的部分代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return new VislibVisType(&#123;</span><br><span class=\"line\">  name: &apos;line&apos;,</span><br><span class=\"line\">  title: &apos;Line&apos;,</span><br><span class=\"line\">  image,</span><br><span class=\"line\">  description: &apos;Emphasize trends&apos;,</span><br><span class=\"line\">  category: VisType.CATEGORY.BASIC,</span><br><span class=\"line\">  params: &#123;</span><br><span class=\"line\">    defaults: &#123;</span><br><span class=\"line\">      grid: &#123;</span><br><span class=\"line\">        categoryLines: false,</span><br><span class=\"line\">        style: &#123;</span><br><span class=\"line\">          color: &apos;#eee&apos;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      ...</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    positions: [&apos;top&apos;, &apos;left&apos;, &apos;right&apos;, &apos;bottom&apos;],</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    editor: pointSeriesTemplate,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    schemas: new Schemas([</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      group: &apos;metrics&apos;,</span><br><span class=\"line\">      name: &apos;metric&apos;,</span><br><span class=\"line\">      title: &apos;Y-Axis&apos;,</span><br><span class=\"line\">      min: 1,</span><br><span class=\"line\">      aggFilter: [&apos;!geo_centroid&apos;],</span><br><span class=\"line\">      defaults: [</span><br><span class=\"line\">        &#123; schema: &apos;metric&apos;, type: &apos;count&apos; &#125;</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">   \t....</span><br><span class=\"line\">  ])</span><br></pre></td></tr></table></figure>\n\n<p>和上方extended_metric_vis.js粘出来的代码很相似吧，只不过一个是使用的TemplateVisType，一个是VislibVisType，其实这两个类也很相似，都是继承vis_type。不过从这点上来看，定义vis组件的套路其实差不多，区别呢，就是官方的组件的话视图绘制的部分应该是内定的，直接选择出来绘制就好了(在后面会看到选择的代码)，但是自定义vis组件的话，视图部分是需要自己自定义的，而不是选择原有的，所以自定义需要TemplateVisType对象，传入template视图。</p>\n</li>\n<li><p>src/public/ui/vis/vis_type</p>\n<p>定义基本属性和方法createRenderbot。继承这个的话需要实现createRenderbot方法返回Renderbot对象。</p>\n</li>\n<li><p>src/public/ui/vislib_vis_type/vislib_vis_type</p>\n<p>继承vis_type。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">const updateParams = function (params) &#123;</span><br><span class=\"line\">\tconst updateIfSet = (from, to, prop, func) =&gt; &#123;</span><br><span class=\"line\">      if (from[prop]) &#123;</span><br><span class=\"line\">        to[prop] = func ? func(from[prop]) : from[prop];</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">...</span><br><span class=\"line\">// ·。第一，继承VisType，看到responseConverter默认是转换为点线图数组的。</span><br><span class=\"line\">_.class(VislibVisType).inherits(VisType);</span><br><span class=\"line\">  function VislibVisType(opts = &#123;&#125;) &#123;</span><br><span class=\"line\">    VislibVisType.Super.call(this, opts);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (this.responseConverter == null) &#123;</span><br><span class=\"line\">      this.responseConverter = pointSeries;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    this.listeners = opts.listeners || &#123;&#125;;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">// ·。第二，实现createRenderbot</span><br><span class=\"line\">   VislibVisType.prototype.createRenderbot = function (vis, $el, uiState) &#123;</span><br><span class=\"line\">   // 在返回新VislibRenderbot对象之前，对vis.params进行了相应的转换和判断，比如把一些params下的属性对应移到params.seriesParams[0]或者params.valueAxes[0]，params.categoryAxes[0]下</span><br><span class=\"line\">    updateParams(vis.params);</span><br><span class=\"line\">    return new VislibRenderbot(vis, $el, uiState);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到基本就是params的转换，和返回VislibRenderbot作为Renderbot对象，那么，久闻的Renderbot的作用？预知后事如何，请看后面..</p>\n</li>\n<li><p>src/public/ui/vislib_vis_type/vislib_renderbot</p>\n<p>恩，Renderbot中定义了需实现的一些方法，VislibRenderbot就继承Renderbot，故就直接看VislibRenderbot的代码了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VislibRenderbot.prototype.render = function (esResponse) &#123;</span><br><span class=\"line\">  this.chartData = this.buildChartData(esResponse);</span><br><span class=\"line\">  return AngularPromise.delay(1).then(() =&gt; &#123;</span><br><span class=\"line\">    this.vislibVis.render(this.chartData, this.uiState); //绘制</span><br><span class=\"line\">    this.refreshLegend++;</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>例如render方法,通过调用vislibRenderbot.render方法实现绘制。<br>看到这里，不知道有没有看到加了注释那句代码，绘制的主要工作应该就在这行代码，那么好奇一下this.vislibVis又是什么呢？找到this.vislibVis的初始化</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">this.vislibVis = new vislib.Vis(this.$el[0], this.vislibParams);</span><br></pre></td></tr></table></figure>\n\n<p>在Vis中，主要是visConfig和handler, handler绘制，visConfig选择生成相应的数据结构。对于visConfig的代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//src/public/ui/vislib/vis_config.js</span><br><span class=\"line\">const visType = visTypes[visConfigArgs.type];</span><br><span class=\"line\">const typeDefaults = visType(visConfigArgs, this.data); // &lt;= 数据结构更改</span><br><span class=\"line\"></span><br><span class=\"line\">//visTypes =&gt; src/public/ui/vislib/types</span><br><span class=\"line\">  return &#123;</span><br><span class=\"line\">    histogram: pointSeries.column,</span><br><span class=\"line\">    horizontal_bar: pointSeries.column,</span><br><span class=\"line\">    line: pointSeries.line,</span><br><span class=\"line\">    pie: Private(VislibLibTypesPieProvider),</span><br><span class=\"line\">    area: pointSeries.area,</span><br><span class=\"line\">    point_series: pointSeries.line,</span><br><span class=\"line\">    heatmap: pointSeries.heatmap,</span><br><span class=\"line\">  &#125;;</span><br></pre></td></tr></table></figure>\n\n<p>handler绘制,handler的render方法中,可以看到chart.render</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// render in handler</span><br><span class=\"line\">render() &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tconst chart = new self.ChartClass(self, this, chartData);</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tchart.render();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//ChartClass in handler</span><br><span class=\"line\">this.ChartClass = chartTypes[visConfig.get(&apos;type&apos;)];</span><br><span class=\"line\"></span><br><span class=\"line\">//chartTypes from src/public/ui/vislib/visualizations/vis_types</span><br><span class=\"line\">//这里面是进行可视化的地方，可视化对象都继承自Chart类，components/vislib/visualizations/_chart</span><br><span class=\"line\">  Chart.prototype.render = function () &#123;</span><br><span class=\"line\">      var selection = d3.select(this.chartEl);</span><br><span class=\"line\">      selection.selectAll(&apos;*&apos;).remove();</span><br><span class=\"line\">      selection.call(this.draw());</span><br><span class=\"line\">   &#125;;</span><br><span class=\"line\">  //也就是说，各个可视化对象，只需要用 d3.js 或者其他绘图库，完成自己的 draw() 函数，就可以了！可以在本文件夹下查看具体一些绘制代码</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>src/public/visualize/visualize</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.$watch(&apos;esResp&apos;, prereq(function (resp) &#123;</span><br><span class=\"line\">    if (!resp) return;</span><br><span class=\"line\">    $scope.renderbot.render(resp);</span><br><span class=\"line\">  &#125;));</span><br></pre></td></tr></table></figure>\n\n<p> 很明显，visualize.js是Visualization的大Boss，通过代码可以看出，visualize与vis_types交互主要通过调用renderbot的各种方法，包括render。</p>\n</li>\n</ul>\n<p>大致总结一下，要定义vis组件的话，返回VislibVisType或TemplateVisType对象，这两个类内部都会生成对应的renderbot对象，visualize与通过调用renderbot对象进行一系列的操作，如果是自定义组件的话，返回的TemplateVisType对象需要具有template属性，为图表视图模板(html), 官方自带的组件的话，会根据类型进行选择视图。对于视图的绘制(包括修改选项卡，重绘)，visualize会调用renderbot.render方法，VisRenderbot的render方法即重绘..在上方粘贴的代码也可以看到，TemplateRenderbot的render方法是将esResponse数据绑定到当前作用域的esResponse变量上，所以自定义插件中要完成绘制的话，需要监听当前作用域的esResponse变量。</p>\n<p>好啦，官方自带的组件的代码介绍和自开发插件的代码介绍就到这里就结束啦。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Kibana插件第一视角\"><a href=\"#Kibana插件第一视角\" class=\"headerlink\" title=\"Kibana插件第一视角\"></a>Kibana插件第一视角</h2><h3 id=\"Kibana插件大概类型有\"><a href=\"#Kibana插件大概类型有\" class=\"headerlink\" title=\"Kibana插件大概类型有\"></a>Kibana插件大概类型有</h3><ul>\n<li>visTypes 视图组件，Visualize</li>\n<li>app 应用组件，如timeline</li>\n<li>hacks, Any module that should be included in every application</li>\n<li>chromeNavControls,</li>\n<li><a href=\"https://www.elastic.co/guide/en/kibana/current/development-uiexports.html\" target=\"_blank\" rel=\"noopener\">更多</a>…</li>\n</ul>\n<h4 id=\"首要目标是visTypes\"><a href=\"#首要目标是visTypes\" class=\"headerlink\" title=\"首要目标是visTypes\"></a>首要目标是visTypes</h4><hr>\n<h3 id=\"全军出击\"><a href=\"#全军出击\" class=\"headerlink\" title=\"全军出击\"></a>全军出击</h3><ul>\n<li><p>git clone kibana，切换到与es对应的版本</p>\n</li>\n<li><p>npm install,</p>\n<ul>\n<li>git切换 http</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global url.&quot;https://&quot;.insteadOf &quot;git://&quot;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>chromedriver失败</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm ERR! chromedriver@2.32.3 install: `node install.js`</span><br></pre></td></tr></table></figure>\n\n<p> 解决方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install chromedriver --chromedriver_cdnurl=https://npm.taobao.org/mirrors/chromedriver</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>默认dev 启动方式会使用ssl,所以是https,如果需要修改的话，可以修改\\kibana\\src\\cli\\serve\\serve.js文件。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (opts.dev) &#123;</span><br><span class=\"line\">  set(&apos;env&apos;, &apos;development&apos;);</span><br><span class=\"line\">  set(&apos;optimize.lazy&apos;, true);</span><br><span class=\"line\"></span><br><span class=\"line\">  // if (opts.ssl) &#123;</span><br><span class=\"line\">  //   set(&apos;server.ssl.enabled&apos;, true);</span><br><span class=\"line\">  // &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // if (opts.ssl &amp;&amp; !has(&apos;server.ssl.certificate&apos;) &amp;&amp; !has(&apos;server.ssl.key&apos;)) &#123;</span><br><span class=\"line\">  //   set(&apos;server.ssl.certificate&apos;, DEV_SSL_CERT_PATH);</span><br><span class=\"line\">  //   set(&apos;server.ssl.key&apos;, DEV_SSL_KEY_PATH);</span><br><span class=\"line\">  // &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>npm start</p>\n</li>\n</ul>\n<h3 id=\"First-Blood\"><a href=\"#First-Blood\" class=\"headerlink\" title=\"First Blood\"></a>First Blood</h3><p>自定义visTypes的话，在kibana/plugins下新建文件夹，在新建的文件夹下执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sao kibana-plugin</span><br></pre></td></tr></table></figure>\n\n<p>可生成对应文件夹格式，如果是visTypes的话，app component，translation files，an hack component， a server API都选no就好了</p>\n<ul>\n<li>new TemplateVisType参数解析</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return new TemplateVisType(&#123;</span><br><span class=\"line\">    name: &apos;extended_metric&apos;,</span><br><span class=\"line\">    title: &apos;Extended Metric&apos;,</span><br><span class=\"line\">    description: &apos;Based on the core Metric-Plugin but gives you the ability&apos; +</span><br><span class=\"line\">      &apos;to output custom aggregates on metric-results.&apos;,</span><br><span class=\"line\">    icon: &apos;fa-calculator&apos;,</span><br><span class=\"line\">    template: extendedMetricVisTemplate, //视图模板</span><br><span class=\"line\">    params: &#123; //Options选项</span><br><span class=\"line\">      defaults: &#123;</span><br><span class=\"line\">        handleNoResults: true,</span><br><span class=\"line\">        fontSize: 60,</span><br><span class=\"line\">        outputs: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            formula: &apos;metrics[0].value * metrics[0].value&apos;,</span><br><span class=\"line\">            label: &apos;Count squared&apos;,</span><br><span class=\"line\">            enabled: true</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      editor: metricVisParamsTemplate //Options视图模板</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    schemas: new Schemas([ //Data相关</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        group: &apos;metrics&apos;,</span><br><span class=\"line\">        name: &apos;metric&apos;,</span><br><span class=\"line\">        title: &apos;Metric&apos;,</span><br><span class=\"line\">        min: 1,</span><br><span class=\"line\">        defaults: [</span><br><span class=\"line\">          &#123; type: &apos;count&apos;, schema: &apos;metric&apos; &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    ])</span><br><span class=\"line\">  &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>上面的例子来源于<a href=\"https://github.com/ommsolutions/kibana_ext_metrics_vis\">地址</a>，一个vis插件。</p>\n<p>看着AngularJS的语法，我想静静。</p>\n<p>目前看起来，vis包括主要的内容包括</p>\n<ul>\n<li>schema, 为左边栏Data部分，选择已有的组件即可。一般来说，metric 数值聚合肯定是 Y 轴；bucket 聚合肯定是 X 轴；而在此基础上，Kibana4 还可以让 bucket 有不同效果，也就是 Schema 里的 segment(默认), group 和 split。根据效果不同，这里是各有增减的，比如饼图就不会有 group。</li>\n<li>Options(params),为左边栏Options部分，包括渲染html</li>\n<li>显示可视化视图html</li>\n<li>controller, 为html的逻辑部分, V &lt;-&gt; C是双向绑定的。</li>\n</ul>\n<p>先梳理一下需求，最好是在es聚合数据拿到之后，到view的那层中间将数据做修改。然后我需要找到数据处理的代码。既然这样，去看看原始vis组件吧。<a href=\"https://sunyonggang.gitbooks.io/elkstack-guide-cn/content/kibana/v4/source-code-analysis/visualize_app.html\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n<ul>\n<li>src/core_plugins/kbn_vislib_vis_types下方是各组件的定义部分</li>\n<li>src/ui/public/vislib是vis具体渲染，vis组件的controller和html渲染主要就是在这个文件下，然而我没找到比较明显的controller,渲染主要是d3进行渲染</li>\n</ul>\n<p>感觉很茫然..</p>\n<p>走不下去的时候，又倒回来重新走。解析一下上面粘的代码，首先是TemplateVisType。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export default function TemplateVisTypeFactory(Private) &#123;</span><br><span class=\"line\">  const VisType = Private(VisVisTypeProvider);</span><br><span class=\"line\">  const TemplateRenderbot = Private(TemplateVisTypeTemplateRenderbotProvider);</span><br><span class=\"line\"></span><br><span class=\"line\">\t// ·。第一，继承VisType，增加了template检测</span><br><span class=\"line\">  _.class(TemplateVisType).inherits(VisType);</span><br><span class=\"line\">  function TemplateVisType(opts = &#123;&#125;) &#123;</span><br><span class=\"line\">    TemplateVisType.Super.call(this, opts);</span><br><span class=\"line\"></span><br><span class=\"line\">    this.template = opts.template;</span><br><span class=\"line\">    if (!this.template) &#123;</span><br><span class=\"line\">      throw new Error(&apos;Missing template for TemplateVisType&apos;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">\t// ·。第二，增加了createRenderbot，下面会对比看看，重写的意义</span><br><span class=\"line\">  TemplateVisType.prototype.createRenderbot = function (vis, $el, uiState) &#123;</span><br><span class=\"line\">    return new TemplateRenderbot(vis, $el, uiState);</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">  return TemplateVisType;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后是看看VislibVisType，基本vis继承的是这个，跟TemplateVisType应该是差不多的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export default function VislibVisTypeFactory(Private) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tconst updateParams = function (params) &#123;</span><br><span class=\"line\">\t\tconst updateIfSet = (from, to, prop, func) =&gt; &#123;</span><br><span class=\"line\">\t      if (from[prop]) &#123;</span><br><span class=\"line\">\t        to[prop] = func ? func(from[prop]) : from[prop];</span><br><span class=\"line\">\t      &#125;</span><br><span class=\"line\">\t    &#125;;</span><br><span class=\"line\">\t    ...</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t// ·。第一，继承VisType，看到responseConverter默认是转换为点线图数组的。</span><br><span class=\"line\">\t_.class(VislibVisType).inherits(VisType);</span><br><span class=\"line\">   function VislibVisType(opts = &#123;&#125;) &#123;</span><br><span class=\"line\">     VislibVisType.Super.call(this, opts);</span><br><span class=\"line\"></span><br><span class=\"line\">     if (this.responseConverter == null) &#123;</span><br><span class=\"line\">       this.responseConverter = pointSeries;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">     this.listeners = opts.listeners || &#123;&#125;;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">\t// ·。第二，增加了createRenderbot</span><br><span class=\"line\">\t   VislibVisType.prototype.createRenderbot = function (vis, $el, uiState) &#123;</span><br><span class=\"line\">\t   // 在返回新VislibRenderbot对象之前，对vis.params进行了相应的转换和判断，比如把一些params下的属性对应移到params.seriesParams[0]或者params.valueAxes[0]，params.categoryAxes[0]下</span><br><span class=\"line\">\t    updateParams(vis.params);</span><br><span class=\"line\">\t    return new VislibRenderbot(vis, $el, uiState);</span><br><span class=\"line\">\t&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>好啦，再看看他们都实现的VisType的庐山真面目</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export default function VisTypeFactory(Private) &#123;</span><br><span class=\"line\">  /**</span><br><span class=\"line\">   * Provides the visualizations for the vislib 👈官方注释很重要。大概意思是输入参数为angular module,输出为vis的class</span><br><span class=\"line\">   *</span><br><span class=\"line\">   * @module vislib</span><br><span class=\"line\">   * @submodule VisTypeFactory</span><br><span class=\"line\">   * @param Private &#123;Object&#125; Loads any function as an angular module</span><br><span class=\"line\">   * @return &#123;Function&#125; Returns an Object of Visualization classes</span><br><span class=\"line\">   */</span><br><span class=\"line\">  return &#123;</span><br><span class=\"line\">    pie: Private(VislibVisualizationsPieChartProvider),</span><br><span class=\"line\">    point_series: Private(VislibVisualizationsPointSeriesProvider)</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>好，其实一点没看到，比如继承那个语法就很蒙圈…不过暂时连蒙带猜的总结下吧。就是讲一个angular module搞到vis的class的过程。具体是怎么搞的，可能一会会看到，可能不会。接下来看看VislibRenderbot的代码。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//具体就不贴了，主要定义了几个类似生命周期的方法，如</span><br><span class=\"line\">VislibRenderbot.prototype._createVis</span><br><span class=\"line\">VislibRenderbot.prototype._getVislibParams</span><br><span class=\"line\">VislibRenderbot.prototype.destroy</span><br><span class=\"line\">VislibRenderbot.prototype.updateParams</span><br><span class=\"line\">//看到render方法了，贴一下具体的代码，看起来重要的是，buildChartData方法和vislibVis对象</span><br><span class=\"line\">VislibRenderbot.prototype.render = function (esResponse) &#123;</span><br><span class=\"line\">    this.chartData = this.buildChartData(esResponse);</span><br><span class=\"line\">    return AngularPromise.delay(1).then(() =&gt; &#123;</span><br><span class=\"line\">      this.vislibVis.render(this.chartData, this.uiState);</span><br><span class=\"line\">      this.refreshLegend++;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">  &#125;;</span><br></pre></td></tr></table></figure>\n\n<p>好吧..再往下追，很多很多..就不挨着解释了，大概说一下，vislibVis类中主要是选择和绘制图。在src/ui/visualization下是各个组件确切的绘图代码，他们都继承自_chart.js,在_chart.js中看到render方法调用自身draw方法，故实现_chart的类实现draw方法即可。好啦，源码分析在这里就差不多了，其实还是没有找到自己想找的东西。这个时候在github上看到了另一个vis的插件。</p>\n<p>Vis类中是渲染了，然后render的参数，data -&gt; {Object} Elasticsearch query results, 要找data从哪里来的话，就开始找类似vis.render的调用，搜了下，调用位置在VislibRenderbot的_createVis方法中，恩，这就跟一开始联系起来了，又回到了VislibRenderbot上了。然后继续找vislibrenderbot实例化的位置，来到了src/ui/public/visualize/visualize.js，看起来这像是高地了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.$watch(&apos;esResp&apos;, prereq(function (resp) &#123;</span><br><span class=\"line\">  if (!resp) return;</span><br><span class=\"line\">  $scope.renderbot.render(resp); //es请求回来的结果传给了renderbot</span><br><span class=\"line\">&#125;));</span><br></pre></td></tr></table></figure>\n\n<p>倒回去看看VislibRenderbot的代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VislibRenderbot.prototype.render = function (esResponse) &#123;</span><br><span class=\"line\">  this.chartData = this.buildChartData(esResponse);</span><br><span class=\"line\">  return AngularPromise.delay(1).then(() =&gt; &#123;</span><br><span class=\"line\">    this.vislibVis.render(this.chartData, this.uiState);</span><br><span class=\"line\">    this.refreshLegend++;</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>好! 好像稍微有点眉目了。通过render方法把es的数据传给了renderbot，renderbot通过buildChartData进行搞事完了就是最后的chartData了，也就是vis.render中的data了。</p>\n<p>恩! 仔细一想，好像还是有点乱，再捋捋。VislibVisType的方法createRenderbot返回的是VislibRenderbot,然后VislibRenderbot的是跟visualize连接的核心，在visualize中，VislibRenderbot进行初始化，传入vislibVis的html元素，和es返回的data,然后在VislibRenderbot内部进行绘制。默认的VislibRenderbot内部data会进行buildChartData转换。</p>\n<h4 id=\"示例extended-metric\"><a href=\"#示例extended-metric\" class=\"headerlink\" title=\"示例extended_metric\"></a>示例extended_metric</h4><p>然后再看TemplateVisType, 这个是自定义时候的VislibVisType，对应的renderbot为TemplateRenderbot,定义的render为，就是裸数据，在$scope中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TemplateRenderbot.prototype.render = function (esResponse) &#123;</span><br><span class=\"line\">  this.$scope.esResponse = esResponse;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>最开始提到了extended_metric插件，然后以这个为例，看看数据的流向。在controller中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// watches</span><br><span class=\"line\">$scope.$watch(&apos;esResponse&apos;, function (resp) &#123;</span><br><span class=\"line\">  if (resp) &#123;</span><br><span class=\"line\">    calcOutputs.length = 0;</span><br><span class=\"line\">    metrics.length = 0;</span><br><span class=\"line\">    for (let key in metrics) &#123;</span><br><span class=\"line\">      if (metrics.hasOwnProperty(key)) &#123;</span><br><span class=\"line\">        delete metrics[key];</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    $scope.processTableGroups(tabifyAggResponse($scope.vis, resp));</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<p>啊虽然是找到了数据的来源和流向，可是，又是Angular.. Angular基础为零的我心好累…不过也算是了然了。然后具体看看extended_metric插件拿到数据之后做的事</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.processTableGroups = function (tableGroups) &#123;</span><br><span class=\"line\">  tableGroups.tables.forEach(function (table) &#123;</span><br><span class=\"line\">    table.columns.forEach(function (column, i) &#123;</span><br><span class=\"line\">      const fieldFormatter = table.aggConfig(column).fieldFormatter();</span><br><span class=\"line\">      let value = table.rows[0][i]; //es数据存在table.rows内</span><br><span class=\"line\">      let formattedValue = isInvalid(value) ? &apos;?&apos; : fieldFormatter(value);     //数据转换后拿出label, formattedValue</span><br><span class=\"line\">      const metric = &#123;</span><br><span class=\"line\">        label: column.title,</span><br><span class=\"line\">        value: value,</span><br><span class=\"line\">        formattedValue: formattedValue</span><br><span class=\"line\">      &#125;;</span><br><span class=\"line\">      metrics.push(metric);</span><br><span class=\"line\">      metrics[column.title] = metric;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">  updateOutputs();</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>上面两段代码是相连的，首先processTableGroups的参数是tabifyAggResponse($scope.vis, resp)，tabifyAggResponse是一个内部已有的方法，主要是把es返回的已知结构的数据，转换成标准格式，这里选择的是table,如果是line的话，可以看看point_series.js。转换包括参数包括数据之外，还有vis,转换完成得到的数据中包含es数据之外，还包括选项卡中的数据，如设置的label等。</p>\n<h4 id=\"示例line-sg\"><a href=\"#示例line-sg\" class=\"headerlink\" title=\"示例line_sg\"></a>示例line_sg</h4><p>示例<a href=\"https://github.com/sbeyn/kibana-plugin-line-sg\">地址</a></p>\n<p>然后分析一下，顺便巩固一下上面的知识。</p>\n<p>在line_sg.js中，熟悉的控件，TemplateVisType，包含params和schemas。</p>\n<p>在视图line_sg.html中,使用c3绘制，只有几行代码，看似很简单，我想控制绘制的代码应该在controller中，然后看看_params.html,是Option的选项卡，主要应该是视图的配置相关。然后看看controller,在视图controller中，前面很大一部分是关于要画的准备工作，以数据流向为接入点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.$watch(&apos;esResponse&apos;, function (resp) &#123;</span><br><span class=\"line\">    if (resp) &#123;</span><br><span class=\"line\">      console.log(resp);</span><br><span class=\"line\">      metrics.length = 0; //重置metrics，重置数组的方式是修改length,emmm学到了</span><br><span class=\"line\">      $scope.processTableGroups(tabifyAggResponse($scope.vis, resp)); //还是使用的数据表格形式，为什么大家都选这个转换形式？我猜可能是因为数据比较好拿出来..数据还是集中的，数据拿出来搞成自己格式的，与视图相关的数据都在metrics中，</span><br><span class=\"line\">      $scope.showGraph(); //从metrics中拿出数据，做图</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>这个是示例是使用c3来完成绘制的示例，因为和需求的方波刚好可以吻合，就具体细节学习下吧。首先将代码拷入plugins文件夹，启动kibana,查看效果。发现不怎么好看，另外选择chart_types=step似乎不工作，看看代码吧。</p>\n<p>首先尝试是，设置params之后，点击重绘，没有效果。</p>\n<p>仔细看了看插件的绘制和c3的使用，看了看线上的kibana，发现line是真的可以有step..而且图形没有错…其实本来line画图就有方波。好吧，还是先看看这个插件为什么设置params之后，点击重绘，没有触发重绘吧。结论是没有监听变量的变化..$scope.$watch、$watchController等监听方法，虽然没有看到具体代码，大概是，侧边栏部分没有修改的话，那个重绘的按钮就无法点击，那个按钮的点击事件应该是触发watch的监听事件的，有修改，就会触发监听事件，要重绘的话其实就是在监听事件的回调中加入视图重绘的部分，其实数据会自动绑定，只是需要个刷新机制。</p>\n<hr>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">                                                 /===-_---~~~~~~~~~------____</span><br><span class=\"line\">                                                |===-~___                _,-&apos;</span><br><span class=\"line\">                 -==\\\\                         `//~\\\\   ~~~~`---.___.-~~</span><br><span class=\"line\">             ______-==|                         | |  \\\\           _-~`</span><br><span class=\"line\">       __--~~~  ,-/-==\\\\                        | |   `\\        ,&apos;</span><br><span class=\"line\">    _-~       /&apos;    |  \\\\                      / /      \\      /</span><br><span class=\"line\">  .&apos;        /       |   \\\\                   /&apos; /        \\   /&apos;</span><br><span class=\"line\"> /  ____  /         |    \\`\\.__/-~~ ~ \\ _ _/&apos;  /          \\/&apos;</span><br><span class=\"line\">/-&apos;~    ~~~~~---__  |     ~-/~         ( )   /&apos;        _--~`</span><br><span class=\"line\">                  \\_|      /        _)   ;  ),   __--~~</span><br><span class=\"line\">                    &apos;~~--_/      _-~/-  / \\   &apos;-~ \\</span><br><span class=\"line\">                   &#123;\\__--_/&#125;    / \\\\_&gt;- )&lt;__\\      \\</span><br><span class=\"line\">                   /&apos;   (_/  _-~  | |__&gt;--&lt;__|      |</span><br><span class=\"line\">                  |0  0 _/) )-~     | |__&gt;--&lt;__|      |</span><br><span class=\"line\">                  / /~ ,_/       / /__&gt;---&lt;__/      |</span><br><span class=\"line\">                 o o _//        /-~_&gt;---&lt;__-~      /</span><br><span class=\"line\">                 (^(~          /~_&gt;---&lt;__-      _-~</span><br><span class=\"line\">                ,/|           /__&gt;--&lt;__/     _-~</span><br><span class=\"line\">             ,//(&apos;(          |__&gt;--&lt;__|     /                  .----_</span><br><span class=\"line\">            ( ( &apos;))          |__&gt;--&lt;__|    |                 /&apos; _---_~\\</span><br><span class=\"line\">         `-)) )) (           |__&gt;--&lt;__|    |               /&apos;  /     ~\\`\\</span><br><span class=\"line\">        ,/,&apos;//( (             \\__&gt;--&lt;__\\    \\            /&apos;  //        ||</span><br><span class=\"line\">      ,( ( ((, ))              ~-__&gt;--&lt;_~-_  ~--____---~&apos; _/&apos;/        /&apos;</span><br><span class=\"line\">    `~/  )` ) ,/|                 ~-_~&gt;--&lt;_/-__       __-~ _/</span><br><span class=\"line\">  ._-~//( )/ )) `                    ~~-&apos;_/_/ /~~~~~~~__--~</span><br><span class=\"line\">   ;&apos;( &apos;)/ ,)(                              ~~~~~~~~~~</span><br><span class=\"line\">  &apos; &apos;) &apos;( (/</span><br><span class=\"line\">    &apos;   &apos;  `</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>后面整理了下，思路稍微清晰一点的。</p>\n<p>开发插件的话，都需要一定的模板，官方推荐的生成模板的脚手架<a href=\"https://github.com/saojs/sao\">sao</a>,具体使用<a href=\"https://github.com/elastic/template-kibana-plugin\">样例</a>。还有插件开发的<a href=\"https://www.gitbook.com/book/trumandu/kibana-plugin-development-tutorial/details\" target=\"_blank\" rel=\"noopener\">教程</a>。篇幅原因，就省去教程系列，主要看看结构，源码什么的..</p>\n<h3 id=\"visTypes\"><a href=\"#visTypes\" class=\"headerlink\" title=\"visTypes\"></a>visTypes</h3><p>Visualize插件的开发，组成主要是es6,angular(听说angular1和2完全没关系，特地指出kibana采用的是angular1)。kibana的Visualize组件的绘制主要是通过<a href=\"https://d3js.org/\" target=\"_blank\" rel=\"noopener\">d3</a>这个伟大的可视化库。</p>\n<h4 id=\"插件样例\"><a href=\"#插件样例\" class=\"headerlink\" title=\"插件样例\"></a>插件样例</h4><p>从众多优秀的vis插件中选择了一个比较简单的<a href=\"https://github.com/ommsolutions/kibana_ext_metrics_vis\">样例</a>来做分析(主要是人家有图)。效果如gif图，用文字来说明的话，就是实现了一个可计算的插件，选择metric值，然后填入计算公式，得出值。(因为见识有限，以前总说在kibana中实现计算很复杂，现在看来真是啪啪(*10)打脸)。</p>\n<p>extended_metric_vis.js很明显，是这个插件的大头。稍微粘一点代码。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return new TemplateVisType(&#123;</span><br><span class=\"line\">    name: &apos;extended_metric&apos;,</span><br><span class=\"line\">    title: &apos;Extended Metric&apos;,</span><br><span class=\"line\">    description: &apos;Based on the core Metric-Plugin but gives you the ability&apos; +</span><br><span class=\"line\">      &apos;to output custom aggregates on metric-results.&apos;,</span><br><span class=\"line\">    icon: &apos;fa-calculator&apos;,</span><br><span class=\"line\">    template: extendedMetricVisTemplate, //视图模板.html</span><br><span class=\"line\">    params: &#123; //Options选项，预定义的Options选项及值，在对应视图中会有具体使用</span><br><span class=\"line\">      defaults: &#123;</span><br><span class=\"line\">        handleNoResults: true,</span><br><span class=\"line\">        fontSize: 60,</span><br><span class=\"line\">        outputs: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            formula: &apos;metrics[0].value * metrics[0].value&apos;,</span><br><span class=\"line\">            label: &apos;Count squared&apos;,</span><br><span class=\"line\">            enabled: true</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      editor: metricVisParamsTemplate //Options选项卡视图模板.html</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    schemas: new Schemas([ //Data相关，这里就不是自由发挥的地界了，属于半命题类型，根据自己需要的数据选择对应类型，基本</span><br><span class=\"line\">    \t\t\t\t\t//就是metric，bucket的组合，一般来说，metric 数值聚合肯定是 Y 轴；bucket 聚合肯定是 X 轴；</span><br><span class=\"line\">      &#123;           //而在此基础上，还可以让 bucket 有不同效果，也就是 Schema 里的 segment(默认), group 和 split。</span><br><span class=\"line\">        group: &apos;metrics&apos;,</span><br><span class=\"line\">        name: &apos;metric&apos;,</span><br><span class=\"line\">        title: &apos;Metric&apos;,</span><br><span class=\"line\">        min: 1,</span><br><span class=\"line\">        defaults: [</span><br><span class=\"line\">          &#123; type: &apos;count&apos;, schema: &apos;metric&apos; &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    ])</span><br><span class=\"line\">  &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>如果稍微看了下vis插件的教程的话，就会很熟悉，因为模板就差不多是这样，利用TemplateVisType生成对应实例，基本备注都在代码里了，就不再啰嗦了。</p>\n<p>然后根据上面的代码直接的找到两个html，extended_metric_vis.html和extended_metric_vis_params.html, 很显示，就是view,会看到伟大的angular进行mvc的管理，然后去看c =&gt; extended_metric_vis_controller.js。这个代码里，主要是angular与其控制器的绑定，跳过这个，进到方法里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.$watch(&apos;esResponse&apos;, function (resp) &#123;</span><br><span class=\"line\">    if (resp) &#123;</span><br><span class=\"line\">      calcOutputs.length = 0;</span><br><span class=\"line\">      metrics.length = 0;</span><br><span class=\"line\">      //清空metrics</span><br><span class=\"line\">      for (let key in metrics) &#123;</span><br><span class=\"line\">        if (metrics.hasOwnProperty(key)) &#123;</span><br><span class=\"line\">          delete metrics[key];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      $scope.processTableGroups(tabifyAggResponse($scope.vis, resp));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>很明显，这里是接受es查询结果的代码，结论很明显是，获得es查询结果只需要监听esResponse变量就可以。然后看看拿到结果的处理processTableGroups方法。首先是tabifyAggResponse是按照已知的es查询结果结构生成与视图(data选项卡)强相关的数据结构，为什么说强相关呢，比如tabifyAggResponse后的结果主要包括columns和rows，分别是data选项卡的分组和对应的数据，就拿这个例子来说，如果新建了两个metric, columns里就是这两个metric的属性，包含title(即输入的label)等，对应index的rows里的数据就是对应metric的结果。转换之后，在processTableGroups方法里，只需要把对应的数据拿出来组合下，比如，例子里就是以columns中的title为键，以metric的结果为值，组成数据到metrics(装数据的对象，下方会用到)中。</p>\n<p>view有了，数据也有了，还差最后一步，就是怎么把公式套进去？在这里，我不得不再次感叹下js的伟大。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">try &#123;</span><br><span class=\"line\">  const func = Function(&quot;metrics&quot;, &quot;return &quot; + output.formula); //&lt;&lt;&lt;&lt;=这里是亮点</span><br><span class=\"line\">  output.value = func(metrics) || &quot;?&quot;;</span><br><span class=\"line\">&#125; catch (e) &#123;</span><br><span class=\"line\">  output.value = &apos;?&apos;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>output.formula为输入的公式，类型为string，然后一句string的字符串就变成方法了？！是的。很神奇。有了方法，把数据套进去，答案就出来了。</p>\n<p>大概内容就是这样，可能还有些细节需要注意，比如，修改了data/option点击那么重绘的按钮，重新计算，需要监听对应数据，如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//updateOutputs为计算的过程</span><br><span class=\"line\">$scope.$watchCollection(&apos;vis.params.outputs&apos;, updateOutputs);</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"源码样例\"><a href=\"#源码样例\" class=\"headerlink\" title=\"源码样例\"></a>源码样例</h4><p>接下来就看看稍微肤浅点的源码，时间和能力确实有限啊。比如上面出现过的TemplateVisType，整体理解下结构和运作。</p>\n<ul>\n<li><p>src/core_plugins/kbn_vislib_vis_types</p>\n<p>自带的vis组件定义的地方。还包括options选项卡的html,js等等，看看line.js的部分代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">return new VislibVisType(&#123;</span><br><span class=\"line\">  name: &apos;line&apos;,</span><br><span class=\"line\">  title: &apos;Line&apos;,</span><br><span class=\"line\">  image,</span><br><span class=\"line\">  description: &apos;Emphasize trends&apos;,</span><br><span class=\"line\">  category: VisType.CATEGORY.BASIC,</span><br><span class=\"line\">  params: &#123;</span><br><span class=\"line\">    defaults: &#123;</span><br><span class=\"line\">      grid: &#123;</span><br><span class=\"line\">        categoryLines: false,</span><br><span class=\"line\">        style: &#123;</span><br><span class=\"line\">          color: &apos;#eee&apos;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      ...</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    positions: [&apos;top&apos;, &apos;left&apos;, &apos;right&apos;, &apos;bottom&apos;],</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    editor: pointSeriesTemplate,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    schemas: new Schemas([</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      group: &apos;metrics&apos;,</span><br><span class=\"line\">      name: &apos;metric&apos;,</span><br><span class=\"line\">      title: &apos;Y-Axis&apos;,</span><br><span class=\"line\">      min: 1,</span><br><span class=\"line\">      aggFilter: [&apos;!geo_centroid&apos;],</span><br><span class=\"line\">      defaults: [</span><br><span class=\"line\">        &#123; schema: &apos;metric&apos;, type: &apos;count&apos; &#125;</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">   \t....</span><br><span class=\"line\">  ])</span><br></pre></td></tr></table></figure>\n\n<p>和上方extended_metric_vis.js粘出来的代码很相似吧，只不过一个是使用的TemplateVisType，一个是VislibVisType，其实这两个类也很相似，都是继承vis_type。不过从这点上来看，定义vis组件的套路其实差不多，区别呢，就是官方的组件的话视图绘制的部分应该是内定的，直接选择出来绘制就好了(在后面会看到选择的代码)，但是自定义vis组件的话，视图部分是需要自己自定义的，而不是选择原有的，所以自定义需要TemplateVisType对象，传入template视图。</p>\n</li>\n<li><p>src/public/ui/vis/vis_type</p>\n<p>定义基本属性和方法createRenderbot。继承这个的话需要实现createRenderbot方法返回Renderbot对象。</p>\n</li>\n<li><p>src/public/ui/vislib_vis_type/vislib_vis_type</p>\n<p>继承vis_type。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">const updateParams = function (params) &#123;</span><br><span class=\"line\">\tconst updateIfSet = (from, to, prop, func) =&gt; &#123;</span><br><span class=\"line\">      if (from[prop]) &#123;</span><br><span class=\"line\">        to[prop] = func ? func(from[prop]) : from[prop];</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">...</span><br><span class=\"line\">// ·。第一，继承VisType，看到responseConverter默认是转换为点线图数组的。</span><br><span class=\"line\">_.class(VislibVisType).inherits(VisType);</span><br><span class=\"line\">  function VislibVisType(opts = &#123;&#125;) &#123;</span><br><span class=\"line\">    VislibVisType.Super.call(this, opts);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (this.responseConverter == null) &#123;</span><br><span class=\"line\">      this.responseConverter = pointSeries;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    this.listeners = opts.listeners || &#123;&#125;;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">// ·。第二，实现createRenderbot</span><br><span class=\"line\">   VislibVisType.prototype.createRenderbot = function (vis, $el, uiState) &#123;</span><br><span class=\"line\">   // 在返回新VislibRenderbot对象之前，对vis.params进行了相应的转换和判断，比如把一些params下的属性对应移到params.seriesParams[0]或者params.valueAxes[0]，params.categoryAxes[0]下</span><br><span class=\"line\">    updateParams(vis.params);</span><br><span class=\"line\">    return new VislibRenderbot(vis, $el, uiState);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到基本就是params的转换，和返回VislibRenderbot作为Renderbot对象，那么，久闻的Renderbot的作用？预知后事如何，请看后面..</p>\n</li>\n<li><p>src/public/ui/vislib_vis_type/vislib_renderbot</p>\n<p>恩，Renderbot中定义了需实现的一些方法，VislibRenderbot就继承Renderbot，故就直接看VislibRenderbot的代码了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VislibRenderbot.prototype.render = function (esResponse) &#123;</span><br><span class=\"line\">  this.chartData = this.buildChartData(esResponse);</span><br><span class=\"line\">  return AngularPromise.delay(1).then(() =&gt; &#123;</span><br><span class=\"line\">    this.vislibVis.render(this.chartData, this.uiState); //绘制</span><br><span class=\"line\">    this.refreshLegend++;</span><br><span class=\"line\">  &#125;);</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>例如render方法,通过调用vislibRenderbot.render方法实现绘制。<br>看到这里，不知道有没有看到加了注释那句代码，绘制的主要工作应该就在这行代码，那么好奇一下this.vislibVis又是什么呢？找到this.vislibVis的初始化</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">this.vislibVis = new vislib.Vis(this.$el[0], this.vislibParams);</span><br></pre></td></tr></table></figure>\n\n<p>在Vis中，主要是visConfig和handler, handler绘制，visConfig选择生成相应的数据结构。对于visConfig的代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//src/public/ui/vislib/vis_config.js</span><br><span class=\"line\">const visType = visTypes[visConfigArgs.type];</span><br><span class=\"line\">const typeDefaults = visType(visConfigArgs, this.data); // &lt;= 数据结构更改</span><br><span class=\"line\"></span><br><span class=\"line\">//visTypes =&gt; src/public/ui/vislib/types</span><br><span class=\"line\">  return &#123;</span><br><span class=\"line\">    histogram: pointSeries.column,</span><br><span class=\"line\">    horizontal_bar: pointSeries.column,</span><br><span class=\"line\">    line: pointSeries.line,</span><br><span class=\"line\">    pie: Private(VislibLibTypesPieProvider),</span><br><span class=\"line\">    area: pointSeries.area,</span><br><span class=\"line\">    point_series: pointSeries.line,</span><br><span class=\"line\">    heatmap: pointSeries.heatmap,</span><br><span class=\"line\">  &#125;;</span><br></pre></td></tr></table></figure>\n\n<p>handler绘制,handler的render方法中,可以看到chart.render</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// render in handler</span><br><span class=\"line\">render() &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tconst chart = new self.ChartClass(self, this, chartData);</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tchart.render();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//ChartClass in handler</span><br><span class=\"line\">this.ChartClass = chartTypes[visConfig.get(&apos;type&apos;)];</span><br><span class=\"line\"></span><br><span class=\"line\">//chartTypes from src/public/ui/vislib/visualizations/vis_types</span><br><span class=\"line\">//这里面是进行可视化的地方，可视化对象都继承自Chart类，components/vislib/visualizations/_chart</span><br><span class=\"line\">  Chart.prototype.render = function () &#123;</span><br><span class=\"line\">      var selection = d3.select(this.chartEl);</span><br><span class=\"line\">      selection.selectAll(&apos;*&apos;).remove();</span><br><span class=\"line\">      selection.call(this.draw());</span><br><span class=\"line\">   &#125;;</span><br><span class=\"line\">  //也就是说，各个可视化对象，只需要用 d3.js 或者其他绘图库，完成自己的 draw() 函数，就可以了！可以在本文件夹下查看具体一些绘制代码</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>src/public/visualize/visualize</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$scope.$watch(&apos;esResp&apos;, prereq(function (resp) &#123;</span><br><span class=\"line\">    if (!resp) return;</span><br><span class=\"line\">    $scope.renderbot.render(resp);</span><br><span class=\"line\">  &#125;));</span><br></pre></td></tr></table></figure>\n\n<p> 很明显，visualize.js是Visualization的大Boss，通过代码可以看出，visualize与vis_types交互主要通过调用renderbot的各种方法，包括render。</p>\n</li>\n</ul>\n<p>大致总结一下，要定义vis组件的话，返回VislibVisType或TemplateVisType对象，这两个类内部都会生成对应的renderbot对象，visualize与通过调用renderbot对象进行一系列的操作，如果是自定义组件的话，返回的TemplateVisType对象需要具有template属性，为图表视图模板(html), 官方自带的组件的话，会根据类型进行选择视图。对于视图的绘制(包括修改选项卡，重绘)，visualize会调用renderbot.render方法，VisRenderbot的render方法即重绘..在上方粘贴的代码也可以看到，TemplateRenderbot的render方法是将esResponse数据绑定到当前作用域的esResponse变量上，所以自定义插件中要完成绘制的话，需要监听当前作用域的esResponse变量。</p>\n<p>好啦，官方自带的组件的代码介绍和自开发插件的代码介绍就到这里就结束啦。</p>\n"},{"title":"zilliqa","date":"2019-10-14T06:39:28.000Z","_content":"\n## Zil白皮书翻译\n\n\n\n扩大吞吐量的关键是网络和共识协议的设计。\n\n\n\n#### 加密层\n\n密码层定义了ZILLIQA中使用的密码基础。 与其他几个区块链平台类似，ZILLIQA依靠椭圆曲线密码学进行数字签名，并使用内存硬散列函数进行校对（PoW）。 在整个白皮书中，我们广泛使用SHA3 [6]散列函数来呈现我们的设计。 SHA3最初基于Keccak [7]，广泛应用于不同的区块链平台，尤其是以太坊。 在不久的将来，我们可能会转向Keccak以实现与其他平台更好的互操作性。\n\n- 数字签名\n\n  ZILLIQA采用基于椭圆曲线的Schnorr签名算法（EC-Schnorr）[8]作为基础签名算法。我们用secp256k1曲线实例化了这个方案[9]。比特币和以太坊目前使用相同的曲线，但使用不同的签名算法ECDSA。通过ECDSA选择ECSchnorr有几个好处，我们将在下面讨论：\n\n  1. 非可塑性：非正式地说，非可塑性属性意味着给定一组使用私钥生成的签名，对于攻击者来说很难为相应的公钥生成相同消息的新签名。与ECDSA不同，EC Schnorr已被证明是不可修改的。[10]\n  2. 多重签名：多重签名方案允许多个设计者将他们的签名集合到一个给定的消息中，并将其集中到一个单一的签名中，这个签名可以通过一个公钥即“汇集”所有授权方的钥匙。而EC-Schnorr本质上是一种多重签名方案（参见[11]），ECDSA允许创建多重签名，但不够灵活。当消息需要多个签名时，ZILLIQA使用基于EC-Schnorr的多重签名来减少签名大小。较小的签名在我们的共识协议中尤为重要，因为多方需要通过签署协议来达成一致\n  3. 速度：EC-Schnorr比ECDSA更快，因为后者需要计算大数反模。 EC-Schnorr不需要反转。\n\n  EC-Schnorr密钥生成，签名和验证程序在附录A中给出。在附录中，我们还介绍了EC-Schnorr如何用作多重签名方案\n\n\n\n- POW\n\n  ZILLIQA仅使用PoW来防止Sybil攻击并生成节点标识。这与许多现有的区块链平台（特别是比特币和以太坊）形成鲜明对比，其中PoW用于达成分布式共识。 ZILLIQA采用Ethash ，即Ethereum 1.0中使用的PoW算法。 Ethash是一种内存硬散列函数，旨在使用GPU很容易挖掘，但使用专用计算硬件（如ASIC）很难。为此，Ethash计算需要大量内存（以GB为单位）和I / O带宽，以便该功能不能在专用计算硬件上并行调用。粗略地说，Ethash将一个数据（例如一个块头）和一个64位随机数作为输入，并生成一个256位的摘要。该算法由四个以给定顺序运行的子例程组成：\n\n  1. 种子生成：种子是一个SHA3-256摘要，每30000个块称为一个时期后更新。对于第一个时代，它是一系列32字节零的SHA3-256散列。对于其他时代，它始终是前一个种子的SHA3-256散列。\n  2. 缓存生成：种子用于使用SHA3-512生成伪随机缓存。缓存的大小随着时期线性增加。缓存的初始大小为16 MB。\n  3. 数据集生成：然后使用高速缓存生成数据集，其中数据集中的每个“项目”仅取决于缓存中的少量项目。数据集每次更新一次，以便矿工不必非常频繁地进行更改。数据集的大小也随着时期线性增加。数据集的初始大小为1 GB。\n  4. 挖掘和验证：挖掘包括抓取数据集的随机切片并将它们散列在一起。验证使用缓存重新生成计算哈希所需的特定数据集。\n\n\n\n#### 数据层\n\n广义而言，数据层定义了构成ZILLIQA全局状态的数据。 通过扩展，它还定义了ZILLIQA中不同实体更新其全局状态所需的数据。\n\n- 账户、地址和状态\n\n  ZILLIQA是一个基于账户的系统（如以太坊）。 有两种类型的帐户：普通帐户和合同帐户。 通过生成ECSchnorr私钥创建普通帐户。 合同帐户由另一个帐户创建。每个帐户由根据其类型导出的地址标识。 普通账户的地址来源于账户的私钥。 对于给定的私钥sk，地址Anormal是一个160位的值，其计算公式如下：\n\n  ```\n  Anormal = LSB160(SHA3-256(PubKey(sk))),\n  ```\n\n  其中，LSB160（·）返回输入的最右边的160位，PubKey（·）返回与输入密钥对应的公钥。 合约帐户的地址是根据其创建者的地址以及创建者帐户发送的交易次数计算的，也就是帐户随机数（如下所述）\n\n  ```\n  Acontract = LSB160(SHA3-256(address||nonce)),\n  ```\n\n  其中，address是创建者账户的地址，nonce是创建者的现时值。每个账户（无论是正常账户还是合约）都与账户状态相关联。账户状态是一个关键的价值存储区，由以下键组成：\n\n  1）帐户现时：（64位）计数从普通帐户发送的交易数量的计数器（初始化为0）。如果是合同帐户，它会计算帐户创建的合同数量。\n\n  2）余额：（128位）一个非负值。每当一个账户收到来自另一个账户的token时，收到的金额将被添加到账户的余额中。当一个账户向另一个账户发送token时，余额会减少适当的金额。\n\n  3）代码散列：（256位）这存储合同代码的SHA3-256摘要。对于普通帐户，它是空字符串的SHA3-256摘要。\n\n  4）存储根：（256位）每个帐户都有一个存储，它又是一个key-value存储，存储256位密钥和256位值。存储根目录是代表此存储的SHA3-256摘要。例如，如果存储是一个trie，那么存储根就是trie的根的摘要。\n\n  ZILLIQA的全局状态（状态）是帐户地址和帐户状态之间的映射。它使用类似于数据结构的trie来实现。\n\n- 交易\n\n  交易总是从普通账户地址发送，并更新ZILLIQA的全局状态。交易具有以下字段：\n  1）版本（32位）：当前版本。\n  2）nonce（64位）：一个计数器，等于此交易发送者发送的交易数。\n  3）目的（160位）：目的地帐户地址。如果交易创建新的合同帐户，则该字段是空字符串的最右边的160位SHA3-256。\n  4）金额（128位）：要转移到目标地址的交易金额。\n  5）gas价格（128位）：gas被定义为计算的最小单位。gas价格是发送者愿意为交易处理过程中发生的计算而支付的每单位gas的金额。\n  6）gas限制（128位）：处理交易时应使用的最大gas量。\n  7）代码（无限制）：指定合同代码的可扩展字节数组。只有在交易创建新的合同帐户时才存在。\n  8）data（无限）：一个可扩展的字节数组，用于指定应该用来处理数据的数据。它仅在交易调用目标地址的合同调用时才存在。\n  9）公钥（264位）：应该用来验证签名的EC-Schnorr公钥。 pubkey字段也决定了交易的发送地址。\n  10）签名（512位）：整个数据上的EC-Schnorr签名。每个交易都由一个交易ID唯一标识 - 一个排除签名字段的交易数据的SHA3-256摘要。\n\n\n\n#### 块\n\nZILLIQA协议引入了两种类型的块（以及两个块链）：事务块（TX块）和目录服务块（DS块）。 TX块包含用户发送的交易，而DS块包含有关参与共识协议的矿工的元数据。\n\n- DS块：DS块具有两部分：头部和签名。 DS块的标题部分包含以下字段：\n\n​\t1）版本（32位）：当前版本。\n​\t2）先前的散列（256位）：其父块标题的SHA3-256摘要。\n​\t3）公钥（264位）：在这个块头上做PoW的矿工的公钥。\n​\t4）难度（64位）：这可以从前面的块的难度和块编号中计算出来。它存储了PoW难题的难度。\n​\t5）数字（256位）：祖先块的数量。生成块的块号为0。\n​\t6）时间戳（64位）：Unix创建该块时的时间（）。\n​\t7）mixHash（256比特）：根据nonce计算出的摘要，用于检测DoS攻击。\n​\t8）nonce（64位）：PoW的解决方案。\n\n DS块的签名部分包含以下两个字段：\n​\t1）签名（512比特）：签名是DS节点签名的DS块头上的基于EC-Schnorr的多重签名。\n​\t2）位图（1024位）：它记录哪些DS节点参与多重签名。我们用位向量B表示位图，其中，B [i] = 0, 如果第i个节点签名B [i] = 1。\n\nDS块形成DS区块链。\n\n- 交易块：\n\n  如前所述，DS块包含有关交易共识节点的信息。 TX块存储关于DS块中的节点同意的交易的信息。每个DS块都链接到多个TX块。 TX块包含三部分：标题，数据和签名。标题由以下字段组成：\n  1）类型（8位）：TX-Block有两种类型，即微块（0x00）和最终块（0x01）。更多关于这些在第V-D部分。\n  2）版本（32位）：当前版本。\n  3）先前的散列（256位）：其父块标题的SHA3-256摘要。\n  4）gas限制（128位）：每个块中gas消耗的限制。\n  5）使用的gas（128位）：本区块交易使用的gas总量。\n  6）数字（256位）：祖先块的数量。genesis块的块号为0。\n  7）时间戳（64位）：Unix创建该块时的时间（）。\n  8）状态根（256位）：这是一个SHA3-256摘要，表示所有交易执行并完成后的全局状态。如果全局状态被存储为一个trie，那么状态根就是trie的根的摘要。\n  9）交易根（256位）：这是一个SHA3-256摘要，表示存储此块中存在的所有交易的Merkle树的根。\n  10）tx散列（每个256位）：交易的SHA3-256摘要列表。交易的签名部分也被散列。\n  11）公钥（264位）：提出该块的领导者的EC-Schnorr公钥。\n  12）pubkey微块（无限制）：它是ECSchnorr公钥的列表（每个长度为264位）。该清单包含提交交易的领导人的公钥。该字段仅在final块才存在。\n  13）父块散列（256位）：它是前一个最后块标题的SHA3-256摘要。\n  14）父DS散列（256位）：它是其父DS-Block头的SHA3-256摘要。\n  15）父DS块号（256位）：它是父DS块号。\n\n   TX块的数据部分包含交易列表。它有以下领域：\n  1）tx计数（32位）：该块中的交易数。\n  2）tx list（unlimited）：交易清单。\n\n   TX-Block的签名部分包含基于ECSchnorr的多重签名。它有以下两个字段：\n\n  1. 签名（512比特）：签名基于EC-Schnorr的多重签名，由一组节点在TX-Bloc上进行签名。签名的节点取决于它是微块还是最终块的不同节点组。第V-D节给出了签署方的进一步细节。\n\n  2）位图（1024位）：它记录参与多重签名的节点。我们用位向量B表示位图，其中，如果第i个节点对头部进行签名，则B [i] = 1，否则B [i] = 0。\n\n  final块形成交易区块链。交易区块链不包含微块\n\n\n\n### 网络层\n\nZILLIQA被设计成是交易率按比例决定。主要的想法是，分片。即，将挖矿网络分成小分片，每个小分片处理交易是并行的。在本节中，我们将介绍网络和交易分片。\n\n#### 网络分片\n\n网络分片。将挖矿网络分成小分片是一个两个的过程，首先，一组专用的称为目录服务委员会（或DS委员会）的节点被选举出来，然后他们将将网络和节点分到他们的分片中。在下面，将具体介绍细节。\n\n- 目录服务委员会（Directory Service Committee）：为了促进网络的切分，我们首先会选举出一组节点，成为目录服务(DS)节点。**DS节点形成一个DS委员会。DS节点的选举是基于proof-of-work1算法**。\n\n  ```\n  //Algorithm 1: PoW1 for DS committee election.\n  Input: i: Current DS-epoch, DSi−1: Prev. DS committee\n  composition.\n  Output: header: DS-Block header.\n   On each competing node:\n  // get epoch randomness from the DS blockchain\n  // DBi−1: Most recent DS-Block before start of i-th epoch\n   r1 ← GetEpochRand(DBi−1)\n  // get epoch randomness from the transaction blockchain\n  // TBj : Most recent TX-Block before start of i-th epoch\n   r2 ← GetEpochRand(TBj )\n  // pk: node’s public key, IP = node’s IP address\n   nonce, mixHash ← Ethash-PoW(pk, IP, r1, r2)\n   header ← BuildHeader(nonce, mixHash, pk)\n  // header includes pk and nonce among other fields\n  // IP, header is multicast to members in the DS committee\n   MulticastToDSi−1(IP, header)\n   return header\n  ```\n\n  比其他节点更早成功产生一个有效的随机数的节点，将为新块提供区块头。回想一下DS-Block头和签名部分，当一个节点解决了POW1，它便可以生产仅仅1个区块头，区块头随后会被多点广播给DS委员会的所有节点，DS委员会将对产生的区块头进行共识后生成签名部分。2f个DS节点签名了区块头，这个区块便被确认添加到DS区块链中。\n\n   在成功引导阶段后，在任何时候，规定DS节点的组成为一个预定义的窗口大小n0。在最近n0节点中并成功挖掘DS-Block的节点将加入DS委员会。\n\n  连续挖到两个DS-Block之间的平均时间称为DS-epoch。DS-eposh的值的设置是减小两个竞争块几率的一种方法。在DS-epoch的开始，一个新的DS节点加入DS委员然后DS委员会中最老的成员会出去。这固定了在DS-eposh期间DS委员会的大小始终是n0。**DS委员中最新的成员将成为leader, 并领导该时期的共识协议。** 这进一步导致了DS委员会成员的严格排序。\n\n  可以看到的是，如果DS委员会的规模n0足够大（比如说800），那么在n0个委员会成员中极有可能最多有1/3是拜占庭。\n\n- 冲突解决：我们的共识协议不允许在DS区块链中分叉。  当多个节点大致同时解决难题时，可能会出现分叉。 为了解决冲突，每个DS节点从接收到的头中检索nonce字段，并按递增顺序对它们进行排序。 让我们假设第i个DS节点的最大随机数是max(nⁱ)。\n\n  DS委员会的leader然后提出自己的header（对应于他所见过的最大随机数），并运行一致的协议来就DS-         Block header达成一致。 只有当相应的随机数大于或等于max(nⁱ)时，第i个DS节点才被同意接受建议的header。 一旦达成共识，DS-Block的签名部分就建立起来了，然后成为领导者\n\n- 分片生成：一旦选出DS委员会，网络的实际分片就可以开始。 为了使节点参与下面的共识协议，它必须执行工作证明（PoW2）。 分片协议在每个DS时期开始时重复。 算法2给出了PoW2的算法\n\n  ```\n  Algorithm 2: PoW2 for shard membership.\n  Input: i: Current DS-epoch, DSi: Current DS committee\n  composition.\n  Output: nonce, mixHash: outputs of Ethash-PoW\n   On each competing node:\n  // get epoch randomness from the DS blockchain\n  // DBi−1: Most recent DS-Block before start of i-th epoch\n   r ← GetEpochRand(DBi)\n  // pk: node’s public key, IP = node’s IP address\n   nonce, mixHash ← Ethash-PoW(pk, IP, r)\n  // IP, header is multicast to members in the DS committee\n   MulticastToDSi(nonce, mixHash, pk, IP)\n   return nonce, mixHash\n\n  ```\n\n  然后将**计算出的PoW2的有效随机数（和混合散列）多播到DS委员会。 DS节点将共同接受足够的PoW解决方案，以分解为L个共识委员会或分片，每个都具有n0个节点以达成共识**。一旦DS委员会负责人收到足够数量的PoW2解决方案，他就启动一个协商一致的协议，以就该组有效的PoW2解决方案达成一致。在共识协议结束时，leader生成由DS节点签名的EC-Schnorr多重签名。为了进一步进行下去，超过2/3的DS节点必须同意一组可接受的PoW2解决方案。\n  Sharding利用确定性函数将节点分配给分片。让我们假设我们需要每个都有n0个节点的碎片。随机数值按升序排序，第一个有n0个节点的节点们被分配给第一个分片，下一个n0分配到下一个分片，依此类推。**在碎片中提出最大随机数的矿工的身份被宣布为leader**。这进一步诱导了对分片成员的严格排序。也可以表明，如果n0足够大（比如800以上），那么在每个碎片内至多有1/3个是具有高概率的拜占庭\n\n#### 公共信道\n\nDS节点在公共信道上发布某些信息，包括DS节点的身份和连接信息，每个分片中的节点列表以及交易的分片逻辑（在第V-D节中解释）。 公共频道不可信，并假定所有节点均可访问。 在我们的实现中，我们的广播原语实现了这样的公共频道。 我们区块链的用户想要提交交易以进行接受，然后可以检查分片信息以获取负责处理其交易的碎片。 在公共频道上发布的信息预计将由任何节点或用户可验证的DS节点的2/3以上进行签名。\n\n#### 新节点加入ZILLIQA\n\n对于新节点加入网络，它可以尝试解决PoW1成为DS节点或PoW2成为分片的成员。 为此，它需要从区块链获得关于PoW1或PoW2所需的随机性的信息。 一旦获得了随机性信息，新节点就可以将其解决方案提交给DS委员会。\n\n#### 交易分片和过程\n\n如以上所述，网络分片创建了每个能够并行处理交易的分片。 在本节中，我们将介绍特定交易如何分配给分片以及如何处理交易。 为此，我们使用以下抽象：A -ⁿ->B来指示从发件人账户A到收件人账户B的n个ZIL的交易\n\n- 交易分配：任何交易都表示A -ⁿ->B被单个分片处理。 假设有L个分片，编号为0到L-1，交易被分配到由发送者地址的(log₂L + 1)右边的位（bit）标识的碎片。即，实例中A的账户地址。因为账户地址是一个160位(bit)的整型数据，所以L的范围应该为**log₂L + 1 ≤ 160**。但实际上，它会小于100。\n\n  一旦识别了分配的分片，交易就会被多播到分片中的一些节点，节点然后再进一步广播它。 一旦交易到达指定分片的领导者，它将把交易包含在TX-Block中并运行共识协议。\n\n  **双花（或重播攻击）可以使用每笔交易中的随机数轻松检测**。 回想一下，每笔交易都有一个随机数，用于统计发件人帐户发送的交易数量。 一旦交易进入交易区块链，nonce在账户状态中更新，从而处于全局状态。 当前值小于或等于全局状态当前值的交易被矿工拒绝。 根据发件人的帐户地址本地分片交易允许分片成员检测双倍支出，因为发件人的每个交易都将在同一分片中处理。\n\n- 交易处理：委员会内的所有节点都可以提出交易。这些交易被发送给领导者以运行一组协议，其中一组交易形成下一个TX块。由每个分片建议的块称为微块（由类型标记0x00标识）。一个微块包含EC-Schnorr多重签名，由分片中的2/3个节点组成。leader还建立一个标识签名者公钥的位图B。如果分片的第i个成员签署了TX-Block头部，则B [i] = 1。当一个分片在TX块上达成共识时，其领导者将块头和签名多播给一些DS节点。 DS节点然后在DS委员会内广播它，以便该块到达其领导者。块的数据部分可以异步发送到节点。 DS委员会然后汇集从分片发送的所有块，并且在它们之间运行另一轮共识协议以达成最终块。最后的块是由类型标记0x01标识的TX块。最后一个块包含来自DS委员会的超过2/3个n0节点的EC-Schnorr多重签名。 DS委员会的leader还构建了一个位图B，用于标识签名者的公钥。如果DS委员会的第i个成员签署了TX-Block标题，则B [i] = 1。最后的块头和签名，然后被组播到每个分片中的一些节点。实际的TX块数据不是由DS节点发送的。(DS节点发送的是块头和签名，tx块数据应该是由分片节点间进行同步广播)\n\n  在每个分片中，采取以下步骤来处理最终的块:\n\n  1. 分片中的每个节点使用DS节点的公钥验证EC-Schnorr多重签名。 如果签名对由位图表示的超过2/3个n0公钥有效，则节点执行下一个检查。\n  2. 对于包含在最终块头中的每个交易hash，节点检查其相应的交易内容是否可用。 如果相应的交易由节点所属的分片提出，则将交易数据的散列与包含在最后块header中的散列进行比较。 如果交易是由另一个分片提出的，则交易数据跨分片异步共享\n  3. 一旦交易数据可用，最终块的data部分被重构并且TX块被附加到本地交易区块链。 账户状态和全局状态相应地被更新。\n  4. 如果交易内容不可用，则节点在其本地账户视图中临时使该交易的发送账户失效，以便该账户的任何其他未决交易被拒绝，直到本地交易内容可以与全局状态同步。 这些被拒绝的事务将不得不由发送节点重试\n\n\n\n### 共识层\n\n如以上提到的，每个分片和DS委员会需要分别在微块和终块上跑一个共识协议。在这一块，我们将展示在每一个分片和DS委员会中定义的共识协议的共识层。在讨论中，我们将分片和DS委员会代指为共识组。\n\n##### 实用拜占庭容错\n\nZILLIQA共识协议的核心依赖于实用拜占庭容错(PBFT)协议。然而我们通过在PBFT中使用EC-Schnorr多签名来提升效率。EC-Schnorr多重签名的使用将正常情况下的通信延迟从O(n*n)降低为O(n)，并将签名大小从O(n)减小到O(1)，其中n是共识组的大小。 在这个部分，我们提供PBFT的概述。\n\n在PBFT中，共识组内的所有节点都按顺序排列，它有一个主节点（或领导者），其他节点称为备份节点。 每轮PBFT都有三个阶段，如下所述：\n\n- 预准备阶段:  在这个阶段，领导者宣布该小组将应该达成一致共识的下一个记录（在我们的案例中是TX-Block）\n- 准备阶段：在接收到预先准备消息后，每个节点验证其正确性并将准备消息多播给所有其他节点\n- 提交阶段：在收到超过2/3\\*n准备消息时，节点向组播组发送提交消息。最后，节点等待超过2/3\\*n的提交消息，以确保有足够数量的节点做出相同的决定。 因此，所有诚实的节点都接受相同的有效记录。\n\nPBFT依靠正确的领导者开始每个阶段，并在足够多节点存在时继续进行。 如果领导是拜占庭，它可能会拖延整个共识协议。 为了应对这一挑战，PBFT提供了视图更改协议来使用另一个取代拜占庭领袖。 如果节点在有限的时间内没有看到任何进展，他们可以独立宣布改变领导者的愿望。 如果超过2/3\\*n个节点的法定人数决定领导者有问题，那么在已知计划中的下一个领导者就会接管。\n\n 由于在准备/提交阶段每个节点的多播，正常情况下PBFT的通信复杂度为O（n*n）\n\n\n\n##### 提高效率\n\n经典的PBFT使用消息认证码（MAC）进行节点之间的认证通信。 由于MAC需要在每两个节点之间共享密钥，所以一个共识组中的节点可以在同一个记录上达成一致，其中每个节点的通信复杂度为O（n*n）。 由于二次复杂性，当委员会有20多个节点时，PBFT变得不切实际。\n\n为了提高效率，我们使用来源于ByzCoin的想法：\n\n- 我们用数字签名替换MAC来有效地减少O（n）的通信开销。\n- 与此同时，为了让其他节点能够验证协议，一种典型的方法是从诚实的多数收集签名并将它们附加到协议中，从而导致协商规模与协商组的大小成线性关系。 为了改善这一点，我们使用EC-Schnorr多重签名来将几个签名聚合成O（1） - 大小多重签名\n\n然而，我们不能直接在PBFT设置中使用经典的EC-Schnorr多重签名方案。 这是因为在古典设置中，所有签名者都同意签署给定的消息，并且签名只有在所有签名者都签名后才有效。 在PBFT设置中，我们只需要在共识组中超过2/3\\*n个节点签署消息。 所需的主要修改之一是为参与签名过程的签名者维护位图B. 如果第i个节点参与该过程，则B [i] = 1，否则为0。位图由领导者构建。 位图可以被任何验证者用来验证签名。 最终的协议留在附录B中。\n\n\n\n##### Zilliqa共识\n\n在ZILLIQA中，我们使用PBFT作为基础共识协议，并采用两轮EC-Schnorr多重签名来替换PBFT中的准备阶段和提交阶段。 下面将解释对PBFT阶段的不同修改。\n\n- 预准备阶段: 与标准PBFT中一样，领导者将TX-Block或声明（由领导者签名）分发给共识组中的所有节点。\n- 准备阶段：所有诚实的节点检查TX块的有效性，并且领导者收集来自超过2/3\\*n个节点的响应。 这保证领导者提出的陈述是安全的并且与以前的所有历史一致。 签名是使用EC-Schnorr多重签名生成的。 领导者还构建签署TX块的节点的位图\n- 提交阶段：为了确保超过2/3\\*n的节点知道超过2/3\\*n节点验证了TX-Block的事实。我们进行第二轮EC-Schnorr多重签名。 正在签署的声明是上一轮生成的多重签名。\n\n在三个阶段结束时，就领导者提出的TX-Block将达成共识。\n\n\n\n##### 领导者改变\n\n在我们的共识协议中，如果领导者是诚实的，它可以不断的推动共识小组中的节点就新的交易达成协议。 但是，如果领导是拜占庭，它可以有意地延迟或丢弃来自诚实节点的消息，并减慢协议。 为了惩罚这些恶意领导者，我们的协议会定期更改每个分片的领导和DS委员会。 这可以防止拜占庭领袖在无限期的时间内拖延共识协议。 由于所有节点都是有序的，下一个领导者将以循环方式选择。\n\n 事实上，每一个微块后分片的领导者都会改变，并且在每个最后一个区块之后DS委员会的领导者也会更改。 让我们假设共识组的大小为n，那么在一个DS-epoch时期内，我们允许的最终块的最大值为n，每个最终块最多在1个分片聚合1个微块。\n\n\n\n\n\n#### 附录A，数字签名算法\n\n##### EC-Schnorr（单个签名者）机制\n\nEC-Schnorr工作在离散对数很难的组[8]，[24]，[25]。 ZILLIQA使用在流行的secp256k1曲线上定义的椭圆曲线组。 我们用C :=（p，G，n）表示定义组的参数集合，其中p是指定基础场Fp的质数，G是曲线上的基点，n（素数）是 G的顺序。EC-Schnorr还需要一个密码散列函数H，我们用SHA3-256 [6]实例化。\n\n EC-Schnorr是我们在本节中介绍的一组三种算法KeyGen，Sign和Verify。 在下面的算法中，对于任何标量x和点Q，我们用[x] Q表示乘法\n\n- KeyGen(C): 该算法取曲线参数C并返回一对公钥（pk）和私钥（sk）。算法省略\n- Sign(C, pk, sk, m)：该算法由签名者运行。 根据曲线参数C，公钥和私钥对（pk，sk）以及签署的消息。 它返回一个签名σ\n- Verify(C, σ, pk, m): 该算法由希望检查签名有效性的验证者运行。 它取曲线参数C，签名σ，公钥pk和消息m。 如果签名对于pk下的m有效，则返回1，否则返回0\n\n#####  \n\n##### EC-Schnorr多重签名机制\n\n- 设置和假设：EC-Schnorr也可以用作多重签名方案[11]。在多重签名方案中，我们有T个签名者：P1，...。 。 。 ，PT，聚合器和验证者。签名者希望联合签署消息m。聚合者扮演促进者的角色并聚合每个签名者发送的签名。验证者验证汇总的签名。聚合者和验证者的角色可以由同一个实体来扮演。每个签名者Pi拥有她自己的用于EC-Schnorr单签名者方案的公共私钥对（pki，ski）。\n\n  我们用P = {pk1，。 。 。 ，pkT}表示所有公钥的集合。我们还假设每个实体都知道公共消息mp。消息mp可能是特定于应用场景的，并采取以下形式：我知道会话ID为XXXX的公钥的私钥。这个消息的目的是为了击败对该方案的某些已知攻击[26]。\n\n- 多重签名协议：多重签名是签名者，聚合器和验证者之间的交互协议（参见图2的示意图）。该协议有六个步骤，如下所述。\n\n  1. （一次性）身份设置：此步骤在每个参与者和验证者之间运行。在协议开始时，每个签名者Pi如果当前不涉及另一个签名协议，则在消息mp上生成EC-Schnorr签名σi。然后Pi将（σi，pki）发送给验证者。验证者然后执行以下检查：\n\n     - 检查pki∈P.如果检查失败，检验器将中止。\n     - 通过调用Verify（C，σi，pki，mp）来检查每个σi是否是pki上mp的有效EC-Schnorr签名。如果任何这些签名验证返回0，则验证程序中止。如果所有签名均有效，则协议进行到下一步。\n\n     如果验证程序没有收到P中每个pki的σi，她也会中止。为了记录她是否收到来自Pi的签名，她使用位图Z [1，...。 。 。 ，| P |] .身份设置是一个一次性过程，随后是任意数量的下一步。只有在设置成功结束后，协议的后续步骤才能开始。\n\n  2. commitment 阶段：每个签名者Pi随后选择一个随机ki $←[1，n-1]并计算Qi = [ki] G。回想一下，G是椭圆曲线上的基点，n是G的阶数.Pi然后将Qi发送给聚合器。\n\n  3. Challenge 阶段：聚合器首先用P中的密钥计算聚合密钥。她还计算前一步骤中接收到的Qi的聚合。然后她计算r←H（Q || pk || m）mod n并将（r，Q，pk）发送给每个Pi\n\n  4. 响应生成：每个签名者Pi首先检查之前收到的r的完整性。这是通过重新计算H（Q || pk || m）并检查它是否等于接收到的r来完成的。如果检查失败，则Pi会中止协议或者生成si←（ki -r·ski）mod n并将si发送给聚合器。\n\n  5. 响应聚合：聚合器计算聚合响应s = Pi si mod n并建立聚合签名σ=（r，s）。然后，她将（m，σ）发送给验证者。\n\n  6. 签名验证：Verifier现在检查签名是否有效。她执行以下步骤：\n\n     - 将P中的公钥集中为pk0。\n     - 通过调用，检查σ是否为m上公钥pk0的有效EC-Schnorr签名\n\n\n\n有点难理解，以下比较偏好理解的角度来说。\n\n多重签名方案基本上分两步进行。在协议的第一步中，每个节点将其公钥发送给聚合者，聚合者根据公钥的数学形式，通过简单的加法或乘法将之聚合为一个单一的公钥。\n\n例如，聚合公钥= 公钥_1 + 公钥_2 + …+公钥_n。\n\n然后聚合者将聚合公钥转发给验证者从而可以使后者验证聚合签名，与此同时聚合者也将聚合公钥发送给每个签名者让所有人签名。\n\n在第二步中，聚合者启动与每个签名者的交互协议（interactive protocol）。这个交互协议总分包含三个阶段：\n\n**1、提交阶段（Commit phase）：**此阶段每个节点生成一些随机内容并提交给交互协议。如果你不了解什么是加密提交（cryptographic commitment），那么可以通过这种类比的方式理解：每个节点都秘密地掷骰子，然后将结果写在一张纸上并将其放在一个盒子中锁好，最后发送给聚合者。聚合者无权打开盒子。\n\n**2、挑战阶段（Challenge phase）：**此阶段聚合者首先使用加法或乘法将所有的提交聚合为一个聚合提交，然后使用它以及聚合公钥、消息生成一个挑战，再将挑战发送到所有节点。之后挑战可用于确认所有节点都知道公钥对应的私钥。这与常规数字签名的工作方式类似，即由签名证明签名人确实知道私钥。\n\n**3、回应阶段（Response phase）：**所有节点为了应对挑战会向挑战发送私钥进行回应，之后聚合者将聚合所有的回应。因此回应可被视为签名者知道其公钥对应的私钥的证据。\n\n因此，最后的聚合签名实际上是挑战和聚合回应的信息对，并能验证第一步生成的聚合公钥。\n\n值得注意的是，聚合签名的大小不取决于签名者的数量，它是固定的。\n\n图中蓝色的节点是聚合者。H是用于将消息m生成挑战的密码散列函数。聚合签名就是R和S的信息对。R的大小等于Ri，S的大小等于Si的。仅在知道私钥的情况下才能生成有效的回应。\n\n当验证者检查聚合签名时，它检查的不是每个单独签名者是否都正确地遵守协议，而是检查所有签名者作为一个整体是否正确地遵守协议并知道私钥。因此，验证者做出的决定是全有或全无（all-or-nothing）。\n","source":"_posts/zilliqa.md","raw":"---\ntitle: zilliqa\ncategories:\n  - zilliqa\ndate: 2019-10-14 14:39:28\ntags:\n---\n\n## Zil白皮书翻译\n\n\n\n扩大吞吐量的关键是网络和共识协议的设计。\n\n\n\n#### 加密层\n\n密码层定义了ZILLIQA中使用的密码基础。 与其他几个区块链平台类似，ZILLIQA依靠椭圆曲线密码学进行数字签名，并使用内存硬散列函数进行校对（PoW）。 在整个白皮书中，我们广泛使用SHA3 [6]散列函数来呈现我们的设计。 SHA3最初基于Keccak [7]，广泛应用于不同的区块链平台，尤其是以太坊。 在不久的将来，我们可能会转向Keccak以实现与其他平台更好的互操作性。\n\n- 数字签名\n\n  ZILLIQA采用基于椭圆曲线的Schnorr签名算法（EC-Schnorr）[8]作为基础签名算法。我们用secp256k1曲线实例化了这个方案[9]。比特币和以太坊目前使用相同的曲线，但使用不同的签名算法ECDSA。通过ECDSA选择ECSchnorr有几个好处，我们将在下面讨论：\n\n  1. 非可塑性：非正式地说，非可塑性属性意味着给定一组使用私钥生成的签名，对于攻击者来说很难为相应的公钥生成相同消息的新签名。与ECDSA不同，EC Schnorr已被证明是不可修改的。[10]\n  2. 多重签名：多重签名方案允许多个设计者将他们的签名集合到一个给定的消息中，并将其集中到一个单一的签名中，这个签名可以通过一个公钥即“汇集”所有授权方的钥匙。而EC-Schnorr本质上是一种多重签名方案（参见[11]），ECDSA允许创建多重签名，但不够灵活。当消息需要多个签名时，ZILLIQA使用基于EC-Schnorr的多重签名来减少签名大小。较小的签名在我们的共识协议中尤为重要，因为多方需要通过签署协议来达成一致\n  3. 速度：EC-Schnorr比ECDSA更快，因为后者需要计算大数反模。 EC-Schnorr不需要反转。\n\n  EC-Schnorr密钥生成，签名和验证程序在附录A中给出。在附录中，我们还介绍了EC-Schnorr如何用作多重签名方案\n\n\n\n- POW\n\n  ZILLIQA仅使用PoW来防止Sybil攻击并生成节点标识。这与许多现有的区块链平台（特别是比特币和以太坊）形成鲜明对比，其中PoW用于达成分布式共识。 ZILLIQA采用Ethash ，即Ethereum 1.0中使用的PoW算法。 Ethash是一种内存硬散列函数，旨在使用GPU很容易挖掘，但使用专用计算硬件（如ASIC）很难。为此，Ethash计算需要大量内存（以GB为单位）和I / O带宽，以便该功能不能在专用计算硬件上并行调用。粗略地说，Ethash将一个数据（例如一个块头）和一个64位随机数作为输入，并生成一个256位的摘要。该算法由四个以给定顺序运行的子例程组成：\n\n  1. 种子生成：种子是一个SHA3-256摘要，每30000个块称为一个时期后更新。对于第一个时代，它是一系列32字节零的SHA3-256散列。对于其他时代，它始终是前一个种子的SHA3-256散列。\n  2. 缓存生成：种子用于使用SHA3-512生成伪随机缓存。缓存的大小随着时期线性增加。缓存的初始大小为16 MB。\n  3. 数据集生成：然后使用高速缓存生成数据集，其中数据集中的每个“项目”仅取决于缓存中的少量项目。数据集每次更新一次，以便矿工不必非常频繁地进行更改。数据集的大小也随着时期线性增加。数据集的初始大小为1 GB。\n  4. 挖掘和验证：挖掘包括抓取数据集的随机切片并将它们散列在一起。验证使用缓存重新生成计算哈希所需的特定数据集。\n\n\n\n#### 数据层\n\n广义而言，数据层定义了构成ZILLIQA全局状态的数据。 通过扩展，它还定义了ZILLIQA中不同实体更新其全局状态所需的数据。\n\n- 账户、地址和状态\n\n  ZILLIQA是一个基于账户的系统（如以太坊）。 有两种类型的帐户：普通帐户和合同帐户。 通过生成ECSchnorr私钥创建普通帐户。 合同帐户由另一个帐户创建。每个帐户由根据其类型导出的地址标识。 普通账户的地址来源于账户的私钥。 对于给定的私钥sk，地址Anormal是一个160位的值，其计算公式如下：\n\n  ```\n  Anormal = LSB160(SHA3-256(PubKey(sk))),\n  ```\n\n  其中，LSB160（·）返回输入的最右边的160位，PubKey（·）返回与输入密钥对应的公钥。 合约帐户的地址是根据其创建者的地址以及创建者帐户发送的交易次数计算的，也就是帐户随机数（如下所述）\n\n  ```\n  Acontract = LSB160(SHA3-256(address||nonce)),\n  ```\n\n  其中，address是创建者账户的地址，nonce是创建者的现时值。每个账户（无论是正常账户还是合约）都与账户状态相关联。账户状态是一个关键的价值存储区，由以下键组成：\n\n  1）帐户现时：（64位）计数从普通帐户发送的交易数量的计数器（初始化为0）。如果是合同帐户，它会计算帐户创建的合同数量。\n\n  2）余额：（128位）一个非负值。每当一个账户收到来自另一个账户的token时，收到的金额将被添加到账户的余额中。当一个账户向另一个账户发送token时，余额会减少适当的金额。\n\n  3）代码散列：（256位）这存储合同代码的SHA3-256摘要。对于普通帐户，它是空字符串的SHA3-256摘要。\n\n  4）存储根：（256位）每个帐户都有一个存储，它又是一个key-value存储，存储256位密钥和256位值。存储根目录是代表此存储的SHA3-256摘要。例如，如果存储是一个trie，那么存储根就是trie的根的摘要。\n\n  ZILLIQA的全局状态（状态）是帐户地址和帐户状态之间的映射。它使用类似于数据结构的trie来实现。\n\n- 交易\n\n  交易总是从普通账户地址发送，并更新ZILLIQA的全局状态。交易具有以下字段：\n  1）版本（32位）：当前版本。\n  2）nonce（64位）：一个计数器，等于此交易发送者发送的交易数。\n  3）目的（160位）：目的地帐户地址。如果交易创建新的合同帐户，则该字段是空字符串的最右边的160位SHA3-256。\n  4）金额（128位）：要转移到目标地址的交易金额。\n  5）gas价格（128位）：gas被定义为计算的最小单位。gas价格是发送者愿意为交易处理过程中发生的计算而支付的每单位gas的金额。\n  6）gas限制（128位）：处理交易时应使用的最大gas量。\n  7）代码（无限制）：指定合同代码的可扩展字节数组。只有在交易创建新的合同帐户时才存在。\n  8）data（无限）：一个可扩展的字节数组，用于指定应该用来处理数据的数据。它仅在交易调用目标地址的合同调用时才存在。\n  9）公钥（264位）：应该用来验证签名的EC-Schnorr公钥。 pubkey字段也决定了交易的发送地址。\n  10）签名（512位）：整个数据上的EC-Schnorr签名。每个交易都由一个交易ID唯一标识 - 一个排除签名字段的交易数据的SHA3-256摘要。\n\n\n\n#### 块\n\nZILLIQA协议引入了两种类型的块（以及两个块链）：事务块（TX块）和目录服务块（DS块）。 TX块包含用户发送的交易，而DS块包含有关参与共识协议的矿工的元数据。\n\n- DS块：DS块具有两部分：头部和签名。 DS块的标题部分包含以下字段：\n\n​\t1）版本（32位）：当前版本。\n​\t2）先前的散列（256位）：其父块标题的SHA3-256摘要。\n​\t3）公钥（264位）：在这个块头上做PoW的矿工的公钥。\n​\t4）难度（64位）：这可以从前面的块的难度和块编号中计算出来。它存储了PoW难题的难度。\n​\t5）数字（256位）：祖先块的数量。生成块的块号为0。\n​\t6）时间戳（64位）：Unix创建该块时的时间（）。\n​\t7）mixHash（256比特）：根据nonce计算出的摘要，用于检测DoS攻击。\n​\t8）nonce（64位）：PoW的解决方案。\n\n DS块的签名部分包含以下两个字段：\n​\t1）签名（512比特）：签名是DS节点签名的DS块头上的基于EC-Schnorr的多重签名。\n​\t2）位图（1024位）：它记录哪些DS节点参与多重签名。我们用位向量B表示位图，其中，B [i] = 0, 如果第i个节点签名B [i] = 1。\n\nDS块形成DS区块链。\n\n- 交易块：\n\n  如前所述，DS块包含有关交易共识节点的信息。 TX块存储关于DS块中的节点同意的交易的信息。每个DS块都链接到多个TX块。 TX块包含三部分：标题，数据和签名。标题由以下字段组成：\n  1）类型（8位）：TX-Block有两种类型，即微块（0x00）和最终块（0x01）。更多关于这些在第V-D部分。\n  2）版本（32位）：当前版本。\n  3）先前的散列（256位）：其父块标题的SHA3-256摘要。\n  4）gas限制（128位）：每个块中gas消耗的限制。\n  5）使用的gas（128位）：本区块交易使用的gas总量。\n  6）数字（256位）：祖先块的数量。genesis块的块号为0。\n  7）时间戳（64位）：Unix创建该块时的时间（）。\n  8）状态根（256位）：这是一个SHA3-256摘要，表示所有交易执行并完成后的全局状态。如果全局状态被存储为一个trie，那么状态根就是trie的根的摘要。\n  9）交易根（256位）：这是一个SHA3-256摘要，表示存储此块中存在的所有交易的Merkle树的根。\n  10）tx散列（每个256位）：交易的SHA3-256摘要列表。交易的签名部分也被散列。\n  11）公钥（264位）：提出该块的领导者的EC-Schnorr公钥。\n  12）pubkey微块（无限制）：它是ECSchnorr公钥的列表（每个长度为264位）。该清单包含提交交易的领导人的公钥。该字段仅在final块才存在。\n  13）父块散列（256位）：它是前一个最后块标题的SHA3-256摘要。\n  14）父DS散列（256位）：它是其父DS-Block头的SHA3-256摘要。\n  15）父DS块号（256位）：它是父DS块号。\n\n   TX块的数据部分包含交易列表。它有以下领域：\n  1）tx计数（32位）：该块中的交易数。\n  2）tx list（unlimited）：交易清单。\n\n   TX-Block的签名部分包含基于ECSchnorr的多重签名。它有以下两个字段：\n\n  1. 签名（512比特）：签名基于EC-Schnorr的多重签名，由一组节点在TX-Bloc上进行签名。签名的节点取决于它是微块还是最终块的不同节点组。第V-D节给出了签署方的进一步细节。\n\n  2）位图（1024位）：它记录参与多重签名的节点。我们用位向量B表示位图，其中，如果第i个节点对头部进行签名，则B [i] = 1，否则B [i] = 0。\n\n  final块形成交易区块链。交易区块链不包含微块\n\n\n\n### 网络层\n\nZILLIQA被设计成是交易率按比例决定。主要的想法是，分片。即，将挖矿网络分成小分片，每个小分片处理交易是并行的。在本节中，我们将介绍网络和交易分片。\n\n#### 网络分片\n\n网络分片。将挖矿网络分成小分片是一个两个的过程，首先，一组专用的称为目录服务委员会（或DS委员会）的节点被选举出来，然后他们将将网络和节点分到他们的分片中。在下面，将具体介绍细节。\n\n- 目录服务委员会（Directory Service Committee）：为了促进网络的切分，我们首先会选举出一组节点，成为目录服务(DS)节点。**DS节点形成一个DS委员会。DS节点的选举是基于proof-of-work1算法**。\n\n  ```\n  //Algorithm 1: PoW1 for DS committee election.\n  Input: i: Current DS-epoch, DSi−1: Prev. DS committee\n  composition.\n  Output: header: DS-Block header.\n   On each competing node:\n  // get epoch randomness from the DS blockchain\n  // DBi−1: Most recent DS-Block before start of i-th epoch\n   r1 ← GetEpochRand(DBi−1)\n  // get epoch randomness from the transaction blockchain\n  // TBj : Most recent TX-Block before start of i-th epoch\n   r2 ← GetEpochRand(TBj )\n  // pk: node’s public key, IP = node’s IP address\n   nonce, mixHash ← Ethash-PoW(pk, IP, r1, r2)\n   header ← BuildHeader(nonce, mixHash, pk)\n  // header includes pk and nonce among other fields\n  // IP, header is multicast to members in the DS committee\n   MulticastToDSi−1(IP, header)\n   return header\n  ```\n\n  比其他节点更早成功产生一个有效的随机数的节点，将为新块提供区块头。回想一下DS-Block头和签名部分，当一个节点解决了POW1，它便可以生产仅仅1个区块头，区块头随后会被多点广播给DS委员会的所有节点，DS委员会将对产生的区块头进行共识后生成签名部分。2f个DS节点签名了区块头，这个区块便被确认添加到DS区块链中。\n\n   在成功引导阶段后，在任何时候，规定DS节点的组成为一个预定义的窗口大小n0。在最近n0节点中并成功挖掘DS-Block的节点将加入DS委员会。\n\n  连续挖到两个DS-Block之间的平均时间称为DS-epoch。DS-eposh的值的设置是减小两个竞争块几率的一种方法。在DS-epoch的开始，一个新的DS节点加入DS委员然后DS委员会中最老的成员会出去。这固定了在DS-eposh期间DS委员会的大小始终是n0。**DS委员中最新的成员将成为leader, 并领导该时期的共识协议。** 这进一步导致了DS委员会成员的严格排序。\n\n  可以看到的是，如果DS委员会的规模n0足够大（比如说800），那么在n0个委员会成员中极有可能最多有1/3是拜占庭。\n\n- 冲突解决：我们的共识协议不允许在DS区块链中分叉。  当多个节点大致同时解决难题时，可能会出现分叉。 为了解决冲突，每个DS节点从接收到的头中检索nonce字段，并按递增顺序对它们进行排序。 让我们假设第i个DS节点的最大随机数是max(nⁱ)。\n\n  DS委员会的leader然后提出自己的header（对应于他所见过的最大随机数），并运行一致的协议来就DS-         Block header达成一致。 只有当相应的随机数大于或等于max(nⁱ)时，第i个DS节点才被同意接受建议的header。 一旦达成共识，DS-Block的签名部分就建立起来了，然后成为领导者\n\n- 分片生成：一旦选出DS委员会，网络的实际分片就可以开始。 为了使节点参与下面的共识协议，它必须执行工作证明（PoW2）。 分片协议在每个DS时期开始时重复。 算法2给出了PoW2的算法\n\n  ```\n  Algorithm 2: PoW2 for shard membership.\n  Input: i: Current DS-epoch, DSi: Current DS committee\n  composition.\n  Output: nonce, mixHash: outputs of Ethash-PoW\n   On each competing node:\n  // get epoch randomness from the DS blockchain\n  // DBi−1: Most recent DS-Block before start of i-th epoch\n   r ← GetEpochRand(DBi)\n  // pk: node’s public key, IP = node’s IP address\n   nonce, mixHash ← Ethash-PoW(pk, IP, r)\n  // IP, header is multicast to members in the DS committee\n   MulticastToDSi(nonce, mixHash, pk, IP)\n   return nonce, mixHash\n\n  ```\n\n  然后将**计算出的PoW2的有效随机数（和混合散列）多播到DS委员会。 DS节点将共同接受足够的PoW解决方案，以分解为L个共识委员会或分片，每个都具有n0个节点以达成共识**。一旦DS委员会负责人收到足够数量的PoW2解决方案，他就启动一个协商一致的协议，以就该组有效的PoW2解决方案达成一致。在共识协议结束时，leader生成由DS节点签名的EC-Schnorr多重签名。为了进一步进行下去，超过2/3的DS节点必须同意一组可接受的PoW2解决方案。\n  Sharding利用确定性函数将节点分配给分片。让我们假设我们需要每个都有n0个节点的碎片。随机数值按升序排序，第一个有n0个节点的节点们被分配给第一个分片，下一个n0分配到下一个分片，依此类推。**在碎片中提出最大随机数的矿工的身份被宣布为leader**。这进一步诱导了对分片成员的严格排序。也可以表明，如果n0足够大（比如800以上），那么在每个碎片内至多有1/3个是具有高概率的拜占庭\n\n#### 公共信道\n\nDS节点在公共信道上发布某些信息，包括DS节点的身份和连接信息，每个分片中的节点列表以及交易的分片逻辑（在第V-D节中解释）。 公共频道不可信，并假定所有节点均可访问。 在我们的实现中，我们的广播原语实现了这样的公共频道。 我们区块链的用户想要提交交易以进行接受，然后可以检查分片信息以获取负责处理其交易的碎片。 在公共频道上发布的信息预计将由任何节点或用户可验证的DS节点的2/3以上进行签名。\n\n#### 新节点加入ZILLIQA\n\n对于新节点加入网络，它可以尝试解决PoW1成为DS节点或PoW2成为分片的成员。 为此，它需要从区块链获得关于PoW1或PoW2所需的随机性的信息。 一旦获得了随机性信息，新节点就可以将其解决方案提交给DS委员会。\n\n#### 交易分片和过程\n\n如以上所述，网络分片创建了每个能够并行处理交易的分片。 在本节中，我们将介绍特定交易如何分配给分片以及如何处理交易。 为此，我们使用以下抽象：A -ⁿ->B来指示从发件人账户A到收件人账户B的n个ZIL的交易\n\n- 交易分配：任何交易都表示A -ⁿ->B被单个分片处理。 假设有L个分片，编号为0到L-1，交易被分配到由发送者地址的(log₂L + 1)右边的位（bit）标识的碎片。即，实例中A的账户地址。因为账户地址是一个160位(bit)的整型数据，所以L的范围应该为**log₂L + 1 ≤ 160**。但实际上，它会小于100。\n\n  一旦识别了分配的分片，交易就会被多播到分片中的一些节点，节点然后再进一步广播它。 一旦交易到达指定分片的领导者，它将把交易包含在TX-Block中并运行共识协议。\n\n  **双花（或重播攻击）可以使用每笔交易中的随机数轻松检测**。 回想一下，每笔交易都有一个随机数，用于统计发件人帐户发送的交易数量。 一旦交易进入交易区块链，nonce在账户状态中更新，从而处于全局状态。 当前值小于或等于全局状态当前值的交易被矿工拒绝。 根据发件人的帐户地址本地分片交易允许分片成员检测双倍支出，因为发件人的每个交易都将在同一分片中处理。\n\n- 交易处理：委员会内的所有节点都可以提出交易。这些交易被发送给领导者以运行一组协议，其中一组交易形成下一个TX块。由每个分片建议的块称为微块（由类型标记0x00标识）。一个微块包含EC-Schnorr多重签名，由分片中的2/3个节点组成。leader还建立一个标识签名者公钥的位图B。如果分片的第i个成员签署了TX-Block头部，则B [i] = 1。当一个分片在TX块上达成共识时，其领导者将块头和签名多播给一些DS节点。 DS节点然后在DS委员会内广播它，以便该块到达其领导者。块的数据部分可以异步发送到节点。 DS委员会然后汇集从分片发送的所有块，并且在它们之间运行另一轮共识协议以达成最终块。最后的块是由类型标记0x01标识的TX块。最后一个块包含来自DS委员会的超过2/3个n0节点的EC-Schnorr多重签名。 DS委员会的leader还构建了一个位图B，用于标识签名者的公钥。如果DS委员会的第i个成员签署了TX-Block标题，则B [i] = 1。最后的块头和签名，然后被组播到每个分片中的一些节点。实际的TX块数据不是由DS节点发送的。(DS节点发送的是块头和签名，tx块数据应该是由分片节点间进行同步广播)\n\n  在每个分片中，采取以下步骤来处理最终的块:\n\n  1. 分片中的每个节点使用DS节点的公钥验证EC-Schnorr多重签名。 如果签名对由位图表示的超过2/3个n0公钥有效，则节点执行下一个检查。\n  2. 对于包含在最终块头中的每个交易hash，节点检查其相应的交易内容是否可用。 如果相应的交易由节点所属的分片提出，则将交易数据的散列与包含在最后块header中的散列进行比较。 如果交易是由另一个分片提出的，则交易数据跨分片异步共享\n  3. 一旦交易数据可用，最终块的data部分被重构并且TX块被附加到本地交易区块链。 账户状态和全局状态相应地被更新。\n  4. 如果交易内容不可用，则节点在其本地账户视图中临时使该交易的发送账户失效，以便该账户的任何其他未决交易被拒绝，直到本地交易内容可以与全局状态同步。 这些被拒绝的事务将不得不由发送节点重试\n\n\n\n### 共识层\n\n如以上提到的，每个分片和DS委员会需要分别在微块和终块上跑一个共识协议。在这一块，我们将展示在每一个分片和DS委员会中定义的共识协议的共识层。在讨论中，我们将分片和DS委员会代指为共识组。\n\n##### 实用拜占庭容错\n\nZILLIQA共识协议的核心依赖于实用拜占庭容错(PBFT)协议。然而我们通过在PBFT中使用EC-Schnorr多签名来提升效率。EC-Schnorr多重签名的使用将正常情况下的通信延迟从O(n*n)降低为O(n)，并将签名大小从O(n)减小到O(1)，其中n是共识组的大小。 在这个部分，我们提供PBFT的概述。\n\n在PBFT中，共识组内的所有节点都按顺序排列，它有一个主节点（或领导者），其他节点称为备份节点。 每轮PBFT都有三个阶段，如下所述：\n\n- 预准备阶段:  在这个阶段，领导者宣布该小组将应该达成一致共识的下一个记录（在我们的案例中是TX-Block）\n- 准备阶段：在接收到预先准备消息后，每个节点验证其正确性并将准备消息多播给所有其他节点\n- 提交阶段：在收到超过2/3\\*n准备消息时，节点向组播组发送提交消息。最后，节点等待超过2/3\\*n的提交消息，以确保有足够数量的节点做出相同的决定。 因此，所有诚实的节点都接受相同的有效记录。\n\nPBFT依靠正确的领导者开始每个阶段，并在足够多节点存在时继续进行。 如果领导是拜占庭，它可能会拖延整个共识协议。 为了应对这一挑战，PBFT提供了视图更改协议来使用另一个取代拜占庭领袖。 如果节点在有限的时间内没有看到任何进展，他们可以独立宣布改变领导者的愿望。 如果超过2/3\\*n个节点的法定人数决定领导者有问题，那么在已知计划中的下一个领导者就会接管。\n\n 由于在准备/提交阶段每个节点的多播，正常情况下PBFT的通信复杂度为O（n*n）\n\n\n\n##### 提高效率\n\n经典的PBFT使用消息认证码（MAC）进行节点之间的认证通信。 由于MAC需要在每两个节点之间共享密钥，所以一个共识组中的节点可以在同一个记录上达成一致，其中每个节点的通信复杂度为O（n*n）。 由于二次复杂性，当委员会有20多个节点时，PBFT变得不切实际。\n\n为了提高效率，我们使用来源于ByzCoin的想法：\n\n- 我们用数字签名替换MAC来有效地减少O（n）的通信开销。\n- 与此同时，为了让其他节点能够验证协议，一种典型的方法是从诚实的多数收集签名并将它们附加到协议中，从而导致协商规模与协商组的大小成线性关系。 为了改善这一点，我们使用EC-Schnorr多重签名来将几个签名聚合成O（1） - 大小多重签名\n\n然而，我们不能直接在PBFT设置中使用经典的EC-Schnorr多重签名方案。 这是因为在古典设置中，所有签名者都同意签署给定的消息，并且签名只有在所有签名者都签名后才有效。 在PBFT设置中，我们只需要在共识组中超过2/3\\*n个节点签署消息。 所需的主要修改之一是为参与签名过程的签名者维护位图B. 如果第i个节点参与该过程，则B [i] = 1，否则为0。位图由领导者构建。 位图可以被任何验证者用来验证签名。 最终的协议留在附录B中。\n\n\n\n##### Zilliqa共识\n\n在ZILLIQA中，我们使用PBFT作为基础共识协议，并采用两轮EC-Schnorr多重签名来替换PBFT中的准备阶段和提交阶段。 下面将解释对PBFT阶段的不同修改。\n\n- 预准备阶段: 与标准PBFT中一样，领导者将TX-Block或声明（由领导者签名）分发给共识组中的所有节点。\n- 准备阶段：所有诚实的节点检查TX块的有效性，并且领导者收集来自超过2/3\\*n个节点的响应。 这保证领导者提出的陈述是安全的并且与以前的所有历史一致。 签名是使用EC-Schnorr多重签名生成的。 领导者还构建签署TX块的节点的位图\n- 提交阶段：为了确保超过2/3\\*n的节点知道超过2/3\\*n节点验证了TX-Block的事实。我们进行第二轮EC-Schnorr多重签名。 正在签署的声明是上一轮生成的多重签名。\n\n在三个阶段结束时，就领导者提出的TX-Block将达成共识。\n\n\n\n##### 领导者改变\n\n在我们的共识协议中，如果领导者是诚实的，它可以不断的推动共识小组中的节点就新的交易达成协议。 但是，如果领导是拜占庭，它可以有意地延迟或丢弃来自诚实节点的消息，并减慢协议。 为了惩罚这些恶意领导者，我们的协议会定期更改每个分片的领导和DS委员会。 这可以防止拜占庭领袖在无限期的时间内拖延共识协议。 由于所有节点都是有序的，下一个领导者将以循环方式选择。\n\n 事实上，每一个微块后分片的领导者都会改变，并且在每个最后一个区块之后DS委员会的领导者也会更改。 让我们假设共识组的大小为n，那么在一个DS-epoch时期内，我们允许的最终块的最大值为n，每个最终块最多在1个分片聚合1个微块。\n\n\n\n\n\n#### 附录A，数字签名算法\n\n##### EC-Schnorr（单个签名者）机制\n\nEC-Schnorr工作在离散对数很难的组[8]，[24]，[25]。 ZILLIQA使用在流行的secp256k1曲线上定义的椭圆曲线组。 我们用C :=（p，G，n）表示定义组的参数集合，其中p是指定基础场Fp的质数，G是曲线上的基点，n（素数）是 G的顺序。EC-Schnorr还需要一个密码散列函数H，我们用SHA3-256 [6]实例化。\n\n EC-Schnorr是我们在本节中介绍的一组三种算法KeyGen，Sign和Verify。 在下面的算法中，对于任何标量x和点Q，我们用[x] Q表示乘法\n\n- KeyGen(C): 该算法取曲线参数C并返回一对公钥（pk）和私钥（sk）。算法省略\n- Sign(C, pk, sk, m)：该算法由签名者运行。 根据曲线参数C，公钥和私钥对（pk，sk）以及签署的消息。 它返回一个签名σ\n- Verify(C, σ, pk, m): 该算法由希望检查签名有效性的验证者运行。 它取曲线参数C，签名σ，公钥pk和消息m。 如果签名对于pk下的m有效，则返回1，否则返回0\n\n#####  \n\n##### EC-Schnorr多重签名机制\n\n- 设置和假设：EC-Schnorr也可以用作多重签名方案[11]。在多重签名方案中，我们有T个签名者：P1，...。 。 。 ，PT，聚合器和验证者。签名者希望联合签署消息m。聚合者扮演促进者的角色并聚合每个签名者发送的签名。验证者验证汇总的签名。聚合者和验证者的角色可以由同一个实体来扮演。每个签名者Pi拥有她自己的用于EC-Schnorr单签名者方案的公共私钥对（pki，ski）。\n\n  我们用P = {pk1，。 。 。 ，pkT}表示所有公钥的集合。我们还假设每个实体都知道公共消息mp。消息mp可能是特定于应用场景的，并采取以下形式：我知道会话ID为XXXX的公钥的私钥。这个消息的目的是为了击败对该方案的某些已知攻击[26]。\n\n- 多重签名协议：多重签名是签名者，聚合器和验证者之间的交互协议（参见图2的示意图）。该协议有六个步骤，如下所述。\n\n  1. （一次性）身份设置：此步骤在每个参与者和验证者之间运行。在协议开始时，每个签名者Pi如果当前不涉及另一个签名协议，则在消息mp上生成EC-Schnorr签名σi。然后Pi将（σi，pki）发送给验证者。验证者然后执行以下检查：\n\n     - 检查pki∈P.如果检查失败，检验器将中止。\n     - 通过调用Verify（C，σi，pki，mp）来检查每个σi是否是pki上mp的有效EC-Schnorr签名。如果任何这些签名验证返回0，则验证程序中止。如果所有签名均有效，则协议进行到下一步。\n\n     如果验证程序没有收到P中每个pki的σi，她也会中止。为了记录她是否收到来自Pi的签名，她使用位图Z [1，...。 。 。 ，| P |] .身份设置是一个一次性过程，随后是任意数量的下一步。只有在设置成功结束后，协议的后续步骤才能开始。\n\n  2. commitment 阶段：每个签名者Pi随后选择一个随机ki $←[1，n-1]并计算Qi = [ki] G。回想一下，G是椭圆曲线上的基点，n是G的阶数.Pi然后将Qi发送给聚合器。\n\n  3. Challenge 阶段：聚合器首先用P中的密钥计算聚合密钥。她还计算前一步骤中接收到的Qi的聚合。然后她计算r←H（Q || pk || m）mod n并将（r，Q，pk）发送给每个Pi\n\n  4. 响应生成：每个签名者Pi首先检查之前收到的r的完整性。这是通过重新计算H（Q || pk || m）并检查它是否等于接收到的r来完成的。如果检查失败，则Pi会中止协议或者生成si←（ki -r·ski）mod n并将si发送给聚合器。\n\n  5. 响应聚合：聚合器计算聚合响应s = Pi si mod n并建立聚合签名σ=（r，s）。然后，她将（m，σ）发送给验证者。\n\n  6. 签名验证：Verifier现在检查签名是否有效。她执行以下步骤：\n\n     - 将P中的公钥集中为pk0。\n     - 通过调用，检查σ是否为m上公钥pk0的有效EC-Schnorr签名\n\n\n\n有点难理解，以下比较偏好理解的角度来说。\n\n多重签名方案基本上分两步进行。在协议的第一步中，每个节点将其公钥发送给聚合者，聚合者根据公钥的数学形式，通过简单的加法或乘法将之聚合为一个单一的公钥。\n\n例如，聚合公钥= 公钥_1 + 公钥_2 + …+公钥_n。\n\n然后聚合者将聚合公钥转发给验证者从而可以使后者验证聚合签名，与此同时聚合者也将聚合公钥发送给每个签名者让所有人签名。\n\n在第二步中，聚合者启动与每个签名者的交互协议（interactive protocol）。这个交互协议总分包含三个阶段：\n\n**1、提交阶段（Commit phase）：**此阶段每个节点生成一些随机内容并提交给交互协议。如果你不了解什么是加密提交（cryptographic commitment），那么可以通过这种类比的方式理解：每个节点都秘密地掷骰子，然后将结果写在一张纸上并将其放在一个盒子中锁好，最后发送给聚合者。聚合者无权打开盒子。\n\n**2、挑战阶段（Challenge phase）：**此阶段聚合者首先使用加法或乘法将所有的提交聚合为一个聚合提交，然后使用它以及聚合公钥、消息生成一个挑战，再将挑战发送到所有节点。之后挑战可用于确认所有节点都知道公钥对应的私钥。这与常规数字签名的工作方式类似，即由签名证明签名人确实知道私钥。\n\n**3、回应阶段（Response phase）：**所有节点为了应对挑战会向挑战发送私钥进行回应，之后聚合者将聚合所有的回应。因此回应可被视为签名者知道其公钥对应的私钥的证据。\n\n因此，最后的聚合签名实际上是挑战和聚合回应的信息对，并能验证第一步生成的聚合公钥。\n\n值得注意的是，聚合签名的大小不取决于签名者的数量，它是固定的。\n\n图中蓝色的节点是聚合者。H是用于将消息m生成挑战的密码散列函数。聚合签名就是R和S的信息对。R的大小等于Ri，S的大小等于Si的。仅在知道私钥的情况下才能生成有效的回应。\n\n当验证者检查聚合签名时，它检查的不是每个单独签名者是否都正确地遵守协议，而是检查所有签名者作为一个整体是否正确地遵守协议并知道私钥。因此，验证者做出的决定是全有或全无（all-or-nothing）。\n","slug":"zilliqa","published":1,"updated":"2019-10-14T06:40:25.020Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69xy002st6xvbwt6358n","content":"<h2 id=\"Zil白皮书翻译\"><a href=\"#Zil白皮书翻译\" class=\"headerlink\" title=\"Zil白皮书翻译\"></a>Zil白皮书翻译</h2><p>扩大吞吐量的关键是网络和共识协议的设计。</p>\n<h4 id=\"加密层\"><a href=\"#加密层\" class=\"headerlink\" title=\"加密层\"></a>加密层</h4><p>密码层定义了ZILLIQA中使用的密码基础。 与其他几个区块链平台类似，ZILLIQA依靠椭圆曲线密码学进行数字签名，并使用内存硬散列函数进行校对（PoW）。 在整个白皮书中，我们广泛使用SHA3 [6]散列函数来呈现我们的设计。 SHA3最初基于Keccak [7]，广泛应用于不同的区块链平台，尤其是以太坊。 在不久的将来，我们可能会转向Keccak以实现与其他平台更好的互操作性。</p>\n<ul>\n<li><p>数字签名</p>\n<p>ZILLIQA采用基于椭圆曲线的Schnorr签名算法（EC-Schnorr）[8]作为基础签名算法。我们用secp256k1曲线实例化了这个方案[9]。比特币和以太坊目前使用相同的曲线，但使用不同的签名算法ECDSA。通过ECDSA选择ECSchnorr有几个好处，我们将在下面讨论：</p>\n<ol>\n<li>非可塑性：非正式地说，非可塑性属性意味着给定一组使用私钥生成的签名，对于攻击者来说很难为相应的公钥生成相同消息的新签名。与ECDSA不同，EC Schnorr已被证明是不可修改的。[10]</li>\n<li>多重签名：多重签名方案允许多个设计者将他们的签名集合到一个给定的消息中，并将其集中到一个单一的签名中，这个签名可以通过一个公钥即“汇集”所有授权方的钥匙。而EC-Schnorr本质上是一种多重签名方案（参见[11]），ECDSA允许创建多重签名，但不够灵活。当消息需要多个签名时，ZILLIQA使用基于EC-Schnorr的多重签名来减少签名大小。较小的签名在我们的共识协议中尤为重要，因为多方需要通过签署协议来达成一致</li>\n<li>速度：EC-Schnorr比ECDSA更快，因为后者需要计算大数反模。 EC-Schnorr不需要反转。</li>\n</ol>\n<p>EC-Schnorr密钥生成，签名和验证程序在附录A中给出。在附录中，我们还介绍了EC-Schnorr如何用作多重签名方案</p>\n</li>\n</ul>\n<ul>\n<li><p>POW</p>\n<p>ZILLIQA仅使用PoW来防止Sybil攻击并生成节点标识。这与许多现有的区块链平台（特别是比特币和以太坊）形成鲜明对比，其中PoW用于达成分布式共识。 ZILLIQA采用Ethash ，即Ethereum 1.0中使用的PoW算法。 Ethash是一种内存硬散列函数，旨在使用GPU很容易挖掘，但使用专用计算硬件（如ASIC）很难。为此，Ethash计算需要大量内存（以GB为单位）和I / O带宽，以便该功能不能在专用计算硬件上并行调用。粗略地说，Ethash将一个数据（例如一个块头）和一个64位随机数作为输入，并生成一个256位的摘要。该算法由四个以给定顺序运行的子例程组成：</p>\n<ol>\n<li>种子生成：种子是一个SHA3-256摘要，每30000个块称为一个时期后更新。对于第一个时代，它是一系列32字节零的SHA3-256散列。对于其他时代，它始终是前一个种子的SHA3-256散列。</li>\n<li>缓存生成：种子用于使用SHA3-512生成伪随机缓存。缓存的大小随着时期线性增加。缓存的初始大小为16 MB。</li>\n<li>数据集生成：然后使用高速缓存生成数据集，其中数据集中的每个“项目”仅取决于缓存中的少量项目。数据集每次更新一次，以便矿工不必非常频繁地进行更改。数据集的大小也随着时期线性增加。数据集的初始大小为1 GB。</li>\n<li>挖掘和验证：挖掘包括抓取数据集的随机切片并将它们散列在一起。验证使用缓存重新生成计算哈希所需的特定数据集。</li>\n</ol>\n</li>\n</ul>\n<h4 id=\"数据层\"><a href=\"#数据层\" class=\"headerlink\" title=\"数据层\"></a>数据层</h4><p>广义而言，数据层定义了构成ZILLIQA全局状态的数据。 通过扩展，它还定义了ZILLIQA中不同实体更新其全局状态所需的数据。</p>\n<ul>\n<li><p>账户、地址和状态</p>\n<p>ZILLIQA是一个基于账户的系统（如以太坊）。 有两种类型的帐户：普通帐户和合同帐户。 通过生成ECSchnorr私钥创建普通帐户。 合同帐户由另一个帐户创建。每个帐户由根据其类型导出的地址标识。 普通账户的地址来源于账户的私钥。 对于给定的私钥sk，地址Anormal是一个160位的值，其计算公式如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Anormal = LSB160(SHA3-256(PubKey(sk))),</span><br></pre></td></tr></table></figure>\n\n<p>其中，LSB160（·）返回输入的最右边的160位，PubKey（·）返回与输入密钥对应的公钥。 合约帐户的地址是根据其创建者的地址以及创建者帐户发送的交易次数计算的，也就是帐户随机数（如下所述）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Acontract = LSB160(SHA3-256(address||nonce)),</span><br></pre></td></tr></table></figure>\n\n<p>其中，address是创建者账户的地址，nonce是创建者的现时值。每个账户（无论是正常账户还是合约）都与账户状态相关联。账户状态是一个关键的价值存储区，由以下键组成：</p>\n<p>1）帐户现时：（64位）计数从普通帐户发送的交易数量的计数器（初始化为0）。如果是合同帐户，它会计算帐户创建的合同数量。</p>\n<p>2）余额：（128位）一个非负值。每当一个账户收到来自另一个账户的token时，收到的金额将被添加到账户的余额中。当一个账户向另一个账户发送token时，余额会减少适当的金额。</p>\n<p>3）代码散列：（256位）这存储合同代码的SHA3-256摘要。对于普通帐户，它是空字符串的SHA3-256摘要。</p>\n<p>4）存储根：（256位）每个帐户都有一个存储，它又是一个key-value存储，存储256位密钥和256位值。存储根目录是代表此存储的SHA3-256摘要。例如，如果存储是一个trie，那么存储根就是trie的根的摘要。</p>\n<p>ZILLIQA的全局状态（状态）是帐户地址和帐户状态之间的映射。它使用类似于数据结构的trie来实现。</p>\n</li>\n<li><p>交易</p>\n<p>交易总是从普通账户地址发送，并更新ZILLIQA的全局状态。交易具有以下字段：<br>1）版本（32位）：当前版本。<br>2）nonce（64位）：一个计数器，等于此交易发送者发送的交易数。<br>3）目的（160位）：目的地帐户地址。如果交易创建新的合同帐户，则该字段是空字符串的最右边的160位SHA3-256。<br>4）金额（128位）：要转移到目标地址的交易金额。<br>5）gas价格（128位）：gas被定义为计算的最小单位。gas价格是发送者愿意为交易处理过程中发生的计算而支付的每单位gas的金额。<br>6）gas限制（128位）：处理交易时应使用的最大gas量。<br>7）代码（无限制）：指定合同代码的可扩展字节数组。只有在交易创建新的合同帐户时才存在。<br>8）data（无限）：一个可扩展的字节数组，用于指定应该用来处理数据的数据。它仅在交易调用目标地址的合同调用时才存在。<br>9）公钥（264位）：应该用来验证签名的EC-Schnorr公钥。 pubkey字段也决定了交易的发送地址。<br>10）签名（512位）：整个数据上的EC-Schnorr签名。每个交易都由一个交易ID唯一标识 - 一个排除签名字段的交易数据的SHA3-256摘要。</p>\n</li>\n</ul>\n<h4 id=\"块\"><a href=\"#块\" class=\"headerlink\" title=\"块\"></a>块</h4><p>ZILLIQA协议引入了两种类型的块（以及两个块链）：事务块（TX块）和目录服务块（DS块）。 TX块包含用户发送的交易，而DS块包含有关参与共识协议的矿工的元数据。</p>\n<ul>\n<li>DS块：DS块具有两部分：头部和签名。 DS块的标题部分包含以下字段：</li>\n</ul>\n<p>​    1）版本（32位）：当前版本。<br>​    2）先前的散列（256位）：其父块标题的SHA3-256摘要。<br>​    3）公钥（264位）：在这个块头上做PoW的矿工的公钥。<br>​    4）难度（64位）：这可以从前面的块的难度和块编号中计算出来。它存储了PoW难题的难度。<br>​    5）数字（256位）：祖先块的数量。生成块的块号为0。<br>​    6）时间戳（64位）：Unix创建该块时的时间（）。<br>​    7）mixHash（256比特）：根据nonce计算出的摘要，用于检测DoS攻击。<br>​    8）nonce（64位）：PoW的解决方案。</p>\n<p> DS块的签名部分包含以下两个字段：<br>​    1）签名（512比特）：签名是DS节点签名的DS块头上的基于EC-Schnorr的多重签名。<br>​    2）位图（1024位）：它记录哪些DS节点参与多重签名。我们用位向量B表示位图，其中，B [i] = 0, 如果第i个节点签名B [i] = 1。</p>\n<p>DS块形成DS区块链。</p>\n<ul>\n<li><p>交易块：</p>\n<p>如前所述，DS块包含有关交易共识节点的信息。 TX块存储关于DS块中的节点同意的交易的信息。每个DS块都链接到多个TX块。 TX块包含三部分：标题，数据和签名。标题由以下字段组成：<br>1）类型（8位）：TX-Block有两种类型，即微块（0x00）和最终块（0x01）。更多关于这些在第V-D部分。<br>2）版本（32位）：当前版本。<br>3）先前的散列（256位）：其父块标题的SHA3-256摘要。<br>4）gas限制（128位）：每个块中gas消耗的限制。<br>5）使用的gas（128位）：本区块交易使用的gas总量。<br>6）数字（256位）：祖先块的数量。genesis块的块号为0。<br>7）时间戳（64位）：Unix创建该块时的时间（）。<br>8）状态根（256位）：这是一个SHA3-256摘要，表示所有交易执行并完成后的全局状态。如果全局状态被存储为一个trie，那么状态根就是trie的根的摘要。<br>9）交易根（256位）：这是一个SHA3-256摘要，表示存储此块中存在的所有交易的Merkle树的根。<br>10）tx散列（每个256位）：交易的SHA3-256摘要列表。交易的签名部分也被散列。<br>11）公钥（264位）：提出该块的领导者的EC-Schnorr公钥。<br>12）pubkey微块（无限制）：它是ECSchnorr公钥的列表（每个长度为264位）。该清单包含提交交易的领导人的公钥。该字段仅在final块才存在。<br>13）父块散列（256位）：它是前一个最后块标题的SHA3-256摘要。<br>14）父DS散列（256位）：它是其父DS-Block头的SHA3-256摘要。<br>15）父DS块号（256位）：它是父DS块号。</p>\n<p> TX块的数据部分包含交易列表。它有以下领域：<br>1）tx计数（32位）：该块中的交易数。<br>2）tx list（unlimited）：交易清单。</p>\n<p> TX-Block的签名部分包含基于ECSchnorr的多重签名。它有以下两个字段：</p>\n<ol>\n<li>签名（512比特）：签名基于EC-Schnorr的多重签名，由一组节点在TX-Bloc上进行签名。签名的节点取决于它是微块还是最终块的不同节点组。第V-D节给出了签署方的进一步细节。</li>\n</ol>\n<p>2）位图（1024位）：它记录参与多重签名的节点。我们用位向量B表示位图，其中，如果第i个节点对头部进行签名，则B [i] = 1，否则B [i] = 0。</p>\n<p>final块形成交易区块链。交易区块链不包含微块</p>\n</li>\n</ul>\n<h3 id=\"网络层\"><a href=\"#网络层\" class=\"headerlink\" title=\"网络层\"></a>网络层</h3><p>ZILLIQA被设计成是交易率按比例决定。主要的想法是，分片。即，将挖矿网络分成小分片，每个小分片处理交易是并行的。在本节中，我们将介绍网络和交易分片。</p>\n<h4 id=\"网络分片\"><a href=\"#网络分片\" class=\"headerlink\" title=\"网络分片\"></a>网络分片</h4><p>网络分片。将挖矿网络分成小分片是一个两个的过程，首先，一组专用的称为目录服务委员会（或DS委员会）的节点被选举出来，然后他们将将网络和节点分到他们的分片中。在下面，将具体介绍细节。</p>\n<ul>\n<li><p>目录服务委员会（Directory Service Committee）：为了促进网络的切分，我们首先会选举出一组节点，成为目录服务(DS)节点。<strong>DS节点形成一个DS委员会。DS节点的选举是基于proof-of-work1算法</strong>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//Algorithm 1: PoW1 for DS committee election.</span><br><span class=\"line\">Input: i: Current DS-epoch, DSi−1: Prev. DS committee</span><br><span class=\"line\">composition.</span><br><span class=\"line\">Output: header: DS-Block header.</span><br><span class=\"line\"> On each competing node:</span><br><span class=\"line\">// get epoch randomness from the DS blockchain</span><br><span class=\"line\">// DBi−1: Most recent DS-Block before start of i-th epoch</span><br><span class=\"line\"> r1 ← GetEpochRand(DBi−1)</span><br><span class=\"line\">// get epoch randomness from the transaction blockchain</span><br><span class=\"line\">// TBj : Most recent TX-Block before start of i-th epoch</span><br><span class=\"line\"> r2 ← GetEpochRand(TBj )</span><br><span class=\"line\">// pk: node’s public key, IP = node’s IP address</span><br><span class=\"line\"> nonce, mixHash ← Ethash-PoW(pk, IP, r1, r2)</span><br><span class=\"line\"> header ← BuildHeader(nonce, mixHash, pk)</span><br><span class=\"line\">// header includes pk and nonce among other fields</span><br><span class=\"line\">// IP, header is multicast to members in the DS committee</span><br><span class=\"line\"> MulticastToDSi−1(IP, header)</span><br><span class=\"line\"> return header</span><br></pre></td></tr></table></figure>\n\n<p>比其他节点更早成功产生一个有效的随机数的节点，将为新块提供区块头。回想一下DS-Block头和签名部分，当一个节点解决了POW1，它便可以生产仅仅1个区块头，区块头随后会被多点广播给DS委员会的所有节点，DS委员会将对产生的区块头进行共识后生成签名部分。2f个DS节点签名了区块头，这个区块便被确认添加到DS区块链中。</p>\n<p> 在成功引导阶段后，在任何时候，规定DS节点的组成为一个预定义的窗口大小n0。在最近n0节点中并成功挖掘DS-Block的节点将加入DS委员会。</p>\n<p>连续挖到两个DS-Block之间的平均时间称为DS-epoch。DS-eposh的值的设置是减小两个竞争块几率的一种方法。在DS-epoch的开始，一个新的DS节点加入DS委员然后DS委员会中最老的成员会出去。这固定了在DS-eposh期间DS委员会的大小始终是n0。<strong>DS委员中最新的成员将成为leader, 并领导该时期的共识协议。</strong> 这进一步导致了DS委员会成员的严格排序。</p>\n<p>可以看到的是，如果DS委员会的规模n0足够大（比如说800），那么在n0个委员会成员中极有可能最多有1/3是拜占庭。</p>\n</li>\n<li><p>冲突解决：我们的共识协议不允许在DS区块链中分叉。  当多个节点大致同时解决难题时，可能会出现分叉。 为了解决冲突，每个DS节点从接收到的头中检索nonce字段，并按递增顺序对它们进行排序。 让我们假设第i个DS节点的最大随机数是max(nⁱ)。</p>\n<p>DS委员会的leader然后提出自己的header（对应于他所见过的最大随机数），并运行一致的协议来就DS-         Block header达成一致。 只有当相应的随机数大于或等于max(nⁱ)时，第i个DS节点才被同意接受建议的header。 一旦达成共识，DS-Block的签名部分就建立起来了，然后成为领导者</p>\n</li>\n<li><p>分片生成：一旦选出DS委员会，网络的实际分片就可以开始。 为了使节点参与下面的共识协议，它必须执行工作证明（PoW2）。 分片协议在每个DS时期开始时重复。 算法2给出了PoW2的算法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Algorithm 2: PoW2 for shard membership.</span><br><span class=\"line\">Input: i: Current DS-epoch, DSi: Current DS committee</span><br><span class=\"line\">composition.</span><br><span class=\"line\">Output: nonce, mixHash: outputs of Ethash-PoW</span><br><span class=\"line\"> On each competing node:</span><br><span class=\"line\">// get epoch randomness from the DS blockchain</span><br><span class=\"line\">// DBi−1: Most recent DS-Block before start of i-th epoch</span><br><span class=\"line\"> r ← GetEpochRand(DBi)</span><br><span class=\"line\">// pk: node’s public key, IP = node’s IP address</span><br><span class=\"line\"> nonce, mixHash ← Ethash-PoW(pk, IP, r)</span><br><span class=\"line\">// IP, header is multicast to members in the DS committee</span><br><span class=\"line\"> MulticastToDSi(nonce, mixHash, pk, IP)</span><br><span class=\"line\"> return nonce, mixHash</span><br></pre></td></tr></table></figure>\n\n<p>然后将<strong>计算出的PoW2的有效随机数（和混合散列）多播到DS委员会。 DS节点将共同接受足够的PoW解决方案，以分解为L个共识委员会或分片，每个都具有n0个节点以达成共识</strong>。一旦DS委员会负责人收到足够数量的PoW2解决方案，他就启动一个协商一致的协议，以就该组有效的PoW2解决方案达成一致。在共识协议结束时，leader生成由DS节点签名的EC-Schnorr多重签名。为了进一步进行下去，超过2/3的DS节点必须同意一组可接受的PoW2解决方案。<br>Sharding利用确定性函数将节点分配给分片。让我们假设我们需要每个都有n0个节点的碎片。随机数值按升序排序，第一个有n0个节点的节点们被分配给第一个分片，下一个n0分配到下一个分片，依此类推。<strong>在碎片中提出最大随机数的矿工的身份被宣布为leader</strong>。这进一步诱导了对分片成员的严格排序。也可以表明，如果n0足够大（比如800以上），那么在每个碎片内至多有1/3个是具有高概率的拜占庭</p>\n</li>\n</ul>\n<h4 id=\"公共信道\"><a href=\"#公共信道\" class=\"headerlink\" title=\"公共信道\"></a>公共信道</h4><p>DS节点在公共信道上发布某些信息，包括DS节点的身份和连接信息，每个分片中的节点列表以及交易的分片逻辑（在第V-D节中解释）。 公共频道不可信，并假定所有节点均可访问。 在我们的实现中，我们的广播原语实现了这样的公共频道。 我们区块链的用户想要提交交易以进行接受，然后可以检查分片信息以获取负责处理其交易的碎片。 在公共频道上发布的信息预计将由任何节点或用户可验证的DS节点的2/3以上进行签名。</p>\n<h4 id=\"新节点加入ZILLIQA\"><a href=\"#新节点加入ZILLIQA\" class=\"headerlink\" title=\"新节点加入ZILLIQA\"></a>新节点加入ZILLIQA</h4><p>对于新节点加入网络，它可以尝试解决PoW1成为DS节点或PoW2成为分片的成员。 为此，它需要从区块链获得关于PoW1或PoW2所需的随机性的信息。 一旦获得了随机性信息，新节点就可以将其解决方案提交给DS委员会。</p>\n<h4 id=\"交易分片和过程\"><a href=\"#交易分片和过程\" class=\"headerlink\" title=\"交易分片和过程\"></a>交易分片和过程</h4><p>如以上所述，网络分片创建了每个能够并行处理交易的分片。 在本节中，我们将介绍特定交易如何分配给分片以及如何处理交易。 为此，我们使用以下抽象：A -ⁿ-&gt;B来指示从发件人账户A到收件人账户B的n个ZIL的交易</p>\n<ul>\n<li><p>交易分配：任何交易都表示A -ⁿ-&gt;B被单个分片处理。 假设有L个分片，编号为0到L-1，交易被分配到由发送者地址的(log₂L + 1)右边的位（bit）标识的碎片。即，实例中A的账户地址。因为账户地址是一个160位(bit)的整型数据，所以L的范围应该为<strong>log₂L + 1 ≤ 160</strong>。但实际上，它会小于100。</p>\n<p>一旦识别了分配的分片，交易就会被多播到分片中的一些节点，节点然后再进一步广播它。 一旦交易到达指定分片的领导者，它将把交易包含在TX-Block中并运行共识协议。</p>\n<p><strong>双花（或重播攻击）可以使用每笔交易中的随机数轻松检测</strong>。 回想一下，每笔交易都有一个随机数，用于统计发件人帐户发送的交易数量。 一旦交易进入交易区块链，nonce在账户状态中更新，从而处于全局状态。 当前值小于或等于全局状态当前值的交易被矿工拒绝。 根据发件人的帐户地址本地分片交易允许分片成员检测双倍支出，因为发件人的每个交易都将在同一分片中处理。</p>\n</li>\n<li><p>交易处理：委员会内的所有节点都可以提出交易。这些交易被发送给领导者以运行一组协议，其中一组交易形成下一个TX块。由每个分片建议的块称为微块（由类型标记0x00标识）。一个微块包含EC-Schnorr多重签名，由分片中的2/3个节点组成。leader还建立一个标识签名者公钥的位图B。如果分片的第i个成员签署了TX-Block头部，则B [i] = 1。当一个分片在TX块上达成共识时，其领导者将块头和签名多播给一些DS节点。 DS节点然后在DS委员会内广播它，以便该块到达其领导者。块的数据部分可以异步发送到节点。 DS委员会然后汇集从分片发送的所有块，并且在它们之间运行另一轮共识协议以达成最终块。最后的块是由类型标记0x01标识的TX块。最后一个块包含来自DS委员会的超过2/3个n0节点的EC-Schnorr多重签名。 DS委员会的leader还构建了一个位图B，用于标识签名者的公钥。如果DS委员会的第i个成员签署了TX-Block标题，则B [i] = 1。最后的块头和签名，然后被组播到每个分片中的一些节点。实际的TX块数据不是由DS节点发送的。(DS节点发送的是块头和签名，tx块数据应该是由分片节点间进行同步广播)</p>\n<p>在每个分片中，采取以下步骤来处理最终的块:</p>\n<ol>\n<li>分片中的每个节点使用DS节点的公钥验证EC-Schnorr多重签名。 如果签名对由位图表示的超过2/3个n0公钥有效，则节点执行下一个检查。</li>\n<li>对于包含在最终块头中的每个交易hash，节点检查其相应的交易内容是否可用。 如果相应的交易由节点所属的分片提出，则将交易数据的散列与包含在最后块header中的散列进行比较。 如果交易是由另一个分片提出的，则交易数据跨分片异步共享</li>\n<li>一旦交易数据可用，最终块的data部分被重构并且TX块被附加到本地交易区块链。 账户状态和全局状态相应地被更新。</li>\n<li>如果交易内容不可用，则节点在其本地账户视图中临时使该交易的发送账户失效，以便该账户的任何其他未决交易被拒绝，直到本地交易内容可以与全局状态同步。 这些被拒绝的事务将不得不由发送节点重试</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"共识层\"><a href=\"#共识层\" class=\"headerlink\" title=\"共识层\"></a>共识层</h3><p>如以上提到的，每个分片和DS委员会需要分别在微块和终块上跑一个共识协议。在这一块，我们将展示在每一个分片和DS委员会中定义的共识协议的共识层。在讨论中，我们将分片和DS委员会代指为共识组。</p>\n<h5 id=\"实用拜占庭容错\"><a href=\"#实用拜占庭容错\" class=\"headerlink\" title=\"实用拜占庭容错\"></a>实用拜占庭容错</h5><p>ZILLIQA共识协议的核心依赖于实用拜占庭容错(PBFT)协议。然而我们通过在PBFT中使用EC-Schnorr多签名来提升效率。EC-Schnorr多重签名的使用将正常情况下的通信延迟从O(n*n)降低为O(n)，并将签名大小从O(n)减小到O(1)，其中n是共识组的大小。 在这个部分，我们提供PBFT的概述。</p>\n<p>在PBFT中，共识组内的所有节点都按顺序排列，它有一个主节点（或领导者），其他节点称为备份节点。 每轮PBFT都有三个阶段，如下所述：</p>\n<ul>\n<li>预准备阶段:  在这个阶段，领导者宣布该小组将应该达成一致共识的下一个记录（在我们的案例中是TX-Block）</li>\n<li>准备阶段：在接收到预先准备消息后，每个节点验证其正确性并将准备消息多播给所有其他节点</li>\n<li>提交阶段：在收到超过2/3*n准备消息时，节点向组播组发送提交消息。最后，节点等待超过2/3*n的提交消息，以确保有足够数量的节点做出相同的决定。 因此，所有诚实的节点都接受相同的有效记录。</li>\n</ul>\n<p>PBFT依靠正确的领导者开始每个阶段，并在足够多节点存在时继续进行。 如果领导是拜占庭，它可能会拖延整个共识协议。 为了应对这一挑战，PBFT提供了视图更改协议来使用另一个取代拜占庭领袖。 如果节点在有限的时间内没有看到任何进展，他们可以独立宣布改变领导者的愿望。 如果超过2/3*n个节点的法定人数决定领导者有问题，那么在已知计划中的下一个领导者就会接管。</p>\n<p> 由于在准备/提交阶段每个节点的多播，正常情况下PBFT的通信复杂度为O（n*n）</p>\n<h5 id=\"提高效率\"><a href=\"#提高效率\" class=\"headerlink\" title=\"提高效率\"></a>提高效率</h5><p>经典的PBFT使用消息认证码（MAC）进行节点之间的认证通信。 由于MAC需要在每两个节点之间共享密钥，所以一个共识组中的节点可以在同一个记录上达成一致，其中每个节点的通信复杂度为O（n*n）。 由于二次复杂性，当委员会有20多个节点时，PBFT变得不切实际。</p>\n<p>为了提高效率，我们使用来源于ByzCoin的想法：</p>\n<ul>\n<li>我们用数字签名替换MAC来有效地减少O（n）的通信开销。</li>\n<li>与此同时，为了让其他节点能够验证协议，一种典型的方法是从诚实的多数收集签名并将它们附加到协议中，从而导致协商规模与协商组的大小成线性关系。 为了改善这一点，我们使用EC-Schnorr多重签名来将几个签名聚合成O（1） - 大小多重签名</li>\n</ul>\n<p>然而，我们不能直接在PBFT设置中使用经典的EC-Schnorr多重签名方案。 这是因为在古典设置中，所有签名者都同意签署给定的消息，并且签名只有在所有签名者都签名后才有效。 在PBFT设置中，我们只需要在共识组中超过2/3*n个节点签署消息。 所需的主要修改之一是为参与签名过程的签名者维护位图B. 如果第i个节点参与该过程，则B [i] = 1，否则为0。位图由领导者构建。 位图可以被任何验证者用来验证签名。 最终的协议留在附录B中。</p>\n<h5 id=\"Zilliqa共识\"><a href=\"#Zilliqa共识\" class=\"headerlink\" title=\"Zilliqa共识\"></a>Zilliqa共识</h5><p>在ZILLIQA中，我们使用PBFT作为基础共识协议，并采用两轮EC-Schnorr多重签名来替换PBFT中的准备阶段和提交阶段。 下面将解释对PBFT阶段的不同修改。</p>\n<ul>\n<li>预准备阶段: 与标准PBFT中一样，领导者将TX-Block或声明（由领导者签名）分发给共识组中的所有节点。</li>\n<li>准备阶段：所有诚实的节点检查TX块的有效性，并且领导者收集来自超过2/3*n个节点的响应。 这保证领导者提出的陈述是安全的并且与以前的所有历史一致。 签名是使用EC-Schnorr多重签名生成的。 领导者还构建签署TX块的节点的位图</li>\n<li>提交阶段：为了确保超过2/3*n的节点知道超过2/3*n节点验证了TX-Block的事实。我们进行第二轮EC-Schnorr多重签名。 正在签署的声明是上一轮生成的多重签名。</li>\n</ul>\n<p>在三个阶段结束时，就领导者提出的TX-Block将达成共识。</p>\n<h5 id=\"领导者改变\"><a href=\"#领导者改变\" class=\"headerlink\" title=\"领导者改变\"></a>领导者改变</h5><p>在我们的共识协议中，如果领导者是诚实的，它可以不断的推动共识小组中的节点就新的交易达成协议。 但是，如果领导是拜占庭，它可以有意地延迟或丢弃来自诚实节点的消息，并减慢协议。 为了惩罚这些恶意领导者，我们的协议会定期更改每个分片的领导和DS委员会。 这可以防止拜占庭领袖在无限期的时间内拖延共识协议。 由于所有节点都是有序的，下一个领导者将以循环方式选择。</p>\n<p> 事实上，每一个微块后分片的领导者都会改变，并且在每个最后一个区块之后DS委员会的领导者也会更改。 让我们假设共识组的大小为n，那么在一个DS-epoch时期内，我们允许的最终块的最大值为n，每个最终块最多在1个分片聚合1个微块。</p>\n<h4 id=\"附录A，数字签名算法\"><a href=\"#附录A，数字签名算法\" class=\"headerlink\" title=\"附录A，数字签名算法\"></a>附录A，数字签名算法</h4><h5 id=\"EC-Schnorr（单个签名者）机制\"><a href=\"#EC-Schnorr（单个签名者）机制\" class=\"headerlink\" title=\"EC-Schnorr（单个签名者）机制\"></a>EC-Schnorr（单个签名者）机制</h5><p>EC-Schnorr工作在离散对数很难的组[8]，[24]，[25]。 ZILLIQA使用在流行的secp256k1曲线上定义的椭圆曲线组。 我们用C :=（p，G，n）表示定义组的参数集合，其中p是指定基础场Fp的质数，G是曲线上的基点，n（素数）是 G的顺序。EC-Schnorr还需要一个密码散列函数H，我们用SHA3-256 [6]实例化。</p>\n<p> EC-Schnorr是我们在本节中介绍的一组三种算法KeyGen，Sign和Verify。 在下面的算法中，对于任何标量x和点Q，我们用[x] Q表示乘法</p>\n<ul>\n<li>KeyGen(C): 该算法取曲线参数C并返回一对公钥（pk）和私钥（sk）。算法省略</li>\n<li>Sign(C, pk, sk, m)：该算法由签名者运行。 根据曲线参数C，公钥和私钥对（pk，sk）以及签署的消息。 它返回一个签名σ</li>\n<li>Verify(C, σ, pk, m): 该算法由希望检查签名有效性的验证者运行。 它取曲线参数C，签名σ，公钥pk和消息m。 如果签名对于pk下的m有效，则返回1，否则返回0</li>\n</ul>\n<h5 id><a href=\"#\" class=\"headerlink\" title></a></h5><h5 id=\"EC-Schnorr多重签名机制\"><a href=\"#EC-Schnorr多重签名机制\" class=\"headerlink\" title=\"EC-Schnorr多重签名机制\"></a>EC-Schnorr多重签名机制</h5><ul>\n<li><p>设置和假设：EC-Schnorr也可以用作多重签名方案[11]。在多重签名方案中，我们有T个签名者：P1，…。 。 。 ，PT，聚合器和验证者。签名者希望联合签署消息m。聚合者扮演促进者的角色并聚合每个签名者发送的签名。验证者验证汇总的签名。聚合者和验证者的角色可以由同一个实体来扮演。每个签名者Pi拥有她自己的用于EC-Schnorr单签名者方案的公共私钥对（pki，ski）。</p>\n<p>我们用P = {pk1，。 。 。 ，pkT}表示所有公钥的集合。我们还假设每个实体都知道公共消息mp。消息mp可能是特定于应用场景的，并采取以下形式：我知道会话ID为XXXX的公钥的私钥。这个消息的目的是为了击败对该方案的某些已知攻击[26]。</p>\n</li>\n<li><p>多重签名协议：多重签名是签名者，聚合器和验证者之间的交互协议（参见图2的示意图）。该协议有六个步骤，如下所述。</p>\n<ol>\n<li><p>（一次性）身份设置：此步骤在每个参与者和验证者之间运行。在协议开始时，每个签名者Pi如果当前不涉及另一个签名协议，则在消息mp上生成EC-Schnorr签名σi。然后Pi将（σi，pki）发送给验证者。验证者然后执行以下检查：</p>\n<ul>\n<li>检查pki∈P.如果检查失败，检验器将中止。</li>\n<li>通过调用Verify（C，σi，pki，mp）来检查每个σi是否是pki上mp的有效EC-Schnorr签名。如果任何这些签名验证返回0，则验证程序中止。如果所有签名均有效，则协议进行到下一步。</li>\n</ul>\n<p>如果验证程序没有收到P中每个pki的σi，她也会中止。为了记录她是否收到来自Pi的签名，她使用位图Z [1，…。 。 。 ，| P |] .身份设置是一个一次性过程，随后是任意数量的下一步。只有在设置成功结束后，协议的后续步骤才能开始。</p>\n</li>\n<li><p>commitment 阶段：每个签名者Pi随后选择一个随机ki $←[1，n-1]并计算Qi = [ki] G。回想一下，G是椭圆曲线上的基点，n是G的阶数.Pi然后将Qi发送给聚合器。</p>\n</li>\n<li><p>Challenge 阶段：聚合器首先用P中的密钥计算聚合密钥。她还计算前一步骤中接收到的Qi的聚合。然后她计算r←H（Q || pk || m）mod n并将（r，Q，pk）发送给每个Pi</p>\n</li>\n<li><p>响应生成：每个签名者Pi首先检查之前收到的r的完整性。这是通过重新计算H（Q || pk || m）并检查它是否等于接收到的r来完成的。如果检查失败，则Pi会中止协议或者生成si←（ki -r·ski）mod n并将si发送给聚合器。</p>\n</li>\n<li><p>响应聚合：聚合器计算聚合响应s = Pi si mod n并建立聚合签名σ=（r，s）。然后，她将（m，σ）发送给验证者。</p>\n</li>\n<li><p>签名验证：Verifier现在检查签名是否有效。她执行以下步骤：</p>\n<ul>\n<li>将P中的公钥集中为pk0。</li>\n<li>通过调用，检查σ是否为m上公钥pk0的有效EC-Schnorr签名</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<p>有点难理解，以下比较偏好理解的角度来说。</p>\n<p>多重签名方案基本上分两步进行。在协议的第一步中，每个节点将其公钥发送给聚合者，聚合者根据公钥的数学形式，通过简单的加法或乘法将之聚合为一个单一的公钥。</p>\n<p>例如，聚合公钥= 公钥_1 + 公钥_2 + …+公钥_n。</p>\n<p>然后聚合者将聚合公钥转发给验证者从而可以使后者验证聚合签名，与此同时聚合者也将聚合公钥发送给每个签名者让所有人签名。</p>\n<p>在第二步中，聚合者启动与每个签名者的交互协议（interactive protocol）。这个交互协议总分包含三个阶段：</p>\n<p><strong>1、提交阶段（Commit phase）：</strong>此阶段每个节点生成一些随机内容并提交给交互协议。如果你不了解什么是加密提交（cryptographic commitment），那么可以通过这种类比的方式理解：每个节点都秘密地掷骰子，然后将结果写在一张纸上并将其放在一个盒子中锁好，最后发送给聚合者。聚合者无权打开盒子。</p>\n<p><strong>2、挑战阶段（Challenge phase）：</strong>此阶段聚合者首先使用加法或乘法将所有的提交聚合为一个聚合提交，然后使用它以及聚合公钥、消息生成一个挑战，再将挑战发送到所有节点。之后挑战可用于确认所有节点都知道公钥对应的私钥。这与常规数字签名的工作方式类似，即由签名证明签名人确实知道私钥。</p>\n<p><strong>3、回应阶段（Response phase）：</strong>所有节点为了应对挑战会向挑战发送私钥进行回应，之后聚合者将聚合所有的回应。因此回应可被视为签名者知道其公钥对应的私钥的证据。</p>\n<p>因此，最后的聚合签名实际上是挑战和聚合回应的信息对，并能验证第一步生成的聚合公钥。</p>\n<p>值得注意的是，聚合签名的大小不取决于签名者的数量，它是固定的。</p>\n<p>图中蓝色的节点是聚合者。H是用于将消息m生成挑战的密码散列函数。聚合签名就是R和S的信息对。R的大小等于Ri，S的大小等于Si的。仅在知道私钥的情况下才能生成有效的回应。</p>\n<p>当验证者检查聚合签名时，它检查的不是每个单独签名者是否都正确地遵守协议，而是检查所有签名者作为一个整体是否正确地遵守协议并知道私钥。因此，验证者做出的决定是全有或全无（all-or-nothing）。</p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h2 id=\"Zil白皮书翻译\"><a href=\"#Zil白皮书翻译\" class=\"headerlink\" title=\"Zil白皮书翻译\"></a>Zil白皮书翻译</h2><p>扩大吞吐量的关键是网络和共识协议的设计。</p>\n<h4 id=\"加密层\"><a href=\"#加密层\" class=\"headerlink\" title=\"加密层\"></a>加密层</h4><p>密码层定义了ZILLIQA中使用的密码基础。 与其他几个区块链平台类似，ZILLIQA依靠椭圆曲线密码学进行数字签名，并使用内存硬散列函数进行校对（PoW）。 在整个白皮书中，我们广泛使用SHA3 [6]散列函数来呈现我们的设计。 SHA3最初基于Keccak [7]，广泛应用于不同的区块链平台，尤其是以太坊。 在不久的将来，我们可能会转向Keccak以实现与其他平台更好的互操作性。</p>\n<ul>\n<li><p>数字签名</p>\n<p>ZILLIQA采用基于椭圆曲线的Schnorr签名算法（EC-Schnorr）[8]作为基础签名算法。我们用secp256k1曲线实例化了这个方案[9]。比特币和以太坊目前使用相同的曲线，但使用不同的签名算法ECDSA。通过ECDSA选择ECSchnorr有几个好处，我们将在下面讨论：</p>\n<ol>\n<li>非可塑性：非正式地说，非可塑性属性意味着给定一组使用私钥生成的签名，对于攻击者来说很难为相应的公钥生成相同消息的新签名。与ECDSA不同，EC Schnorr已被证明是不可修改的。[10]</li>\n<li>多重签名：多重签名方案允许多个设计者将他们的签名集合到一个给定的消息中，并将其集中到一个单一的签名中，这个签名可以通过一个公钥即“汇集”所有授权方的钥匙。而EC-Schnorr本质上是一种多重签名方案（参见[11]），ECDSA允许创建多重签名，但不够灵活。当消息需要多个签名时，ZILLIQA使用基于EC-Schnorr的多重签名来减少签名大小。较小的签名在我们的共识协议中尤为重要，因为多方需要通过签署协议来达成一致</li>\n<li>速度：EC-Schnorr比ECDSA更快，因为后者需要计算大数反模。 EC-Schnorr不需要反转。</li>\n</ol>\n<p>EC-Schnorr密钥生成，签名和验证程序在附录A中给出。在附录中，我们还介绍了EC-Schnorr如何用作多重签名方案</p>\n</li>\n</ul>\n<ul>\n<li><p>POW</p>\n<p>ZILLIQA仅使用PoW来防止Sybil攻击并生成节点标识。这与许多现有的区块链平台（特别是比特币和以太坊）形成鲜明对比，其中PoW用于达成分布式共识。 ZILLIQA采用Ethash ，即Ethereum 1.0中使用的PoW算法。 Ethash是一种内存硬散列函数，旨在使用GPU很容易挖掘，但使用专用计算硬件（如ASIC）很难。为此，Ethash计算需要大量内存（以GB为单位）和I / O带宽，以便该功能不能在专用计算硬件上并行调用。粗略地说，Ethash将一个数据（例如一个块头）和一个64位随机数作为输入，并生成一个256位的摘要。该算法由四个以给定顺序运行的子例程组成：</p>\n<ol>\n<li>种子生成：种子是一个SHA3-256摘要，每30000个块称为一个时期后更新。对于第一个时代，它是一系列32字节零的SHA3-256散列。对于其他时代，它始终是前一个种子的SHA3-256散列。</li>\n<li>缓存生成：种子用于使用SHA3-512生成伪随机缓存。缓存的大小随着时期线性增加。缓存的初始大小为16 MB。</li>\n<li>数据集生成：然后使用高速缓存生成数据集，其中数据集中的每个“项目”仅取决于缓存中的少量项目。数据集每次更新一次，以便矿工不必非常频繁地进行更改。数据集的大小也随着时期线性增加。数据集的初始大小为1 GB。</li>\n<li>挖掘和验证：挖掘包括抓取数据集的随机切片并将它们散列在一起。验证使用缓存重新生成计算哈希所需的特定数据集。</li>\n</ol>\n</li>\n</ul>\n<h4 id=\"数据层\"><a href=\"#数据层\" class=\"headerlink\" title=\"数据层\"></a>数据层</h4><p>广义而言，数据层定义了构成ZILLIQA全局状态的数据。 通过扩展，它还定义了ZILLIQA中不同实体更新其全局状态所需的数据。</p>\n<ul>\n<li><p>账户、地址和状态</p>\n<p>ZILLIQA是一个基于账户的系统（如以太坊）。 有两种类型的帐户：普通帐户和合同帐户。 通过生成ECSchnorr私钥创建普通帐户。 合同帐户由另一个帐户创建。每个帐户由根据其类型导出的地址标识。 普通账户的地址来源于账户的私钥。 对于给定的私钥sk，地址Anormal是一个160位的值，其计算公式如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Anormal = LSB160(SHA3-256(PubKey(sk))),</span><br></pre></td></tr></table></figure>\n\n<p>其中，LSB160（·）返回输入的最右边的160位，PubKey（·）返回与输入密钥对应的公钥。 合约帐户的地址是根据其创建者的地址以及创建者帐户发送的交易次数计算的，也就是帐户随机数（如下所述）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Acontract = LSB160(SHA3-256(address||nonce)),</span><br></pre></td></tr></table></figure>\n\n<p>其中，address是创建者账户的地址，nonce是创建者的现时值。每个账户（无论是正常账户还是合约）都与账户状态相关联。账户状态是一个关键的价值存储区，由以下键组成：</p>\n<p>1）帐户现时：（64位）计数从普通帐户发送的交易数量的计数器（初始化为0）。如果是合同帐户，它会计算帐户创建的合同数量。</p>\n<p>2）余额：（128位）一个非负值。每当一个账户收到来自另一个账户的token时，收到的金额将被添加到账户的余额中。当一个账户向另一个账户发送token时，余额会减少适当的金额。</p>\n<p>3）代码散列：（256位）这存储合同代码的SHA3-256摘要。对于普通帐户，它是空字符串的SHA3-256摘要。</p>\n<p>4）存储根：（256位）每个帐户都有一个存储，它又是一个key-value存储，存储256位密钥和256位值。存储根目录是代表此存储的SHA3-256摘要。例如，如果存储是一个trie，那么存储根就是trie的根的摘要。</p>\n<p>ZILLIQA的全局状态（状态）是帐户地址和帐户状态之间的映射。它使用类似于数据结构的trie来实现。</p>\n</li>\n<li><p>交易</p>\n<p>交易总是从普通账户地址发送，并更新ZILLIQA的全局状态。交易具有以下字段：<br>1）版本（32位）：当前版本。<br>2）nonce（64位）：一个计数器，等于此交易发送者发送的交易数。<br>3）目的（160位）：目的地帐户地址。如果交易创建新的合同帐户，则该字段是空字符串的最右边的160位SHA3-256。<br>4）金额（128位）：要转移到目标地址的交易金额。<br>5）gas价格（128位）：gas被定义为计算的最小单位。gas价格是发送者愿意为交易处理过程中发生的计算而支付的每单位gas的金额。<br>6）gas限制（128位）：处理交易时应使用的最大gas量。<br>7）代码（无限制）：指定合同代码的可扩展字节数组。只有在交易创建新的合同帐户时才存在。<br>8）data（无限）：一个可扩展的字节数组，用于指定应该用来处理数据的数据。它仅在交易调用目标地址的合同调用时才存在。<br>9）公钥（264位）：应该用来验证签名的EC-Schnorr公钥。 pubkey字段也决定了交易的发送地址。<br>10）签名（512位）：整个数据上的EC-Schnorr签名。每个交易都由一个交易ID唯一标识 - 一个排除签名字段的交易数据的SHA3-256摘要。</p>\n</li>\n</ul>\n<h4 id=\"块\"><a href=\"#块\" class=\"headerlink\" title=\"块\"></a>块</h4><p>ZILLIQA协议引入了两种类型的块（以及两个块链）：事务块（TX块）和目录服务块（DS块）。 TX块包含用户发送的交易，而DS块包含有关参与共识协议的矿工的元数据。</p>\n<ul>\n<li>DS块：DS块具有两部分：头部和签名。 DS块的标题部分包含以下字段：</li>\n</ul>\n<p>​    1）版本（32位）：当前版本。<br>​    2）先前的散列（256位）：其父块标题的SHA3-256摘要。<br>​    3）公钥（264位）：在这个块头上做PoW的矿工的公钥。<br>​    4）难度（64位）：这可以从前面的块的难度和块编号中计算出来。它存储了PoW难题的难度。<br>​    5）数字（256位）：祖先块的数量。生成块的块号为0。<br>​    6）时间戳（64位）：Unix创建该块时的时间（）。<br>​    7）mixHash（256比特）：根据nonce计算出的摘要，用于检测DoS攻击。<br>​    8）nonce（64位）：PoW的解决方案。</p>\n<p> DS块的签名部分包含以下两个字段：<br>​    1）签名（512比特）：签名是DS节点签名的DS块头上的基于EC-Schnorr的多重签名。<br>​    2）位图（1024位）：它记录哪些DS节点参与多重签名。我们用位向量B表示位图，其中，B [i] = 0, 如果第i个节点签名B [i] = 1。</p>\n<p>DS块形成DS区块链。</p>\n<ul>\n<li><p>交易块：</p>\n<p>如前所述，DS块包含有关交易共识节点的信息。 TX块存储关于DS块中的节点同意的交易的信息。每个DS块都链接到多个TX块。 TX块包含三部分：标题，数据和签名。标题由以下字段组成：<br>1）类型（8位）：TX-Block有两种类型，即微块（0x00）和最终块（0x01）。更多关于这些在第V-D部分。<br>2）版本（32位）：当前版本。<br>3）先前的散列（256位）：其父块标题的SHA3-256摘要。<br>4）gas限制（128位）：每个块中gas消耗的限制。<br>5）使用的gas（128位）：本区块交易使用的gas总量。<br>6）数字（256位）：祖先块的数量。genesis块的块号为0。<br>7）时间戳（64位）：Unix创建该块时的时间（）。<br>8）状态根（256位）：这是一个SHA3-256摘要，表示所有交易执行并完成后的全局状态。如果全局状态被存储为一个trie，那么状态根就是trie的根的摘要。<br>9）交易根（256位）：这是一个SHA3-256摘要，表示存储此块中存在的所有交易的Merkle树的根。<br>10）tx散列（每个256位）：交易的SHA3-256摘要列表。交易的签名部分也被散列。<br>11）公钥（264位）：提出该块的领导者的EC-Schnorr公钥。<br>12）pubkey微块（无限制）：它是ECSchnorr公钥的列表（每个长度为264位）。该清单包含提交交易的领导人的公钥。该字段仅在final块才存在。<br>13）父块散列（256位）：它是前一个最后块标题的SHA3-256摘要。<br>14）父DS散列（256位）：它是其父DS-Block头的SHA3-256摘要。<br>15）父DS块号（256位）：它是父DS块号。</p>\n<p> TX块的数据部分包含交易列表。它有以下领域：<br>1）tx计数（32位）：该块中的交易数。<br>2）tx list（unlimited）：交易清单。</p>\n<p> TX-Block的签名部分包含基于ECSchnorr的多重签名。它有以下两个字段：</p>\n<ol>\n<li>签名（512比特）：签名基于EC-Schnorr的多重签名，由一组节点在TX-Bloc上进行签名。签名的节点取决于它是微块还是最终块的不同节点组。第V-D节给出了签署方的进一步细节。</li>\n</ol>\n<p>2）位图（1024位）：它记录参与多重签名的节点。我们用位向量B表示位图，其中，如果第i个节点对头部进行签名，则B [i] = 1，否则B [i] = 0。</p>\n<p>final块形成交易区块链。交易区块链不包含微块</p>\n</li>\n</ul>\n<h3 id=\"网络层\"><a href=\"#网络层\" class=\"headerlink\" title=\"网络层\"></a>网络层</h3><p>ZILLIQA被设计成是交易率按比例决定。主要的想法是，分片。即，将挖矿网络分成小分片，每个小分片处理交易是并行的。在本节中，我们将介绍网络和交易分片。</p>\n<h4 id=\"网络分片\"><a href=\"#网络分片\" class=\"headerlink\" title=\"网络分片\"></a>网络分片</h4><p>网络分片。将挖矿网络分成小分片是一个两个的过程，首先，一组专用的称为目录服务委员会（或DS委员会）的节点被选举出来，然后他们将将网络和节点分到他们的分片中。在下面，将具体介绍细节。</p>\n<ul>\n<li><p>目录服务委员会（Directory Service Committee）：为了促进网络的切分，我们首先会选举出一组节点，成为目录服务(DS)节点。<strong>DS节点形成一个DS委员会。DS节点的选举是基于proof-of-work1算法</strong>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//Algorithm 1: PoW1 for DS committee election.</span><br><span class=\"line\">Input: i: Current DS-epoch, DSi−1: Prev. DS committee</span><br><span class=\"line\">composition.</span><br><span class=\"line\">Output: header: DS-Block header.</span><br><span class=\"line\"> On each competing node:</span><br><span class=\"line\">// get epoch randomness from the DS blockchain</span><br><span class=\"line\">// DBi−1: Most recent DS-Block before start of i-th epoch</span><br><span class=\"line\"> r1 ← GetEpochRand(DBi−1)</span><br><span class=\"line\">// get epoch randomness from the transaction blockchain</span><br><span class=\"line\">// TBj : Most recent TX-Block before start of i-th epoch</span><br><span class=\"line\"> r2 ← GetEpochRand(TBj )</span><br><span class=\"line\">// pk: node’s public key, IP = node’s IP address</span><br><span class=\"line\"> nonce, mixHash ← Ethash-PoW(pk, IP, r1, r2)</span><br><span class=\"line\"> header ← BuildHeader(nonce, mixHash, pk)</span><br><span class=\"line\">// header includes pk and nonce among other fields</span><br><span class=\"line\">// IP, header is multicast to members in the DS committee</span><br><span class=\"line\"> MulticastToDSi−1(IP, header)</span><br><span class=\"line\"> return header</span><br></pre></td></tr></table></figure>\n\n<p>比其他节点更早成功产生一个有效的随机数的节点，将为新块提供区块头。回想一下DS-Block头和签名部分，当一个节点解决了POW1，它便可以生产仅仅1个区块头，区块头随后会被多点广播给DS委员会的所有节点，DS委员会将对产生的区块头进行共识后生成签名部分。2f个DS节点签名了区块头，这个区块便被确认添加到DS区块链中。</p>\n<p> 在成功引导阶段后，在任何时候，规定DS节点的组成为一个预定义的窗口大小n0。在最近n0节点中并成功挖掘DS-Block的节点将加入DS委员会。</p>\n<p>连续挖到两个DS-Block之间的平均时间称为DS-epoch。DS-eposh的值的设置是减小两个竞争块几率的一种方法。在DS-epoch的开始，一个新的DS节点加入DS委员然后DS委员会中最老的成员会出去。这固定了在DS-eposh期间DS委员会的大小始终是n0。<strong>DS委员中最新的成员将成为leader, 并领导该时期的共识协议。</strong> 这进一步导致了DS委员会成员的严格排序。</p>\n<p>可以看到的是，如果DS委员会的规模n0足够大（比如说800），那么在n0个委员会成员中极有可能最多有1/3是拜占庭。</p>\n</li>\n<li><p>冲突解决：我们的共识协议不允许在DS区块链中分叉。  当多个节点大致同时解决难题时，可能会出现分叉。 为了解决冲突，每个DS节点从接收到的头中检索nonce字段，并按递增顺序对它们进行排序。 让我们假设第i个DS节点的最大随机数是max(nⁱ)。</p>\n<p>DS委员会的leader然后提出自己的header（对应于他所见过的最大随机数），并运行一致的协议来就DS-         Block header达成一致。 只有当相应的随机数大于或等于max(nⁱ)时，第i个DS节点才被同意接受建议的header。 一旦达成共识，DS-Block的签名部分就建立起来了，然后成为领导者</p>\n</li>\n<li><p>分片生成：一旦选出DS委员会，网络的实际分片就可以开始。 为了使节点参与下面的共识协议，它必须执行工作证明（PoW2）。 分片协议在每个DS时期开始时重复。 算法2给出了PoW2的算法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Algorithm 2: PoW2 for shard membership.</span><br><span class=\"line\">Input: i: Current DS-epoch, DSi: Current DS committee</span><br><span class=\"line\">composition.</span><br><span class=\"line\">Output: nonce, mixHash: outputs of Ethash-PoW</span><br><span class=\"line\"> On each competing node:</span><br><span class=\"line\">// get epoch randomness from the DS blockchain</span><br><span class=\"line\">// DBi−1: Most recent DS-Block before start of i-th epoch</span><br><span class=\"line\"> r ← GetEpochRand(DBi)</span><br><span class=\"line\">// pk: node’s public key, IP = node’s IP address</span><br><span class=\"line\"> nonce, mixHash ← Ethash-PoW(pk, IP, r)</span><br><span class=\"line\">// IP, header is multicast to members in the DS committee</span><br><span class=\"line\"> MulticastToDSi(nonce, mixHash, pk, IP)</span><br><span class=\"line\"> return nonce, mixHash</span><br></pre></td></tr></table></figure>\n\n<p>然后将<strong>计算出的PoW2的有效随机数（和混合散列）多播到DS委员会。 DS节点将共同接受足够的PoW解决方案，以分解为L个共识委员会或分片，每个都具有n0个节点以达成共识</strong>。一旦DS委员会负责人收到足够数量的PoW2解决方案，他就启动一个协商一致的协议，以就该组有效的PoW2解决方案达成一致。在共识协议结束时，leader生成由DS节点签名的EC-Schnorr多重签名。为了进一步进行下去，超过2/3的DS节点必须同意一组可接受的PoW2解决方案。<br>Sharding利用确定性函数将节点分配给分片。让我们假设我们需要每个都有n0个节点的碎片。随机数值按升序排序，第一个有n0个节点的节点们被分配给第一个分片，下一个n0分配到下一个分片，依此类推。<strong>在碎片中提出最大随机数的矿工的身份被宣布为leader</strong>。这进一步诱导了对分片成员的严格排序。也可以表明，如果n0足够大（比如800以上），那么在每个碎片内至多有1/3个是具有高概率的拜占庭</p>\n</li>\n</ul>\n<h4 id=\"公共信道\"><a href=\"#公共信道\" class=\"headerlink\" title=\"公共信道\"></a>公共信道</h4><p>DS节点在公共信道上发布某些信息，包括DS节点的身份和连接信息，每个分片中的节点列表以及交易的分片逻辑（在第V-D节中解释）。 公共频道不可信，并假定所有节点均可访问。 在我们的实现中，我们的广播原语实现了这样的公共频道。 我们区块链的用户想要提交交易以进行接受，然后可以检查分片信息以获取负责处理其交易的碎片。 在公共频道上发布的信息预计将由任何节点或用户可验证的DS节点的2/3以上进行签名。</p>\n<h4 id=\"新节点加入ZILLIQA\"><a href=\"#新节点加入ZILLIQA\" class=\"headerlink\" title=\"新节点加入ZILLIQA\"></a>新节点加入ZILLIQA</h4><p>对于新节点加入网络，它可以尝试解决PoW1成为DS节点或PoW2成为分片的成员。 为此，它需要从区块链获得关于PoW1或PoW2所需的随机性的信息。 一旦获得了随机性信息，新节点就可以将其解决方案提交给DS委员会。</p>\n<h4 id=\"交易分片和过程\"><a href=\"#交易分片和过程\" class=\"headerlink\" title=\"交易分片和过程\"></a>交易分片和过程</h4><p>如以上所述，网络分片创建了每个能够并行处理交易的分片。 在本节中，我们将介绍特定交易如何分配给分片以及如何处理交易。 为此，我们使用以下抽象：A -ⁿ-&gt;B来指示从发件人账户A到收件人账户B的n个ZIL的交易</p>\n<ul>\n<li><p>交易分配：任何交易都表示A -ⁿ-&gt;B被单个分片处理。 假设有L个分片，编号为0到L-1，交易被分配到由发送者地址的(log₂L + 1)右边的位（bit）标识的碎片。即，实例中A的账户地址。因为账户地址是一个160位(bit)的整型数据，所以L的范围应该为<strong>log₂L + 1 ≤ 160</strong>。但实际上，它会小于100。</p>\n<p>一旦识别了分配的分片，交易就会被多播到分片中的一些节点，节点然后再进一步广播它。 一旦交易到达指定分片的领导者，它将把交易包含在TX-Block中并运行共识协议。</p>\n<p><strong>双花（或重播攻击）可以使用每笔交易中的随机数轻松检测</strong>。 回想一下，每笔交易都有一个随机数，用于统计发件人帐户发送的交易数量。 一旦交易进入交易区块链，nonce在账户状态中更新，从而处于全局状态。 当前值小于或等于全局状态当前值的交易被矿工拒绝。 根据发件人的帐户地址本地分片交易允许分片成员检测双倍支出，因为发件人的每个交易都将在同一分片中处理。</p>\n</li>\n<li><p>交易处理：委员会内的所有节点都可以提出交易。这些交易被发送给领导者以运行一组协议，其中一组交易形成下一个TX块。由每个分片建议的块称为微块（由类型标记0x00标识）。一个微块包含EC-Schnorr多重签名，由分片中的2/3个节点组成。leader还建立一个标识签名者公钥的位图B。如果分片的第i个成员签署了TX-Block头部，则B [i] = 1。当一个分片在TX块上达成共识时，其领导者将块头和签名多播给一些DS节点。 DS节点然后在DS委员会内广播它，以便该块到达其领导者。块的数据部分可以异步发送到节点。 DS委员会然后汇集从分片发送的所有块，并且在它们之间运行另一轮共识协议以达成最终块。最后的块是由类型标记0x01标识的TX块。最后一个块包含来自DS委员会的超过2/3个n0节点的EC-Schnorr多重签名。 DS委员会的leader还构建了一个位图B，用于标识签名者的公钥。如果DS委员会的第i个成员签署了TX-Block标题，则B [i] = 1。最后的块头和签名，然后被组播到每个分片中的一些节点。实际的TX块数据不是由DS节点发送的。(DS节点发送的是块头和签名，tx块数据应该是由分片节点间进行同步广播)</p>\n<p>在每个分片中，采取以下步骤来处理最终的块:</p>\n<ol>\n<li>分片中的每个节点使用DS节点的公钥验证EC-Schnorr多重签名。 如果签名对由位图表示的超过2/3个n0公钥有效，则节点执行下一个检查。</li>\n<li>对于包含在最终块头中的每个交易hash，节点检查其相应的交易内容是否可用。 如果相应的交易由节点所属的分片提出，则将交易数据的散列与包含在最后块header中的散列进行比较。 如果交易是由另一个分片提出的，则交易数据跨分片异步共享</li>\n<li>一旦交易数据可用，最终块的data部分被重构并且TX块被附加到本地交易区块链。 账户状态和全局状态相应地被更新。</li>\n<li>如果交易内容不可用，则节点在其本地账户视图中临时使该交易的发送账户失效，以便该账户的任何其他未决交易被拒绝，直到本地交易内容可以与全局状态同步。 这些被拒绝的事务将不得不由发送节点重试</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"共识层\"><a href=\"#共识层\" class=\"headerlink\" title=\"共识层\"></a>共识层</h3><p>如以上提到的，每个分片和DS委员会需要分别在微块和终块上跑一个共识协议。在这一块，我们将展示在每一个分片和DS委员会中定义的共识协议的共识层。在讨论中，我们将分片和DS委员会代指为共识组。</p>\n<h5 id=\"实用拜占庭容错\"><a href=\"#实用拜占庭容错\" class=\"headerlink\" title=\"实用拜占庭容错\"></a>实用拜占庭容错</h5><p>ZILLIQA共识协议的核心依赖于实用拜占庭容错(PBFT)协议。然而我们通过在PBFT中使用EC-Schnorr多签名来提升效率。EC-Schnorr多重签名的使用将正常情况下的通信延迟从O(n*n)降低为O(n)，并将签名大小从O(n)减小到O(1)，其中n是共识组的大小。 在这个部分，我们提供PBFT的概述。</p>\n<p>在PBFT中，共识组内的所有节点都按顺序排列，它有一个主节点（或领导者），其他节点称为备份节点。 每轮PBFT都有三个阶段，如下所述：</p>\n<ul>\n<li>预准备阶段:  在这个阶段，领导者宣布该小组将应该达成一致共识的下一个记录（在我们的案例中是TX-Block）</li>\n<li>准备阶段：在接收到预先准备消息后，每个节点验证其正确性并将准备消息多播给所有其他节点</li>\n<li>提交阶段：在收到超过2/3*n准备消息时，节点向组播组发送提交消息。最后，节点等待超过2/3*n的提交消息，以确保有足够数量的节点做出相同的决定。 因此，所有诚实的节点都接受相同的有效记录。</li>\n</ul>\n<p>PBFT依靠正确的领导者开始每个阶段，并在足够多节点存在时继续进行。 如果领导是拜占庭，它可能会拖延整个共识协议。 为了应对这一挑战，PBFT提供了视图更改协议来使用另一个取代拜占庭领袖。 如果节点在有限的时间内没有看到任何进展，他们可以独立宣布改变领导者的愿望。 如果超过2/3*n个节点的法定人数决定领导者有问题，那么在已知计划中的下一个领导者就会接管。</p>\n<p> 由于在准备/提交阶段每个节点的多播，正常情况下PBFT的通信复杂度为O（n*n）</p>\n<h5 id=\"提高效率\"><a href=\"#提高效率\" class=\"headerlink\" title=\"提高效率\"></a>提高效率</h5><p>经典的PBFT使用消息认证码（MAC）进行节点之间的认证通信。 由于MAC需要在每两个节点之间共享密钥，所以一个共识组中的节点可以在同一个记录上达成一致，其中每个节点的通信复杂度为O（n*n）。 由于二次复杂性，当委员会有20多个节点时，PBFT变得不切实际。</p>\n<p>为了提高效率，我们使用来源于ByzCoin的想法：</p>\n<ul>\n<li>我们用数字签名替换MAC来有效地减少O（n）的通信开销。</li>\n<li>与此同时，为了让其他节点能够验证协议，一种典型的方法是从诚实的多数收集签名并将它们附加到协议中，从而导致协商规模与协商组的大小成线性关系。 为了改善这一点，我们使用EC-Schnorr多重签名来将几个签名聚合成O（1） - 大小多重签名</li>\n</ul>\n<p>然而，我们不能直接在PBFT设置中使用经典的EC-Schnorr多重签名方案。 这是因为在古典设置中，所有签名者都同意签署给定的消息，并且签名只有在所有签名者都签名后才有效。 在PBFT设置中，我们只需要在共识组中超过2/3*n个节点签署消息。 所需的主要修改之一是为参与签名过程的签名者维护位图B. 如果第i个节点参与该过程，则B [i] = 1，否则为0。位图由领导者构建。 位图可以被任何验证者用来验证签名。 最终的协议留在附录B中。</p>\n<h5 id=\"Zilliqa共识\"><a href=\"#Zilliqa共识\" class=\"headerlink\" title=\"Zilliqa共识\"></a>Zilliqa共识</h5><p>在ZILLIQA中，我们使用PBFT作为基础共识协议，并采用两轮EC-Schnorr多重签名来替换PBFT中的准备阶段和提交阶段。 下面将解释对PBFT阶段的不同修改。</p>\n<ul>\n<li>预准备阶段: 与标准PBFT中一样，领导者将TX-Block或声明（由领导者签名）分发给共识组中的所有节点。</li>\n<li>准备阶段：所有诚实的节点检查TX块的有效性，并且领导者收集来自超过2/3*n个节点的响应。 这保证领导者提出的陈述是安全的并且与以前的所有历史一致。 签名是使用EC-Schnorr多重签名生成的。 领导者还构建签署TX块的节点的位图</li>\n<li>提交阶段：为了确保超过2/3*n的节点知道超过2/3*n节点验证了TX-Block的事实。我们进行第二轮EC-Schnorr多重签名。 正在签署的声明是上一轮生成的多重签名。</li>\n</ul>\n<p>在三个阶段结束时，就领导者提出的TX-Block将达成共识。</p>\n<h5 id=\"领导者改变\"><a href=\"#领导者改变\" class=\"headerlink\" title=\"领导者改变\"></a>领导者改变</h5><p>在我们的共识协议中，如果领导者是诚实的，它可以不断的推动共识小组中的节点就新的交易达成协议。 但是，如果领导是拜占庭，它可以有意地延迟或丢弃来自诚实节点的消息，并减慢协议。 为了惩罚这些恶意领导者，我们的协议会定期更改每个分片的领导和DS委员会。 这可以防止拜占庭领袖在无限期的时间内拖延共识协议。 由于所有节点都是有序的，下一个领导者将以循环方式选择。</p>\n<p> 事实上，每一个微块后分片的领导者都会改变，并且在每个最后一个区块之后DS委员会的领导者也会更改。 让我们假设共识组的大小为n，那么在一个DS-epoch时期内，我们允许的最终块的最大值为n，每个最终块最多在1个分片聚合1个微块。</p>\n<h4 id=\"附录A，数字签名算法\"><a href=\"#附录A，数字签名算法\" class=\"headerlink\" title=\"附录A，数字签名算法\"></a>附录A，数字签名算法</h4><h5 id=\"EC-Schnorr（单个签名者）机制\"><a href=\"#EC-Schnorr（单个签名者）机制\" class=\"headerlink\" title=\"EC-Schnorr（单个签名者）机制\"></a>EC-Schnorr（单个签名者）机制</h5><p>EC-Schnorr工作在离散对数很难的组[8]，[24]，[25]。 ZILLIQA使用在流行的secp256k1曲线上定义的椭圆曲线组。 我们用C :=（p，G，n）表示定义组的参数集合，其中p是指定基础场Fp的质数，G是曲线上的基点，n（素数）是 G的顺序。EC-Schnorr还需要一个密码散列函数H，我们用SHA3-256 [6]实例化。</p>\n<p> EC-Schnorr是我们在本节中介绍的一组三种算法KeyGen，Sign和Verify。 在下面的算法中，对于任何标量x和点Q，我们用[x] Q表示乘法</p>\n<ul>\n<li>KeyGen(C): 该算法取曲线参数C并返回一对公钥（pk）和私钥（sk）。算法省略</li>\n<li>Sign(C, pk, sk, m)：该算法由签名者运行。 根据曲线参数C，公钥和私钥对（pk，sk）以及签署的消息。 它返回一个签名σ</li>\n<li>Verify(C, σ, pk, m): 该算法由希望检查签名有效性的验证者运行。 它取曲线参数C，签名σ，公钥pk和消息m。 如果签名对于pk下的m有效，则返回1，否则返回0</li>\n</ul>\n<h5 id><a href=\"#\" class=\"headerlink\" title></a></h5><h5 id=\"EC-Schnorr多重签名机制\"><a href=\"#EC-Schnorr多重签名机制\" class=\"headerlink\" title=\"EC-Schnorr多重签名机制\"></a>EC-Schnorr多重签名机制</h5><ul>\n<li><p>设置和假设：EC-Schnorr也可以用作多重签名方案[11]。在多重签名方案中，我们有T个签名者：P1，…。 。 。 ，PT，聚合器和验证者。签名者希望联合签署消息m。聚合者扮演促进者的角色并聚合每个签名者发送的签名。验证者验证汇总的签名。聚合者和验证者的角色可以由同一个实体来扮演。每个签名者Pi拥有她自己的用于EC-Schnorr单签名者方案的公共私钥对（pki，ski）。</p>\n<p>我们用P = {pk1，。 。 。 ，pkT}表示所有公钥的集合。我们还假设每个实体都知道公共消息mp。消息mp可能是特定于应用场景的，并采取以下形式：我知道会话ID为XXXX的公钥的私钥。这个消息的目的是为了击败对该方案的某些已知攻击[26]。</p>\n</li>\n<li><p>多重签名协议：多重签名是签名者，聚合器和验证者之间的交互协议（参见图2的示意图）。该协议有六个步骤，如下所述。</p>\n<ol>\n<li><p>（一次性）身份设置：此步骤在每个参与者和验证者之间运行。在协议开始时，每个签名者Pi如果当前不涉及另一个签名协议，则在消息mp上生成EC-Schnorr签名σi。然后Pi将（σi，pki）发送给验证者。验证者然后执行以下检查：</p>\n<ul>\n<li>检查pki∈P.如果检查失败，检验器将中止。</li>\n<li>通过调用Verify（C，σi，pki，mp）来检查每个σi是否是pki上mp的有效EC-Schnorr签名。如果任何这些签名验证返回0，则验证程序中止。如果所有签名均有效，则协议进行到下一步。</li>\n</ul>\n<p>如果验证程序没有收到P中每个pki的σi，她也会中止。为了记录她是否收到来自Pi的签名，她使用位图Z [1，…。 。 。 ，| P |] .身份设置是一个一次性过程，随后是任意数量的下一步。只有在设置成功结束后，协议的后续步骤才能开始。</p>\n</li>\n<li><p>commitment 阶段：每个签名者Pi随后选择一个随机ki $←[1，n-1]并计算Qi = [ki] G。回想一下，G是椭圆曲线上的基点，n是G的阶数.Pi然后将Qi发送给聚合器。</p>\n</li>\n<li><p>Challenge 阶段：聚合器首先用P中的密钥计算聚合密钥。她还计算前一步骤中接收到的Qi的聚合。然后她计算r←H（Q || pk || m）mod n并将（r，Q，pk）发送给每个Pi</p>\n</li>\n<li><p>响应生成：每个签名者Pi首先检查之前收到的r的完整性。这是通过重新计算H（Q || pk || m）并检查它是否等于接收到的r来完成的。如果检查失败，则Pi会中止协议或者生成si←（ki -r·ski）mod n并将si发送给聚合器。</p>\n</li>\n<li><p>响应聚合：聚合器计算聚合响应s = Pi si mod n并建立聚合签名σ=（r，s）。然后，她将（m，σ）发送给验证者。</p>\n</li>\n<li><p>签名验证：Verifier现在检查签名是否有效。她执行以下步骤：</p>\n<ul>\n<li>将P中的公钥集中为pk0。</li>\n<li>通过调用，检查σ是否为m上公钥pk0的有效EC-Schnorr签名</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<p>有点难理解，以下比较偏好理解的角度来说。</p>\n<p>多重签名方案基本上分两步进行。在协议的第一步中，每个节点将其公钥发送给聚合者，聚合者根据公钥的数学形式，通过简单的加法或乘法将之聚合为一个单一的公钥。</p>\n<p>例如，聚合公钥= 公钥_1 + 公钥_2 + …+公钥_n。</p>\n<p>然后聚合者将聚合公钥转发给验证者从而可以使后者验证聚合签名，与此同时聚合者也将聚合公钥发送给每个签名者让所有人签名。</p>\n<p>在第二步中，聚合者启动与每个签名者的交互协议（interactive protocol）。这个交互协议总分包含三个阶段：</p>\n<p><strong>1、提交阶段（Commit phase）：</strong>此阶段每个节点生成一些随机内容并提交给交互协议。如果你不了解什么是加密提交（cryptographic commitment），那么可以通过这种类比的方式理解：每个节点都秘密地掷骰子，然后将结果写在一张纸上并将其放在一个盒子中锁好，最后发送给聚合者。聚合者无权打开盒子。</p>\n<p><strong>2、挑战阶段（Challenge phase）：</strong>此阶段聚合者首先使用加法或乘法将所有的提交聚合为一个聚合提交，然后使用它以及聚合公钥、消息生成一个挑战，再将挑战发送到所有节点。之后挑战可用于确认所有节点都知道公钥对应的私钥。这与常规数字签名的工作方式类似，即由签名证明签名人确实知道私钥。</p>\n<p><strong>3、回应阶段（Response phase）：</strong>所有节点为了应对挑战会向挑战发送私钥进行回应，之后聚合者将聚合所有的回应。因此回应可被视为签名者知道其公钥对应的私钥的证据。</p>\n<p>因此，最后的聚合签名实际上是挑战和聚合回应的信息对，并能验证第一步生成的聚合公钥。</p>\n<p>值得注意的是，聚合签名的大小不取决于签名者的数量，它是固定的。</p>\n<p>图中蓝色的节点是聚合者。H是用于将消息m生成挑战的密码散列函数。聚合签名就是R和S的信息对。R的大小等于Ri，S的大小等于Si的。仅在知道私钥的情况下才能生成有效的回应。</p>\n<p>当验证者检查聚合签名时，它检查的不是每个单独签名者是否都正确地遵守协议，而是检查所有签名者作为一个整体是否正确地遵守协议并知道私钥。因此，验证者做出的决定是全有或全无（all-or-nothing）。</p>\n"},{"title":"eth_code_tx_event","date":"2019-10-14T06:47:58.000Z","_content":"\n#### ApplyTransaction\n\n```\n// ApplyTransaction attempts to apply a transaction to the given state database\n// and uses the input parameters for its environment. It returns the receipt\n// for the transaction, gas used and an error if the transaction failed,\n// indicating the block was invalid.\n//应用交易到state database中\nfunc ApplyTransaction(config *params.ChainConfig, bc ChainContext, author *common.Address, gp *GasPool, statedb *state.StateDB, header *types.Header, tx *types.Transaction, usedGas *uint64, cfg vm.Config) (*types.Receipt, uint64, error) {\n\t//构造交易消息\n\tmsg, err := tx.AsMessage(types.MakeSigner(config, header.Number))\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\t//EVM进行交易处理，返回为处理结果、消耗gas、是否失败、err，logs是在evm处理时产生的\n\t// Create a new context to be used in the EVM environment\n\tcontext := NewEVMContext(msg, header, bc, author)\n\t// Create a new environment which holds all relevant information\n\t// about the transaction and calling mechanisms.\n\tvmenv := vm.NewEVM(context, statedb, config, cfg)\n\t// Apply the transaction to the current state (included in the env)\n\t_, gas, failed, err := ApplyMessage(vmenv, msg, gp)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\n\t//根据处理结果构建返回数据\n\t// Update the state with pending changes\n\tvar root []byte\n\tif config.IsByzantium(header.Number) {\n\t\tstatedb.Finalise(true)\n\t} else {\n\t\troot = statedb.IntermediateRoot(config.IsEIP158(header.Number)).Bytes()\n\t}\n\t*usedGas += gas\n\n\t// Create a new receipt for the transaction, storing the intermediate root and gas used by the tx\n\t// based on the eip phase, we're passing whether the root touch-delete accounts.\n\treceipt := types.NewReceipt(root, failed, *usedGas)\n\treceipt.TxHash = tx.Hash()\n\treceipt.GasUsed = gas\n\t// if the transaction created a contract, store the creation address in the receipt.\n\tif msg.To() == nil {\n\t\treceipt.ContractAddress = crypto.CreateAddress(vmenv.Context.Origin, tx.Nonce())\n\t}\n\t// Set the receipt logs and create a bloom for filtering\n\treceipt.Logs = statedb.GetLogs(tx.Hash())\n\treceipt.Bloom = types.CreateBloom(types.Receipts{receipt})\n\n\treturn receipt, gas, err\n}\n\n```\n\n\n\n```\nfunc (evm *EVM) Call(caller ContractRef, addr common.Address, input []byte, gas uint64, value *big.Int) (ret []byte, leftOverGas uint64, err error) {\n\tif evm.vmConfig.NoRecursion && evm.depth > 0 {\n\t\treturn nil, gas, nil\n\t}\n\n\t// Fail if we're trying to execute above the call depth limit\n\tif evm.depth > int(params.CallCreateDepth) {\n\t\treturn nil, gas, ErrDepth\n\t}\n\t// Fail if we're trying to transfer more than the available balance\n\tif !evm.Context.CanTransfer(evm.StateDB, caller.Address(), value) {\n\t\treturn nil, gas, ErrInsufficientBalance\n\t}\n\n\tvar (\n\t\tto       = AccountRef(addr)\n\t\tsnapshot = evm.StateDB.Snapshot()\n\t)\n\tif !evm.StateDB.Exist(addr) {\n\t\tprecompiles := PrecompiledContractsHomestead\n\t\tif evm.ChainConfig().IsByzantium(evm.BlockNumber) {\n\t\t\tprecompiles = PrecompiledContractsByzantium\n\t\t}\n\t\tif precompiles[addr] == nil && evm.ChainConfig().IsEIP158(evm.BlockNumber) && value.Sign() == 0 {\n\t\t\t// Calling a non existing account, don't do anything, but ping the tracer\n\t\t\tif evm.vmConfig.Debug && evm.depth == 0 {\n\t\t\t\tevm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value)\n\t\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, 0, 0, nil)\n\t\t\t}\n\t\t\treturn nil, gas, nil\n\t\t}\n\t\tevm.StateDB.CreateAccount(addr)\n\t}\n\tevm.Transfer(evm.StateDB, caller.Address(), to.Address(), value)\n\t// Initialise a new contract and set the code that is to be used by the EVM.\n\t// The contract is a scoped environment for this execution context only.\n\tcontract := NewContract(caller, to, value, gas)\n\tcontract.SetCallCode(&addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr))\n\n\t// Even if the account has no code, we need to continue because it might be a precompile\n\tstart := time.Now()\n\n\t// Capture the tracer start/end events in debug mode\n\tif evm.vmConfig.Debug && evm.depth == 0 {\n\t\tevm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value)\n\n\t\tdefer func() { // Lazy evaluation of the parameters\n\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, gas-contract.Gas, time.Since(start), err)\n\t\t}()\n\t}\n\tret, err = run(evm, contract, input, false)\n\n\t// When an error was returned by the EVM or when setting the creation code\n\t// above we revert to the snapshot and consume any gas remaining. Additionally\n\t// when we're in homestead this also counts for code storage gas errors.\n\tif err != nil {\n\t\tevm.StateDB.RevertToSnapshot(snapshot)\n\t\tif err != errExecutionReverted {\n\t\t\tcontract.UseGas(contract.Gas)\n\t\t}\n\t}\n\treturn ret, contract.Gas, err\n}\n```\n\n\n\n\n\n\n\n\n\n#### handleMsg\n\n处理接收到的消息码\n\n- ```\n  StatusMsg\n  ```\n\n  收到这个消息说明握手失败\n\n- ```\n  GetBlockHeadersMsg\n  ```\n\n  查询区块头请求，回复区块头信息\n\n  ```\n  BlockHeadersMsg\n  ```\n\n  区块头信息的回复\n\n- ```\n  GetBlockBodiesMsg\n  ```\n\n  查询区块请求\n\n  ```\n  BlockBodiesMsg\n  ```\n\n  区块请求查询的回复，\n\n- ```\n  GetNodeDataMsg\n  ```\n\n- ```\n  NodeDataMsg\n  ```\n\n- ```\n  GetReceiptsMsg\n  ```\n\n- ```\n  ReceiptsMsg\n  ```\n\n- ```\n  NewBlockHashesMsg\n  ```\n\n- ```\n  NewBlockMsg\n  ```\n\n- ```\n  TxMsg\n  ```\n\n\n\n#### Start\n\n这四个goroutine 基本上就在不停的做广播区块、广播交易，同步到区块、同步到交易，再广播区块、广播交易。\n\n- txBroadcastLoop\n\n  ```\n  func (self *ProtocolManager) txBroadcastLoop() {\n      for {\n          select {\n          case event := <-self.txCh:\n              self.BroadcastTx(event.Tx.Hash(), event.Tx)\n\n          // Err() channel will be closed when unsubscribing.\n          case <-self.txSub.Err():\n              return\n          }\n      }\n  }\n  ```\n\n  core/tx_pool.go 产生新的交易的时候会send self.txCh，这时候会激活\n  self.BroadcastTx(event.Tx.Hash(), event.Tx)\n\n  ```\n  func (pm *ProtocolManager) BroadcastTx(hash common.Hash, tx *types.Transaction) {\n      // Broadcast transaction to a batch of peers not knowing about it\n      peers := pm.peers.PeersWithoutTx(hash)\n      //FIXME include this again: peers = peers[:int(math.Sqrt(float64(len(peers))))]\n      for _, peer := range peers {\n          peer.SendTransactions(types.Transactions{tx})\n      }\n      log.Trace(\"Broadcast transaction\", \"hash\", hash, \"recipients\", len(peers))\n  }\n\n  ```\n\n  向缓存的没有这个交易hash的网络节点广播此次交易。\n\n- minedBroadcastLoop\n\n  收到miner.go 里面NewMinedBlockEvent 挖到新区块的事件通知，激活self.BroadcastBlock(ev.Block, true)\n\n  ```\n  // Mined broadcast loop\n  func (self *ProtocolManager) minedBroadcastLoop() {\n      // automatically stops if unsubscribe\n      for obj := range self.minedBlockSub.Chan() {\n          switch ev := obj.Data.(type) {\n          case core.NewMinedBlockEvent:\n              self.BroadcastBlock(ev.Block, true)  // First propagate block to peers\n              self.BroadcastBlock(ev.Block, false) // Only then announce to the rest\n          }\n      }\n  }\n\n  ```\n\n  ```\n  func (pm *ProtocolManager) BroadcastBlock(block *types.Block, propagate bool) {\n      hash := block.Hash()\n      peers := pm.peers.PeersWithoutBlock(hash)\n\n      // If propagation is requested, send to a subset of the peer\n      if propagate {\n          // Calculate the TD of the block (it's not imported yet, so block.Td is not valid)\n          var td *big.Int\n          if parent := pm.blockchain.GetBlock(block.ParentHash(), block.NumberU64()-1); parent != nil {\n              td = new(big.Int).Add(block.Difficulty(), pm.blockchain.GetTd(block.ParentHash(), block.NumberU64()-1))\n          } else {\n              log.Error(\"Propagating dangling block\", \"number\", block.Number(), \"hash\", hash)\n              return\n          }\n          // Send the block to a subset of our peers\n          transfer := peers[:int(math.Sqrt(float64(len(peers))))]\n          for _, peer := range transfer {\n              peer.SendNewBlock(block, td)\n          }\n          log.Trace(\"Propagated block\", \"hash\", hash, \"recipients\", len(transfer), \"duration\", common.PrettyDuration(time.Since(block.ReceivedAt)))\n          return\n      }\n      // Otherwise if the block is indeed in out own chain, announce it\n      if pm.blockchain.HasBlock(hash, block.NumberU64()) {\n          for _, peer := range peers {\n              peer.SendNewBlockHashes([]common.Hash{hash}, []uint64{block.NumberU64()})\n          }\n          log.Trace(\"Announced block\", \"hash\", hash, \"recipients\", len(peers), \"duration\", common.PrettyDuration(time.Since(block.ReceivedAt)))\n      }\n  }\n\n  ```\n\n  如果propagate为true 向网络节点广播整个挖到的block，为false 只广播挖到的区块的hash值和number值。广播的区块还包括这个区块打包的所有交易。\n\n- syncer\n\n  ```\n  func (pm *ProtocolManager) syncer() {\n      // Start and ensure cleanup of sync mechanisms\n      pm.fetcher.Start()\n      defer pm.fetcher.Stop()\n      defer pm.downloader.Terminate()\n\n      // Wait for different events to fire synchronisation operations\n      forceSync := time.NewTicker(forceSyncCycle)\n      defer forceSync.Stop()\n\n      for {\n          select {\n          case <-pm.newPeerCh:\n              // Make sure we have peers to select from, then sync\n              if pm.peers.Len() < minDesiredPeerCount {\n                  break\n              }\n              go pm.synchronise(pm.peers.BestPeer())\n\n          case <-forceSync.C:\n              // Force a sync even if not enough peers are present\n              go pm.synchronise(pm.peers.BestPeer())\n\n          case <-pm.noMorePeers:\n              return\n          }\n      }\n  }\n\n\n  ```\n\n  pm.fetcher.Start()启动 fetcher，辅助同步区块数据\n\n  当P2P server执行 ProtocolManager 的p2p.Protocol 的Run指针的时候会send pm.newPeerCh，这时候选择最优的网络节点（TD 总难度最大的）启动pm.synchronise(pm.peers.BestPeer()) goroutine。\n\n  ```\n  // synchronise tries to sync up our local block chain with a remote peer.\n  func (pm *ProtocolManager) synchronise(peer *peer) {\n      // Short circuit if no peers are available\n      if peer == nil {\n          return\n      }\n      // Make sure the peer's TD is higher than our own\n      currentBlock := pm.blockchain.CurrentBlock()\n      td := pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())\n\n      pHead, pTd := peer.Head()\n      if pTd.Cmp(td) <= 0 {\n          return\n      }\n      // Otherwise try to sync with the downloader\n      mode := downloader.FullSync\n      if atomic.LoadUint32(&pm.fastSync) == 1 {\n          // Fast sync was explicitly requested, and explicitly granted\n          mode = downloader.FastSync\n      } else if currentBlock.NumberU64() == 0 && pm.blockchain.CurrentFastBlock().NumberU64() > 0 {\n          // The database seems empty as the current block is the genesis. Yet the fast\n          // block is ahead, so fast sync was enabled for this node at a certain point.\n          // The only scenario where this can happen is if the user manually (or via a\n          // bad block) rolled back a fast sync node below the sync point. In this case\n          // however it's safe to reenable fast sync.\n          atomic.StoreUint32(&pm.fastSync, 1)\n          mode = downloader.FastSync\n      }\n      // Run the sync cycle, and disable fast sync if we've went past the pivot block\n      if err := pm.downloader.Synchronise(peer.id, pHead, pTd, mode); err != nil {\n          return\n      }\n      if atomic.LoadUint32(&pm.fastSync) == 1 {\n          log.Info(\"Fast sync complete, auto disabling\")\n          atomic.StoreUint32(&pm.fastSync, 0)\n      }\n      atomic.StoreUint32(&pm.acceptTxs, 1) // Mark initial sync done\n      if head := pm.blockchain.CurrentBlock(); head.NumberU64() > 0 {\n          // We've completed a sync cycle, notify all peers of new state. This path is\n          // essential in star-topology networks where a gateway node needs to notify\n          // all its out-of-date peers of the availability of a new block. This failure\n          // scenario will most often crop up in private and hackathon networks with\n          // degenerate connectivity, but it should be healthy for the mainnet too to\n          // more reliably update peers or the local TD state.\n          go pm.BroadcastBlock(head, false)\n      }\n  }\n\n\n  ```\n\n  如果最优的网络节点的TD值大于本地最新区块的TD值，调用pm.downloader.Synchronise(peer.id, pHead, pTd, mode)进行同步。同步完成后再屌用go pm.BroadcastBlock(head, false)，把自己最新的区块状态广播出去。\n\n- txsyncLoop\n\n  ```\n  func (pm *ProtocolManager) txsyncLoop() {\n      var (\n          pending = make(map[discover.NodeID]*txsync)\n          sending = false               // whether a send is active\n          pack    = new(txsync)         // the pack that is being sent\n          done    = make(chan error, 1) // result of the send\n      )\n\n      // send starts a sending a pack of transactions from the sync.\n      send := func(s *txsync) {\n          // Fill pack with transactions up to the target size.\n          size := common.StorageSize(0)\n          pack.p = s.p\n          pack.txs = pack.txs[:0]\n          for i := 0; i < len(s.txs) && size < txsyncPackSize; i++ {\n              pack.txs = append(pack.txs, s.txs[i])\n              size += s.txs[i].Size()\n          }\n          // Remove the transactions that will be sent.\n          s.txs = s.txs[:copy(s.txs, s.txs[len(pack.txs):])]\n          if len(s.txs) == 0 {\n              delete(pending, s.p.ID())\n          }\n          // Send the pack in the background.\n          s.p.Log().Trace(\"Sending batch of transactions\", \"count\", len(pack.txs), \"bytes\", size)\n          sending = true\n          go func() { done <- pack.p.SendTransactions(pack.txs) }()\n      }\n\n      // pick chooses the next pending sync.\n      pick := func() *txsync {\n          if len(pending) == 0 {\n              return nil\n          }\n          n := rand.Intn(len(pending)) + 1\n          for _, s := range pending {\n              if n--; n == 0 {\n                  return s\n              }\n          }\n          return nil\n      }\n\n      for {\n          select {\n          case s := <-pm.txsyncCh:\n              pending[s.p.ID()] = s\n              if !sending {\n                  send(s)\n              }\n          case err := <-done:\n              sending = false\n              // Stop tracking peers that cause send failures.\n              if err != nil {\n                  pack.p.Log().Debug(\"Transaction send failed\", \"err\", err)\n                  delete(pending, pack.p.ID())\n              }\n              // Schedule the next send.\n              if s := pick(); s != nil {\n                  send(s)\n              }\n          case <-pm.quitSync:\n              return\n          }\n      }\n  }\n\n  ```\n\n  当从网络节点同步过来最新的交易数据后，本地也会把新同步下来的交易数据广播给网络中的其他节点。\n\n\n\n#### fetch\n\nfetcher是用来辅助同步区块数据的，记录各个区块头和区块体的同步状态，但它并不做真正下载区块数据的事情，下载的事情交由downloader来做。那fetcher具体是怎么工作的呢？\n我们先看看pm.handleMsg 在收到 NewBlockHashesMsg广播通知的处理代码：\n\n```\ncase msg.Code == NewBlockHashesMsg:\n        var announces newBlockHashesData\n        if err := msg.Decode(&announces); err != nil {\n            return errResp(ErrDecode, \"%v: %v\", msg, err)\n        }\n        // Mark the hashes as present at the remote node\n        for _, block := range announces {\n            p.MarkBlock(block.Hash)\n        }\n        // Schedule all the unknown hashes for retrieval\n        unknown := make(newBlockHashesData, 0, len(announces))\n        for _, block := range announces {\n            if !pm.blockchain.HasBlock(block.Hash, block.Number) {\n                unknown = append(unknown, block)\n            }\n        }\n        for _, block := range unknown {\n            pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)\n        }\n\n\n```\n\n从广播通知里会获取到一个newBlockHashesData的列表。newBlockHashesData只包括block的hash值和block的number值。\n然后每个newBlockHashesData调用pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)方法，除了传入block的hash值和block的number值，还需要传入当前的时间戳，peer.go的两个函数指针。\n\n```\nfunc (f *Fetcher) Notify(peer string, hash common.Hash, number uint64, time time.Time,\n    headerFetcher headerRequesterFn, bodyFetcher bodyRequesterFn) error {\n    block := &announce{\n        hash:        hash,\n        number:      number,\n        time:        time,\n        origin:      peer,\n        fetchHeader: headerFetcher,\n        fetchBodies: bodyFetcher,\n    }\n    select {\n    case f.notify <- block:\n        return nil\n    case <-f.quit:\n        return errTerminated\n    }\n}\n\n\n```\n\nNotify()方法把传进来的参数拼成一个announce对象，然后send给f.notify。fetcher的loop()主回路里f.notify receive 到这个notification, 进行处理。\n\n```\ncase notification := <-f.notify:\n            // A block was announced, make sure the peer isn't DOSing us\n            propAnnounceInMeter.Mark(1)\n\n            count := f.announces[notification.origin] + 1\n            if count > hashLimit {\n                log.Debug(\"Peer exceeded outstanding announces\", \"peer\", notification.origin, \"limit\", hashLimit)\n                propAnnounceDOSMeter.Mark(1)\n                break\n            }\n            // If we have a valid block number, check that it's potentially useful\n            if notification.number > 0 {\n                if dist := int64(notification.number) - int64(f.chainHeight()); dist < -maxUncleDist || dist > maxQueueDist {\n                    log.Debug(\"Peer discarded announcement\", \"peer\", notification.origin, \"number\", notification.number, \"hash\", notification.hash, \"distance\", dist)\n                    propAnnounceDropMeter.Mark(1)\n                    break\n                }\n            }\n            // All is well, schedule the announce if block's not yet downloading\n            if _, ok := f.fetching[notification.hash]; ok {\n                break\n            }\n            if _, ok := f.completing[notification.hash]; ok {\n                break\n            }\n            f.announces[notification.origin] = count\n            f.announced[notification.hash] = append(f.announced[notification.hash], notification)\n            if f.announceChangeHook != nil && len(f.announced[notification.hash]) == 1 {\n                f.announceChangeHook(notification.hash, true)\n            }\n            if len(f.announced) == 1 {\n                f.rescheduleFetch(fetchTimer)\n            }\n\n\n```\n\n1，将收到的不满足条件的通知都丢弃掉，如果在f.fetching 状态列表里和f.completing 状态列表里，也直接返回。接着更新notification.origin 这个节点的announces 数量，添加到f.announced 等待fetch的表里。\n2，如果len(f.announced[notification.hash]) == 1 说明f.announced只有这一个通知，则调用f.announceChangeHook。\n3，如果len(f.announced) == 1 也说明只有一个通知，则启动fetchTimer的调度。\n\n```\ncase <-fetchTimer.C:\n            // At least one block's timer ran out, check for needing retrieval\n            request := make(map[string][]common.Hash)\n\n            for hash, announces := range f.announced {\n                if time.Since(announces[0].time) > arriveTimeout-gatherSlack {\n                    // Pick a random peer to retrieve from, reset all others\n                    announce := announces[rand.Intn(len(announces))]\n                    f.forgetHash(hash)\n\n                    // If the block still didn't arrive, queue for fetching\n                    if f.getBlock(hash) == nil {\n                        request[announce.origin] = append(request[announce.origin], hash)\n                        f.fetching[hash] = announce\n                    }\n                }\n            }\n            // Send out all block header requests\n            for peer, hashes := range request {\n                log.Trace(\"Fetching scheduled headers\", \"peer\", peer, \"list\", hashes)\n\n                // Create a closure of the fetch and schedule in on a new thread\n                fetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes\n                go func() {\n                    if f.fetchingHook != nil {\n                        f.fetchingHook(hashes)\n                    }\n                    for _, hash := range hashes {\n                        headerFetchMeter.Mark(1)\n                        fetchHeader(hash) // Suboptimal, but protocol doesn't allow batch header retrievals\n                    }\n                }()\n            }\n            // Schedule the next fetch if blocks are still pending\n            f.rescheduleFetch(fetchTimer)\n\n\n```\n\n1，首先遍历f.announced，如果超过了arriveTimeout-gatherSlack这个时间，把这个hash对应在fetcher里面的状态都清了。\n这里随机拿这个announces里面任意一个announce，为啥随机取一个呢？因为都是同一个block的hash，这个hash下的哪一个announce都是一样的。\n如果发现超时了还没有没有获取到这个hash的block，则把这个announce加到request列表中，同时重新把announce放到f.fetching状态列表。\n2，然后遍历request列表，request列表里面的每个网络节点过来的所有的block的hash，都会调用fetchHeader(hash)方法来获取header数据。\n这个fetchHeader(hash)方法是pm.fetcher.Notify传进来的，peer.go\n里面的一个全局方法。\n3， 这时候NewBlockHashesMsg 的fetcher处理就结束了，最后再启动fetchTimer的调度。\n\n三，Fetcher分析， 之FilterHeaders()\nfetchHeader(hash)方法，调用了peer.go 里面的全局方法RequestOneHeader(hash common.Hash)  Send给网络节点一个GetBlockHeadersMsg 消息。\n然后pm.handleMsg 收到 BlockHashesMsg广播通知\n\n```\ncase msg.Code == BlockHeadersMsg:\n        // A batch of headers arrived to one of our previous requests\n        var headers []*types.Header\n        if err := msg.Decode(&headers); err != nil {\n            return errResp(ErrDecode, \"msg %v: %v\", msg, err)\n        }\n        // If no headers were received, but we're expending a DAO fork check, maybe it's that\n        if len(headers) == 0 && p.forkDrop != nil {\n            // Possibly an empty reply to the fork header checks, sanity check TDs\n            verifyDAO := true\n\n            // If we already have a DAO header, we can check the peer's TD against it. If\n            // the peer's ahead of this, it too must have a reply to the DAO check\n            if daoHeader := pm.blockchain.GetHeaderByNumber(pm.chainconfig.DAOForkBlock.Uint64()); daoHeader != nil {\n                if _, td := p.Head(); td.Cmp(pm.blockchain.GetTd(daoHeader.Hash(), daoHeader.Number.Uint64())) >= 0 {\n                    verifyDAO = false\n                }\n            }\n            // If we're seemingly on the same chain, disable the drop timer\n            if verifyDAO {\n                p.Log().Debug(\"Seems to be on the same side of the DAO fork\")\n                p.forkDrop.Stop()\n                p.forkDrop = nil\n                return nil\n            }\n        }\n        // Filter out any explicitly requested headers, deliver the rest to the downloader\n        filter := len(headers) == 1\n        if filter {\n            // If it's a potential DAO fork check, validate against the rules\n            if p.forkDrop != nil && pm.chainconfig.DAOForkBlock.Cmp(headers[0].Number) == 0 {\n                // Disable the fork drop timer\n                p.forkDrop.Stop()\n                p.forkDrop = nil\n\n                // Validate the header and either drop the peer or continue\n                if err := misc.VerifyDAOHeaderExtraData(pm.chainconfig, headers[0]); err != nil {\n                    p.Log().Debug(\"Verified to be on the other side of the DAO fork, dropping\")\n                    return err\n                }\n                p.Log().Debug(\"Verified to be on the same side of the DAO fork\")\n                return nil\n            }\n            // Irrelevant of the fork checks, send the header to the fetcher just in case\n            headers = pm.fetcher.FilterHeaders(p.id, headers, time.Now())\n        }\n        if len(headers) > 0 || !filter {\n            err := pm.downloader.DeliverHeaders(p.id, headers)\n            if err != nil {\n                log.Debug(\"Failed to deliver headers\", \"err\", err)\n            }\n        }\n\n\n```\n\n如果不是硬分叉的daoHeader，同时len(headers) == 1，则执行pm.fetcher.FilterHeaders(p.id, headers, time.Now())方法\n\n```\nfunc (f *Fetcher) FilterHeaders(peer string, headers []*types.Header, time time.Time) []*types.Header {\n    log.Trace(\"Filtering headers\", \"peer\", peer, \"headers\", len(headers))\n\n    // Send the filter channel to the fetcher\n    filter := make(chan *headerFilterTask)\n\n    select {\n    case f.headerFilter <- filter:\n    case <-f.quit:\n        return nil\n    }\n    // Request the filtering of the header list\n    select {\n    case filter <- &headerFilterTask{peer: peer, headers: headers, time: time}:\n    case <-f.quit:\n        return nil\n    }\n    // Retrieve the headers remaining after filtering\n    select {\n    case task := <-filter:\n        return task.headers\n    case <-f.quit:\n        return nil\n    }\n}\n\n\n```\n\nsend 一个filter 到f.headerFilter，fetcher的loop()主回路里f.headerFilter receive 到这个filter，进行处理。\n\n```\ncase filter := <-f.headerFilter:\n            // Headers arrived from a remote peer. Extract those that were explicitly\n            // requested by the fetcher, and return everything else so it's delivered\n            // to other parts of the system.\n            var task *headerFilterTask\n            select {\n            case task = <-filter:\n            case <-f.quit:\n                return\n            }\n            headerFilterInMeter.Mark(int64(len(task.headers)))\n\n            // Split the batch of headers into unknown ones (to return to the caller),\n            // known incomplete ones (requiring body retrievals) and completed blocks.\n            unknown, incomplete, complete := []*types.Header{}, []*announce{}, []*types.Block{}\n            for _, header := range task.headers {\n                hash := header.Hash()\n\n                // Filter fetcher-requested headers from other synchronisation algorithms\n                if announce := f.fetching[hash]; announce != nil && announce.origin == task.peer && f.fetched[hash] == nil && f.completing[hash] == nil && f.queued[hash] == nil {\n                    // If the delivered header does not match the promised number, drop the announcer\n                    if header.Number.Uint64() != announce.number {\n                        log.Trace(\"Invalid block number fetched\", \"peer\", announce.origin, \"hash\", header.Hash(), \"announced\", announce.number, \"provided\", header.Number)\n                        f.dropPeer(announce.origin)\n                        f.forgetHash(hash)\n                        continue\n                    }\n                    // Only keep if not imported by other means\n                    if f.getBlock(hash) == nil {\n                        announce.header = header\n                        announce.time = task.time\n\n                        // If the block is empty (header only), short circuit into the final import queue\n                        if header.TxHash == types.DeriveSha(types.Transactions{}) && header.UncleHash == types.CalcUncleHash([]*types.Header{}) {\n                            log.Trace(\"Block empty, skipping body retrieval\", \"peer\", announce.origin, \"number\", header.Number, \"hash\", header.Hash())\n\n                            block := types.NewBlockWithHeader(header)\n                            block.ReceivedAt = task.time\n\n                            complete = append(complete, block)\n                            f.completing[hash] = announce\n                            continue\n                        }\n                        // Otherwise add to the list of blocks needing completion\n                        incomplete = append(incomplete, announce)\n                    } else {\n                        log.Trace(\"Block already imported, discarding header\", \"peer\", announce.origin, \"number\", header.Number, \"hash\", header.Hash())\n                        f.forgetHash(hash)\n                    }\n                } else {\n                    // Fetcher doesn't know about it, add to the return list\n                    unknown = append(unknown, header)\n                }\n            }\n            headerFilterOutMeter.Mark(int64(len(unknown)))\n            select {\n            case filter <- &headerFilterTask{headers: unknown, time: task.time}:\n            case <-f.quit:\n                return\n            }\n            // Schedule the retrieved headers for body completion\n            for _, announce := range incomplete {\n                hash := announce.header.Hash()\n                if _, ok := f.completing[hash]; ok {\n                    continue\n                }\n                f.fetched[hash] = append(f.fetched[hash], announce)\n                if len(f.fetched) == 1 {\n                    f.rescheduleComplete(completeTimer)\n                }\n            }\n            // Schedule the header-only blocks for import\n            for _, block := range complete {\n                if announce := f.completing[block.Hash()]; announce != nil {\n                    f.enqueue(announce.origin, block)\n                }\n            }\n\n\n```\n\n1，遍历headerFilter里面的各个header，如果在 f.fetching状态列表，且不在f.fetched状态列表和 f.completing状态列表，就继续进行过滤，否则塞进unknown队列 发送给filter，FilterHeaders里面task 接收到filter，并作为FilterHeaders的返回值返回。\n2，如果发现这个header的number和从f.fetching状态列表取到的announce的number不一样，说明有可能收到一个伪造的区块通知，此时就要把这个可能的伪造节点和可能的伪造的hash抛弃，另可错杀，不能放过。\n3，如果本节点已经有这个hash的block，则放弃这个hash。如果这个block里面没有任何交易也没有任何叔区块，则把这个hash放入complete列表同时加入f.completing状态列表，否则放入incomplete列表。\n4，在incomplete列表里面，且不在f.completing状态列表里，则加入f.fetched状态列表，启动completeTimer的调度。\n5，在complete列表里面，同时也在f.completing状态列表，则调用f.enqueue(announce.origin, block)方法。\n\n```\ncase <-completeTimer.C:\n            // At least one header's timer ran out, retrieve everything\n            request := make(map[string][]common.Hash)\n\n            for hash, announces := range f.fetched {\n                // Pick a random peer to retrieve from, reset all others\n                announce := announces[rand.Intn(len(announces))]\n                f.forgetHash(hash)\n\n                // If the block still didn't arrive, queue for completion\n                if f.getBlock(hash) == nil {\n                    request[announce.origin] = append(request[announce.origin], hash)\n                    f.completing[hash] = announce\n                }\n            }\n            // Send out all block body requests\n            for peer, hashes := range request {\n                log.Trace(\"Fetching scheduled bodies\", \"peer\", peer, \"list\", hashes)\n\n                // Create a closure of the fetch and schedule in on a new thread\n                if f.completingHook != nil {\n                    f.completingHook(hashes)\n                }\n                bodyFetchMeter.Mark(int64(len(hashes)))\n                go f.completing[hashes[0]].fetchBodies(hashes)\n            }\n            // Schedule the next fetch if blocks are still pending\n            f.rescheduleComplete(completeTimer)\n\n```\n\n1，首先遍历f.fetched，hash对应在fetcher里面的状态都清了。\n如果发现超时了还没有没有获取到这个hash的block，则把这个announce加到request列表中，同时重新把announce放到f.completing状态列表。\n2，然后遍历request列表，request列表里面的每个网络节点过来的所有的block的hash，都会调用fetchBodies(hashes)方法来获取区块body数据。这个fetchBodies(hashes)方法是peer.go里面的一个全局方法。\n3， 这时候BlockHashesMsg 的fetcher处理就结束了，最后再启动completeTimer循环调度。\n\n四，Fetcher分析， 之FilterBodies() ，Enqueue(），\n1，fetchBodies(hash)方法，调用了peer.go 里面的全局方法RequestBodies(hashes []common.Hash) Send给网络节点一个GetBlockBodiesMsg 消息。\n2，然后pm.handleMsg 会收到 BlockBodiesMsg广播通知。\n3，执行 pm.fetcher.FilterBodies(p.id, trasactions, uncles, time.Now())。\n接下来就和FilterHeaders()流程类似，一顿啪啪啪验证，一顿啪啪啪改变状态，一顿啪啪啪通道跳转\n4，庆幸的是，走完FilterBodies()就完事了，不用在走timer调度，也不用再发网络请求了。\n5，在FilterHeaders()和FilterBodies()最后都走到了f.enqueue(announce.origin, block)方法\n\n```\nfunc (f *Fetcher) enqueue(peer string, block *types.Block) {\n    hash := block.Hash()\n\n    // Ensure the peer isn't DOSing us\n    count := f.queues[peer] + 1\n    if count > blockLimit {\n        log.Debug(\"Discarded propagated block, exceeded allowance\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"limit\", blockLimit)\n        propBroadcastDOSMeter.Mark(1)\n        f.forgetHash(hash)\n        return\n    }\n    // Discard any past or too distant blocks\n    if dist := int64(block.NumberU64()) - int64(f.chainHeight()); dist < -maxUncleDist || dist > maxQueueDist {\n        log.Debug(\"Discarded propagated block, too far away\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"distance\", dist)\n        propBroadcastDropMeter.Mark(1)\n        f.forgetHash(hash)\n        return\n    }\n    // Schedule the block for future importing\n    if _, ok := f.queued[hash]; !ok {\n        op := &inject{\n            origin: peer,\n            block:  block,\n        }\n        f.queues[peer] = count\n        f.queued[hash] = op\n        f.queue.Push(op, -float32(block.NumberU64()))\n        if f.queueChangeHook != nil {\n            f.queueChangeHook(op.block.Hash(), true)\n        }\n        log.Debug(\"Queued propagated block\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"queued\", f.queue.Size())\n    }\n}\n\n```\n\n过滤掉太远的区块。并把hash加入到f.queue列表中。\n在loop主回路里面遍历f.queue列表，并把列表中的block insert到本地的block chain中。\n\n```\nfunc (f *Fetcher) insert(peer string, block *types.Block) {\n    hash := block.Hash()\n\n    // Run the import on a new thread\n    log.Debug(\"Importing propagated block\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash)\n    go func() {\n        defer func() { f.done <- hash }()\n\n        // If the parent's unknown, abort insertion\n        parent := f.getBlock(block.ParentHash())\n        if parent == nil {\n            log.Debug(\"Unknown parent of propagated block\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"parent\", block.ParentHash())\n            return\n        }\n        // Quickly validate the header and propagate the block if it passes\n        switch err := f.verifyHeader(block.Header()); err {\n        case nil:\n            // All ok, quickly propagate to our peers\n            propBroadcastOutTimer.UpdateSince(block.ReceivedAt)\n            go f.broadcastBlock(block, true)\n\n        case consensus.ErrFutureBlock:\n            // Weird future block, don't fail, but neither propagate\n\n        default:\n            // Something went very wrong, drop the peer\n            log.Debug(\"Propagated block verification failed\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"err\", err)\n            f.dropPeer(peer)\n            return\n        }\n        // Run the actual import and log any issues\n        if _, err := f.insertChain(types.Blocks{block}); err != nil {\n            log.Debug(\"Propagated block import failed\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"err\", err)\n            return\n        }\n        // If import succeeded, broadcast the block\n        propAnnounceOutTimer.UpdateSince(block.ReceivedAt)\n        go f.broadcastBlock(block, false)\n\n        // Invoke the testing hook if needed\n        if f.importedHook != nil {\n            f.importedHook(block)\n        }\n    }()\n}\n\n\n```\n\n首先调用共识引擎的方法f.verifyHeader(block.Header())，验证blockHeader的有效性。\n如果没问题就广播出去，告诉全世界我的区块链更新了一个新区块。\n然后调用f.insertChain(types.Blocks{block}) 插入本地区块链。\n插入成功，最后再广播一次(这是多么的自恋啊)，这次只广播block的hash。\n\n总结\nfetcher.go 作为以太坊同步区块的一个辅助类，它的职责就是层层把关，层层过滤，抵制无效的区块进入，杜绝无用的同步请求。这块代码很多很乱，第一次看可能会有点晕，第二次看可能还是很晕，多看几次可能还会晕😄，不过只要知道它做什么就好了。\n\n\n\n\n\n#### Downloader\n\n一，启动Downloader\nProtocolManager初始化的时候会进行Downloader的初始化：\n\n```\nfunc New(mode SyncMode, stateDb ethdb.Database, mux *event.TypeMux, chain BlockChain, lightchain LightChain, dropPeer peerDropFn) *Downloader {\n    if lightchain == nil {\n        lightchain = chain\n    }\n\n    dl := &Downloader{\n        mode:           mode,\n        stateDB:        stateDb,\n        mux:            mux,\n        queue:          newQueue(),\n        peers:          newPeerSet(),\n        rttEstimate:    uint64(rttMaxEstimate),\n        rttConfidence:  uint64(1000000),\n        blockchain:     chain,\n        lightchain:     lightchain,\n        dropPeer:       dropPeer,\n        headerCh:       make(chan dataPack, 1),\n        bodyCh:         make(chan dataPack, 1),\n        receiptCh:      make(chan dataPack, 1),\n        bodyWakeCh:     make(chan bool, 1),\n        receiptWakeCh:  make(chan bool, 1),\n        headerProcCh:   make(chan []*types.Header, 1),\n        quitCh:         make(chan struct{}),\n        stateCh:        make(chan dataPack),\n        stateSyncStart: make(chan *stateSync),\n        trackStateReq:  make(chan *stateReq),\n    }\n    go dl.qosTuner()\n    go dl.stateFetcher()\n    return dl\n}\n\n```\n\n首先初始化Downloader对象的成员，然后启动dl.qosTuner() goroutine计算请求回路时间，启动dl.stateFetcher() goroutine 开启Downloader状态监控。\n\nProtocolManager收到新的区块消息广播或者有新的P2P网络节点加入的时候会调用ProtocolManager的 synchronise(peer *peer)方法，这时候会调用Downloader的Synchronise(peer.id, pHead, pTd, mode)方法。\n\nSynchronise方法，重置d.queue和d.peers，清空d.bodyWakeCh, d.receiptWakeCh，d.headerCh, d.bodyCh, d.receiptCh，d.headerProcCh。调用d.syncWithPeer(p, hash, td)方法：\n\n```\nfunc (d *Downloader) syncWithPeer(p *peerConnection, hash common.Hash, td *big.Int) (err error) {\n    d.mux.Post(StartEvent{})\n    defer func() {\n        // reset on error\n        if err != nil {\n            d.mux.Post(FailedEvent{err})\n        } else {\n            d.mux.Post(DoneEvent{})\n        }\n    }()\n    if p.version < 62 {\n        return errTooOld\n    }\n\n    log.Debug(\"Synchronising with the network\", \"peer\", p.id, \"eth\", p.version, \"head\", hash, \"td\", td, \"mode\", d.mode)\n    defer func(start time.Time) {\n        log.Debug(\"Synchronisation terminated\", \"elapsed\", time.Since(start))\n    }(time.Now())\n\n    // Look up the sync boundaries: the common ancestor and the target block\n    latest, err := d.fetchHeight(p)\n    if err != nil {\n        return err\n    }\n    height := latest.Number.Uint64()\n\n    origin, err := d.findAncestor(p, height)\n    if err != nil {\n        return err\n    }\n    d.syncStatsLock.Lock()\n    if d.syncStatsChainHeight <= origin || d.syncStatsChainOrigin > origin {\n        d.syncStatsChainOrigin = origin\n    }\n    d.syncStatsChainHeight = height\n    d.syncStatsLock.Unlock()\n\n    // Ensure our origin point is below any fast sync pivot point\n    pivot := uint64(0)\n    if d.mode == FastSync {\n        if height <= uint64(fsMinFullBlocks) {\n            origin = 0\n        } else {\n            pivot = height - uint64(fsMinFullBlocks)\n            if pivot <= origin {\n                origin = pivot - 1\n            }\n        }\n    }\n    d.committed = 1\n    if d.mode == FastSync && pivot != 0 {\n        d.committed = 0\n    }\n    // Initiate the sync using a concurrent header and content retrieval algorithm\n    d.queue.Prepare(origin+1, d.mode)\n    if d.syncInitHook != nil {\n        d.syncInitHook(origin, height)\n    }\n\n    fetchers := []func() error{\n        func() error { return d.fetchHeaders(p, origin+1, pivot) }, // Headers are always retrieved\n        func() error { return d.fetchBodies(origin + 1) },          // Bodies are retrieved during normal and fast sync\n        func() error { return d.fetchReceipts(origin + 1) },        // Receipts are retrieved during fast sync\n        func() error { return d.processHeaders(origin+1, pivot, td) },\n    }\n    if d.mode == FastSync {\n        fetchers = append(fetchers, func() error { return d.processFastSyncContent(latest) })\n    } else if d.mode == FullSync {\n        fetchers = append(fetchers, d.processFullSyncContent)\n    }\n    return d.spawnSync(fetchers)\n}\n\n```\n\n首先调用latest, err := d.fetchHeight(p)获取到peer节点最新的区块头,这个方法有点绕，我们来分析一下：\n\n```\nfunc (d *Downloader) fetchHeight(p *peerConnection) (*types.Header, error) {\n    p.log.Debug(\"Retrieving remote chain height\")\n\n    // Request the advertised remote head block and wait for the response\n    head, _ := p.peer.Head()\n    go p.peer.RequestHeadersByHash(head, 1, 0, false)\n\n    ttl := d.requestTTL()\n    timeout := time.After(ttl)\n    for {\n        select {\n        case <-d.cancelCh:\n            return nil, errCancelBlockFetch\n\n        case packet := <-d.headerCh:\n            // Discard anything not from the origin peer\n            if packet.PeerId() != p.id {\n                log.Debug(\"Received headers from incorrect peer\", \"peer\", packet.PeerId())\n                break\n            }\n            // Make sure the peer actually gave something valid\n            headers := packet.(*headerPack).headers\n            if len(headers) != 1 {\n                p.log.Debug(\"Multiple headers for single request\", \"headers\", len(headers))\n                return nil, errBadPeer\n            }\n            head := headers[0]\n            p.log.Debug(\"Remote head header identified\", \"number\", head.Number, \"hash\", head.Hash())\n            return head, nil\n\n        case <-timeout:\n            p.log.Debug(\"Waiting for head header timed out\", \"elapsed\", ttl)\n            return nil, errTimeout\n\n        case <-d.bodyCh:\n        case <-d.receiptCh:\n            // Out of bounds delivery, ignore\n        }\n    }\n}\n\n\n```\n\n1，调用peer.RequestHeadersByHash(head, 1, 0, false)，给网络节点发送一个GetBlockHeadersMsg的消息\n2，然后阻塞住线程，直到收到d.headerCh或者timeout\n3，本地节点会收到网络节点的BlockHeadersMsg的消息返回\n4，调用downloader.DeliverHeaders(p.id, headers)\n5，这时候会把p.id和headers打包发送给d.headerCh\n6，这时候select收到d.headerCh，阻塞打开，并返回header内容\n\nsyncWithPeer() 方法接着调用 d.findAncestor(p, height)来获取本地节点和网络节点共同的祖先：\n\n```\nfunc (d *Downloader) findAncestor(p *peerConnection, height uint64) (uint64, error) {\n    // Figure out the valid ancestor range to prevent rewrite attacks\n    floor, ceil := int64(-1), d.lightchain.CurrentHeader().Number.Uint64()\n\n    if d.mode == FullSync {\n        ceil = d.blockchain.CurrentBlock().NumberU64()\n    } else if d.mode == FastSync {\n        ceil = d.blockchain.CurrentFastBlock().NumberU64()\n    }\n    if ceil >= MaxForkAncestry {\n        floor = int64(ceil - MaxForkAncestry)\n    }\n    p.log.Debug(\"Looking for common ancestor\", \"local\", ceil, \"remote\", height)\n\n    // Request the topmost blocks to short circuit binary ancestor lookup\n    head := ceil\n    if head > height {\n        head = height\n    }\n    from := int64(head) - int64(MaxHeaderFetch)\n    if from < 0 {\n        from = 0\n    }\n    // Span out with 15 block gaps into the future to catch bad head reports\n    limit := 2 * MaxHeaderFetch / 16\n    count := 1 + int((int64(ceil)-from)/16)\n    if count > limit {\n        count = limit\n    }\n    go p.peer.RequestHeadersByNumber(uint64(from), count, 15, false)\n\n    // Wait for the remote response to the head fetch\n    number, hash := uint64(0), common.Hash{}\n\n    ttl := d.requestTTL()\n    timeout := time.After(ttl)\n\n    for finished := false; !finished; {\n        select {\n        case <-d.cancelCh:\n            return 0, errCancelHeaderFetch\n\n        case packet := <-d.headerCh:\n            // Discard anything not from the origin peer\n            if packet.PeerId() != p.id {\n                log.Debug(\"Received headers from incorrect peer\", \"peer\", packet.PeerId())\n                break\n            }\n            // Make sure the peer actually gave something valid\n            headers := packet.(*headerPack).headers\n            if len(headers) == 0 {\n                p.log.Warn(\"Empty head header set\")\n                return 0, errEmptyHeaderSet\n            }\n            // Make sure the peer's reply conforms to the request\n            for i := 0; i < len(headers); i++ {\n                if number := headers[i].Number.Int64(); number != from+int64(i)*16 {\n                    p.log.Warn(\"Head headers broke chain ordering\", \"index\", i, \"requested\", from+int64(i)*16, \"received\", number)\n                    return 0, errInvalidChain\n                }\n            }\n            // Check if a common ancestor was found\n            finished = true\n            for i := len(headers) - 1; i >= 0; i-- {\n                // Skip any headers that underflow/overflow our requested set\n                if headers[i].Number.Int64() < from || headers[i].Number.Uint64() > ceil {\n                    continue\n                }\n                // Otherwise check if we already know the header or not\n                if (d.mode == FullSync && d.blockchain.HasBlock(headers[i].Hash(), headers[i].Number.Uint64())) || (d.mode != FullSync && d.lightchain.HasHeader(headers[i].Hash(), headers[i].Number.Uint64())) {\n                    number, hash = headers[i].Number.Uint64(), headers[i].Hash()\n\n                    // If every header is known, even future ones, the peer straight out lied about its head\n                    if number > height && i == limit-1 {\n                        p.log.Warn(\"Lied about chain head\", \"reported\", height, \"found\", number)\n                        return 0, errStallingPeer\n                    }\n                    break\n                }\n            }\n\n        case <-timeout:\n            p.log.Debug(\"Waiting for head header timed out\", \"elapsed\", ttl)\n            return 0, errTimeout\n\n        case <-d.bodyCh:\n        case <-d.receiptCh:\n            // Out of bounds delivery, ignore\n        }\n    }\n    // If the head fetch already found an ancestor, return\n    if !common.EmptyHash(hash) {\n        if int64(number) <= floor {\n            p.log.Warn(\"Ancestor below allowance\", \"number\", number, \"hash\", hash, \"allowance\", floor)\n            return 0, errInvalidAncestor\n        }\n        p.log.Debug(\"Found common ancestor\", \"number\", number, \"hash\", hash)\n        return number, nil\n    }\n    // Ancestor not found, we need to binary search over our chain\n    start, end := uint64(0), head\n    if floor > 0 {\n        start = uint64(floor)\n    }\n    for start+1 < end {\n        // Split our chain interval in two, and request the hash to cross check\n        check := (start + end) / 2\n\n        ttl := d.requestTTL()\n        timeout := time.After(ttl)\n\n        go p.peer.RequestHeadersByNumber(check, 1, 0, false)\n\n        // Wait until a reply arrives to this request\n        for arrived := false; !arrived; {\n            select {\n            case <-d.cancelCh:\n                return 0, errCancelHeaderFetch\n\n            case packer := <-d.headerCh:\n                // Discard anything not from the origin peer\n                if packer.PeerId() != p.id {\n                    log.Debug(\"Received headers from incorrect peer\", \"peer\", packer.PeerId())\n                    break\n                }\n                // Make sure the peer actually gave something valid\n                headers := packer.(*headerPack).headers\n                if len(headers) != 1 {\n                    p.log.Debug(\"Multiple headers for single request\", \"headers\", len(headers))\n                    return 0, errBadPeer\n                }\n                arrived = true\n\n                // Modify the search interval based on the response\n                if (d.mode == FullSync && !d.blockchain.HasBlock(headers[0].Hash(), headers[0].Number.Uint64())) || (d.mode != FullSync && !d.lightchain.HasHeader(headers[0].Hash(), headers[0].Number.Uint64())) {\n                    end = check\n                    break\n                }\n                header := d.lightchain.GetHeaderByHash(headers[0].Hash()) // Independent of sync mode, header surely exists\n                if header.Number.Uint64() != check {\n                    p.log.Debug(\"Received non requested header\", \"number\", header.Number, \"hash\", header.Hash(), \"request\", check)\n                    return 0, errBadPeer\n                }\n                start = check\n\n            case <-timeout:\n                p.log.Debug(\"Waiting for search header timed out\", \"elapsed\", ttl)\n                return 0, errTimeout\n\n            case <-d.bodyCh:\n            case <-d.receiptCh:\n                // Out of bounds delivery, ignore\n            }\n        }\n    }\n    // Ensure valid ancestry and return\n    if int64(start) <= floor {\n        p.log.Warn(\"Ancestor below allowance\", \"number\", start, \"hash\", hash, \"allowance\", floor)\n        return 0, errInvalidAncestor\n    }\n    p.log.Debug(\"Found common ancestor\", \"number\", start, \"hash\", hash)\n    return start, nil\n}\n\n```\n\n1，调用peer.RequestHeadersByNumber(uint64(from), count, 15, false)，获取header。这里传入 count和 15，指从本地最高的header往前数192个区块的头，每16个区块取一个区块头。为了后面select收到d.headerCh时加以验证。\n2，select收到了headers，遍历header，看是否在本地是否存在这个header，如果有，并且不为空，就说明找到共同的祖先，返回祖先number\n3，如果没有找到共同的祖先，再重新从本地的区块链MaxForkAncestry起的一半的位置开始取区块头，一一验证是否跟网络节点返回的header一致，如果有就说明有共同的祖先，并返回，没有的话就返回0.\n\n继续syncWithPeer()方法，找到同步的轴心的pivot，最后把要同步的数据和同步的方法传给d.spawnSync(fetchers)，并执行。d.spawnSync(fetchers)挨个执行传入的同步方法。\n\n二，Downloader同步数据方法\nfetchHeaders()，fetchBodies() , fetchReceipts()\n\n```\nfunc (d *Downloader) fetchHeaders(p *peerConnection, from uint64, pivot uint64) error {\n    p.log.Debug(\"Directing header downloads\", \"origin\", from)\n    defer p.log.Debug(\"Header download terminated\")\n\n    // Create a timeout timer, and the associated header fetcher\n    skeleton := true            // Skeleton assembly phase or finishing up\n    request := time.Now()       // time of the last skeleton fetch request\n    timeout := time.NewTimer(0) // timer to dump a non-responsive active peer\n    <-timeout.C                 // timeout channel should be initially empty\n    defer timeout.Stop()\n\n    var ttl time.Duration\n    getHeaders := func(from uint64) {\n        request = time.Now()\n\n        ttl = d.requestTTL()\n        timeout.Reset(ttl)\n\n        if skeleton {\n            p.log.Trace(\"Fetching skeleton headers\", \"count\", MaxHeaderFetch, \"from\", from)\n            go p.peer.RequestHeadersByNumber(from+uint64(MaxHeaderFetch)-1, MaxSkeletonSize, MaxHeaderFetch-1, false)\n        } else {\n            p.log.Trace(\"Fetching full headers\", \"count\", MaxHeaderFetch, \"from\", from)\n            go p.peer.RequestHeadersByNumber(from, MaxHeaderFetch, 0, false)\n        }\n    }\n    // Start pulling the header chain skeleton until all is done\n    getHeaders(from)\n\n    for {\n        select {\n        case <-d.cancelCh:\n            return errCancelHeaderFetch\n\n        case packet := <-d.headerCh:\n            // Make sure the active peer is giving us the skeleton headers\n            if packet.PeerId() != p.id {\n                log.Debug(\"Received skeleton from incorrect peer\", \"peer\", packet.PeerId())\n                break\n            }\n            headerReqTimer.UpdateSince(request)\n            timeout.Stop()\n\n            // If the skeleton's finished, pull any remaining head headers directly from the origin\n            if packet.Items() == 0 && skeleton {\n                skeleton = false\n                getHeaders(from)\n                continue\n            }\n            // If no more headers are inbound, notify the content fetchers and return\n            if packet.Items() == 0 {\n                // Don't abort header fetches while the pivot is downloading\n                if atomic.LoadInt32(&d.committed) == 0 && pivot <= from {\n                    p.log.Debug(\"No headers, waiting for pivot commit\")\n                    select {\n                    case <-time.After(fsHeaderContCheck):\n                        getHeaders(from)\n                        continue\n                    case <-d.cancelCh:\n                        return errCancelHeaderFetch\n                    }\n                }\n                // Pivot done (or not in fast sync) and no more headers, terminate the process\n                p.log.Debug(\"No more headers available\")\n                select {\n                case d.headerProcCh <- nil:\n                    return nil\n                case <-d.cancelCh:\n                    return errCancelHeaderFetch\n                }\n            }\n            headers := packet.(*headerPack).headers\n\n            // If we received a skeleton batch, resolve internals concurrently\n            if skeleton {\n                filled, proced, err := d.fillHeaderSkeleton(from, headers)\n                if err != nil {\n                    p.log.Debug(\"Skeleton chain invalid\", \"err\", err)\n                    return errInvalidChain\n                }\n                headers = filled[proced:]\n                from += uint64(proced)\n            }\n            // Insert all the new headers and fetch the next batch\n            if len(headers) > 0 {\n                p.log.Trace(\"Scheduling new headers\", \"count\", len(headers), \"from\", from)\n                select {\n                case d.headerProcCh <- headers:\n                case <-d.cancelCh:\n                    return errCancelHeaderFetch\n                }\n                from += uint64(len(headers))\n            }\n            getHeaders(from)\n\n        case <-timeout.C:\n            if d.dropPeer == nil {\n                // The dropPeer method is nil when `--copydb` is used for a local copy.\n                // Timeouts can occur if e.g. compaction hits at the wrong time, and can be ignored\n                p.log.Warn(\"Downloader wants to drop peer, but peerdrop-function is not set\", \"peer\", p.id)\n                break\n            }\n            // Header retrieval timed out, consider the peer bad and drop\n            p.log.Debug(\"Header request timed out\", \"elapsed\", ttl)\n            headerTimeoutMeter.Mark(1)\n            d.dropPeer(p.id)\n\n            // Finish the sync gracefully instead of dumping the gathered data though\n            for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n                select {\n                case ch <- false:\n                case <-d.cancelCh:\n                }\n            }\n            select {\n            case d.headerProcCh <- nil:\n            case <-d.cancelCh:\n            }\n            return errBadPeer\n        }\n    }\n}\n\n```\n\n1，getHeaders()调用peer.RequestHeadersByNumber()方法 获取网络节点的headers。\n2，有两种获取方式，首先走的是skeleton方式，从查找到的共同祖先区块+192个区块位置开始，每隔192个区块，获取128个区块头。非skeleton方式，从共同祖先区块开始，获取192个区块头。\n3，如果第一种方式获取不到区块头，则执行第二种获取方式，如果第二种方式还是没有获取到区块头的话，直接返回\n4，如果是skeleton获取到的，调用fillHeaderSkeleton()方法加入到skeleton header chain\n5，然后调整from值，再递归调用getHeaders()方法\n\n```\nfunc (d *Downloader) fillHeaderSkeleton(from uint64, skeleton []*types.Header) ([]*types.Header, int, error) {\n    log.Debug(\"Filling up skeleton\", \"from\", from)\n    d.queue.ScheduleSkeleton(from, skeleton)\n\n    var (\n        deliver = func(packet dataPack) (int, error) {\n            pack := packet.(*headerPack)\n            return d.queue.DeliverHeaders(pack.peerId, pack.headers, d.headerProcCh)\n        }\n        expire   = func() map[string]int { return d.queue.ExpireHeaders(d.requestTTL()) }\n        throttle = func() bool { return false }\n        reserve  = func(p *peerConnection, count int) (*fetchRequest, bool, error) {\n            return d.queue.ReserveHeaders(p, count), false, nil\n        }\n        fetch    = func(p *peerConnection, req *fetchRequest) error { return p.FetchHeaders(req.From, MaxHeaderFetch) }\n        capacity = func(p *peerConnection) int { return p.HeaderCapacity(d.requestRTT()) }\n        setIdle  = func(p *peerConnection, accepted int) { p.SetHeadersIdle(accepted) }\n    )\n    err := d.fetchParts(errCancelHeaderFetch, d.headerCh, deliver, d.queue.headerContCh, expire,\n        d.queue.PendingHeaders, d.queue.InFlightHeaders, throttle, reserve,\n        nil, fetch, d.queue.CancelHeaders, capacity, d.peers.HeaderIdlePeers, setIdle, \"headers\")\n\n    log.Debug(\"Skeleton fill terminated\", \"err\", err)\n\n    filled, proced := d.queue.RetrieveHeaders()\n    return filled, proced, err\n}\n\n\n```\n\na) 把skeleton的headers加入queue.ScheduleSkeleton调度队列，\nb) 然后执行d.fetchParts()方法。\nd.fetchParts()方法主要做了这几件事情\n1，对收到的headers执行d.queue.DeliverHeaders()方法。\n2，如果d.queue.PendingHeaders有pending的headers，调用d.peers.HeaderIdlePeers获取到idle的peers\n3，调用d.queue.ReserveHeaders把pending的headers储备到idle的peers里面\n4，用idle的peers调用p.FetchHeaders(req.From, MaxHeaderFetch)去获取headers\nc) 最后执行d.queue.RetrieveHeaders()，获取到filled进去的headers\n\n其他同步区块数据的方法d.fetchBodies() , d.fetchReceipts() 和fetchHeaders()流程类似，还更简单一些。\n\n三，Downloader同步数据过程\nd.processHeaders(), d.processFastSyncContent(latest) , d.processFullSyncContent\n1，d.processHeaders() 方法\n\n```\nfunc (d *Downloader) processHeaders(origin uint64, pivot uint64, td *big.Int) error {\n    // Keep a count of uncertain headers to roll back\n    rollback := []*types.Header{}\n    defer func() {\n        if len(rollback) > 0 {\n            // Flatten the headers and roll them back\n            hashes := make([]common.Hash, len(rollback))\n            for i, header := range rollback {\n                hashes[i] = header.Hash()\n            }\n            lastHeader, lastFastBlock, lastBlock := d.lightchain.CurrentHeader().Number, common.Big0, common.Big0\n            if d.mode != LightSync {\n                lastFastBlock = d.blockchain.CurrentFastBlock().Number()\n                lastBlock = d.blockchain.CurrentBlock().Number()\n            }\n            d.lightchain.Rollback(hashes)\n            curFastBlock, curBlock := common.Big0, common.Big0\n            if d.mode != LightSync {\n                curFastBlock = d.blockchain.CurrentFastBlock().Number()\n                curBlock = d.blockchain.CurrentBlock().Number()\n            }\n            log.Warn(\"Rolled back headers\", \"count\", len(hashes),\n                \"header\", fmt.Sprintf(\"%d->%d\", lastHeader, d.lightchain.CurrentHeader().Number),\n                \"fast\", fmt.Sprintf(\"%d->%d\", lastFastBlock, curFastBlock),\n                \"block\", fmt.Sprintf(\"%d->%d\", lastBlock, curBlock))\n        }\n    }()\n\n    // Wait for batches of headers to process\n    gotHeaders := false\n\n    for {\n        select {\n        case <-d.cancelCh:\n            return errCancelHeaderProcessing\n\n        case headers := <-d.headerProcCh:\n            // Terminate header processing if we synced up\n            if len(headers) == 0 {\n                // Notify everyone that headers are fully processed\n                for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n                    select {\n                    case ch <- false:\n                    case <-d.cancelCh:\n                    }\n                }\n                if d.mode != LightSync {\n                    head := d.blockchain.CurrentBlock()\n                    if !gotHeaders && td.Cmp(d.blockchain.GetTd(head.Hash(), head.NumberU64())) > 0 {\n                        return errStallingPeer\n                    }\n                }\n                if d.mode == FastSync || d.mode == LightSync {\n                    head := d.lightchain.CurrentHeader()\n                    if td.Cmp(d.lightchain.GetTd(head.Hash(), head.Number.Uint64())) > 0 {\n                        return errStallingPeer\n                    }\n                }\n                // Disable any rollback and return\n                rollback = nil\n                return nil\n            }\n            // Otherwise split the chunk of headers into batches and process them\n            gotHeaders = true\n\n            for len(headers) > 0 {\n                // Terminate if something failed in between processing chunks\n                select {\n                case <-d.cancelCh:\n                    return errCancelHeaderProcessing\n                default:\n                }\n                // Select the next chunk of headers to import\n                limit := maxHeadersProcess\n                if limit > len(headers) {\n                    limit = len(headers)\n                }\n                chunk := headers[:limit]\n\n                // In case of header only syncing, validate the chunk immediately\n                if d.mode == FastSync || d.mode == LightSync {\n                    // Collect the yet unknown headers to mark them as uncertain\n                    unknown := make([]*types.Header, 0, len(headers))\n                    for _, header := range chunk {\n                        if !d.lightchain.HasHeader(header.Hash(), header.Number.Uint64()) {\n                            unknown = append(unknown, header)\n                        }\n                    }\n                    // If we're importing pure headers, verify based on their recentness\n                    frequency := fsHeaderCheckFrequency\n                    if chunk[len(chunk)-1].Number.Uint64()+uint64(fsHeaderForceVerify) > pivot {\n                        frequency = 1\n                    }\n                    if n, err := d.lightchain.InsertHeaderChain(chunk, frequency); err != nil {\n                        // If some headers were inserted, add them too to the rollback list\n                        if n > 0 {\n                            rollback = append(rollback, chunk[:n]...)\n                        }\n                        log.Debug(\"Invalid header encountered\", \"number\", chunk[n].Number, \"hash\", chunk[n].Hash(), \"err\", err)\n                        return errInvalidChain\n                    }\n                    // All verifications passed, store newly found uncertain headers\n                    rollback = append(rollback, unknown...)\n                    if len(rollback) > fsHeaderSafetyNet {\n                        rollback = append(rollback[:0], rollback[len(rollback)-fsHeaderSafetyNet:]...)\n                    }\n                }\n                // Unless we're doing light chains, schedule the headers for associated content retrieval\n                if d.mode == FullSync || d.mode == FastSync {\n                    // If we've reached the allowed number of pending headers, stall a bit\n                    for d.queue.PendingBlocks() >= maxQueuedHeaders || d.queue.PendingReceipts() >= maxQueuedHeaders {\n                        select {\n                        case <-d.cancelCh:\n                            return errCancelHeaderProcessing\n                        case <-time.After(time.Second):\n                        }\n                    }\n                    // Otherwise insert the headers for content retrieval\n                    inserts := d.queue.Schedule(chunk, origin)\n                    if len(inserts) != len(chunk) {\n                        log.Debug(\"Stale headers\")\n                        return errBadPeer\n                    }\n                }\n                headers = headers[limit:]\n                origin += uint64(limit)\n            }\n            // Signal the content downloaders of the availablility of new tasks\n            for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n                select {\n                case ch <- true:\n                default:\n                }\n            }\n        }\n    }\n}\n\n```\n\n1，收到从fetchHeaders()方法 中d.headerProcCh发送过来的headers\n2，如果是FastSync或者LightSync模式，直接调用lightchain.InsertHeaderChain(chunk, frequency)插入到headerChain。\n3，如果是FullSync或者FastSyn模式，调用d.queue.Schedule(chunk, origin)，放入downloader.queue来调度\n\n2，processFastSyncContent() 方法\n\n```\nfunc (d *Downloader) processFastSyncContent(latest *types.Header) error {\n    // Start syncing state of the reported head block. This should get us most of\n    // the state of the pivot block.\n    stateSync := d.syncState(latest.Root)\n    defer stateSync.Cancel()\n    go func() {\n        if err := stateSync.Wait(); err != nil && err != errCancelStateFetch {\n            d.queue.Close() // wake up WaitResults\n        }\n    }()\n    // Figure out the ideal pivot block. Note, that this goalpost may move if the\n    // sync takes long enough for the chain head to move significantly.\n    pivot := uint64(0)\n    if height := latest.Number.Uint64(); height > uint64(fsMinFullBlocks) {\n        pivot = height - uint64(fsMinFullBlocks)\n    }\n    // To cater for moving pivot points, track the pivot block and subsequently\n    // accumulated download results separatey.\n    var (\n        oldPivot *fetchResult   // Locked in pivot block, might change eventually\n        oldTail  []*fetchResult // Downloaded content after the pivot\n    )\n    for {\n        // Wait for the next batch of downloaded data to be available, and if the pivot\n        // block became stale, move the goalpost\n        results := d.queue.Results(oldPivot == nil) // Block if we're not monitoring pivot staleness\n        if len(results) == 0 {\n            // If pivot sync is done, stop\n            if oldPivot == nil {\n                return stateSync.Cancel()\n            }\n            // If sync failed, stop\n            select {\n            case <-d.cancelCh:\n                return stateSync.Cancel()\n            default:\n            }\n        }\n        if d.chainInsertHook != nil {\n            d.chainInsertHook(results)\n        }\n        if oldPivot != nil {\n            results = append(append([]*fetchResult{oldPivot}, oldTail...), results...)\n        }\n        // Split around the pivot block and process the two sides via fast/full sync\n        if atomic.LoadInt32(&d.committed) == 0 {\n            latest = results[len(results)-1].Header\n            if height := latest.Number.Uint64(); height > pivot+2*uint64(fsMinFullBlocks) {\n                log.Warn(\"Pivot became stale, moving\", \"old\", pivot, \"new\", height-uint64(fsMinFullBlocks))\n                pivot = height - uint64(fsMinFullBlocks)\n            }\n        }\n        P, beforeP, afterP := splitAroundPivot(pivot, results)\n        if err := d.commitFastSyncData(beforeP, stateSync); err != nil {\n            return err\n        }\n        if P != nil {\n            // If new pivot block found, cancel old state retrieval and restart\n            if oldPivot != P {\n                stateSync.Cancel()\n\n                stateSync = d.syncState(P.Header.Root)\n                defer stateSync.Cancel()\n                go func() {\n                    if err := stateSync.Wait(); err != nil && err != errCancelStateFetch {\n                        d.queue.Close() // wake up WaitResults\n                    }\n                }()\n                oldPivot = P\n            }\n            // Wait for completion, occasionally checking for pivot staleness\n            select {\n            case <-stateSync.done:\n                if stateSync.err != nil {\n                    return stateSync.err\n                }\n                if err := d.commitPivotBlock(P); err != nil {\n                    return err\n                }\n                oldPivot = nil\n\n            case <-time.After(time.Second):\n                oldTail = afterP\n                continue\n            }\n        }\n        // Fast sync done, pivot commit done, full import\n        if err := d.importBlockResults(afterP); err != nil {\n            return err\n        }\n    }\n}\n\n```\n\n1，同步最新的状态信息，的到最新的pivot值\n2，不停的从d.queue 的result缓存中获取要处理的result数据\n3，如果results数据为空，同时pivot也为空的时候，说明同步完成了，并返回\n4，根据pivot值和results计算：pivot值对应的result，和pivot值之前的results和pivot值之后的results\n5，调用commitFastSyncData把pivot值之前的results 插入本地区块链中，带上收据和交易数据\n6，更新同步状态信息后，把pivot值对应的result 调用commitPivotBlock插入本地区块链中，并调用FastSyncCommitHead，记录这个pivot的hash值\n7，调用d.importBlockResults把pivot值之后的results插入本地区块链中，这时候不插入区块交易收据数据。\n\n3，processFullSyncContent()方法\n\n```\nfunc (d *Downloader) processFullSyncContent() error {\n    for {\n        results := d.queue.Results(true)\n        if len(results) == 0 {\n            return nil\n        }\n        if d.chainInsertHook != nil {\n            d.chainInsertHook(results)\n        }\n        if err := d.importBlockResults(results); err != nil {\n            return err\n        }\n    }\n}\n\nfunc (d *Downloader) importBlockResults(results []*fetchResult) error {\n    // Check for any early termination requests\n    if len(results) == 0 {\n        return nil\n    }\n    select {\n    case <-d.quitCh:\n        return errCancelContentProcessing\n    default:\n    }\n    // Retrieve the a batch of results to import\n    first, last := results[0].Header, results[len(results)-1].Header\n    log.Debug(\"Inserting downloaded chain\", \"items\", len(results),\n        \"firstnum\", first.Number, \"firsthash\", first.Hash(),\n        \"lastnum\", last.Number, \"lasthash\", last.Hash(),\n    )\n    blocks := make([]*types.Block, len(results))\n    for i, result := range results {\n        blocks[i] = types.NewBlockWithHeader(result.Header).WithBody(result.Transactions, result.Uncles)\n    }\n    if index, err := d.blockchain.InsertChain(blocks); err != nil {\n        log.Debug(\"Downloaded item processing failed\", \"number\", results[index].Header.Number, \"hash\", results[index].Header.Hash(), \"err\", err)\n        return errInvalidChain\n    }\n    return nil\n}\n\n```\n\nprocessFullSyncContent方法比较简单：直接获取缓存的results数据，并插入到本地区块链中。\n\n总结：\nDownloader看似非常复杂，其实逻辑还好，如果没有light模式，读起来会好很多。其实light模式不太成熟，基本也没什么用。fast模式比full模式逻辑上面多了一个pivot，处理起来就复杂很多。但是fast模式在本地存储了收据数据，大大减少了区块交易验证的时间。如果要更清楚明白fast模式的原理，可以看看以太坊白皮书关于fast模式同步这一部分：[文档](https://github.com/ethereum/go-ethereum/pull/1889)\n","source":"_posts/eth-code-tx-event.md","raw":"---\ntitle: eth_code_tx_event\ncategories:\n  - eth\ndate: 2019-10-14 14:47:58\ntags:\n---\n\n#### ApplyTransaction\n\n```\n// ApplyTransaction attempts to apply a transaction to the given state database\n// and uses the input parameters for its environment. It returns the receipt\n// for the transaction, gas used and an error if the transaction failed,\n// indicating the block was invalid.\n//应用交易到state database中\nfunc ApplyTransaction(config *params.ChainConfig, bc ChainContext, author *common.Address, gp *GasPool, statedb *state.StateDB, header *types.Header, tx *types.Transaction, usedGas *uint64, cfg vm.Config) (*types.Receipt, uint64, error) {\n\t//构造交易消息\n\tmsg, err := tx.AsMessage(types.MakeSigner(config, header.Number))\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\t//EVM进行交易处理，返回为处理结果、消耗gas、是否失败、err，logs是在evm处理时产生的\n\t// Create a new context to be used in the EVM environment\n\tcontext := NewEVMContext(msg, header, bc, author)\n\t// Create a new environment which holds all relevant information\n\t// about the transaction and calling mechanisms.\n\tvmenv := vm.NewEVM(context, statedb, config, cfg)\n\t// Apply the transaction to the current state (included in the env)\n\t_, gas, failed, err := ApplyMessage(vmenv, msg, gp)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\n\t//根据处理结果构建返回数据\n\t// Update the state with pending changes\n\tvar root []byte\n\tif config.IsByzantium(header.Number) {\n\t\tstatedb.Finalise(true)\n\t} else {\n\t\troot = statedb.IntermediateRoot(config.IsEIP158(header.Number)).Bytes()\n\t}\n\t*usedGas += gas\n\n\t// Create a new receipt for the transaction, storing the intermediate root and gas used by the tx\n\t// based on the eip phase, we're passing whether the root touch-delete accounts.\n\treceipt := types.NewReceipt(root, failed, *usedGas)\n\treceipt.TxHash = tx.Hash()\n\treceipt.GasUsed = gas\n\t// if the transaction created a contract, store the creation address in the receipt.\n\tif msg.To() == nil {\n\t\treceipt.ContractAddress = crypto.CreateAddress(vmenv.Context.Origin, tx.Nonce())\n\t}\n\t// Set the receipt logs and create a bloom for filtering\n\treceipt.Logs = statedb.GetLogs(tx.Hash())\n\treceipt.Bloom = types.CreateBloom(types.Receipts{receipt})\n\n\treturn receipt, gas, err\n}\n\n```\n\n\n\n```\nfunc (evm *EVM) Call(caller ContractRef, addr common.Address, input []byte, gas uint64, value *big.Int) (ret []byte, leftOverGas uint64, err error) {\n\tif evm.vmConfig.NoRecursion && evm.depth > 0 {\n\t\treturn nil, gas, nil\n\t}\n\n\t// Fail if we're trying to execute above the call depth limit\n\tif evm.depth > int(params.CallCreateDepth) {\n\t\treturn nil, gas, ErrDepth\n\t}\n\t// Fail if we're trying to transfer more than the available balance\n\tif !evm.Context.CanTransfer(evm.StateDB, caller.Address(), value) {\n\t\treturn nil, gas, ErrInsufficientBalance\n\t}\n\n\tvar (\n\t\tto       = AccountRef(addr)\n\t\tsnapshot = evm.StateDB.Snapshot()\n\t)\n\tif !evm.StateDB.Exist(addr) {\n\t\tprecompiles := PrecompiledContractsHomestead\n\t\tif evm.ChainConfig().IsByzantium(evm.BlockNumber) {\n\t\t\tprecompiles = PrecompiledContractsByzantium\n\t\t}\n\t\tif precompiles[addr] == nil && evm.ChainConfig().IsEIP158(evm.BlockNumber) && value.Sign() == 0 {\n\t\t\t// Calling a non existing account, don't do anything, but ping the tracer\n\t\t\tif evm.vmConfig.Debug && evm.depth == 0 {\n\t\t\t\tevm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value)\n\t\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, 0, 0, nil)\n\t\t\t}\n\t\t\treturn nil, gas, nil\n\t\t}\n\t\tevm.StateDB.CreateAccount(addr)\n\t}\n\tevm.Transfer(evm.StateDB, caller.Address(), to.Address(), value)\n\t// Initialise a new contract and set the code that is to be used by the EVM.\n\t// The contract is a scoped environment for this execution context only.\n\tcontract := NewContract(caller, to, value, gas)\n\tcontract.SetCallCode(&addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr))\n\n\t// Even if the account has no code, we need to continue because it might be a precompile\n\tstart := time.Now()\n\n\t// Capture the tracer start/end events in debug mode\n\tif evm.vmConfig.Debug && evm.depth == 0 {\n\t\tevm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value)\n\n\t\tdefer func() { // Lazy evaluation of the parameters\n\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, gas-contract.Gas, time.Since(start), err)\n\t\t}()\n\t}\n\tret, err = run(evm, contract, input, false)\n\n\t// When an error was returned by the EVM or when setting the creation code\n\t// above we revert to the snapshot and consume any gas remaining. Additionally\n\t// when we're in homestead this also counts for code storage gas errors.\n\tif err != nil {\n\t\tevm.StateDB.RevertToSnapshot(snapshot)\n\t\tif err != errExecutionReverted {\n\t\t\tcontract.UseGas(contract.Gas)\n\t\t}\n\t}\n\treturn ret, contract.Gas, err\n}\n```\n\n\n\n\n\n\n\n\n\n#### handleMsg\n\n处理接收到的消息码\n\n- ```\n  StatusMsg\n  ```\n\n  收到这个消息说明握手失败\n\n- ```\n  GetBlockHeadersMsg\n  ```\n\n  查询区块头请求，回复区块头信息\n\n  ```\n  BlockHeadersMsg\n  ```\n\n  区块头信息的回复\n\n- ```\n  GetBlockBodiesMsg\n  ```\n\n  查询区块请求\n\n  ```\n  BlockBodiesMsg\n  ```\n\n  区块请求查询的回复，\n\n- ```\n  GetNodeDataMsg\n  ```\n\n- ```\n  NodeDataMsg\n  ```\n\n- ```\n  GetReceiptsMsg\n  ```\n\n- ```\n  ReceiptsMsg\n  ```\n\n- ```\n  NewBlockHashesMsg\n  ```\n\n- ```\n  NewBlockMsg\n  ```\n\n- ```\n  TxMsg\n  ```\n\n\n\n#### Start\n\n这四个goroutine 基本上就在不停的做广播区块、广播交易，同步到区块、同步到交易，再广播区块、广播交易。\n\n- txBroadcastLoop\n\n  ```\n  func (self *ProtocolManager) txBroadcastLoop() {\n      for {\n          select {\n          case event := <-self.txCh:\n              self.BroadcastTx(event.Tx.Hash(), event.Tx)\n\n          // Err() channel will be closed when unsubscribing.\n          case <-self.txSub.Err():\n              return\n          }\n      }\n  }\n  ```\n\n  core/tx_pool.go 产生新的交易的时候会send self.txCh，这时候会激活\n  self.BroadcastTx(event.Tx.Hash(), event.Tx)\n\n  ```\n  func (pm *ProtocolManager) BroadcastTx(hash common.Hash, tx *types.Transaction) {\n      // Broadcast transaction to a batch of peers not knowing about it\n      peers := pm.peers.PeersWithoutTx(hash)\n      //FIXME include this again: peers = peers[:int(math.Sqrt(float64(len(peers))))]\n      for _, peer := range peers {\n          peer.SendTransactions(types.Transactions{tx})\n      }\n      log.Trace(\"Broadcast transaction\", \"hash\", hash, \"recipients\", len(peers))\n  }\n\n  ```\n\n  向缓存的没有这个交易hash的网络节点广播此次交易。\n\n- minedBroadcastLoop\n\n  收到miner.go 里面NewMinedBlockEvent 挖到新区块的事件通知，激活self.BroadcastBlock(ev.Block, true)\n\n  ```\n  // Mined broadcast loop\n  func (self *ProtocolManager) minedBroadcastLoop() {\n      // automatically stops if unsubscribe\n      for obj := range self.minedBlockSub.Chan() {\n          switch ev := obj.Data.(type) {\n          case core.NewMinedBlockEvent:\n              self.BroadcastBlock(ev.Block, true)  // First propagate block to peers\n              self.BroadcastBlock(ev.Block, false) // Only then announce to the rest\n          }\n      }\n  }\n\n  ```\n\n  ```\n  func (pm *ProtocolManager) BroadcastBlock(block *types.Block, propagate bool) {\n      hash := block.Hash()\n      peers := pm.peers.PeersWithoutBlock(hash)\n\n      // If propagation is requested, send to a subset of the peer\n      if propagate {\n          // Calculate the TD of the block (it's not imported yet, so block.Td is not valid)\n          var td *big.Int\n          if parent := pm.blockchain.GetBlock(block.ParentHash(), block.NumberU64()-1); parent != nil {\n              td = new(big.Int).Add(block.Difficulty(), pm.blockchain.GetTd(block.ParentHash(), block.NumberU64()-1))\n          } else {\n              log.Error(\"Propagating dangling block\", \"number\", block.Number(), \"hash\", hash)\n              return\n          }\n          // Send the block to a subset of our peers\n          transfer := peers[:int(math.Sqrt(float64(len(peers))))]\n          for _, peer := range transfer {\n              peer.SendNewBlock(block, td)\n          }\n          log.Trace(\"Propagated block\", \"hash\", hash, \"recipients\", len(transfer), \"duration\", common.PrettyDuration(time.Since(block.ReceivedAt)))\n          return\n      }\n      // Otherwise if the block is indeed in out own chain, announce it\n      if pm.blockchain.HasBlock(hash, block.NumberU64()) {\n          for _, peer := range peers {\n              peer.SendNewBlockHashes([]common.Hash{hash}, []uint64{block.NumberU64()})\n          }\n          log.Trace(\"Announced block\", \"hash\", hash, \"recipients\", len(peers), \"duration\", common.PrettyDuration(time.Since(block.ReceivedAt)))\n      }\n  }\n\n  ```\n\n  如果propagate为true 向网络节点广播整个挖到的block，为false 只广播挖到的区块的hash值和number值。广播的区块还包括这个区块打包的所有交易。\n\n- syncer\n\n  ```\n  func (pm *ProtocolManager) syncer() {\n      // Start and ensure cleanup of sync mechanisms\n      pm.fetcher.Start()\n      defer pm.fetcher.Stop()\n      defer pm.downloader.Terminate()\n\n      // Wait for different events to fire synchronisation operations\n      forceSync := time.NewTicker(forceSyncCycle)\n      defer forceSync.Stop()\n\n      for {\n          select {\n          case <-pm.newPeerCh:\n              // Make sure we have peers to select from, then sync\n              if pm.peers.Len() < minDesiredPeerCount {\n                  break\n              }\n              go pm.synchronise(pm.peers.BestPeer())\n\n          case <-forceSync.C:\n              // Force a sync even if not enough peers are present\n              go pm.synchronise(pm.peers.BestPeer())\n\n          case <-pm.noMorePeers:\n              return\n          }\n      }\n  }\n\n\n  ```\n\n  pm.fetcher.Start()启动 fetcher，辅助同步区块数据\n\n  当P2P server执行 ProtocolManager 的p2p.Protocol 的Run指针的时候会send pm.newPeerCh，这时候选择最优的网络节点（TD 总难度最大的）启动pm.synchronise(pm.peers.BestPeer()) goroutine。\n\n  ```\n  // synchronise tries to sync up our local block chain with a remote peer.\n  func (pm *ProtocolManager) synchronise(peer *peer) {\n      // Short circuit if no peers are available\n      if peer == nil {\n          return\n      }\n      // Make sure the peer's TD is higher than our own\n      currentBlock := pm.blockchain.CurrentBlock()\n      td := pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())\n\n      pHead, pTd := peer.Head()\n      if pTd.Cmp(td) <= 0 {\n          return\n      }\n      // Otherwise try to sync with the downloader\n      mode := downloader.FullSync\n      if atomic.LoadUint32(&pm.fastSync) == 1 {\n          // Fast sync was explicitly requested, and explicitly granted\n          mode = downloader.FastSync\n      } else if currentBlock.NumberU64() == 0 && pm.blockchain.CurrentFastBlock().NumberU64() > 0 {\n          // The database seems empty as the current block is the genesis. Yet the fast\n          // block is ahead, so fast sync was enabled for this node at a certain point.\n          // The only scenario where this can happen is if the user manually (or via a\n          // bad block) rolled back a fast sync node below the sync point. In this case\n          // however it's safe to reenable fast sync.\n          atomic.StoreUint32(&pm.fastSync, 1)\n          mode = downloader.FastSync\n      }\n      // Run the sync cycle, and disable fast sync if we've went past the pivot block\n      if err := pm.downloader.Synchronise(peer.id, pHead, pTd, mode); err != nil {\n          return\n      }\n      if atomic.LoadUint32(&pm.fastSync) == 1 {\n          log.Info(\"Fast sync complete, auto disabling\")\n          atomic.StoreUint32(&pm.fastSync, 0)\n      }\n      atomic.StoreUint32(&pm.acceptTxs, 1) // Mark initial sync done\n      if head := pm.blockchain.CurrentBlock(); head.NumberU64() > 0 {\n          // We've completed a sync cycle, notify all peers of new state. This path is\n          // essential in star-topology networks where a gateway node needs to notify\n          // all its out-of-date peers of the availability of a new block. This failure\n          // scenario will most often crop up in private and hackathon networks with\n          // degenerate connectivity, but it should be healthy for the mainnet too to\n          // more reliably update peers or the local TD state.\n          go pm.BroadcastBlock(head, false)\n      }\n  }\n\n\n  ```\n\n  如果最优的网络节点的TD值大于本地最新区块的TD值，调用pm.downloader.Synchronise(peer.id, pHead, pTd, mode)进行同步。同步完成后再屌用go pm.BroadcastBlock(head, false)，把自己最新的区块状态广播出去。\n\n- txsyncLoop\n\n  ```\n  func (pm *ProtocolManager) txsyncLoop() {\n      var (\n          pending = make(map[discover.NodeID]*txsync)\n          sending = false               // whether a send is active\n          pack    = new(txsync)         // the pack that is being sent\n          done    = make(chan error, 1) // result of the send\n      )\n\n      // send starts a sending a pack of transactions from the sync.\n      send := func(s *txsync) {\n          // Fill pack with transactions up to the target size.\n          size := common.StorageSize(0)\n          pack.p = s.p\n          pack.txs = pack.txs[:0]\n          for i := 0; i < len(s.txs) && size < txsyncPackSize; i++ {\n              pack.txs = append(pack.txs, s.txs[i])\n              size += s.txs[i].Size()\n          }\n          // Remove the transactions that will be sent.\n          s.txs = s.txs[:copy(s.txs, s.txs[len(pack.txs):])]\n          if len(s.txs) == 0 {\n              delete(pending, s.p.ID())\n          }\n          // Send the pack in the background.\n          s.p.Log().Trace(\"Sending batch of transactions\", \"count\", len(pack.txs), \"bytes\", size)\n          sending = true\n          go func() { done <- pack.p.SendTransactions(pack.txs) }()\n      }\n\n      // pick chooses the next pending sync.\n      pick := func() *txsync {\n          if len(pending) == 0 {\n              return nil\n          }\n          n := rand.Intn(len(pending)) + 1\n          for _, s := range pending {\n              if n--; n == 0 {\n                  return s\n              }\n          }\n          return nil\n      }\n\n      for {\n          select {\n          case s := <-pm.txsyncCh:\n              pending[s.p.ID()] = s\n              if !sending {\n                  send(s)\n              }\n          case err := <-done:\n              sending = false\n              // Stop tracking peers that cause send failures.\n              if err != nil {\n                  pack.p.Log().Debug(\"Transaction send failed\", \"err\", err)\n                  delete(pending, pack.p.ID())\n              }\n              // Schedule the next send.\n              if s := pick(); s != nil {\n                  send(s)\n              }\n          case <-pm.quitSync:\n              return\n          }\n      }\n  }\n\n  ```\n\n  当从网络节点同步过来最新的交易数据后，本地也会把新同步下来的交易数据广播给网络中的其他节点。\n\n\n\n#### fetch\n\nfetcher是用来辅助同步区块数据的，记录各个区块头和区块体的同步状态，但它并不做真正下载区块数据的事情，下载的事情交由downloader来做。那fetcher具体是怎么工作的呢？\n我们先看看pm.handleMsg 在收到 NewBlockHashesMsg广播通知的处理代码：\n\n```\ncase msg.Code == NewBlockHashesMsg:\n        var announces newBlockHashesData\n        if err := msg.Decode(&announces); err != nil {\n            return errResp(ErrDecode, \"%v: %v\", msg, err)\n        }\n        // Mark the hashes as present at the remote node\n        for _, block := range announces {\n            p.MarkBlock(block.Hash)\n        }\n        // Schedule all the unknown hashes for retrieval\n        unknown := make(newBlockHashesData, 0, len(announces))\n        for _, block := range announces {\n            if !pm.blockchain.HasBlock(block.Hash, block.Number) {\n                unknown = append(unknown, block)\n            }\n        }\n        for _, block := range unknown {\n            pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)\n        }\n\n\n```\n\n从广播通知里会获取到一个newBlockHashesData的列表。newBlockHashesData只包括block的hash值和block的number值。\n然后每个newBlockHashesData调用pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)方法，除了传入block的hash值和block的number值，还需要传入当前的时间戳，peer.go的两个函数指针。\n\n```\nfunc (f *Fetcher) Notify(peer string, hash common.Hash, number uint64, time time.Time,\n    headerFetcher headerRequesterFn, bodyFetcher bodyRequesterFn) error {\n    block := &announce{\n        hash:        hash,\n        number:      number,\n        time:        time,\n        origin:      peer,\n        fetchHeader: headerFetcher,\n        fetchBodies: bodyFetcher,\n    }\n    select {\n    case f.notify <- block:\n        return nil\n    case <-f.quit:\n        return errTerminated\n    }\n}\n\n\n```\n\nNotify()方法把传进来的参数拼成一个announce对象，然后send给f.notify。fetcher的loop()主回路里f.notify receive 到这个notification, 进行处理。\n\n```\ncase notification := <-f.notify:\n            // A block was announced, make sure the peer isn't DOSing us\n            propAnnounceInMeter.Mark(1)\n\n            count := f.announces[notification.origin] + 1\n            if count > hashLimit {\n                log.Debug(\"Peer exceeded outstanding announces\", \"peer\", notification.origin, \"limit\", hashLimit)\n                propAnnounceDOSMeter.Mark(1)\n                break\n            }\n            // If we have a valid block number, check that it's potentially useful\n            if notification.number > 0 {\n                if dist := int64(notification.number) - int64(f.chainHeight()); dist < -maxUncleDist || dist > maxQueueDist {\n                    log.Debug(\"Peer discarded announcement\", \"peer\", notification.origin, \"number\", notification.number, \"hash\", notification.hash, \"distance\", dist)\n                    propAnnounceDropMeter.Mark(1)\n                    break\n                }\n            }\n            // All is well, schedule the announce if block's not yet downloading\n            if _, ok := f.fetching[notification.hash]; ok {\n                break\n            }\n            if _, ok := f.completing[notification.hash]; ok {\n                break\n            }\n            f.announces[notification.origin] = count\n            f.announced[notification.hash] = append(f.announced[notification.hash], notification)\n            if f.announceChangeHook != nil && len(f.announced[notification.hash]) == 1 {\n                f.announceChangeHook(notification.hash, true)\n            }\n            if len(f.announced) == 1 {\n                f.rescheduleFetch(fetchTimer)\n            }\n\n\n```\n\n1，将收到的不满足条件的通知都丢弃掉，如果在f.fetching 状态列表里和f.completing 状态列表里，也直接返回。接着更新notification.origin 这个节点的announces 数量，添加到f.announced 等待fetch的表里。\n2，如果len(f.announced[notification.hash]) == 1 说明f.announced只有这一个通知，则调用f.announceChangeHook。\n3，如果len(f.announced) == 1 也说明只有一个通知，则启动fetchTimer的调度。\n\n```\ncase <-fetchTimer.C:\n            // At least one block's timer ran out, check for needing retrieval\n            request := make(map[string][]common.Hash)\n\n            for hash, announces := range f.announced {\n                if time.Since(announces[0].time) > arriveTimeout-gatherSlack {\n                    // Pick a random peer to retrieve from, reset all others\n                    announce := announces[rand.Intn(len(announces))]\n                    f.forgetHash(hash)\n\n                    // If the block still didn't arrive, queue for fetching\n                    if f.getBlock(hash) == nil {\n                        request[announce.origin] = append(request[announce.origin], hash)\n                        f.fetching[hash] = announce\n                    }\n                }\n            }\n            // Send out all block header requests\n            for peer, hashes := range request {\n                log.Trace(\"Fetching scheduled headers\", \"peer\", peer, \"list\", hashes)\n\n                // Create a closure of the fetch and schedule in on a new thread\n                fetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes\n                go func() {\n                    if f.fetchingHook != nil {\n                        f.fetchingHook(hashes)\n                    }\n                    for _, hash := range hashes {\n                        headerFetchMeter.Mark(1)\n                        fetchHeader(hash) // Suboptimal, but protocol doesn't allow batch header retrievals\n                    }\n                }()\n            }\n            // Schedule the next fetch if blocks are still pending\n            f.rescheduleFetch(fetchTimer)\n\n\n```\n\n1，首先遍历f.announced，如果超过了arriveTimeout-gatherSlack这个时间，把这个hash对应在fetcher里面的状态都清了。\n这里随机拿这个announces里面任意一个announce，为啥随机取一个呢？因为都是同一个block的hash，这个hash下的哪一个announce都是一样的。\n如果发现超时了还没有没有获取到这个hash的block，则把这个announce加到request列表中，同时重新把announce放到f.fetching状态列表。\n2，然后遍历request列表，request列表里面的每个网络节点过来的所有的block的hash，都会调用fetchHeader(hash)方法来获取header数据。\n这个fetchHeader(hash)方法是pm.fetcher.Notify传进来的，peer.go\n里面的一个全局方法。\n3， 这时候NewBlockHashesMsg 的fetcher处理就结束了，最后再启动fetchTimer的调度。\n\n三，Fetcher分析， 之FilterHeaders()\nfetchHeader(hash)方法，调用了peer.go 里面的全局方法RequestOneHeader(hash common.Hash)  Send给网络节点一个GetBlockHeadersMsg 消息。\n然后pm.handleMsg 收到 BlockHashesMsg广播通知\n\n```\ncase msg.Code == BlockHeadersMsg:\n        // A batch of headers arrived to one of our previous requests\n        var headers []*types.Header\n        if err := msg.Decode(&headers); err != nil {\n            return errResp(ErrDecode, \"msg %v: %v\", msg, err)\n        }\n        // If no headers were received, but we're expending a DAO fork check, maybe it's that\n        if len(headers) == 0 && p.forkDrop != nil {\n            // Possibly an empty reply to the fork header checks, sanity check TDs\n            verifyDAO := true\n\n            // If we already have a DAO header, we can check the peer's TD against it. If\n            // the peer's ahead of this, it too must have a reply to the DAO check\n            if daoHeader := pm.blockchain.GetHeaderByNumber(pm.chainconfig.DAOForkBlock.Uint64()); daoHeader != nil {\n                if _, td := p.Head(); td.Cmp(pm.blockchain.GetTd(daoHeader.Hash(), daoHeader.Number.Uint64())) >= 0 {\n                    verifyDAO = false\n                }\n            }\n            // If we're seemingly on the same chain, disable the drop timer\n            if verifyDAO {\n                p.Log().Debug(\"Seems to be on the same side of the DAO fork\")\n                p.forkDrop.Stop()\n                p.forkDrop = nil\n                return nil\n            }\n        }\n        // Filter out any explicitly requested headers, deliver the rest to the downloader\n        filter := len(headers) == 1\n        if filter {\n            // If it's a potential DAO fork check, validate against the rules\n            if p.forkDrop != nil && pm.chainconfig.DAOForkBlock.Cmp(headers[0].Number) == 0 {\n                // Disable the fork drop timer\n                p.forkDrop.Stop()\n                p.forkDrop = nil\n\n                // Validate the header and either drop the peer or continue\n                if err := misc.VerifyDAOHeaderExtraData(pm.chainconfig, headers[0]); err != nil {\n                    p.Log().Debug(\"Verified to be on the other side of the DAO fork, dropping\")\n                    return err\n                }\n                p.Log().Debug(\"Verified to be on the same side of the DAO fork\")\n                return nil\n            }\n            // Irrelevant of the fork checks, send the header to the fetcher just in case\n            headers = pm.fetcher.FilterHeaders(p.id, headers, time.Now())\n        }\n        if len(headers) > 0 || !filter {\n            err := pm.downloader.DeliverHeaders(p.id, headers)\n            if err != nil {\n                log.Debug(\"Failed to deliver headers\", \"err\", err)\n            }\n        }\n\n\n```\n\n如果不是硬分叉的daoHeader，同时len(headers) == 1，则执行pm.fetcher.FilterHeaders(p.id, headers, time.Now())方法\n\n```\nfunc (f *Fetcher) FilterHeaders(peer string, headers []*types.Header, time time.Time) []*types.Header {\n    log.Trace(\"Filtering headers\", \"peer\", peer, \"headers\", len(headers))\n\n    // Send the filter channel to the fetcher\n    filter := make(chan *headerFilterTask)\n\n    select {\n    case f.headerFilter <- filter:\n    case <-f.quit:\n        return nil\n    }\n    // Request the filtering of the header list\n    select {\n    case filter <- &headerFilterTask{peer: peer, headers: headers, time: time}:\n    case <-f.quit:\n        return nil\n    }\n    // Retrieve the headers remaining after filtering\n    select {\n    case task := <-filter:\n        return task.headers\n    case <-f.quit:\n        return nil\n    }\n}\n\n\n```\n\nsend 一个filter 到f.headerFilter，fetcher的loop()主回路里f.headerFilter receive 到这个filter，进行处理。\n\n```\ncase filter := <-f.headerFilter:\n            // Headers arrived from a remote peer. Extract those that were explicitly\n            // requested by the fetcher, and return everything else so it's delivered\n            // to other parts of the system.\n            var task *headerFilterTask\n            select {\n            case task = <-filter:\n            case <-f.quit:\n                return\n            }\n            headerFilterInMeter.Mark(int64(len(task.headers)))\n\n            // Split the batch of headers into unknown ones (to return to the caller),\n            // known incomplete ones (requiring body retrievals) and completed blocks.\n            unknown, incomplete, complete := []*types.Header{}, []*announce{}, []*types.Block{}\n            for _, header := range task.headers {\n                hash := header.Hash()\n\n                // Filter fetcher-requested headers from other synchronisation algorithms\n                if announce := f.fetching[hash]; announce != nil && announce.origin == task.peer && f.fetched[hash] == nil && f.completing[hash] == nil && f.queued[hash] == nil {\n                    // If the delivered header does not match the promised number, drop the announcer\n                    if header.Number.Uint64() != announce.number {\n                        log.Trace(\"Invalid block number fetched\", \"peer\", announce.origin, \"hash\", header.Hash(), \"announced\", announce.number, \"provided\", header.Number)\n                        f.dropPeer(announce.origin)\n                        f.forgetHash(hash)\n                        continue\n                    }\n                    // Only keep if not imported by other means\n                    if f.getBlock(hash) == nil {\n                        announce.header = header\n                        announce.time = task.time\n\n                        // If the block is empty (header only), short circuit into the final import queue\n                        if header.TxHash == types.DeriveSha(types.Transactions{}) && header.UncleHash == types.CalcUncleHash([]*types.Header{}) {\n                            log.Trace(\"Block empty, skipping body retrieval\", \"peer\", announce.origin, \"number\", header.Number, \"hash\", header.Hash())\n\n                            block := types.NewBlockWithHeader(header)\n                            block.ReceivedAt = task.time\n\n                            complete = append(complete, block)\n                            f.completing[hash] = announce\n                            continue\n                        }\n                        // Otherwise add to the list of blocks needing completion\n                        incomplete = append(incomplete, announce)\n                    } else {\n                        log.Trace(\"Block already imported, discarding header\", \"peer\", announce.origin, \"number\", header.Number, \"hash\", header.Hash())\n                        f.forgetHash(hash)\n                    }\n                } else {\n                    // Fetcher doesn't know about it, add to the return list\n                    unknown = append(unknown, header)\n                }\n            }\n            headerFilterOutMeter.Mark(int64(len(unknown)))\n            select {\n            case filter <- &headerFilterTask{headers: unknown, time: task.time}:\n            case <-f.quit:\n                return\n            }\n            // Schedule the retrieved headers for body completion\n            for _, announce := range incomplete {\n                hash := announce.header.Hash()\n                if _, ok := f.completing[hash]; ok {\n                    continue\n                }\n                f.fetched[hash] = append(f.fetched[hash], announce)\n                if len(f.fetched) == 1 {\n                    f.rescheduleComplete(completeTimer)\n                }\n            }\n            // Schedule the header-only blocks for import\n            for _, block := range complete {\n                if announce := f.completing[block.Hash()]; announce != nil {\n                    f.enqueue(announce.origin, block)\n                }\n            }\n\n\n```\n\n1，遍历headerFilter里面的各个header，如果在 f.fetching状态列表，且不在f.fetched状态列表和 f.completing状态列表，就继续进行过滤，否则塞进unknown队列 发送给filter，FilterHeaders里面task 接收到filter，并作为FilterHeaders的返回值返回。\n2，如果发现这个header的number和从f.fetching状态列表取到的announce的number不一样，说明有可能收到一个伪造的区块通知，此时就要把这个可能的伪造节点和可能的伪造的hash抛弃，另可错杀，不能放过。\n3，如果本节点已经有这个hash的block，则放弃这个hash。如果这个block里面没有任何交易也没有任何叔区块，则把这个hash放入complete列表同时加入f.completing状态列表，否则放入incomplete列表。\n4，在incomplete列表里面，且不在f.completing状态列表里，则加入f.fetched状态列表，启动completeTimer的调度。\n5，在complete列表里面，同时也在f.completing状态列表，则调用f.enqueue(announce.origin, block)方法。\n\n```\ncase <-completeTimer.C:\n            // At least one header's timer ran out, retrieve everything\n            request := make(map[string][]common.Hash)\n\n            for hash, announces := range f.fetched {\n                // Pick a random peer to retrieve from, reset all others\n                announce := announces[rand.Intn(len(announces))]\n                f.forgetHash(hash)\n\n                // If the block still didn't arrive, queue for completion\n                if f.getBlock(hash) == nil {\n                    request[announce.origin] = append(request[announce.origin], hash)\n                    f.completing[hash] = announce\n                }\n            }\n            // Send out all block body requests\n            for peer, hashes := range request {\n                log.Trace(\"Fetching scheduled bodies\", \"peer\", peer, \"list\", hashes)\n\n                // Create a closure of the fetch and schedule in on a new thread\n                if f.completingHook != nil {\n                    f.completingHook(hashes)\n                }\n                bodyFetchMeter.Mark(int64(len(hashes)))\n                go f.completing[hashes[0]].fetchBodies(hashes)\n            }\n            // Schedule the next fetch if blocks are still pending\n            f.rescheduleComplete(completeTimer)\n\n```\n\n1，首先遍历f.fetched，hash对应在fetcher里面的状态都清了。\n如果发现超时了还没有没有获取到这个hash的block，则把这个announce加到request列表中，同时重新把announce放到f.completing状态列表。\n2，然后遍历request列表，request列表里面的每个网络节点过来的所有的block的hash，都会调用fetchBodies(hashes)方法来获取区块body数据。这个fetchBodies(hashes)方法是peer.go里面的一个全局方法。\n3， 这时候BlockHashesMsg 的fetcher处理就结束了，最后再启动completeTimer循环调度。\n\n四，Fetcher分析， 之FilterBodies() ，Enqueue(），\n1，fetchBodies(hash)方法，调用了peer.go 里面的全局方法RequestBodies(hashes []common.Hash) Send给网络节点一个GetBlockBodiesMsg 消息。\n2，然后pm.handleMsg 会收到 BlockBodiesMsg广播通知。\n3，执行 pm.fetcher.FilterBodies(p.id, trasactions, uncles, time.Now())。\n接下来就和FilterHeaders()流程类似，一顿啪啪啪验证，一顿啪啪啪改变状态，一顿啪啪啪通道跳转\n4，庆幸的是，走完FilterBodies()就完事了，不用在走timer调度，也不用再发网络请求了。\n5，在FilterHeaders()和FilterBodies()最后都走到了f.enqueue(announce.origin, block)方法\n\n```\nfunc (f *Fetcher) enqueue(peer string, block *types.Block) {\n    hash := block.Hash()\n\n    // Ensure the peer isn't DOSing us\n    count := f.queues[peer] + 1\n    if count > blockLimit {\n        log.Debug(\"Discarded propagated block, exceeded allowance\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"limit\", blockLimit)\n        propBroadcastDOSMeter.Mark(1)\n        f.forgetHash(hash)\n        return\n    }\n    // Discard any past or too distant blocks\n    if dist := int64(block.NumberU64()) - int64(f.chainHeight()); dist < -maxUncleDist || dist > maxQueueDist {\n        log.Debug(\"Discarded propagated block, too far away\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"distance\", dist)\n        propBroadcastDropMeter.Mark(1)\n        f.forgetHash(hash)\n        return\n    }\n    // Schedule the block for future importing\n    if _, ok := f.queued[hash]; !ok {\n        op := &inject{\n            origin: peer,\n            block:  block,\n        }\n        f.queues[peer] = count\n        f.queued[hash] = op\n        f.queue.Push(op, -float32(block.NumberU64()))\n        if f.queueChangeHook != nil {\n            f.queueChangeHook(op.block.Hash(), true)\n        }\n        log.Debug(\"Queued propagated block\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"queued\", f.queue.Size())\n    }\n}\n\n```\n\n过滤掉太远的区块。并把hash加入到f.queue列表中。\n在loop主回路里面遍历f.queue列表，并把列表中的block insert到本地的block chain中。\n\n```\nfunc (f *Fetcher) insert(peer string, block *types.Block) {\n    hash := block.Hash()\n\n    // Run the import on a new thread\n    log.Debug(\"Importing propagated block\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash)\n    go func() {\n        defer func() { f.done <- hash }()\n\n        // If the parent's unknown, abort insertion\n        parent := f.getBlock(block.ParentHash())\n        if parent == nil {\n            log.Debug(\"Unknown parent of propagated block\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"parent\", block.ParentHash())\n            return\n        }\n        // Quickly validate the header and propagate the block if it passes\n        switch err := f.verifyHeader(block.Header()); err {\n        case nil:\n            // All ok, quickly propagate to our peers\n            propBroadcastOutTimer.UpdateSince(block.ReceivedAt)\n            go f.broadcastBlock(block, true)\n\n        case consensus.ErrFutureBlock:\n            // Weird future block, don't fail, but neither propagate\n\n        default:\n            // Something went very wrong, drop the peer\n            log.Debug(\"Propagated block verification failed\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"err\", err)\n            f.dropPeer(peer)\n            return\n        }\n        // Run the actual import and log any issues\n        if _, err := f.insertChain(types.Blocks{block}); err != nil {\n            log.Debug(\"Propagated block import failed\", \"peer\", peer, \"number\", block.Number(), \"hash\", hash, \"err\", err)\n            return\n        }\n        // If import succeeded, broadcast the block\n        propAnnounceOutTimer.UpdateSince(block.ReceivedAt)\n        go f.broadcastBlock(block, false)\n\n        // Invoke the testing hook if needed\n        if f.importedHook != nil {\n            f.importedHook(block)\n        }\n    }()\n}\n\n\n```\n\n首先调用共识引擎的方法f.verifyHeader(block.Header())，验证blockHeader的有效性。\n如果没问题就广播出去，告诉全世界我的区块链更新了一个新区块。\n然后调用f.insertChain(types.Blocks{block}) 插入本地区块链。\n插入成功，最后再广播一次(这是多么的自恋啊)，这次只广播block的hash。\n\n总结\nfetcher.go 作为以太坊同步区块的一个辅助类，它的职责就是层层把关，层层过滤，抵制无效的区块进入，杜绝无用的同步请求。这块代码很多很乱，第一次看可能会有点晕，第二次看可能还是很晕，多看几次可能还会晕😄，不过只要知道它做什么就好了。\n\n\n\n\n\n#### Downloader\n\n一，启动Downloader\nProtocolManager初始化的时候会进行Downloader的初始化：\n\n```\nfunc New(mode SyncMode, stateDb ethdb.Database, mux *event.TypeMux, chain BlockChain, lightchain LightChain, dropPeer peerDropFn) *Downloader {\n    if lightchain == nil {\n        lightchain = chain\n    }\n\n    dl := &Downloader{\n        mode:           mode,\n        stateDB:        stateDb,\n        mux:            mux,\n        queue:          newQueue(),\n        peers:          newPeerSet(),\n        rttEstimate:    uint64(rttMaxEstimate),\n        rttConfidence:  uint64(1000000),\n        blockchain:     chain,\n        lightchain:     lightchain,\n        dropPeer:       dropPeer,\n        headerCh:       make(chan dataPack, 1),\n        bodyCh:         make(chan dataPack, 1),\n        receiptCh:      make(chan dataPack, 1),\n        bodyWakeCh:     make(chan bool, 1),\n        receiptWakeCh:  make(chan bool, 1),\n        headerProcCh:   make(chan []*types.Header, 1),\n        quitCh:         make(chan struct{}),\n        stateCh:        make(chan dataPack),\n        stateSyncStart: make(chan *stateSync),\n        trackStateReq:  make(chan *stateReq),\n    }\n    go dl.qosTuner()\n    go dl.stateFetcher()\n    return dl\n}\n\n```\n\n首先初始化Downloader对象的成员，然后启动dl.qosTuner() goroutine计算请求回路时间，启动dl.stateFetcher() goroutine 开启Downloader状态监控。\n\nProtocolManager收到新的区块消息广播或者有新的P2P网络节点加入的时候会调用ProtocolManager的 synchronise(peer *peer)方法，这时候会调用Downloader的Synchronise(peer.id, pHead, pTd, mode)方法。\n\nSynchronise方法，重置d.queue和d.peers，清空d.bodyWakeCh, d.receiptWakeCh，d.headerCh, d.bodyCh, d.receiptCh，d.headerProcCh。调用d.syncWithPeer(p, hash, td)方法：\n\n```\nfunc (d *Downloader) syncWithPeer(p *peerConnection, hash common.Hash, td *big.Int) (err error) {\n    d.mux.Post(StartEvent{})\n    defer func() {\n        // reset on error\n        if err != nil {\n            d.mux.Post(FailedEvent{err})\n        } else {\n            d.mux.Post(DoneEvent{})\n        }\n    }()\n    if p.version < 62 {\n        return errTooOld\n    }\n\n    log.Debug(\"Synchronising with the network\", \"peer\", p.id, \"eth\", p.version, \"head\", hash, \"td\", td, \"mode\", d.mode)\n    defer func(start time.Time) {\n        log.Debug(\"Synchronisation terminated\", \"elapsed\", time.Since(start))\n    }(time.Now())\n\n    // Look up the sync boundaries: the common ancestor and the target block\n    latest, err := d.fetchHeight(p)\n    if err != nil {\n        return err\n    }\n    height := latest.Number.Uint64()\n\n    origin, err := d.findAncestor(p, height)\n    if err != nil {\n        return err\n    }\n    d.syncStatsLock.Lock()\n    if d.syncStatsChainHeight <= origin || d.syncStatsChainOrigin > origin {\n        d.syncStatsChainOrigin = origin\n    }\n    d.syncStatsChainHeight = height\n    d.syncStatsLock.Unlock()\n\n    // Ensure our origin point is below any fast sync pivot point\n    pivot := uint64(0)\n    if d.mode == FastSync {\n        if height <= uint64(fsMinFullBlocks) {\n            origin = 0\n        } else {\n            pivot = height - uint64(fsMinFullBlocks)\n            if pivot <= origin {\n                origin = pivot - 1\n            }\n        }\n    }\n    d.committed = 1\n    if d.mode == FastSync && pivot != 0 {\n        d.committed = 0\n    }\n    // Initiate the sync using a concurrent header and content retrieval algorithm\n    d.queue.Prepare(origin+1, d.mode)\n    if d.syncInitHook != nil {\n        d.syncInitHook(origin, height)\n    }\n\n    fetchers := []func() error{\n        func() error { return d.fetchHeaders(p, origin+1, pivot) }, // Headers are always retrieved\n        func() error { return d.fetchBodies(origin + 1) },          // Bodies are retrieved during normal and fast sync\n        func() error { return d.fetchReceipts(origin + 1) },        // Receipts are retrieved during fast sync\n        func() error { return d.processHeaders(origin+1, pivot, td) },\n    }\n    if d.mode == FastSync {\n        fetchers = append(fetchers, func() error { return d.processFastSyncContent(latest) })\n    } else if d.mode == FullSync {\n        fetchers = append(fetchers, d.processFullSyncContent)\n    }\n    return d.spawnSync(fetchers)\n}\n\n```\n\n首先调用latest, err := d.fetchHeight(p)获取到peer节点最新的区块头,这个方法有点绕，我们来分析一下：\n\n```\nfunc (d *Downloader) fetchHeight(p *peerConnection) (*types.Header, error) {\n    p.log.Debug(\"Retrieving remote chain height\")\n\n    // Request the advertised remote head block and wait for the response\n    head, _ := p.peer.Head()\n    go p.peer.RequestHeadersByHash(head, 1, 0, false)\n\n    ttl := d.requestTTL()\n    timeout := time.After(ttl)\n    for {\n        select {\n        case <-d.cancelCh:\n            return nil, errCancelBlockFetch\n\n        case packet := <-d.headerCh:\n            // Discard anything not from the origin peer\n            if packet.PeerId() != p.id {\n                log.Debug(\"Received headers from incorrect peer\", \"peer\", packet.PeerId())\n                break\n            }\n            // Make sure the peer actually gave something valid\n            headers := packet.(*headerPack).headers\n            if len(headers) != 1 {\n                p.log.Debug(\"Multiple headers for single request\", \"headers\", len(headers))\n                return nil, errBadPeer\n            }\n            head := headers[0]\n            p.log.Debug(\"Remote head header identified\", \"number\", head.Number, \"hash\", head.Hash())\n            return head, nil\n\n        case <-timeout:\n            p.log.Debug(\"Waiting for head header timed out\", \"elapsed\", ttl)\n            return nil, errTimeout\n\n        case <-d.bodyCh:\n        case <-d.receiptCh:\n            // Out of bounds delivery, ignore\n        }\n    }\n}\n\n\n```\n\n1，调用peer.RequestHeadersByHash(head, 1, 0, false)，给网络节点发送一个GetBlockHeadersMsg的消息\n2，然后阻塞住线程，直到收到d.headerCh或者timeout\n3，本地节点会收到网络节点的BlockHeadersMsg的消息返回\n4，调用downloader.DeliverHeaders(p.id, headers)\n5，这时候会把p.id和headers打包发送给d.headerCh\n6，这时候select收到d.headerCh，阻塞打开，并返回header内容\n\nsyncWithPeer() 方法接着调用 d.findAncestor(p, height)来获取本地节点和网络节点共同的祖先：\n\n```\nfunc (d *Downloader) findAncestor(p *peerConnection, height uint64) (uint64, error) {\n    // Figure out the valid ancestor range to prevent rewrite attacks\n    floor, ceil := int64(-1), d.lightchain.CurrentHeader().Number.Uint64()\n\n    if d.mode == FullSync {\n        ceil = d.blockchain.CurrentBlock().NumberU64()\n    } else if d.mode == FastSync {\n        ceil = d.blockchain.CurrentFastBlock().NumberU64()\n    }\n    if ceil >= MaxForkAncestry {\n        floor = int64(ceil - MaxForkAncestry)\n    }\n    p.log.Debug(\"Looking for common ancestor\", \"local\", ceil, \"remote\", height)\n\n    // Request the topmost blocks to short circuit binary ancestor lookup\n    head := ceil\n    if head > height {\n        head = height\n    }\n    from := int64(head) - int64(MaxHeaderFetch)\n    if from < 0 {\n        from = 0\n    }\n    // Span out with 15 block gaps into the future to catch bad head reports\n    limit := 2 * MaxHeaderFetch / 16\n    count := 1 + int((int64(ceil)-from)/16)\n    if count > limit {\n        count = limit\n    }\n    go p.peer.RequestHeadersByNumber(uint64(from), count, 15, false)\n\n    // Wait for the remote response to the head fetch\n    number, hash := uint64(0), common.Hash{}\n\n    ttl := d.requestTTL()\n    timeout := time.After(ttl)\n\n    for finished := false; !finished; {\n        select {\n        case <-d.cancelCh:\n            return 0, errCancelHeaderFetch\n\n        case packet := <-d.headerCh:\n            // Discard anything not from the origin peer\n            if packet.PeerId() != p.id {\n                log.Debug(\"Received headers from incorrect peer\", \"peer\", packet.PeerId())\n                break\n            }\n            // Make sure the peer actually gave something valid\n            headers := packet.(*headerPack).headers\n            if len(headers) == 0 {\n                p.log.Warn(\"Empty head header set\")\n                return 0, errEmptyHeaderSet\n            }\n            // Make sure the peer's reply conforms to the request\n            for i := 0; i < len(headers); i++ {\n                if number := headers[i].Number.Int64(); number != from+int64(i)*16 {\n                    p.log.Warn(\"Head headers broke chain ordering\", \"index\", i, \"requested\", from+int64(i)*16, \"received\", number)\n                    return 0, errInvalidChain\n                }\n            }\n            // Check if a common ancestor was found\n            finished = true\n            for i := len(headers) - 1; i >= 0; i-- {\n                // Skip any headers that underflow/overflow our requested set\n                if headers[i].Number.Int64() < from || headers[i].Number.Uint64() > ceil {\n                    continue\n                }\n                // Otherwise check if we already know the header or not\n                if (d.mode == FullSync && d.blockchain.HasBlock(headers[i].Hash(), headers[i].Number.Uint64())) || (d.mode != FullSync && d.lightchain.HasHeader(headers[i].Hash(), headers[i].Number.Uint64())) {\n                    number, hash = headers[i].Number.Uint64(), headers[i].Hash()\n\n                    // If every header is known, even future ones, the peer straight out lied about its head\n                    if number > height && i == limit-1 {\n                        p.log.Warn(\"Lied about chain head\", \"reported\", height, \"found\", number)\n                        return 0, errStallingPeer\n                    }\n                    break\n                }\n            }\n\n        case <-timeout:\n            p.log.Debug(\"Waiting for head header timed out\", \"elapsed\", ttl)\n            return 0, errTimeout\n\n        case <-d.bodyCh:\n        case <-d.receiptCh:\n            // Out of bounds delivery, ignore\n        }\n    }\n    // If the head fetch already found an ancestor, return\n    if !common.EmptyHash(hash) {\n        if int64(number) <= floor {\n            p.log.Warn(\"Ancestor below allowance\", \"number\", number, \"hash\", hash, \"allowance\", floor)\n            return 0, errInvalidAncestor\n        }\n        p.log.Debug(\"Found common ancestor\", \"number\", number, \"hash\", hash)\n        return number, nil\n    }\n    // Ancestor not found, we need to binary search over our chain\n    start, end := uint64(0), head\n    if floor > 0 {\n        start = uint64(floor)\n    }\n    for start+1 < end {\n        // Split our chain interval in two, and request the hash to cross check\n        check := (start + end) / 2\n\n        ttl := d.requestTTL()\n        timeout := time.After(ttl)\n\n        go p.peer.RequestHeadersByNumber(check, 1, 0, false)\n\n        // Wait until a reply arrives to this request\n        for arrived := false; !arrived; {\n            select {\n            case <-d.cancelCh:\n                return 0, errCancelHeaderFetch\n\n            case packer := <-d.headerCh:\n                // Discard anything not from the origin peer\n                if packer.PeerId() != p.id {\n                    log.Debug(\"Received headers from incorrect peer\", \"peer\", packer.PeerId())\n                    break\n                }\n                // Make sure the peer actually gave something valid\n                headers := packer.(*headerPack).headers\n                if len(headers) != 1 {\n                    p.log.Debug(\"Multiple headers for single request\", \"headers\", len(headers))\n                    return 0, errBadPeer\n                }\n                arrived = true\n\n                // Modify the search interval based on the response\n                if (d.mode == FullSync && !d.blockchain.HasBlock(headers[0].Hash(), headers[0].Number.Uint64())) || (d.mode != FullSync && !d.lightchain.HasHeader(headers[0].Hash(), headers[0].Number.Uint64())) {\n                    end = check\n                    break\n                }\n                header := d.lightchain.GetHeaderByHash(headers[0].Hash()) // Independent of sync mode, header surely exists\n                if header.Number.Uint64() != check {\n                    p.log.Debug(\"Received non requested header\", \"number\", header.Number, \"hash\", header.Hash(), \"request\", check)\n                    return 0, errBadPeer\n                }\n                start = check\n\n            case <-timeout:\n                p.log.Debug(\"Waiting for search header timed out\", \"elapsed\", ttl)\n                return 0, errTimeout\n\n            case <-d.bodyCh:\n            case <-d.receiptCh:\n                // Out of bounds delivery, ignore\n            }\n        }\n    }\n    // Ensure valid ancestry and return\n    if int64(start) <= floor {\n        p.log.Warn(\"Ancestor below allowance\", \"number\", start, \"hash\", hash, \"allowance\", floor)\n        return 0, errInvalidAncestor\n    }\n    p.log.Debug(\"Found common ancestor\", \"number\", start, \"hash\", hash)\n    return start, nil\n}\n\n```\n\n1，调用peer.RequestHeadersByNumber(uint64(from), count, 15, false)，获取header。这里传入 count和 15，指从本地最高的header往前数192个区块的头，每16个区块取一个区块头。为了后面select收到d.headerCh时加以验证。\n2，select收到了headers，遍历header，看是否在本地是否存在这个header，如果有，并且不为空，就说明找到共同的祖先，返回祖先number\n3，如果没有找到共同的祖先，再重新从本地的区块链MaxForkAncestry起的一半的位置开始取区块头，一一验证是否跟网络节点返回的header一致，如果有就说明有共同的祖先，并返回，没有的话就返回0.\n\n继续syncWithPeer()方法，找到同步的轴心的pivot，最后把要同步的数据和同步的方法传给d.spawnSync(fetchers)，并执行。d.spawnSync(fetchers)挨个执行传入的同步方法。\n\n二，Downloader同步数据方法\nfetchHeaders()，fetchBodies() , fetchReceipts()\n\n```\nfunc (d *Downloader) fetchHeaders(p *peerConnection, from uint64, pivot uint64) error {\n    p.log.Debug(\"Directing header downloads\", \"origin\", from)\n    defer p.log.Debug(\"Header download terminated\")\n\n    // Create a timeout timer, and the associated header fetcher\n    skeleton := true            // Skeleton assembly phase or finishing up\n    request := time.Now()       // time of the last skeleton fetch request\n    timeout := time.NewTimer(0) // timer to dump a non-responsive active peer\n    <-timeout.C                 // timeout channel should be initially empty\n    defer timeout.Stop()\n\n    var ttl time.Duration\n    getHeaders := func(from uint64) {\n        request = time.Now()\n\n        ttl = d.requestTTL()\n        timeout.Reset(ttl)\n\n        if skeleton {\n            p.log.Trace(\"Fetching skeleton headers\", \"count\", MaxHeaderFetch, \"from\", from)\n            go p.peer.RequestHeadersByNumber(from+uint64(MaxHeaderFetch)-1, MaxSkeletonSize, MaxHeaderFetch-1, false)\n        } else {\n            p.log.Trace(\"Fetching full headers\", \"count\", MaxHeaderFetch, \"from\", from)\n            go p.peer.RequestHeadersByNumber(from, MaxHeaderFetch, 0, false)\n        }\n    }\n    // Start pulling the header chain skeleton until all is done\n    getHeaders(from)\n\n    for {\n        select {\n        case <-d.cancelCh:\n            return errCancelHeaderFetch\n\n        case packet := <-d.headerCh:\n            // Make sure the active peer is giving us the skeleton headers\n            if packet.PeerId() != p.id {\n                log.Debug(\"Received skeleton from incorrect peer\", \"peer\", packet.PeerId())\n                break\n            }\n            headerReqTimer.UpdateSince(request)\n            timeout.Stop()\n\n            // If the skeleton's finished, pull any remaining head headers directly from the origin\n            if packet.Items() == 0 && skeleton {\n                skeleton = false\n                getHeaders(from)\n                continue\n            }\n            // If no more headers are inbound, notify the content fetchers and return\n            if packet.Items() == 0 {\n                // Don't abort header fetches while the pivot is downloading\n                if atomic.LoadInt32(&d.committed) == 0 && pivot <= from {\n                    p.log.Debug(\"No headers, waiting for pivot commit\")\n                    select {\n                    case <-time.After(fsHeaderContCheck):\n                        getHeaders(from)\n                        continue\n                    case <-d.cancelCh:\n                        return errCancelHeaderFetch\n                    }\n                }\n                // Pivot done (or not in fast sync) and no more headers, terminate the process\n                p.log.Debug(\"No more headers available\")\n                select {\n                case d.headerProcCh <- nil:\n                    return nil\n                case <-d.cancelCh:\n                    return errCancelHeaderFetch\n                }\n            }\n            headers := packet.(*headerPack).headers\n\n            // If we received a skeleton batch, resolve internals concurrently\n            if skeleton {\n                filled, proced, err := d.fillHeaderSkeleton(from, headers)\n                if err != nil {\n                    p.log.Debug(\"Skeleton chain invalid\", \"err\", err)\n                    return errInvalidChain\n                }\n                headers = filled[proced:]\n                from += uint64(proced)\n            }\n            // Insert all the new headers and fetch the next batch\n            if len(headers) > 0 {\n                p.log.Trace(\"Scheduling new headers\", \"count\", len(headers), \"from\", from)\n                select {\n                case d.headerProcCh <- headers:\n                case <-d.cancelCh:\n                    return errCancelHeaderFetch\n                }\n                from += uint64(len(headers))\n            }\n            getHeaders(from)\n\n        case <-timeout.C:\n            if d.dropPeer == nil {\n                // The dropPeer method is nil when `--copydb` is used for a local copy.\n                // Timeouts can occur if e.g. compaction hits at the wrong time, and can be ignored\n                p.log.Warn(\"Downloader wants to drop peer, but peerdrop-function is not set\", \"peer\", p.id)\n                break\n            }\n            // Header retrieval timed out, consider the peer bad and drop\n            p.log.Debug(\"Header request timed out\", \"elapsed\", ttl)\n            headerTimeoutMeter.Mark(1)\n            d.dropPeer(p.id)\n\n            // Finish the sync gracefully instead of dumping the gathered data though\n            for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n                select {\n                case ch <- false:\n                case <-d.cancelCh:\n                }\n            }\n            select {\n            case d.headerProcCh <- nil:\n            case <-d.cancelCh:\n            }\n            return errBadPeer\n        }\n    }\n}\n\n```\n\n1，getHeaders()调用peer.RequestHeadersByNumber()方法 获取网络节点的headers。\n2，有两种获取方式，首先走的是skeleton方式，从查找到的共同祖先区块+192个区块位置开始，每隔192个区块，获取128个区块头。非skeleton方式，从共同祖先区块开始，获取192个区块头。\n3，如果第一种方式获取不到区块头，则执行第二种获取方式，如果第二种方式还是没有获取到区块头的话，直接返回\n4，如果是skeleton获取到的，调用fillHeaderSkeleton()方法加入到skeleton header chain\n5，然后调整from值，再递归调用getHeaders()方法\n\n```\nfunc (d *Downloader) fillHeaderSkeleton(from uint64, skeleton []*types.Header) ([]*types.Header, int, error) {\n    log.Debug(\"Filling up skeleton\", \"from\", from)\n    d.queue.ScheduleSkeleton(from, skeleton)\n\n    var (\n        deliver = func(packet dataPack) (int, error) {\n            pack := packet.(*headerPack)\n            return d.queue.DeliverHeaders(pack.peerId, pack.headers, d.headerProcCh)\n        }\n        expire   = func() map[string]int { return d.queue.ExpireHeaders(d.requestTTL()) }\n        throttle = func() bool { return false }\n        reserve  = func(p *peerConnection, count int) (*fetchRequest, bool, error) {\n            return d.queue.ReserveHeaders(p, count), false, nil\n        }\n        fetch    = func(p *peerConnection, req *fetchRequest) error { return p.FetchHeaders(req.From, MaxHeaderFetch) }\n        capacity = func(p *peerConnection) int { return p.HeaderCapacity(d.requestRTT()) }\n        setIdle  = func(p *peerConnection, accepted int) { p.SetHeadersIdle(accepted) }\n    )\n    err := d.fetchParts(errCancelHeaderFetch, d.headerCh, deliver, d.queue.headerContCh, expire,\n        d.queue.PendingHeaders, d.queue.InFlightHeaders, throttle, reserve,\n        nil, fetch, d.queue.CancelHeaders, capacity, d.peers.HeaderIdlePeers, setIdle, \"headers\")\n\n    log.Debug(\"Skeleton fill terminated\", \"err\", err)\n\n    filled, proced := d.queue.RetrieveHeaders()\n    return filled, proced, err\n}\n\n\n```\n\na) 把skeleton的headers加入queue.ScheduleSkeleton调度队列，\nb) 然后执行d.fetchParts()方法。\nd.fetchParts()方法主要做了这几件事情\n1，对收到的headers执行d.queue.DeliverHeaders()方法。\n2，如果d.queue.PendingHeaders有pending的headers，调用d.peers.HeaderIdlePeers获取到idle的peers\n3，调用d.queue.ReserveHeaders把pending的headers储备到idle的peers里面\n4，用idle的peers调用p.FetchHeaders(req.From, MaxHeaderFetch)去获取headers\nc) 最后执行d.queue.RetrieveHeaders()，获取到filled进去的headers\n\n其他同步区块数据的方法d.fetchBodies() , d.fetchReceipts() 和fetchHeaders()流程类似，还更简单一些。\n\n三，Downloader同步数据过程\nd.processHeaders(), d.processFastSyncContent(latest) , d.processFullSyncContent\n1，d.processHeaders() 方法\n\n```\nfunc (d *Downloader) processHeaders(origin uint64, pivot uint64, td *big.Int) error {\n    // Keep a count of uncertain headers to roll back\n    rollback := []*types.Header{}\n    defer func() {\n        if len(rollback) > 0 {\n            // Flatten the headers and roll them back\n            hashes := make([]common.Hash, len(rollback))\n            for i, header := range rollback {\n                hashes[i] = header.Hash()\n            }\n            lastHeader, lastFastBlock, lastBlock := d.lightchain.CurrentHeader().Number, common.Big0, common.Big0\n            if d.mode != LightSync {\n                lastFastBlock = d.blockchain.CurrentFastBlock().Number()\n                lastBlock = d.blockchain.CurrentBlock().Number()\n            }\n            d.lightchain.Rollback(hashes)\n            curFastBlock, curBlock := common.Big0, common.Big0\n            if d.mode != LightSync {\n                curFastBlock = d.blockchain.CurrentFastBlock().Number()\n                curBlock = d.blockchain.CurrentBlock().Number()\n            }\n            log.Warn(\"Rolled back headers\", \"count\", len(hashes),\n                \"header\", fmt.Sprintf(\"%d->%d\", lastHeader, d.lightchain.CurrentHeader().Number),\n                \"fast\", fmt.Sprintf(\"%d->%d\", lastFastBlock, curFastBlock),\n                \"block\", fmt.Sprintf(\"%d->%d\", lastBlock, curBlock))\n        }\n    }()\n\n    // Wait for batches of headers to process\n    gotHeaders := false\n\n    for {\n        select {\n        case <-d.cancelCh:\n            return errCancelHeaderProcessing\n\n        case headers := <-d.headerProcCh:\n            // Terminate header processing if we synced up\n            if len(headers) == 0 {\n                // Notify everyone that headers are fully processed\n                for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n                    select {\n                    case ch <- false:\n                    case <-d.cancelCh:\n                    }\n                }\n                if d.mode != LightSync {\n                    head := d.blockchain.CurrentBlock()\n                    if !gotHeaders && td.Cmp(d.blockchain.GetTd(head.Hash(), head.NumberU64())) > 0 {\n                        return errStallingPeer\n                    }\n                }\n                if d.mode == FastSync || d.mode == LightSync {\n                    head := d.lightchain.CurrentHeader()\n                    if td.Cmp(d.lightchain.GetTd(head.Hash(), head.Number.Uint64())) > 0 {\n                        return errStallingPeer\n                    }\n                }\n                // Disable any rollback and return\n                rollback = nil\n                return nil\n            }\n            // Otherwise split the chunk of headers into batches and process them\n            gotHeaders = true\n\n            for len(headers) > 0 {\n                // Terminate if something failed in between processing chunks\n                select {\n                case <-d.cancelCh:\n                    return errCancelHeaderProcessing\n                default:\n                }\n                // Select the next chunk of headers to import\n                limit := maxHeadersProcess\n                if limit > len(headers) {\n                    limit = len(headers)\n                }\n                chunk := headers[:limit]\n\n                // In case of header only syncing, validate the chunk immediately\n                if d.mode == FastSync || d.mode == LightSync {\n                    // Collect the yet unknown headers to mark them as uncertain\n                    unknown := make([]*types.Header, 0, len(headers))\n                    for _, header := range chunk {\n                        if !d.lightchain.HasHeader(header.Hash(), header.Number.Uint64()) {\n                            unknown = append(unknown, header)\n                        }\n                    }\n                    // If we're importing pure headers, verify based on their recentness\n                    frequency := fsHeaderCheckFrequency\n                    if chunk[len(chunk)-1].Number.Uint64()+uint64(fsHeaderForceVerify) > pivot {\n                        frequency = 1\n                    }\n                    if n, err := d.lightchain.InsertHeaderChain(chunk, frequency); err != nil {\n                        // If some headers were inserted, add them too to the rollback list\n                        if n > 0 {\n                            rollback = append(rollback, chunk[:n]...)\n                        }\n                        log.Debug(\"Invalid header encountered\", \"number\", chunk[n].Number, \"hash\", chunk[n].Hash(), \"err\", err)\n                        return errInvalidChain\n                    }\n                    // All verifications passed, store newly found uncertain headers\n                    rollback = append(rollback, unknown...)\n                    if len(rollback) > fsHeaderSafetyNet {\n                        rollback = append(rollback[:0], rollback[len(rollback)-fsHeaderSafetyNet:]...)\n                    }\n                }\n                // Unless we're doing light chains, schedule the headers for associated content retrieval\n                if d.mode == FullSync || d.mode == FastSync {\n                    // If we've reached the allowed number of pending headers, stall a bit\n                    for d.queue.PendingBlocks() >= maxQueuedHeaders || d.queue.PendingReceipts() >= maxQueuedHeaders {\n                        select {\n                        case <-d.cancelCh:\n                            return errCancelHeaderProcessing\n                        case <-time.After(time.Second):\n                        }\n                    }\n                    // Otherwise insert the headers for content retrieval\n                    inserts := d.queue.Schedule(chunk, origin)\n                    if len(inserts) != len(chunk) {\n                        log.Debug(\"Stale headers\")\n                        return errBadPeer\n                    }\n                }\n                headers = headers[limit:]\n                origin += uint64(limit)\n            }\n            // Signal the content downloaders of the availablility of new tasks\n            for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n                select {\n                case ch <- true:\n                default:\n                }\n            }\n        }\n    }\n}\n\n```\n\n1，收到从fetchHeaders()方法 中d.headerProcCh发送过来的headers\n2，如果是FastSync或者LightSync模式，直接调用lightchain.InsertHeaderChain(chunk, frequency)插入到headerChain。\n3，如果是FullSync或者FastSyn模式，调用d.queue.Schedule(chunk, origin)，放入downloader.queue来调度\n\n2，processFastSyncContent() 方法\n\n```\nfunc (d *Downloader) processFastSyncContent(latest *types.Header) error {\n    // Start syncing state of the reported head block. This should get us most of\n    // the state of the pivot block.\n    stateSync := d.syncState(latest.Root)\n    defer stateSync.Cancel()\n    go func() {\n        if err := stateSync.Wait(); err != nil && err != errCancelStateFetch {\n            d.queue.Close() // wake up WaitResults\n        }\n    }()\n    // Figure out the ideal pivot block. Note, that this goalpost may move if the\n    // sync takes long enough for the chain head to move significantly.\n    pivot := uint64(0)\n    if height := latest.Number.Uint64(); height > uint64(fsMinFullBlocks) {\n        pivot = height - uint64(fsMinFullBlocks)\n    }\n    // To cater for moving pivot points, track the pivot block and subsequently\n    // accumulated download results separatey.\n    var (\n        oldPivot *fetchResult   // Locked in pivot block, might change eventually\n        oldTail  []*fetchResult // Downloaded content after the pivot\n    )\n    for {\n        // Wait for the next batch of downloaded data to be available, and if the pivot\n        // block became stale, move the goalpost\n        results := d.queue.Results(oldPivot == nil) // Block if we're not monitoring pivot staleness\n        if len(results) == 0 {\n            // If pivot sync is done, stop\n            if oldPivot == nil {\n                return stateSync.Cancel()\n            }\n            // If sync failed, stop\n            select {\n            case <-d.cancelCh:\n                return stateSync.Cancel()\n            default:\n            }\n        }\n        if d.chainInsertHook != nil {\n            d.chainInsertHook(results)\n        }\n        if oldPivot != nil {\n            results = append(append([]*fetchResult{oldPivot}, oldTail...), results...)\n        }\n        // Split around the pivot block and process the two sides via fast/full sync\n        if atomic.LoadInt32(&d.committed) == 0 {\n            latest = results[len(results)-1].Header\n            if height := latest.Number.Uint64(); height > pivot+2*uint64(fsMinFullBlocks) {\n                log.Warn(\"Pivot became stale, moving\", \"old\", pivot, \"new\", height-uint64(fsMinFullBlocks))\n                pivot = height - uint64(fsMinFullBlocks)\n            }\n        }\n        P, beforeP, afterP := splitAroundPivot(pivot, results)\n        if err := d.commitFastSyncData(beforeP, stateSync); err != nil {\n            return err\n        }\n        if P != nil {\n            // If new pivot block found, cancel old state retrieval and restart\n            if oldPivot != P {\n                stateSync.Cancel()\n\n                stateSync = d.syncState(P.Header.Root)\n                defer stateSync.Cancel()\n                go func() {\n                    if err := stateSync.Wait(); err != nil && err != errCancelStateFetch {\n                        d.queue.Close() // wake up WaitResults\n                    }\n                }()\n                oldPivot = P\n            }\n            // Wait for completion, occasionally checking for pivot staleness\n            select {\n            case <-stateSync.done:\n                if stateSync.err != nil {\n                    return stateSync.err\n                }\n                if err := d.commitPivotBlock(P); err != nil {\n                    return err\n                }\n                oldPivot = nil\n\n            case <-time.After(time.Second):\n                oldTail = afterP\n                continue\n            }\n        }\n        // Fast sync done, pivot commit done, full import\n        if err := d.importBlockResults(afterP); err != nil {\n            return err\n        }\n    }\n}\n\n```\n\n1，同步最新的状态信息，的到最新的pivot值\n2，不停的从d.queue 的result缓存中获取要处理的result数据\n3，如果results数据为空，同时pivot也为空的时候，说明同步完成了，并返回\n4，根据pivot值和results计算：pivot值对应的result，和pivot值之前的results和pivot值之后的results\n5，调用commitFastSyncData把pivot值之前的results 插入本地区块链中，带上收据和交易数据\n6，更新同步状态信息后，把pivot值对应的result 调用commitPivotBlock插入本地区块链中，并调用FastSyncCommitHead，记录这个pivot的hash值\n7，调用d.importBlockResults把pivot值之后的results插入本地区块链中，这时候不插入区块交易收据数据。\n\n3，processFullSyncContent()方法\n\n```\nfunc (d *Downloader) processFullSyncContent() error {\n    for {\n        results := d.queue.Results(true)\n        if len(results) == 0 {\n            return nil\n        }\n        if d.chainInsertHook != nil {\n            d.chainInsertHook(results)\n        }\n        if err := d.importBlockResults(results); err != nil {\n            return err\n        }\n    }\n}\n\nfunc (d *Downloader) importBlockResults(results []*fetchResult) error {\n    // Check for any early termination requests\n    if len(results) == 0 {\n        return nil\n    }\n    select {\n    case <-d.quitCh:\n        return errCancelContentProcessing\n    default:\n    }\n    // Retrieve the a batch of results to import\n    first, last := results[0].Header, results[len(results)-1].Header\n    log.Debug(\"Inserting downloaded chain\", \"items\", len(results),\n        \"firstnum\", first.Number, \"firsthash\", first.Hash(),\n        \"lastnum\", last.Number, \"lasthash\", last.Hash(),\n    )\n    blocks := make([]*types.Block, len(results))\n    for i, result := range results {\n        blocks[i] = types.NewBlockWithHeader(result.Header).WithBody(result.Transactions, result.Uncles)\n    }\n    if index, err := d.blockchain.InsertChain(blocks); err != nil {\n        log.Debug(\"Downloaded item processing failed\", \"number\", results[index].Header.Number, \"hash\", results[index].Header.Hash(), \"err\", err)\n        return errInvalidChain\n    }\n    return nil\n}\n\n```\n\nprocessFullSyncContent方法比较简单：直接获取缓存的results数据，并插入到本地区块链中。\n\n总结：\nDownloader看似非常复杂，其实逻辑还好，如果没有light模式，读起来会好很多。其实light模式不太成熟，基本也没什么用。fast模式比full模式逻辑上面多了一个pivot，处理起来就复杂很多。但是fast模式在本地存储了收据数据，大大减少了区块交易验证的时间。如果要更清楚明白fast模式的原理，可以看看以太坊白皮书关于fast模式同步这一部分：[文档](https://github.com/ethereum/go-ethereum/pull/1889)\n","slug":"eth-code-tx-event","published":1,"updated":"2019-10-14T06:48:21.961Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3fm69ys002wt6xvyonfly1j","content":"<h4 id=\"ApplyTransaction\"><a href=\"#ApplyTransaction\" class=\"headerlink\" title=\"ApplyTransaction\"></a>ApplyTransaction</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// ApplyTransaction attempts to apply a transaction to the given state database</span><br><span class=\"line\">// and uses the input parameters for its environment. It returns the receipt</span><br><span class=\"line\">// for the transaction, gas used and an error if the transaction failed,</span><br><span class=\"line\">// indicating the block was invalid.</span><br><span class=\"line\">//应用交易到state database中</span><br><span class=\"line\">func ApplyTransaction(config *params.ChainConfig, bc ChainContext, author *common.Address, gp *GasPool, statedb *state.StateDB, header *types.Header, tx *types.Transaction, usedGas *uint64, cfg vm.Config) (*types.Receipt, uint64, error) &#123;</span><br><span class=\"line\">\t//构造交易消息</span><br><span class=\"line\">\tmsg, err := tx.AsMessage(types.MakeSigner(config, header.Number))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn nil, 0, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//EVM进行交易处理，返回为处理结果、消耗gas、是否失败、err，logs是在evm处理时产生的</span><br><span class=\"line\">\t// Create a new context to be used in the EVM environment</span><br><span class=\"line\">\tcontext := NewEVMContext(msg, header, bc, author)</span><br><span class=\"line\">\t// Create a new environment which holds all relevant information</span><br><span class=\"line\">\t// about the transaction and calling mechanisms.</span><br><span class=\"line\">\tvmenv := vm.NewEVM(context, statedb, config, cfg)</span><br><span class=\"line\">\t// Apply the transaction to the current state (included in the env)</span><br><span class=\"line\">\t_, gas, failed, err := ApplyMessage(vmenv, msg, gp)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn nil, 0, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t//根据处理结果构建返回数据</span><br><span class=\"line\">\t// Update the state with pending changes</span><br><span class=\"line\">\tvar root []byte</span><br><span class=\"line\">\tif config.IsByzantium(header.Number) &#123;</span><br><span class=\"line\">\t\tstatedb.Finalise(true)</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\troot = statedb.IntermediateRoot(config.IsEIP158(header.Number)).Bytes()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t*usedGas += gas</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Create a new receipt for the transaction, storing the intermediate root and gas used by the tx</span><br><span class=\"line\">\t// based on the eip phase, we&apos;re passing whether the root touch-delete accounts.</span><br><span class=\"line\">\treceipt := types.NewReceipt(root, failed, *usedGas)</span><br><span class=\"line\">\treceipt.TxHash = tx.Hash()</span><br><span class=\"line\">\treceipt.GasUsed = gas</span><br><span class=\"line\">\t// if the transaction created a contract, store the creation address in the receipt.</span><br><span class=\"line\">\tif msg.To() == nil &#123;</span><br><span class=\"line\">\t\treceipt.ContractAddress = crypto.CreateAddress(vmenv.Context.Origin, tx.Nonce())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// Set the receipt logs and create a bloom for filtering</span><br><span class=\"line\">\treceipt.Logs = statedb.GetLogs(tx.Hash())</span><br><span class=\"line\">\treceipt.Bloom = types.CreateBloom(types.Receipts&#123;receipt&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn receipt, gas, err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (evm *EVM) Call(caller ContractRef, addr common.Address, input []byte, gas uint64, value *big.Int) (ret []byte, leftOverGas uint64, err error) &#123;</span><br><span class=\"line\">\tif evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 &#123;</span><br><span class=\"line\">\t\treturn nil, gas, nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Fail if we&apos;re trying to execute above the call depth limit</span><br><span class=\"line\">\tif evm.depth &gt; int(params.CallCreateDepth) &#123;</span><br><span class=\"line\">\t\treturn nil, gas, ErrDepth</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// Fail if we&apos;re trying to transfer more than the available balance</span><br><span class=\"line\">\tif !evm.Context.CanTransfer(evm.StateDB, caller.Address(), value) &#123;</span><br><span class=\"line\">\t\treturn nil, gas, ErrInsufficientBalance</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tvar (</span><br><span class=\"line\">\t\tto       = AccountRef(addr)</span><br><span class=\"line\">\t\tsnapshot = evm.StateDB.Snapshot()</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\tif !evm.StateDB.Exist(addr) &#123;</span><br><span class=\"line\">\t\tprecompiles := PrecompiledContractsHomestead</span><br><span class=\"line\">\t\tif evm.ChainConfig().IsByzantium(evm.BlockNumber) &#123;</span><br><span class=\"line\">\t\t\tprecompiles = PrecompiledContractsByzantium</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif precompiles[addr] == nil &amp;&amp; evm.ChainConfig().IsEIP158(evm.BlockNumber) &amp;&amp; value.Sign() == 0 &#123;</span><br><span class=\"line\">\t\t\t// Calling a non existing account, don&apos;t do anything, but ping the tracer</span><br><span class=\"line\">\t\t\tif evm.vmConfig.Debug &amp;&amp; evm.depth == 0 &#123;</span><br><span class=\"line\">\t\t\t\tevm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value)</span><br><span class=\"line\">\t\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, 0, 0, nil)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\treturn nil, gas, nil</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tevm.StateDB.CreateAccount(addr)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tevm.Transfer(evm.StateDB, caller.Address(), to.Address(), value)</span><br><span class=\"line\">\t// Initialise a new contract and set the code that is to be used by the EVM.</span><br><span class=\"line\">\t// The contract is a scoped environment for this execution context only.</span><br><span class=\"line\">\tcontract := NewContract(caller, to, value, gas)</span><br><span class=\"line\">\tcontract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr))</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Even if the account has no code, we need to continue because it might be a precompile</span><br><span class=\"line\">\tstart := time.Now()</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Capture the tracer start/end events in debug mode</span><br><span class=\"line\">\tif evm.vmConfig.Debug &amp;&amp; evm.depth == 0 &#123;</span><br><span class=\"line\">\t\tevm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tdefer func() &#123; // Lazy evaluation of the parameters</span><br><span class=\"line\">\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, gas-contract.Gas, time.Since(start), err)</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tret, err = run(evm, contract, input, false)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// When an error was returned by the EVM or when setting the creation code</span><br><span class=\"line\">\t// above we revert to the snapshot and consume any gas remaining. Additionally</span><br><span class=\"line\">\t// when we&apos;re in homestead this also counts for code storage gas errors.</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tevm.StateDB.RevertToSnapshot(snapshot)</span><br><span class=\"line\">\t\tif err != errExecutionReverted &#123;</span><br><span class=\"line\">\t\t\tcontract.UseGas(contract.Gas)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn ret, contract.Gas, err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"handleMsg\"><a href=\"#handleMsg\" class=\"headerlink\" title=\"handleMsg\"></a>handleMsg</h4><p>处理接收到的消息码</p>\n<ul>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StatusMsg</span><br></pre></td></tr></table></figure>\n\n<p>收到这个消息说明握手失败</p>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GetBlockHeadersMsg</span><br></pre></td></tr></table></figure>\n\n<p>查询区块头请求，回复区块头信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BlockHeadersMsg</span><br></pre></td></tr></table></figure>\n\n<p>区块头信息的回复</p>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GetBlockBodiesMsg</span><br></pre></td></tr></table></figure>\n\n<p>查询区块请求</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BlockBodiesMsg</span><br></pre></td></tr></table></figure>\n\n<p>区块请求查询的回复，</p>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GetNodeDataMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NodeDataMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GetReceiptsMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ReceiptsMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NewBlockHashesMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NewBlockMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TxMsg</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h4 id=\"Start\"><a href=\"#Start\" class=\"headerlink\" title=\"Start\"></a>Start</h4><p>这四个goroutine 基本上就在不停的做广播区块、广播交易，同步到区块、同步到交易，再广播区块、广播交易。</p>\n<ul>\n<li><p>txBroadcastLoop</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (self *ProtocolManager) txBroadcastLoop() &#123;</span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case event := &lt;-self.txCh:</span><br><span class=\"line\">            self.BroadcastTx(event.Tx.Hash(), event.Tx)</span><br><span class=\"line\"></span><br><span class=\"line\">        // Err() channel will be closed when unsubscribing.</span><br><span class=\"line\">        case &lt;-self.txSub.Err():</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>core/tx_pool.go 产生新的交易的时候会send self.txCh，这时候会激活<br>self.BroadcastTx(event.Tx.Hash(), event.Tx)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (pm *ProtocolManager) BroadcastTx(hash common.Hash, tx *types.Transaction) &#123;</span><br><span class=\"line\">    // Broadcast transaction to a batch of peers not knowing about it</span><br><span class=\"line\">    peers := pm.peers.PeersWithoutTx(hash)</span><br><span class=\"line\">    //FIXME include this again: peers = peers[:int(math.Sqrt(float64(len(peers))))]</span><br><span class=\"line\">    for _, peer := range peers &#123;</span><br><span class=\"line\">        peer.SendTransactions(types.Transactions&#123;tx&#125;)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log.Trace(&quot;Broadcast transaction&quot;, &quot;hash&quot;, hash, &quot;recipients&quot;, len(peers))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>向缓存的没有这个交易hash的网络节点广播此次交易。</p>\n</li>\n<li><p>minedBroadcastLoop</p>\n<p>收到miner.go 里面NewMinedBlockEvent 挖到新区块的事件通知，激活self.BroadcastBlock(ev.Block, true)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Mined broadcast loop</span><br><span class=\"line\">func (self *ProtocolManager) minedBroadcastLoop() &#123;</span><br><span class=\"line\">    // automatically stops if unsubscribe</span><br><span class=\"line\">    for obj := range self.minedBlockSub.Chan() &#123;</span><br><span class=\"line\">        switch ev := obj.Data.(type) &#123;</span><br><span class=\"line\">        case core.NewMinedBlockEvent:</span><br><span class=\"line\">            self.BroadcastBlock(ev.Block, true)  // First propagate block to peers</span><br><span class=\"line\">            self.BroadcastBlock(ev.Block, false) // Only then announce to the rest</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (pm *ProtocolManager) BroadcastBlock(block *types.Block, propagate bool) &#123;</span><br><span class=\"line\">    hash := block.Hash()</span><br><span class=\"line\">    peers := pm.peers.PeersWithoutBlock(hash)</span><br><span class=\"line\"></span><br><span class=\"line\">    // If propagation is requested, send to a subset of the peer</span><br><span class=\"line\">    if propagate &#123;</span><br><span class=\"line\">        // Calculate the TD of the block (it&apos;s not imported yet, so block.Td is not valid)</span><br><span class=\"line\">        var td *big.Int</span><br><span class=\"line\">        if parent := pm.blockchain.GetBlock(block.ParentHash(), block.NumberU64()-1); parent != nil &#123;</span><br><span class=\"line\">            td = new(big.Int).Add(block.Difficulty(), pm.blockchain.GetTd(block.ParentHash(), block.NumberU64()-1))</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            log.Error(&quot;Propagating dangling block&quot;, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash)</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Send the block to a subset of our peers</span><br><span class=\"line\">        transfer := peers[:int(math.Sqrt(float64(len(peers))))]</span><br><span class=\"line\">        for _, peer := range transfer &#123;</span><br><span class=\"line\">            peer.SendNewBlock(block, td)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        log.Trace(&quot;Propagated block&quot;, &quot;hash&quot;, hash, &quot;recipients&quot;, len(transfer), &quot;duration&quot;, common.PrettyDuration(time.Since(block.ReceivedAt)))</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Otherwise if the block is indeed in out own chain, announce it</span><br><span class=\"line\">    if pm.blockchain.HasBlock(hash, block.NumberU64()) &#123;</span><br><span class=\"line\">        for _, peer := range peers &#123;</span><br><span class=\"line\">            peer.SendNewBlockHashes([]common.Hash&#123;hash&#125;, []uint64&#123;block.NumberU64()&#125;)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        log.Trace(&quot;Announced block&quot;, &quot;hash&quot;, hash, &quot;recipients&quot;, len(peers), &quot;duration&quot;, common.PrettyDuration(time.Since(block.ReceivedAt)))</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果propagate为true 向网络节点广播整个挖到的block，为false 只广播挖到的区块的hash值和number值。广播的区块还包括这个区块打包的所有交易。</p>\n</li>\n<li><p>syncer</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (pm *ProtocolManager) syncer() &#123;</span><br><span class=\"line\">    // Start and ensure cleanup of sync mechanisms</span><br><span class=\"line\">    pm.fetcher.Start()</span><br><span class=\"line\">    defer pm.fetcher.Stop()</span><br><span class=\"line\">    defer pm.downloader.Terminate()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Wait for different events to fire synchronisation operations</span><br><span class=\"line\">    forceSync := time.NewTicker(forceSyncCycle)</span><br><span class=\"line\">    defer forceSync.Stop()</span><br><span class=\"line\"></span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-pm.newPeerCh:</span><br><span class=\"line\">            // Make sure we have peers to select from, then sync</span><br><span class=\"line\">            if pm.peers.Len() &lt; minDesiredPeerCount &#123;</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            go pm.synchronise(pm.peers.BestPeer())</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-forceSync.C:</span><br><span class=\"line\">            // Force a sync even if not enough peers are present</span><br><span class=\"line\">            go pm.synchronise(pm.peers.BestPeer())</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-pm.noMorePeers:</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>pm.fetcher.Start()启动 fetcher，辅助同步区块数据</p>\n<p>当P2P server执行 ProtocolManager 的p2p.Protocol 的Run指针的时候会send pm.newPeerCh，这时候选择最优的网络节点（TD 总难度最大的）启动pm.synchronise(pm.peers.BestPeer()) goroutine。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// synchronise tries to sync up our local block chain with a remote peer.</span><br><span class=\"line\">func (pm *ProtocolManager) synchronise(peer *peer) &#123;</span><br><span class=\"line\">    // Short circuit if no peers are available</span><br><span class=\"line\">    if peer == nil &#123;</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Make sure the peer&apos;s TD is higher than our own</span><br><span class=\"line\">    currentBlock := pm.blockchain.CurrentBlock()</span><br><span class=\"line\">    td := pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())</span><br><span class=\"line\"></span><br><span class=\"line\">    pHead, pTd := peer.Head()</span><br><span class=\"line\">    if pTd.Cmp(td) &lt;= 0 &#123;</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Otherwise try to sync with the downloader</span><br><span class=\"line\">    mode := downloader.FullSync</span><br><span class=\"line\">    if atomic.LoadUint32(&amp;pm.fastSync) == 1 &#123;</span><br><span class=\"line\">        // Fast sync was explicitly requested, and explicitly granted</span><br><span class=\"line\">        mode = downloader.FastSync</span><br><span class=\"line\">    &#125; else if currentBlock.NumberU64() == 0 &amp;&amp; pm.blockchain.CurrentFastBlock().NumberU64() &gt; 0 &#123;</span><br><span class=\"line\">        // The database seems empty as the current block is the genesis. Yet the fast</span><br><span class=\"line\">        // block is ahead, so fast sync was enabled for this node at a certain point.</span><br><span class=\"line\">        // The only scenario where this can happen is if the user manually (or via a</span><br><span class=\"line\">        // bad block) rolled back a fast sync node below the sync point. In this case</span><br><span class=\"line\">        // however it&apos;s safe to reenable fast sync.</span><br><span class=\"line\">        atomic.StoreUint32(&amp;pm.fastSync, 1)</span><br><span class=\"line\">        mode = downloader.FastSync</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Run the sync cycle, and disable fast sync if we&apos;ve went past the pivot block</span><br><span class=\"line\">    if err := pm.downloader.Synchronise(peer.id, pHead, pTd, mode); err != nil &#123;</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if atomic.LoadUint32(&amp;pm.fastSync) == 1 &#123;</span><br><span class=\"line\">        log.Info(&quot;Fast sync complete, auto disabling&quot;)</span><br><span class=\"line\">        atomic.StoreUint32(&amp;pm.fastSync, 0)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    atomic.StoreUint32(&amp;pm.acceptTxs, 1) // Mark initial sync done</span><br><span class=\"line\">    if head := pm.blockchain.CurrentBlock(); head.NumberU64() &gt; 0 &#123;</span><br><span class=\"line\">        // We&apos;ve completed a sync cycle, notify all peers of new state. This path is</span><br><span class=\"line\">        // essential in star-topology networks where a gateway node needs to notify</span><br><span class=\"line\">        // all its out-of-date peers of the availability of a new block. This failure</span><br><span class=\"line\">        // scenario will most often crop up in private and hackathon networks with</span><br><span class=\"line\">        // degenerate connectivity, but it should be healthy for the mainnet too to</span><br><span class=\"line\">        // more reliably update peers or the local TD state.</span><br><span class=\"line\">        go pm.BroadcastBlock(head, false)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果最优的网络节点的TD值大于本地最新区块的TD值，调用pm.downloader.Synchronise(peer.id, pHead, pTd, mode)进行同步。同步完成后再屌用go pm.BroadcastBlock(head, false)，把自己最新的区块状态广播出去。</p>\n</li>\n<li><p>txsyncLoop</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (pm *ProtocolManager) txsyncLoop() &#123;</span><br><span class=\"line\">    var (</span><br><span class=\"line\">        pending = make(map[discover.NodeID]*txsync)</span><br><span class=\"line\">        sending = false               // whether a send is active</span><br><span class=\"line\">        pack    = new(txsync)         // the pack that is being sent</span><br><span class=\"line\">        done    = make(chan error, 1) // result of the send</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    // send starts a sending a pack of transactions from the sync.</span><br><span class=\"line\">    send := func(s *txsync) &#123;</span><br><span class=\"line\">        // Fill pack with transactions up to the target size.</span><br><span class=\"line\">        size := common.StorageSize(0)</span><br><span class=\"line\">        pack.p = s.p</span><br><span class=\"line\">        pack.txs = pack.txs[:0]</span><br><span class=\"line\">        for i := 0; i &lt; len(s.txs) &amp;&amp; size &lt; txsyncPackSize; i++ &#123;</span><br><span class=\"line\">            pack.txs = append(pack.txs, s.txs[i])</span><br><span class=\"line\">            size += s.txs[i].Size()</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Remove the transactions that will be sent.</span><br><span class=\"line\">        s.txs = s.txs[:copy(s.txs, s.txs[len(pack.txs):])]</span><br><span class=\"line\">        if len(s.txs) == 0 &#123;</span><br><span class=\"line\">            delete(pending, s.p.ID())</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Send the pack in the background.</span><br><span class=\"line\">        s.p.Log().Trace(&quot;Sending batch of transactions&quot;, &quot;count&quot;, len(pack.txs), &quot;bytes&quot;, size)</span><br><span class=\"line\">        sending = true</span><br><span class=\"line\">        go func() &#123; done &lt;- pack.p.SendTransactions(pack.txs) &#125;()</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // pick chooses the next pending sync.</span><br><span class=\"line\">    pick := func() *txsync &#123;</span><br><span class=\"line\">        if len(pending) == 0 &#123;</span><br><span class=\"line\">            return nil</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        n := rand.Intn(len(pending)) + 1</span><br><span class=\"line\">        for _, s := range pending &#123;</span><br><span class=\"line\">            if n--; n == 0 &#123;</span><br><span class=\"line\">                return s</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case s := &lt;-pm.txsyncCh:</span><br><span class=\"line\">            pending[s.p.ID()] = s</span><br><span class=\"line\">            if !sending &#123;</span><br><span class=\"line\">                send(s)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        case err := &lt;-done:</span><br><span class=\"line\">            sending = false</span><br><span class=\"line\">            // Stop tracking peers that cause send failures.</span><br><span class=\"line\">            if err != nil &#123;</span><br><span class=\"line\">                pack.p.Log().Debug(&quot;Transaction send failed&quot;, &quot;err&quot;, err)</span><br><span class=\"line\">                delete(pending, pack.p.ID())</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the next send.</span><br><span class=\"line\">            if s := pick(); s != nil &#123;</span><br><span class=\"line\">                send(s)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        case &lt;-pm.quitSync:</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当从网络节点同步过来最新的交易数据后，本地也会把新同步下来的交易数据广播给网络中的其他节点。</p>\n</li>\n</ul>\n<h4 id=\"fetch\"><a href=\"#fetch\" class=\"headerlink\" title=\"fetch\"></a>fetch</h4><p>fetcher是用来辅助同步区块数据的，记录各个区块头和区块体的同步状态，但它并不做真正下载区块数据的事情，下载的事情交由downloader来做。那fetcher具体是怎么工作的呢？<br>我们先看看pm.handleMsg 在收到 NewBlockHashesMsg广播通知的处理代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case msg.Code == NewBlockHashesMsg:</span><br><span class=\"line\">        var announces newBlockHashesData</span><br><span class=\"line\">        if err := msg.Decode(&amp;announces); err != nil &#123;</span><br><span class=\"line\">            return errResp(ErrDecode, &quot;%v: %v&quot;, msg, err)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Mark the hashes as present at the remote node</span><br><span class=\"line\">        for _, block := range announces &#123;</span><br><span class=\"line\">            p.MarkBlock(block.Hash)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Schedule all the unknown hashes for retrieval</span><br><span class=\"line\">        unknown := make(newBlockHashesData, 0, len(announces))</span><br><span class=\"line\">        for _, block := range announces &#123;</span><br><span class=\"line\">            if !pm.blockchain.HasBlock(block.Hash, block.Number) &#123;</span><br><span class=\"line\">                unknown = append(unknown, block)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        for _, block := range unknown &#123;</span><br><span class=\"line\">            pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n\n<p>从广播通知里会获取到一个newBlockHashesData的列表。newBlockHashesData只包括block的hash值和block的number值。<br>然后每个newBlockHashesData调用pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)方法，除了传入block的hash值和block的number值，还需要传入当前的时间戳，peer.go的两个函数指针。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (f *Fetcher) Notify(peer string, hash common.Hash, number uint64, time time.Time,</span><br><span class=\"line\">    headerFetcher headerRequesterFn, bodyFetcher bodyRequesterFn) error &#123;</span><br><span class=\"line\">    block := &amp;announce&#123;</span><br><span class=\"line\">        hash:        hash,</span><br><span class=\"line\">        number:      number,</span><br><span class=\"line\">        time:        time,</span><br><span class=\"line\">        origin:      peer,</span><br><span class=\"line\">        fetchHeader: headerFetcher,</span><br><span class=\"line\">        fetchBodies: bodyFetcher,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case f.notify &lt;- block:</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    case &lt;-f.quit:</span><br><span class=\"line\">        return errTerminated</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Notify()方法把传进来的参数拼成一个announce对象，然后send给f.notify。fetcher的loop()主回路里f.notify receive 到这个notification, 进行处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case notification := &lt;-f.notify:</span><br><span class=\"line\">            // A block was announced, make sure the peer isn&apos;t DOSing us</span><br><span class=\"line\">            propAnnounceInMeter.Mark(1)</span><br><span class=\"line\"></span><br><span class=\"line\">            count := f.announces[notification.origin] + 1</span><br><span class=\"line\">            if count &gt; hashLimit &#123;</span><br><span class=\"line\">                log.Debug(&quot;Peer exceeded outstanding announces&quot;, &quot;peer&quot;, notification.origin, &quot;limit&quot;, hashLimit)</span><br><span class=\"line\">                propAnnounceDOSMeter.Mark(1)</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // If we have a valid block number, check that it&apos;s potentially useful</span><br><span class=\"line\">            if notification.number &gt; 0 &#123;</span><br><span class=\"line\">                if dist := int64(notification.number) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist &#123;</span><br><span class=\"line\">                    log.Debug(&quot;Peer discarded announcement&quot;, &quot;peer&quot;, notification.origin, &quot;number&quot;, notification.number, &quot;hash&quot;, notification.hash, &quot;distance&quot;, dist)</span><br><span class=\"line\">                    propAnnounceDropMeter.Mark(1)</span><br><span class=\"line\">                    break</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // All is well, schedule the announce if block&apos;s not yet downloading</span><br><span class=\"line\">            if _, ok := f.fetching[notification.hash]; ok &#123;</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if _, ok := f.completing[notification.hash]; ok &#123;</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            f.announces[notification.origin] = count</span><br><span class=\"line\">            f.announced[notification.hash] = append(f.announced[notification.hash], notification)</span><br><span class=\"line\">            if f.announceChangeHook != nil &amp;&amp; len(f.announced[notification.hash]) == 1 &#123;</span><br><span class=\"line\">                f.announceChangeHook(notification.hash, true)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if len(f.announced) == 1 &#123;</span><br><span class=\"line\">                f.rescheduleFetch(fetchTimer)</span><br><span class=\"line\">            &#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，将收到的不满足条件的通知都丢弃掉，如果在f.fetching 状态列表里和f.completing 状态列表里，也直接返回。接着更新notification.origin 这个节点的announces 数量，添加到f.announced 等待fetch的表里。<br>2，如果len(f.announced[notification.hash]) == 1 说明f.announced只有这一个通知，则调用f.announceChangeHook。<br>3，如果len(f.announced) == 1 也说明只有一个通知，则启动fetchTimer的调度。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case &lt;-fetchTimer.C:</span><br><span class=\"line\">            // At least one block&apos;s timer ran out, check for needing retrieval</span><br><span class=\"line\">            request := make(map[string][]common.Hash)</span><br><span class=\"line\"></span><br><span class=\"line\">            for hash, announces := range f.announced &#123;</span><br><span class=\"line\">                if time.Since(announces[0].time) &gt; arriveTimeout-gatherSlack &#123;</span><br><span class=\"line\">                    // Pick a random peer to retrieve from, reset all others</span><br><span class=\"line\">                    announce := announces[rand.Intn(len(announces))]</span><br><span class=\"line\">                    f.forgetHash(hash)</span><br><span class=\"line\"></span><br><span class=\"line\">                    // If the block still didn&apos;t arrive, queue for fetching</span><br><span class=\"line\">                    if f.getBlock(hash) == nil &#123;</span><br><span class=\"line\">                        request[announce.origin] = append(request[announce.origin], hash)</span><br><span class=\"line\">                        f.fetching[hash] = announce</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Send out all block header requests</span><br><span class=\"line\">            for peer, hashes := range request &#123;</span><br><span class=\"line\">                log.Trace(&quot;Fetching scheduled headers&quot;, &quot;peer&quot;, peer, &quot;list&quot;, hashes)</span><br><span class=\"line\"></span><br><span class=\"line\">                // Create a closure of the fetch and schedule in on a new thread</span><br><span class=\"line\">                fetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes</span><br><span class=\"line\">                go func() &#123;</span><br><span class=\"line\">                    if f.fetchingHook != nil &#123;</span><br><span class=\"line\">                        f.fetchingHook(hashes)</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    for _, hash := range hashes &#123;</span><br><span class=\"line\">                        headerFetchMeter.Mark(1)</span><br><span class=\"line\">                        fetchHeader(hash) // Suboptimal, but protocol doesn&apos;t allow batch header retrievals</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the next fetch if blocks are still pending</span><br><span class=\"line\">            f.rescheduleFetch(fetchTimer)</span><br></pre></td></tr></table></figure>\n\n<p>1，首先遍历f.announced，如果超过了arriveTimeout-gatherSlack这个时间，把这个hash对应在fetcher里面的状态都清了。<br>这里随机拿这个announces里面任意一个announce，为啥随机取一个呢？因为都是同一个block的hash，这个hash下的哪一个announce都是一样的。<br>如果发现超时了还没有没有获取到这个hash的block，则把这个announce加到request列表中，同时重新把announce放到f.fetching状态列表。<br>2，然后遍历request列表，request列表里面的每个网络节点过来的所有的block的hash，都会调用fetchHeader(hash)方法来获取header数据。<br>这个fetchHeader(hash)方法是pm.fetcher.Notify传进来的，peer.go<br>里面的一个全局方法。<br>3， 这时候NewBlockHashesMsg 的fetcher处理就结束了，最后再启动fetchTimer的调度。</p>\n<p>三，Fetcher分析， 之FilterHeaders()<br>fetchHeader(hash)方法，调用了peer.go 里面的全局方法RequestOneHeader(hash common.Hash)  Send给网络节点一个GetBlockHeadersMsg 消息。<br>然后pm.handleMsg 收到 BlockHashesMsg广播通知</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case msg.Code == BlockHeadersMsg:</span><br><span class=\"line\">        // A batch of headers arrived to one of our previous requests</span><br><span class=\"line\">        var headers []*types.Header</span><br><span class=\"line\">        if err := msg.Decode(&amp;headers); err != nil &#123;</span><br><span class=\"line\">            return errResp(ErrDecode, &quot;msg %v: %v&quot;, msg, err)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // If no headers were received, but we&apos;re expending a DAO fork check, maybe it&apos;s that</span><br><span class=\"line\">        if len(headers) == 0 &amp;&amp; p.forkDrop != nil &#123;</span><br><span class=\"line\">            // Possibly an empty reply to the fork header checks, sanity check TDs</span><br><span class=\"line\">            verifyDAO := true</span><br><span class=\"line\"></span><br><span class=\"line\">            // If we already have a DAO header, we can check the peer&apos;s TD against it. If</span><br><span class=\"line\">            // the peer&apos;s ahead of this, it too must have a reply to the DAO check</span><br><span class=\"line\">            if daoHeader := pm.blockchain.GetHeaderByNumber(pm.chainconfig.DAOForkBlock.Uint64()); daoHeader != nil &#123;</span><br><span class=\"line\">                if _, td := p.Head(); td.Cmp(pm.blockchain.GetTd(daoHeader.Hash(), daoHeader.Number.Uint64())) &gt;= 0 &#123;</span><br><span class=\"line\">                    verifyDAO = false</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // If we&apos;re seemingly on the same chain, disable the drop timer</span><br><span class=\"line\">            if verifyDAO &#123;</span><br><span class=\"line\">                p.Log().Debug(&quot;Seems to be on the same side of the DAO fork&quot;)</span><br><span class=\"line\">                p.forkDrop.Stop()</span><br><span class=\"line\">                p.forkDrop = nil</span><br><span class=\"line\">                return nil</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Filter out any explicitly requested headers, deliver the rest to the downloader</span><br><span class=\"line\">        filter := len(headers) == 1</span><br><span class=\"line\">        if filter &#123;</span><br><span class=\"line\">            // If it&apos;s a potential DAO fork check, validate against the rules</span><br><span class=\"line\">            if p.forkDrop != nil &amp;&amp; pm.chainconfig.DAOForkBlock.Cmp(headers[0].Number) == 0 &#123;</span><br><span class=\"line\">                // Disable the fork drop timer</span><br><span class=\"line\">                p.forkDrop.Stop()</span><br><span class=\"line\">                p.forkDrop = nil</span><br><span class=\"line\"></span><br><span class=\"line\">                // Validate the header and either drop the peer or continue</span><br><span class=\"line\">                if err := misc.VerifyDAOHeaderExtraData(pm.chainconfig, headers[0]); err != nil &#123;</span><br><span class=\"line\">                    p.Log().Debug(&quot;Verified to be on the other side of the DAO fork, dropping&quot;)</span><br><span class=\"line\">                    return err</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                p.Log().Debug(&quot;Verified to be on the same side of the DAO fork&quot;)</span><br><span class=\"line\">                return nil</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Irrelevant of the fork checks, send the header to the fetcher just in case</span><br><span class=\"line\">            headers = pm.fetcher.FilterHeaders(p.id, headers, time.Now())</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if len(headers) &gt; 0 || !filter &#123;</span><br><span class=\"line\">            err := pm.downloader.DeliverHeaders(p.id, headers)</span><br><span class=\"line\">            if err != nil &#123;</span><br><span class=\"line\">                log.Debug(&quot;Failed to deliver headers&quot;, &quot;err&quot;, err)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果不是硬分叉的daoHeader，同时len(headers) == 1，则执行pm.fetcher.FilterHeaders(p.id, headers, time.Now())方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (f *Fetcher) FilterHeaders(peer string, headers []*types.Header, time time.Time) []*types.Header &#123;</span><br><span class=\"line\">    log.Trace(&quot;Filtering headers&quot;, &quot;peer&quot;, peer, &quot;headers&quot;, len(headers))</span><br><span class=\"line\"></span><br><span class=\"line\">    // Send the filter channel to the fetcher</span><br><span class=\"line\">    filter := make(chan *headerFilterTask)</span><br><span class=\"line\"></span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case f.headerFilter &lt;- filter:</span><br><span class=\"line\">    case &lt;-f.quit:</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Request the filtering of the header list</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case filter &lt;- &amp;headerFilterTask&#123;peer: peer, headers: headers, time: time&#125;:</span><br><span class=\"line\">    case &lt;-f.quit:</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Retrieve the headers remaining after filtering</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case task := &lt;-filter:</span><br><span class=\"line\">        return task.headers</span><br><span class=\"line\">    case &lt;-f.quit:</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>send 一个filter 到f.headerFilter，fetcher的loop()主回路里f.headerFilter receive 到这个filter，进行处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case filter := &lt;-f.headerFilter:</span><br><span class=\"line\">            // Headers arrived from a remote peer. Extract those that were explicitly</span><br><span class=\"line\">            // requested by the fetcher, and return everything else so it&apos;s delivered</span><br><span class=\"line\">            // to other parts of the system.</span><br><span class=\"line\">            var task *headerFilterTask</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case task = &lt;-filter:</span><br><span class=\"line\">            case &lt;-f.quit:</span><br><span class=\"line\">                return</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            headerFilterInMeter.Mark(int64(len(task.headers)))</span><br><span class=\"line\"></span><br><span class=\"line\">            // Split the batch of headers into unknown ones (to return to the caller),</span><br><span class=\"line\">            // known incomplete ones (requiring body retrievals) and completed blocks.</span><br><span class=\"line\">            unknown, incomplete, complete := []*types.Header&#123;&#125;, []*announce&#123;&#125;, []*types.Block&#123;&#125;</span><br><span class=\"line\">            for _, header := range task.headers &#123;</span><br><span class=\"line\">                hash := header.Hash()</span><br><span class=\"line\"></span><br><span class=\"line\">                // Filter fetcher-requested headers from other synchronisation algorithms</span><br><span class=\"line\">                if announce := f.fetching[hash]; announce != nil &amp;&amp; announce.origin == task.peer &amp;&amp; f.fetched[hash] == nil &amp;&amp; f.completing[hash] == nil &amp;&amp; f.queued[hash] == nil &#123;</span><br><span class=\"line\">                    // If the delivered header does not match the promised number, drop the announcer</span><br><span class=\"line\">                    if header.Number.Uint64() != announce.number &#123;</span><br><span class=\"line\">                        log.Trace(&quot;Invalid block number fetched&quot;, &quot;peer&quot;, announce.origin, &quot;hash&quot;, header.Hash(), &quot;announced&quot;, announce.number, &quot;provided&quot;, header.Number)</span><br><span class=\"line\">                        f.dropPeer(announce.origin)</span><br><span class=\"line\">                        f.forgetHash(hash)</span><br><span class=\"line\">                        continue</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    // Only keep if not imported by other means</span><br><span class=\"line\">                    if f.getBlock(hash) == nil &#123;</span><br><span class=\"line\">                        announce.header = header</span><br><span class=\"line\">                        announce.time = task.time</span><br><span class=\"line\"></span><br><span class=\"line\">                        // If the block is empty (header only), short circuit into the final import queue</span><br><span class=\"line\">                        if header.TxHash == types.DeriveSha(types.Transactions&#123;&#125;) &amp;&amp; header.UncleHash == types.CalcUncleHash([]*types.Header&#123;&#125;) &#123;</span><br><span class=\"line\">                            log.Trace(&quot;Block empty, skipping body retrieval&quot;, &quot;peer&quot;, announce.origin, &quot;number&quot;, header.Number, &quot;hash&quot;, header.Hash())</span><br><span class=\"line\"></span><br><span class=\"line\">                            block := types.NewBlockWithHeader(header)</span><br><span class=\"line\">                            block.ReceivedAt = task.time</span><br><span class=\"line\"></span><br><span class=\"line\">                            complete = append(complete, block)</span><br><span class=\"line\">                            f.completing[hash] = announce</span><br><span class=\"line\">                            continue</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        // Otherwise add to the list of blocks needing completion</span><br><span class=\"line\">                        incomplete = append(incomplete, announce)</span><br><span class=\"line\">                    &#125; else &#123;</span><br><span class=\"line\">                        log.Trace(&quot;Block already imported, discarding header&quot;, &quot;peer&quot;, announce.origin, &quot;number&quot;, header.Number, &quot;hash&quot;, header.Hash())</span><br><span class=\"line\">                        f.forgetHash(hash)</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    // Fetcher doesn&apos;t know about it, add to the return list</span><br><span class=\"line\">                    unknown = append(unknown, header)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            headerFilterOutMeter.Mark(int64(len(unknown)))</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case filter &lt;- &amp;headerFilterTask&#123;headers: unknown, time: task.time&#125;:</span><br><span class=\"line\">            case &lt;-f.quit:</span><br><span class=\"line\">                return</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the retrieved headers for body completion</span><br><span class=\"line\">            for _, announce := range incomplete &#123;</span><br><span class=\"line\">                hash := announce.header.Hash()</span><br><span class=\"line\">                if _, ok := f.completing[hash]; ok &#123;</span><br><span class=\"line\">                    continue</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                f.fetched[hash] = append(f.fetched[hash], announce)</span><br><span class=\"line\">                if len(f.fetched) == 1 &#123;</span><br><span class=\"line\">                    f.rescheduleComplete(completeTimer)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the header-only blocks for import</span><br><span class=\"line\">            for _, block := range complete &#123;</span><br><span class=\"line\">                if announce := f.completing[block.Hash()]; announce != nil &#123;</span><br><span class=\"line\">                    f.enqueue(announce.origin, block)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，遍历headerFilter里面的各个header，如果在 f.fetching状态列表，且不在f.fetched状态列表和 f.completing状态列表，就继续进行过滤，否则塞进unknown队列 发送给filter，FilterHeaders里面task 接收到filter，并作为FilterHeaders的返回值返回。<br>2，如果发现这个header的number和从f.fetching状态列表取到的announce的number不一样，说明有可能收到一个伪造的区块通知，此时就要把这个可能的伪造节点和可能的伪造的hash抛弃，另可错杀，不能放过。<br>3，如果本节点已经有这个hash的block，则放弃这个hash。如果这个block里面没有任何交易也没有任何叔区块，则把这个hash放入complete列表同时加入f.completing状态列表，否则放入incomplete列表。<br>4，在incomplete列表里面，且不在f.completing状态列表里，则加入f.fetched状态列表，启动completeTimer的调度。<br>5，在complete列表里面，同时也在f.completing状态列表，则调用f.enqueue(announce.origin, block)方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case &lt;-completeTimer.C:</span><br><span class=\"line\">            // At least one header&apos;s timer ran out, retrieve everything</span><br><span class=\"line\">            request := make(map[string][]common.Hash)</span><br><span class=\"line\"></span><br><span class=\"line\">            for hash, announces := range f.fetched &#123;</span><br><span class=\"line\">                // Pick a random peer to retrieve from, reset all others</span><br><span class=\"line\">                announce := announces[rand.Intn(len(announces))]</span><br><span class=\"line\">                f.forgetHash(hash)</span><br><span class=\"line\"></span><br><span class=\"line\">                // If the block still didn&apos;t arrive, queue for completion</span><br><span class=\"line\">                if f.getBlock(hash) == nil &#123;</span><br><span class=\"line\">                    request[announce.origin] = append(request[announce.origin], hash)</span><br><span class=\"line\">                    f.completing[hash] = announce</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Send out all block body requests</span><br><span class=\"line\">            for peer, hashes := range request &#123;</span><br><span class=\"line\">                log.Trace(&quot;Fetching scheduled bodies&quot;, &quot;peer&quot;, peer, &quot;list&quot;, hashes)</span><br><span class=\"line\"></span><br><span class=\"line\">                // Create a closure of the fetch and schedule in on a new thread</span><br><span class=\"line\">                if f.completingHook != nil &#123;</span><br><span class=\"line\">                    f.completingHook(hashes)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                bodyFetchMeter.Mark(int64(len(hashes)))</span><br><span class=\"line\">                go f.completing[hashes[0]].fetchBodies(hashes)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the next fetch if blocks are still pending</span><br><span class=\"line\">            f.rescheduleComplete(completeTimer)</span><br></pre></td></tr></table></figure>\n\n<p>1，首先遍历f.fetched，hash对应在fetcher里面的状态都清了。<br>如果发现超时了还没有没有获取到这个hash的block，则把这个announce加到request列表中，同时重新把announce放到f.completing状态列表。<br>2，然后遍历request列表，request列表里面的每个网络节点过来的所有的block的hash，都会调用fetchBodies(hashes)方法来获取区块body数据。这个fetchBodies(hashes)方法是peer.go里面的一个全局方法。<br>3， 这时候BlockHashesMsg 的fetcher处理就结束了，最后再启动completeTimer循环调度。</p>\n<p>四，Fetcher分析， 之FilterBodies() ，Enqueue(），<br>1，fetchBodies(hash)方法，调用了peer.go 里面的全局方法RequestBodies(hashes []common.Hash) Send给网络节点一个GetBlockBodiesMsg 消息。<br>2，然后pm.handleMsg 会收到 BlockBodiesMsg广播通知。<br>3，执行 pm.fetcher.FilterBodies(p.id, trasactions, uncles, time.Now())。<br>接下来就和FilterHeaders()流程类似，一顿啪啪啪验证，一顿啪啪啪改变状态，一顿啪啪啪通道跳转<br>4，庆幸的是，走完FilterBodies()就完事了，不用在走timer调度，也不用再发网络请求了。<br>5，在FilterHeaders()和FilterBodies()最后都走到了f.enqueue(announce.origin, block)方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (f *Fetcher) enqueue(peer string, block *types.Block) &#123;</span><br><span class=\"line\">    hash := block.Hash()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Ensure the peer isn&apos;t DOSing us</span><br><span class=\"line\">    count := f.queues[peer] + 1</span><br><span class=\"line\">    if count &gt; blockLimit &#123;</span><br><span class=\"line\">        log.Debug(&quot;Discarded propagated block, exceeded allowance&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;limit&quot;, blockLimit)</span><br><span class=\"line\">        propBroadcastDOSMeter.Mark(1)</span><br><span class=\"line\">        f.forgetHash(hash)</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Discard any past or too distant blocks</span><br><span class=\"line\">    if dist := int64(block.NumberU64()) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist &#123;</span><br><span class=\"line\">        log.Debug(&quot;Discarded propagated block, too far away&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;distance&quot;, dist)</span><br><span class=\"line\">        propBroadcastDropMeter.Mark(1)</span><br><span class=\"line\">        f.forgetHash(hash)</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Schedule the block for future importing</span><br><span class=\"line\">    if _, ok := f.queued[hash]; !ok &#123;</span><br><span class=\"line\">        op := &amp;inject&#123;</span><br><span class=\"line\">            origin: peer,</span><br><span class=\"line\">            block:  block,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        f.queues[peer] = count</span><br><span class=\"line\">        f.queued[hash] = op</span><br><span class=\"line\">        f.queue.Push(op, -float32(block.NumberU64()))</span><br><span class=\"line\">        if f.queueChangeHook != nil &#123;</span><br><span class=\"line\">            f.queueChangeHook(op.block.Hash(), true)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        log.Debug(&quot;Queued propagated block&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;queued&quot;, f.queue.Size())</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>过滤掉太远的区块。并把hash加入到f.queue列表中。<br>在loop主回路里面遍历f.queue列表，并把列表中的block insert到本地的block chain中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (f *Fetcher) insert(peer string, block *types.Block) &#123;</span><br><span class=\"line\">    hash := block.Hash()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Run the import on a new thread</span><br><span class=\"line\">    log.Debug(&quot;Importing propagated block&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash)</span><br><span class=\"line\">    go func() &#123;</span><br><span class=\"line\">        defer func() &#123; f.done &lt;- hash &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">        // If the parent&apos;s unknown, abort insertion</span><br><span class=\"line\">        parent := f.getBlock(block.ParentHash())</span><br><span class=\"line\">        if parent == nil &#123;</span><br><span class=\"line\">            log.Debug(&quot;Unknown parent of propagated block&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;parent&quot;, block.ParentHash())</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Quickly validate the header and propagate the block if it passes</span><br><span class=\"line\">        switch err := f.verifyHeader(block.Header()); err &#123;</span><br><span class=\"line\">        case nil:</span><br><span class=\"line\">            // All ok, quickly propagate to our peers</span><br><span class=\"line\">            propBroadcastOutTimer.UpdateSince(block.ReceivedAt)</span><br><span class=\"line\">            go f.broadcastBlock(block, true)</span><br><span class=\"line\"></span><br><span class=\"line\">        case consensus.ErrFutureBlock:</span><br><span class=\"line\">            // Weird future block, don&apos;t fail, but neither propagate</span><br><span class=\"line\"></span><br><span class=\"line\">        default:</span><br><span class=\"line\">            // Something went very wrong, drop the peer</span><br><span class=\"line\">            log.Debug(&quot;Propagated block verification failed&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;err&quot;, err)</span><br><span class=\"line\">            f.dropPeer(peer)</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Run the actual import and log any issues</span><br><span class=\"line\">        if _, err := f.insertChain(types.Blocks&#123;block&#125;); err != nil &#123;</span><br><span class=\"line\">            log.Debug(&quot;Propagated block import failed&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;err&quot;, err)</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // If import succeeded, broadcast the block</span><br><span class=\"line\">        propAnnounceOutTimer.UpdateSince(block.ReceivedAt)</span><br><span class=\"line\">        go f.broadcastBlock(block, false)</span><br><span class=\"line\"></span><br><span class=\"line\">        // Invoke the testing hook if needed</span><br><span class=\"line\">        if f.importedHook != nil &#123;</span><br><span class=\"line\">            f.importedHook(block)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>首先调用共识引擎的方法f.verifyHeader(block.Header())，验证blockHeader的有效性。<br>如果没问题就广播出去，告诉全世界我的区块链更新了一个新区块。<br>然后调用f.insertChain(types.Blocks{block}) 插入本地区块链。<br>插入成功，最后再广播一次(这是多么的自恋啊)，这次只广播block的hash。</p>\n<p>总结<br>fetcher.go 作为以太坊同步区块的一个辅助类，它的职责就是层层把关，层层过滤，抵制无效的区块进入，杜绝无用的同步请求。这块代码很多很乱，第一次看可能会有点晕，第二次看可能还是很晕，多看几次可能还会晕😄，不过只要知道它做什么就好了。</p>\n<h4 id=\"Downloader\"><a href=\"#Downloader\" class=\"headerlink\" title=\"Downloader\"></a>Downloader</h4><p>一，启动Downloader<br>ProtocolManager初始化的时候会进行Downloader的初始化：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func New(mode SyncMode, stateDb ethdb.Database, mux *event.TypeMux, chain BlockChain, lightchain LightChain, dropPeer peerDropFn) *Downloader &#123;</span><br><span class=\"line\">    if lightchain == nil &#123;</span><br><span class=\"line\">        lightchain = chain</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    dl := &amp;Downloader&#123;</span><br><span class=\"line\">        mode:           mode,</span><br><span class=\"line\">        stateDB:        stateDb,</span><br><span class=\"line\">        mux:            mux,</span><br><span class=\"line\">        queue:          newQueue(),</span><br><span class=\"line\">        peers:          newPeerSet(),</span><br><span class=\"line\">        rttEstimate:    uint64(rttMaxEstimate),</span><br><span class=\"line\">        rttConfidence:  uint64(1000000),</span><br><span class=\"line\">        blockchain:     chain,</span><br><span class=\"line\">        lightchain:     lightchain,</span><br><span class=\"line\">        dropPeer:       dropPeer,</span><br><span class=\"line\">        headerCh:       make(chan dataPack, 1),</span><br><span class=\"line\">        bodyCh:         make(chan dataPack, 1),</span><br><span class=\"line\">        receiptCh:      make(chan dataPack, 1),</span><br><span class=\"line\">        bodyWakeCh:     make(chan bool, 1),</span><br><span class=\"line\">        receiptWakeCh:  make(chan bool, 1),</span><br><span class=\"line\">        headerProcCh:   make(chan []*types.Header, 1),</span><br><span class=\"line\">        quitCh:         make(chan struct&#123;&#125;),</span><br><span class=\"line\">        stateCh:        make(chan dataPack),</span><br><span class=\"line\">        stateSyncStart: make(chan *stateSync),</span><br><span class=\"line\">        trackStateReq:  make(chan *stateReq),</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    go dl.qosTuner()</span><br><span class=\"line\">    go dl.stateFetcher()</span><br><span class=\"line\">    return dl</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>首先初始化Downloader对象的成员，然后启动dl.qosTuner() goroutine计算请求回路时间，启动dl.stateFetcher() goroutine 开启Downloader状态监控。</p>\n<p>ProtocolManager收到新的区块消息广播或者有新的P2P网络节点加入的时候会调用ProtocolManager的 synchronise(peer *peer)方法，这时候会调用Downloader的Synchronise(peer.id, pHead, pTd, mode)方法。</p>\n<p>Synchronise方法，重置d.queue和d.peers，清空d.bodyWakeCh, d.receiptWakeCh，d.headerCh, d.bodyCh, d.receiptCh，d.headerProcCh。调用d.syncWithPeer(p, hash, td)方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) syncWithPeer(p *peerConnection, hash common.Hash, td *big.Int) (err error) &#123;</span><br><span class=\"line\">    d.mux.Post(StartEvent&#123;&#125;)</span><br><span class=\"line\">    defer func() &#123;</span><br><span class=\"line\">        // reset on error</span><br><span class=\"line\">        if err != nil &#123;</span><br><span class=\"line\">            d.mux.Post(FailedEvent&#123;err&#125;)</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            d.mux.Post(DoneEvent&#123;&#125;)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\">    if p.version &lt; 62 &#123;</span><br><span class=\"line\">        return errTooOld</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    log.Debug(&quot;Synchronising with the network&quot;, &quot;peer&quot;, p.id, &quot;eth&quot;, p.version, &quot;head&quot;, hash, &quot;td&quot;, td, &quot;mode&quot;, d.mode)</span><br><span class=\"line\">    defer func(start time.Time) &#123;</span><br><span class=\"line\">        log.Debug(&quot;Synchronisation terminated&quot;, &quot;elapsed&quot;, time.Since(start))</span><br><span class=\"line\">    &#125;(time.Now())</span><br><span class=\"line\"></span><br><span class=\"line\">    // Look up the sync boundaries: the common ancestor and the target block</span><br><span class=\"line\">    latest, err := d.fetchHeight(p)</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        return err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    height := latest.Number.Uint64()</span><br><span class=\"line\"></span><br><span class=\"line\">    origin, err := d.findAncestor(p, height)</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        return err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    d.syncStatsLock.Lock()</span><br><span class=\"line\">    if d.syncStatsChainHeight &lt;= origin || d.syncStatsChainOrigin &gt; origin &#123;</span><br><span class=\"line\">        d.syncStatsChainOrigin = origin</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    d.syncStatsChainHeight = height</span><br><span class=\"line\">    d.syncStatsLock.Unlock()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Ensure our origin point is below any fast sync pivot point</span><br><span class=\"line\">    pivot := uint64(0)</span><br><span class=\"line\">    if d.mode == FastSync &#123;</span><br><span class=\"line\">        if height &lt;= uint64(fsMinFullBlocks) &#123;</span><br><span class=\"line\">            origin = 0</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            pivot = height - uint64(fsMinFullBlocks)</span><br><span class=\"line\">            if pivot &lt;= origin &#123;</span><br><span class=\"line\">                origin = pivot - 1</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    d.committed = 1</span><br><span class=\"line\">    if d.mode == FastSync &amp;&amp; pivot != 0 &#123;</span><br><span class=\"line\">        d.committed = 0</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Initiate the sync using a concurrent header and content retrieval algorithm</span><br><span class=\"line\">    d.queue.Prepare(origin+1, d.mode)</span><br><span class=\"line\">    if d.syncInitHook != nil &#123;</span><br><span class=\"line\">        d.syncInitHook(origin, height)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    fetchers := []func() error&#123;</span><br><span class=\"line\">        func() error &#123; return d.fetchHeaders(p, origin+1, pivot) &#125;, // Headers are always retrieved</span><br><span class=\"line\">        func() error &#123; return d.fetchBodies(origin + 1) &#125;,          // Bodies are retrieved during normal and fast sync</span><br><span class=\"line\">        func() error &#123; return d.fetchReceipts(origin + 1) &#125;,        // Receipts are retrieved during fast sync</span><br><span class=\"line\">        func() error &#123; return d.processHeaders(origin+1, pivot, td) &#125;,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if d.mode == FastSync &#123;</span><br><span class=\"line\">        fetchers = append(fetchers, func() error &#123; return d.processFastSyncContent(latest) &#125;)</span><br><span class=\"line\">    &#125; else if d.mode == FullSync &#123;</span><br><span class=\"line\">        fetchers = append(fetchers, d.processFullSyncContent)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return d.spawnSync(fetchers)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>首先调用latest, err := d.fetchHeight(p)获取到peer节点最新的区块头,这个方法有点绕，我们来分析一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) fetchHeight(p *peerConnection) (*types.Header, error) &#123;</span><br><span class=\"line\">    p.log.Debug(&quot;Retrieving remote chain height&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    // Request the advertised remote head block and wait for the response</span><br><span class=\"line\">    head, _ := p.peer.Head()</span><br><span class=\"line\">    go p.peer.RequestHeadersByHash(head, 1, 0, false)</span><br><span class=\"line\"></span><br><span class=\"line\">    ttl := d.requestTTL()</span><br><span class=\"line\">    timeout := time.After(ttl)</span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-d.cancelCh:</span><br><span class=\"line\">            return nil, errCancelBlockFetch</span><br><span class=\"line\"></span><br><span class=\"line\">        case packet := &lt;-d.headerCh:</span><br><span class=\"line\">            // Discard anything not from the origin peer</span><br><span class=\"line\">            if packet.PeerId() != p.id &#123;</span><br><span class=\"line\">                log.Debug(&quot;Received headers from incorrect peer&quot;, &quot;peer&quot;, packet.PeerId())</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Make sure the peer actually gave something valid</span><br><span class=\"line\">            headers := packet.(*headerPack).headers</span><br><span class=\"line\">            if len(headers) != 1 &#123;</span><br><span class=\"line\">                p.log.Debug(&quot;Multiple headers for single request&quot;, &quot;headers&quot;, len(headers))</span><br><span class=\"line\">                return nil, errBadPeer</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            head := headers[0]</span><br><span class=\"line\">            p.log.Debug(&quot;Remote head header identified&quot;, &quot;number&quot;, head.Number, &quot;hash&quot;, head.Hash())</span><br><span class=\"line\">            return head, nil</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-timeout:</span><br><span class=\"line\">            p.log.Debug(&quot;Waiting for head header timed out&quot;, &quot;elapsed&quot;, ttl)</span><br><span class=\"line\">            return nil, errTimeout</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-d.bodyCh:</span><br><span class=\"line\">        case &lt;-d.receiptCh:</span><br><span class=\"line\">            // Out of bounds delivery, ignore</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，调用peer.RequestHeadersByHash(head, 1, 0, false)，给网络节点发送一个GetBlockHeadersMsg的消息<br>2，然后阻塞住线程，直到收到d.headerCh或者timeout<br>3，本地节点会收到网络节点的BlockHeadersMsg的消息返回<br>4，调用downloader.DeliverHeaders(p.id, headers)<br>5，这时候会把p.id和headers打包发送给d.headerCh<br>6，这时候select收到d.headerCh，阻塞打开，并返回header内容</p>\n<p>syncWithPeer() 方法接着调用 d.findAncestor(p, height)来获取本地节点和网络节点共同的祖先：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) findAncestor(p *peerConnection, height uint64) (uint64, error) &#123;</span><br><span class=\"line\">    // Figure out the valid ancestor range to prevent rewrite attacks</span><br><span class=\"line\">    floor, ceil := int64(-1), d.lightchain.CurrentHeader().Number.Uint64()</span><br><span class=\"line\"></span><br><span class=\"line\">    if d.mode == FullSync &#123;</span><br><span class=\"line\">        ceil = d.blockchain.CurrentBlock().NumberU64()</span><br><span class=\"line\">    &#125; else if d.mode == FastSync &#123;</span><br><span class=\"line\">        ceil = d.blockchain.CurrentFastBlock().NumberU64()</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if ceil &gt;= MaxForkAncestry &#123;</span><br><span class=\"line\">        floor = int64(ceil - MaxForkAncestry)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    p.log.Debug(&quot;Looking for common ancestor&quot;, &quot;local&quot;, ceil, &quot;remote&quot;, height)</span><br><span class=\"line\"></span><br><span class=\"line\">    // Request the topmost blocks to short circuit binary ancestor lookup</span><br><span class=\"line\">    head := ceil</span><br><span class=\"line\">    if head &gt; height &#123;</span><br><span class=\"line\">        head = height</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    from := int64(head) - int64(MaxHeaderFetch)</span><br><span class=\"line\">    if from &lt; 0 &#123;</span><br><span class=\"line\">        from = 0</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Span out with 15 block gaps into the future to catch bad head reports</span><br><span class=\"line\">    limit := 2 * MaxHeaderFetch / 16</span><br><span class=\"line\">    count := 1 + int((int64(ceil)-from)/16)</span><br><span class=\"line\">    if count &gt; limit &#123;</span><br><span class=\"line\">        count = limit</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    go p.peer.RequestHeadersByNumber(uint64(from), count, 15, false)</span><br><span class=\"line\"></span><br><span class=\"line\">    // Wait for the remote response to the head fetch</span><br><span class=\"line\">    number, hash := uint64(0), common.Hash&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ttl := d.requestTTL()</span><br><span class=\"line\">    timeout := time.After(ttl)</span><br><span class=\"line\"></span><br><span class=\"line\">    for finished := false; !finished; &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-d.cancelCh:</span><br><span class=\"line\">            return 0, errCancelHeaderFetch</span><br><span class=\"line\"></span><br><span class=\"line\">        case packet := &lt;-d.headerCh:</span><br><span class=\"line\">            // Discard anything not from the origin peer</span><br><span class=\"line\">            if packet.PeerId() != p.id &#123;</span><br><span class=\"line\">                log.Debug(&quot;Received headers from incorrect peer&quot;, &quot;peer&quot;, packet.PeerId())</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Make sure the peer actually gave something valid</span><br><span class=\"line\">            headers := packet.(*headerPack).headers</span><br><span class=\"line\">            if len(headers) == 0 &#123;</span><br><span class=\"line\">                p.log.Warn(&quot;Empty head header set&quot;)</span><br><span class=\"line\">                return 0, errEmptyHeaderSet</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Make sure the peer&apos;s reply conforms to the request</span><br><span class=\"line\">            for i := 0; i &lt; len(headers); i++ &#123;</span><br><span class=\"line\">                if number := headers[i].Number.Int64(); number != from+int64(i)*16 &#123;</span><br><span class=\"line\">                    p.log.Warn(&quot;Head headers broke chain ordering&quot;, &quot;index&quot;, i, &quot;requested&quot;, from+int64(i)*16, &quot;received&quot;, number)</span><br><span class=\"line\">                    return 0, errInvalidChain</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Check if a common ancestor was found</span><br><span class=\"line\">            finished = true</span><br><span class=\"line\">            for i := len(headers) - 1; i &gt;= 0; i-- &#123;</span><br><span class=\"line\">                // Skip any headers that underflow/overflow our requested set</span><br><span class=\"line\">                if headers[i].Number.Int64() &lt; from || headers[i].Number.Uint64() &gt; ceil &#123;</span><br><span class=\"line\">                    continue</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Otherwise check if we already know the header or not</span><br><span class=\"line\">                if (d.mode == FullSync &amp;&amp; d.blockchain.HasBlock(headers[i].Hash(), headers[i].Number.Uint64())) || (d.mode != FullSync &amp;&amp; d.lightchain.HasHeader(headers[i].Hash(), headers[i].Number.Uint64())) &#123;</span><br><span class=\"line\">                    number, hash = headers[i].Number.Uint64(), headers[i].Hash()</span><br><span class=\"line\"></span><br><span class=\"line\">                    // If every header is known, even future ones, the peer straight out lied about its head</span><br><span class=\"line\">                    if number &gt; height &amp;&amp; i == limit-1 &#123;</span><br><span class=\"line\">                        p.log.Warn(&quot;Lied about chain head&quot;, &quot;reported&quot;, height, &quot;found&quot;, number)</span><br><span class=\"line\">                        return 0, errStallingPeer</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    break</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-timeout:</span><br><span class=\"line\">            p.log.Debug(&quot;Waiting for head header timed out&quot;, &quot;elapsed&quot;, ttl)</span><br><span class=\"line\">            return 0, errTimeout</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-d.bodyCh:</span><br><span class=\"line\">        case &lt;-d.receiptCh:</span><br><span class=\"line\">            // Out of bounds delivery, ignore</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // If the head fetch already found an ancestor, return</span><br><span class=\"line\">    if !common.EmptyHash(hash) &#123;</span><br><span class=\"line\">        if int64(number) &lt;= floor &#123;</span><br><span class=\"line\">            p.log.Warn(&quot;Ancestor below allowance&quot;, &quot;number&quot;, number, &quot;hash&quot;, hash, &quot;allowance&quot;, floor)</span><br><span class=\"line\">            return 0, errInvalidAncestor</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        p.log.Debug(&quot;Found common ancestor&quot;, &quot;number&quot;, number, &quot;hash&quot;, hash)</span><br><span class=\"line\">        return number, nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Ancestor not found, we need to binary search over our chain</span><br><span class=\"line\">    start, end := uint64(0), head</span><br><span class=\"line\">    if floor &gt; 0 &#123;</span><br><span class=\"line\">        start = uint64(floor)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    for start+1 &lt; end &#123;</span><br><span class=\"line\">        // Split our chain interval in two, and request the hash to cross check</span><br><span class=\"line\">        check := (start + end) / 2</span><br><span class=\"line\"></span><br><span class=\"line\">        ttl := d.requestTTL()</span><br><span class=\"line\">        timeout := time.After(ttl)</span><br><span class=\"line\"></span><br><span class=\"line\">        go p.peer.RequestHeadersByNumber(check, 1, 0, false)</span><br><span class=\"line\"></span><br><span class=\"line\">        // Wait until a reply arrives to this request</span><br><span class=\"line\">        for arrived := false; !arrived; &#123;</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case &lt;-d.cancelCh:</span><br><span class=\"line\">                return 0, errCancelHeaderFetch</span><br><span class=\"line\"></span><br><span class=\"line\">            case packer := &lt;-d.headerCh:</span><br><span class=\"line\">                // Discard anything not from the origin peer</span><br><span class=\"line\">                if packer.PeerId() != p.id &#123;</span><br><span class=\"line\">                    log.Debug(&quot;Received headers from incorrect peer&quot;, &quot;peer&quot;, packer.PeerId())</span><br><span class=\"line\">                    break</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Make sure the peer actually gave something valid</span><br><span class=\"line\">                headers := packer.(*headerPack).headers</span><br><span class=\"line\">                if len(headers) != 1 &#123;</span><br><span class=\"line\">                    p.log.Debug(&quot;Multiple headers for single request&quot;, &quot;headers&quot;, len(headers))</span><br><span class=\"line\">                    return 0, errBadPeer</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                arrived = true</span><br><span class=\"line\"></span><br><span class=\"line\">                // Modify the search interval based on the response</span><br><span class=\"line\">                if (d.mode == FullSync &amp;&amp; !d.blockchain.HasBlock(headers[0].Hash(), headers[0].Number.Uint64())) || (d.mode != FullSync &amp;&amp; !d.lightchain.HasHeader(headers[0].Hash(), headers[0].Number.Uint64())) &#123;</span><br><span class=\"line\">                    end = check</span><br><span class=\"line\">                    break</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                header := d.lightchain.GetHeaderByHash(headers[0].Hash()) // Independent of sync mode, header surely exists</span><br><span class=\"line\">                if header.Number.Uint64() != check &#123;</span><br><span class=\"line\">                    p.log.Debug(&quot;Received non requested header&quot;, &quot;number&quot;, header.Number, &quot;hash&quot;, header.Hash(), &quot;request&quot;, check)</span><br><span class=\"line\">                    return 0, errBadPeer</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                start = check</span><br><span class=\"line\"></span><br><span class=\"line\">            case &lt;-timeout:</span><br><span class=\"line\">                p.log.Debug(&quot;Waiting for search header timed out&quot;, &quot;elapsed&quot;, ttl)</span><br><span class=\"line\">                return 0, errTimeout</span><br><span class=\"line\"></span><br><span class=\"line\">            case &lt;-d.bodyCh:</span><br><span class=\"line\">            case &lt;-d.receiptCh:</span><br><span class=\"line\">                // Out of bounds delivery, ignore</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Ensure valid ancestry and return</span><br><span class=\"line\">    if int64(start) &lt;= floor &#123;</span><br><span class=\"line\">        p.log.Warn(&quot;Ancestor below allowance&quot;, &quot;number&quot;, start, &quot;hash&quot;, hash, &quot;allowance&quot;, floor)</span><br><span class=\"line\">        return 0, errInvalidAncestor</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    p.log.Debug(&quot;Found common ancestor&quot;, &quot;number&quot;, start, &quot;hash&quot;, hash)</span><br><span class=\"line\">    return start, nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，调用peer.RequestHeadersByNumber(uint64(from), count, 15, false)，获取header。这里传入 count和 15，指从本地最高的header往前数192个区块的头，每16个区块取一个区块头。为了后面select收到d.headerCh时加以验证。<br>2，select收到了headers，遍历header，看是否在本地是否存在这个header，如果有，并且不为空，就说明找到共同的祖先，返回祖先number<br>3，如果没有找到共同的祖先，再重新从本地的区块链MaxForkAncestry起的一半的位置开始取区块头，一一验证是否跟网络节点返回的header一致，如果有就说明有共同的祖先，并返回，没有的话就返回0.</p>\n<p>继续syncWithPeer()方法，找到同步的轴心的pivot，最后把要同步的数据和同步的方法传给d.spawnSync(fetchers)，并执行。d.spawnSync(fetchers)挨个执行传入的同步方法。</p>\n<p>二，Downloader同步数据方法<br>fetchHeaders()，fetchBodies() , fetchReceipts()</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) fetchHeaders(p *peerConnection, from uint64, pivot uint64) error &#123;</span><br><span class=\"line\">    p.log.Debug(&quot;Directing header downloads&quot;, &quot;origin&quot;, from)</span><br><span class=\"line\">    defer p.log.Debug(&quot;Header download terminated&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    // Create a timeout timer, and the associated header fetcher</span><br><span class=\"line\">    skeleton := true            // Skeleton assembly phase or finishing up</span><br><span class=\"line\">    request := time.Now()       // time of the last skeleton fetch request</span><br><span class=\"line\">    timeout := time.NewTimer(0) // timer to dump a non-responsive active peer</span><br><span class=\"line\">    &lt;-timeout.C                 // timeout channel should be initially empty</span><br><span class=\"line\">    defer timeout.Stop()</span><br><span class=\"line\"></span><br><span class=\"line\">    var ttl time.Duration</span><br><span class=\"line\">    getHeaders := func(from uint64) &#123;</span><br><span class=\"line\">        request = time.Now()</span><br><span class=\"line\"></span><br><span class=\"line\">        ttl = d.requestTTL()</span><br><span class=\"line\">        timeout.Reset(ttl)</span><br><span class=\"line\"></span><br><span class=\"line\">        if skeleton &#123;</span><br><span class=\"line\">            p.log.Trace(&quot;Fetching skeleton headers&quot;, &quot;count&quot;, MaxHeaderFetch, &quot;from&quot;, from)</span><br><span class=\"line\">            go p.peer.RequestHeadersByNumber(from+uint64(MaxHeaderFetch)-1, MaxSkeletonSize, MaxHeaderFetch-1, false)</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            p.log.Trace(&quot;Fetching full headers&quot;, &quot;count&quot;, MaxHeaderFetch, &quot;from&quot;, from)</span><br><span class=\"line\">            go p.peer.RequestHeadersByNumber(from, MaxHeaderFetch, 0, false)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Start pulling the header chain skeleton until all is done</span><br><span class=\"line\">    getHeaders(from)</span><br><span class=\"line\"></span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-d.cancelCh:</span><br><span class=\"line\">            return errCancelHeaderFetch</span><br><span class=\"line\"></span><br><span class=\"line\">        case packet := &lt;-d.headerCh:</span><br><span class=\"line\">            // Make sure the active peer is giving us the skeleton headers</span><br><span class=\"line\">            if packet.PeerId() != p.id &#123;</span><br><span class=\"line\">                log.Debug(&quot;Received skeleton from incorrect peer&quot;, &quot;peer&quot;, packet.PeerId())</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            headerReqTimer.UpdateSince(request)</span><br><span class=\"line\">            timeout.Stop()</span><br><span class=\"line\"></span><br><span class=\"line\">            // If the skeleton&apos;s finished, pull any remaining head headers directly from the origin</span><br><span class=\"line\">            if packet.Items() == 0 &amp;&amp; skeleton &#123;</span><br><span class=\"line\">                skeleton = false</span><br><span class=\"line\">                getHeaders(from)</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // If no more headers are inbound, notify the content fetchers and return</span><br><span class=\"line\">            if packet.Items() == 0 &#123;</span><br><span class=\"line\">                // Don&apos;t abort header fetches while the pivot is downloading</span><br><span class=\"line\">                if atomic.LoadInt32(&amp;d.committed) == 0 &amp;&amp; pivot &lt;= from &#123;</span><br><span class=\"line\">                    p.log.Debug(&quot;No headers, waiting for pivot commit&quot;)</span><br><span class=\"line\">                    select &#123;</span><br><span class=\"line\">                    case &lt;-time.After(fsHeaderContCheck):</span><br><span class=\"line\">                        getHeaders(from)</span><br><span class=\"line\">                        continue</span><br><span class=\"line\">                    case &lt;-d.cancelCh:</span><br><span class=\"line\">                        return errCancelHeaderFetch</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Pivot done (or not in fast sync) and no more headers, terminate the process</span><br><span class=\"line\">                p.log.Debug(&quot;No more headers available&quot;)</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case d.headerProcCh &lt;- nil:</span><br><span class=\"line\">                    return nil</span><br><span class=\"line\">                case &lt;-d.cancelCh:</span><br><span class=\"line\">                    return errCancelHeaderFetch</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            headers := packet.(*headerPack).headers</span><br><span class=\"line\"></span><br><span class=\"line\">            // If we received a skeleton batch, resolve internals concurrently</span><br><span class=\"line\">            if skeleton &#123;</span><br><span class=\"line\">                filled, proced, err := d.fillHeaderSkeleton(from, headers)</span><br><span class=\"line\">                if err != nil &#123;</span><br><span class=\"line\">                    p.log.Debug(&quot;Skeleton chain invalid&quot;, &quot;err&quot;, err)</span><br><span class=\"line\">                    return errInvalidChain</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                headers = filled[proced:]</span><br><span class=\"line\">                from += uint64(proced)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Insert all the new headers and fetch the next batch</span><br><span class=\"line\">            if len(headers) &gt; 0 &#123;</span><br><span class=\"line\">                p.log.Trace(&quot;Scheduling new headers&quot;, &quot;count&quot;, len(headers), &quot;from&quot;, from)</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case d.headerProcCh &lt;- headers:</span><br><span class=\"line\">                case &lt;-d.cancelCh:</span><br><span class=\"line\">                    return errCancelHeaderFetch</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                from += uint64(len(headers))</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            getHeaders(from)</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-timeout.C:</span><br><span class=\"line\">            if d.dropPeer == nil &#123;</span><br><span class=\"line\">                // The dropPeer method is nil when `--copydb` is used for a local copy.</span><br><span class=\"line\">                // Timeouts can occur if e.g. compaction hits at the wrong time, and can be ignored</span><br><span class=\"line\">                p.log.Warn(&quot;Downloader wants to drop peer, but peerdrop-function is not set&quot;, &quot;peer&quot;, p.id)</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Header retrieval timed out, consider the peer bad and drop</span><br><span class=\"line\">            p.log.Debug(&quot;Header request timed out&quot;, &quot;elapsed&quot;, ttl)</span><br><span class=\"line\">            headerTimeoutMeter.Mark(1)</span><br><span class=\"line\">            d.dropPeer(p.id)</span><br><span class=\"line\"></span><br><span class=\"line\">            // Finish the sync gracefully instead of dumping the gathered data though</span><br><span class=\"line\">            for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123;</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case ch &lt;- false:</span><br><span class=\"line\">                case &lt;-d.cancelCh:</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case d.headerProcCh &lt;- nil:</span><br><span class=\"line\">            case &lt;-d.cancelCh:</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            return errBadPeer</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，getHeaders()调用peer.RequestHeadersByNumber()方法 获取网络节点的headers。<br>2，有两种获取方式，首先走的是skeleton方式，从查找到的共同祖先区块+192个区块位置开始，每隔192个区块，获取128个区块头。非skeleton方式，从共同祖先区块开始，获取192个区块头。<br>3，如果第一种方式获取不到区块头，则执行第二种获取方式，如果第二种方式还是没有获取到区块头的话，直接返回<br>4，如果是skeleton获取到的，调用fillHeaderSkeleton()方法加入到skeleton header chain<br>5，然后调整from值，再递归调用getHeaders()方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) fillHeaderSkeleton(from uint64, skeleton []*types.Header) ([]*types.Header, int, error) &#123;</span><br><span class=\"line\">    log.Debug(&quot;Filling up skeleton&quot;, &quot;from&quot;, from)</span><br><span class=\"line\">    d.queue.ScheduleSkeleton(from, skeleton)</span><br><span class=\"line\"></span><br><span class=\"line\">    var (</span><br><span class=\"line\">        deliver = func(packet dataPack) (int, error) &#123;</span><br><span class=\"line\">            pack := packet.(*headerPack)</span><br><span class=\"line\">            return d.queue.DeliverHeaders(pack.peerId, pack.headers, d.headerProcCh)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        expire   = func() map[string]int &#123; return d.queue.ExpireHeaders(d.requestTTL()) &#125;</span><br><span class=\"line\">        throttle = func() bool &#123; return false &#125;</span><br><span class=\"line\">        reserve  = func(p *peerConnection, count int) (*fetchRequest, bool, error) &#123;</span><br><span class=\"line\">            return d.queue.ReserveHeaders(p, count), false, nil</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        fetch    = func(p *peerConnection, req *fetchRequest) error &#123; return p.FetchHeaders(req.From, MaxHeaderFetch) &#125;</span><br><span class=\"line\">        capacity = func(p *peerConnection) int &#123; return p.HeaderCapacity(d.requestRTT()) &#125;</span><br><span class=\"line\">        setIdle  = func(p *peerConnection, accepted int) &#123; p.SetHeadersIdle(accepted) &#125;</span><br><span class=\"line\">    )</span><br><span class=\"line\">    err := d.fetchParts(errCancelHeaderFetch, d.headerCh, deliver, d.queue.headerContCh, expire,</span><br><span class=\"line\">        d.queue.PendingHeaders, d.queue.InFlightHeaders, throttle, reserve,</span><br><span class=\"line\">        nil, fetch, d.queue.CancelHeaders, capacity, d.peers.HeaderIdlePeers, setIdle, &quot;headers&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    log.Debug(&quot;Skeleton fill terminated&quot;, &quot;err&quot;, err)</span><br><span class=\"line\"></span><br><span class=\"line\">    filled, proced := d.queue.RetrieveHeaders()</span><br><span class=\"line\">    return filled, proced, err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>a) 把skeleton的headers加入queue.ScheduleSkeleton调度队列，<br>b) 然后执行d.fetchParts()方法。<br>d.fetchParts()方法主要做了这几件事情<br>1，对收到的headers执行d.queue.DeliverHeaders()方法。<br>2，如果d.queue.PendingHeaders有pending的headers，调用d.peers.HeaderIdlePeers获取到idle的peers<br>3，调用d.queue.ReserveHeaders把pending的headers储备到idle的peers里面<br>4，用idle的peers调用p.FetchHeaders(req.From, MaxHeaderFetch)去获取headers<br>c) 最后执行d.queue.RetrieveHeaders()，获取到filled进去的headers</p>\n<p>其他同步区块数据的方法d.fetchBodies() , d.fetchReceipts() 和fetchHeaders()流程类似，还更简单一些。</p>\n<p>三，Downloader同步数据过程<br>d.processHeaders(), d.processFastSyncContent(latest) , d.processFullSyncContent<br>1，d.processHeaders() 方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) processHeaders(origin uint64, pivot uint64, td *big.Int) error &#123;</span><br><span class=\"line\">    // Keep a count of uncertain headers to roll back</span><br><span class=\"line\">    rollback := []*types.Header&#123;&#125;</span><br><span class=\"line\">    defer func() &#123;</span><br><span class=\"line\">        if len(rollback) &gt; 0 &#123;</span><br><span class=\"line\">            // Flatten the headers and roll them back</span><br><span class=\"line\">            hashes := make([]common.Hash, len(rollback))</span><br><span class=\"line\">            for i, header := range rollback &#123;</span><br><span class=\"line\">                hashes[i] = header.Hash()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            lastHeader, lastFastBlock, lastBlock := d.lightchain.CurrentHeader().Number, common.Big0, common.Big0</span><br><span class=\"line\">            if d.mode != LightSync &#123;</span><br><span class=\"line\">                lastFastBlock = d.blockchain.CurrentFastBlock().Number()</span><br><span class=\"line\">                lastBlock = d.blockchain.CurrentBlock().Number()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            d.lightchain.Rollback(hashes)</span><br><span class=\"line\">            curFastBlock, curBlock := common.Big0, common.Big0</span><br><span class=\"line\">            if d.mode != LightSync &#123;</span><br><span class=\"line\">                curFastBlock = d.blockchain.CurrentFastBlock().Number()</span><br><span class=\"line\">                curBlock = d.blockchain.CurrentBlock().Number()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            log.Warn(&quot;Rolled back headers&quot;, &quot;count&quot;, len(hashes),</span><br><span class=\"line\">                &quot;header&quot;, fmt.Sprintf(&quot;%d-&gt;%d&quot;, lastHeader, d.lightchain.CurrentHeader().Number),</span><br><span class=\"line\">                &quot;fast&quot;, fmt.Sprintf(&quot;%d-&gt;%d&quot;, lastFastBlock, curFastBlock),</span><br><span class=\"line\">                &quot;block&quot;, fmt.Sprintf(&quot;%d-&gt;%d&quot;, lastBlock, curBlock))</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Wait for batches of headers to process</span><br><span class=\"line\">    gotHeaders := false</span><br><span class=\"line\"></span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-d.cancelCh:</span><br><span class=\"line\">            return errCancelHeaderProcessing</span><br><span class=\"line\"></span><br><span class=\"line\">        case headers := &lt;-d.headerProcCh:</span><br><span class=\"line\">            // Terminate header processing if we synced up</span><br><span class=\"line\">            if len(headers) == 0 &#123;</span><br><span class=\"line\">                // Notify everyone that headers are fully processed</span><br><span class=\"line\">                for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123;</span><br><span class=\"line\">                    select &#123;</span><br><span class=\"line\">                    case ch &lt;- false:</span><br><span class=\"line\">                    case &lt;-d.cancelCh:</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                if d.mode != LightSync &#123;</span><br><span class=\"line\">                    head := d.blockchain.CurrentBlock()</span><br><span class=\"line\">                    if !gotHeaders &amp;&amp; td.Cmp(d.blockchain.GetTd(head.Hash(), head.NumberU64())) &gt; 0 &#123;</span><br><span class=\"line\">                        return errStallingPeer</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                if d.mode == FastSync || d.mode == LightSync &#123;</span><br><span class=\"line\">                    head := d.lightchain.CurrentHeader()</span><br><span class=\"line\">                    if td.Cmp(d.lightchain.GetTd(head.Hash(), head.Number.Uint64())) &gt; 0 &#123;</span><br><span class=\"line\">                        return errStallingPeer</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Disable any rollback and return</span><br><span class=\"line\">                rollback = nil</span><br><span class=\"line\">                return nil</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Otherwise split the chunk of headers into batches and process them</span><br><span class=\"line\">            gotHeaders = true</span><br><span class=\"line\"></span><br><span class=\"line\">            for len(headers) &gt; 0 &#123;</span><br><span class=\"line\">                // Terminate if something failed in between processing chunks</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case &lt;-d.cancelCh:</span><br><span class=\"line\">                    return errCancelHeaderProcessing</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Select the next chunk of headers to import</span><br><span class=\"line\">                limit := maxHeadersProcess</span><br><span class=\"line\">                if limit &gt; len(headers) &#123;</span><br><span class=\"line\">                    limit = len(headers)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                chunk := headers[:limit]</span><br><span class=\"line\"></span><br><span class=\"line\">                // In case of header only syncing, validate the chunk immediately</span><br><span class=\"line\">                if d.mode == FastSync || d.mode == LightSync &#123;</span><br><span class=\"line\">                    // Collect the yet unknown headers to mark them as uncertain</span><br><span class=\"line\">                    unknown := make([]*types.Header, 0, len(headers))</span><br><span class=\"line\">                    for _, header := range chunk &#123;</span><br><span class=\"line\">                        if !d.lightchain.HasHeader(header.Hash(), header.Number.Uint64()) &#123;</span><br><span class=\"line\">                            unknown = append(unknown, header)</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    // If we&apos;re importing pure headers, verify based on their recentness</span><br><span class=\"line\">                    frequency := fsHeaderCheckFrequency</span><br><span class=\"line\">                    if chunk[len(chunk)-1].Number.Uint64()+uint64(fsHeaderForceVerify) &gt; pivot &#123;</span><br><span class=\"line\">                        frequency = 1</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    if n, err := d.lightchain.InsertHeaderChain(chunk, frequency); err != nil &#123;</span><br><span class=\"line\">                        // If some headers were inserted, add them too to the rollback list</span><br><span class=\"line\">                        if n &gt; 0 &#123;</span><br><span class=\"line\">                            rollback = append(rollback, chunk[:n]...)</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        log.Debug(&quot;Invalid header encountered&quot;, &quot;number&quot;, chunk[n].Number, &quot;hash&quot;, chunk[n].Hash(), &quot;err&quot;, err)</span><br><span class=\"line\">                        return errInvalidChain</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    // All verifications passed, store newly found uncertain headers</span><br><span class=\"line\">                    rollback = append(rollback, unknown...)</span><br><span class=\"line\">                    if len(rollback) &gt; fsHeaderSafetyNet &#123;</span><br><span class=\"line\">                        rollback = append(rollback[:0], rollback[len(rollback)-fsHeaderSafetyNet:]...)</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Unless we&apos;re doing light chains, schedule the headers for associated content retrieval</span><br><span class=\"line\">                if d.mode == FullSync || d.mode == FastSync &#123;</span><br><span class=\"line\">                    // If we&apos;ve reached the allowed number of pending headers, stall a bit</span><br><span class=\"line\">                    for d.queue.PendingBlocks() &gt;= maxQueuedHeaders || d.queue.PendingReceipts() &gt;= maxQueuedHeaders &#123;</span><br><span class=\"line\">                        select &#123;</span><br><span class=\"line\">                        case &lt;-d.cancelCh:</span><br><span class=\"line\">                            return errCancelHeaderProcessing</span><br><span class=\"line\">                        case &lt;-time.After(time.Second):</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    // Otherwise insert the headers for content retrieval</span><br><span class=\"line\">                    inserts := d.queue.Schedule(chunk, origin)</span><br><span class=\"line\">                    if len(inserts) != len(chunk) &#123;</span><br><span class=\"line\">                        log.Debug(&quot;Stale headers&quot;)</span><br><span class=\"line\">                        return errBadPeer</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                headers = headers[limit:]</span><br><span class=\"line\">                origin += uint64(limit)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Signal the content downloaders of the availablility of new tasks</span><br><span class=\"line\">            for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123;</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case ch &lt;- true:</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，收到从fetchHeaders()方法 中d.headerProcCh发送过来的headers<br>2，如果是FastSync或者LightSync模式，直接调用lightchain.InsertHeaderChain(chunk, frequency)插入到headerChain。<br>3，如果是FullSync或者FastSyn模式，调用d.queue.Schedule(chunk, origin)，放入downloader.queue来调度</p>\n<p>2，processFastSyncContent() 方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) processFastSyncContent(latest *types.Header) error &#123;</span><br><span class=\"line\">    // Start syncing state of the reported head block. This should get us most of</span><br><span class=\"line\">    // the state of the pivot block.</span><br><span class=\"line\">    stateSync := d.syncState(latest.Root)</span><br><span class=\"line\">    defer stateSync.Cancel()</span><br><span class=\"line\">    go func() &#123;</span><br><span class=\"line\">        if err := stateSync.Wait(); err != nil &amp;&amp; err != errCancelStateFetch &#123;</span><br><span class=\"line\">            d.queue.Close() // wake up WaitResults</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\">    // Figure out the ideal pivot block. Note, that this goalpost may move if the</span><br><span class=\"line\">    // sync takes long enough for the chain head to move significantly.</span><br><span class=\"line\">    pivot := uint64(0)</span><br><span class=\"line\">    if height := latest.Number.Uint64(); height &gt; uint64(fsMinFullBlocks) &#123;</span><br><span class=\"line\">        pivot = height - uint64(fsMinFullBlocks)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // To cater for moving pivot points, track the pivot block and subsequently</span><br><span class=\"line\">    // accumulated download results separatey.</span><br><span class=\"line\">    var (</span><br><span class=\"line\">        oldPivot *fetchResult   // Locked in pivot block, might change eventually</span><br><span class=\"line\">        oldTail  []*fetchResult // Downloaded content after the pivot</span><br><span class=\"line\">    )</span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        // Wait for the next batch of downloaded data to be available, and if the pivot</span><br><span class=\"line\">        // block became stale, move the goalpost</span><br><span class=\"line\">        results := d.queue.Results(oldPivot == nil) // Block if we&apos;re not monitoring pivot staleness</span><br><span class=\"line\">        if len(results) == 0 &#123;</span><br><span class=\"line\">            // If pivot sync is done, stop</span><br><span class=\"line\">            if oldPivot == nil &#123;</span><br><span class=\"line\">                return stateSync.Cancel()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // If sync failed, stop</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case &lt;-d.cancelCh:</span><br><span class=\"line\">                return stateSync.Cancel()</span><br><span class=\"line\">            default:</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if d.chainInsertHook != nil &#123;</span><br><span class=\"line\">            d.chainInsertHook(results)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if oldPivot != nil &#123;</span><br><span class=\"line\">            results = append(append([]*fetchResult&#123;oldPivot&#125;, oldTail...), results...)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Split around the pivot block and process the two sides via fast/full sync</span><br><span class=\"line\">        if atomic.LoadInt32(&amp;d.committed) == 0 &#123;</span><br><span class=\"line\">            latest = results[len(results)-1].Header</span><br><span class=\"line\">            if height := latest.Number.Uint64(); height &gt; pivot+2*uint64(fsMinFullBlocks) &#123;</span><br><span class=\"line\">                log.Warn(&quot;Pivot became stale, moving&quot;, &quot;old&quot;, pivot, &quot;new&quot;, height-uint64(fsMinFullBlocks))</span><br><span class=\"line\">                pivot = height - uint64(fsMinFullBlocks)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        P, beforeP, afterP := splitAroundPivot(pivot, results)</span><br><span class=\"line\">        if err := d.commitFastSyncData(beforeP, stateSync); err != nil &#123;</span><br><span class=\"line\">            return err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if P != nil &#123;</span><br><span class=\"line\">            // If new pivot block found, cancel old state retrieval and restart</span><br><span class=\"line\">            if oldPivot != P &#123;</span><br><span class=\"line\">                stateSync.Cancel()</span><br><span class=\"line\"></span><br><span class=\"line\">                stateSync = d.syncState(P.Header.Root)</span><br><span class=\"line\">                defer stateSync.Cancel()</span><br><span class=\"line\">                go func() &#123;</span><br><span class=\"line\">                    if err := stateSync.Wait(); err != nil &amp;&amp; err != errCancelStateFetch &#123;</span><br><span class=\"line\">                        d.queue.Close() // wake up WaitResults</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;()</span><br><span class=\"line\">                oldPivot = P</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Wait for completion, occasionally checking for pivot staleness</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case &lt;-stateSync.done:</span><br><span class=\"line\">                if stateSync.err != nil &#123;</span><br><span class=\"line\">                    return stateSync.err</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                if err := d.commitPivotBlock(P); err != nil &#123;</span><br><span class=\"line\">                    return err</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                oldPivot = nil</span><br><span class=\"line\"></span><br><span class=\"line\">            case &lt;-time.After(time.Second):</span><br><span class=\"line\">                oldTail = afterP</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Fast sync done, pivot commit done, full import</span><br><span class=\"line\">        if err := d.importBlockResults(afterP); err != nil &#123;</span><br><span class=\"line\">            return err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，同步最新的状态信息，的到最新的pivot值<br>2，不停的从d.queue 的result缓存中获取要处理的result数据<br>3，如果results数据为空，同时pivot也为空的时候，说明同步完成了，并返回<br>4，根据pivot值和results计算：pivot值对应的result，和pivot值之前的results和pivot值之后的results<br>5，调用commitFastSyncData把pivot值之前的results 插入本地区块链中，带上收据和交易数据<br>6，更新同步状态信息后，把pivot值对应的result 调用commitPivotBlock插入本地区块链中，并调用FastSyncCommitHead，记录这个pivot的hash值<br>7，调用d.importBlockResults把pivot值之后的results插入本地区块链中，这时候不插入区块交易收据数据。</p>\n<p>3，processFullSyncContent()方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) processFullSyncContent() error &#123;</span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        results := d.queue.Results(true)</span><br><span class=\"line\">        if len(results) == 0 &#123;</span><br><span class=\"line\">            return nil</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if d.chainInsertHook != nil &#123;</span><br><span class=\"line\">            d.chainInsertHook(results)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if err := d.importBlockResults(results); err != nil &#123;</span><br><span class=\"line\">            return err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (d *Downloader) importBlockResults(results []*fetchResult) error &#123;</span><br><span class=\"line\">    // Check for any early termination requests</span><br><span class=\"line\">    if len(results) == 0 &#123;</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case &lt;-d.quitCh:</span><br><span class=\"line\">        return errCancelContentProcessing</span><br><span class=\"line\">    default:</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Retrieve the a batch of results to import</span><br><span class=\"line\">    first, last := results[0].Header, results[len(results)-1].Header</span><br><span class=\"line\">    log.Debug(&quot;Inserting downloaded chain&quot;, &quot;items&quot;, len(results),</span><br><span class=\"line\">        &quot;firstnum&quot;, first.Number, &quot;firsthash&quot;, first.Hash(),</span><br><span class=\"line\">        &quot;lastnum&quot;, last.Number, &quot;lasthash&quot;, last.Hash(),</span><br><span class=\"line\">    )</span><br><span class=\"line\">    blocks := make([]*types.Block, len(results))</span><br><span class=\"line\">    for i, result := range results &#123;</span><br><span class=\"line\">        blocks[i] = types.NewBlockWithHeader(result.Header).WithBody(result.Transactions, result.Uncles)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if index, err := d.blockchain.InsertChain(blocks); err != nil &#123;</span><br><span class=\"line\">        log.Debug(&quot;Downloaded item processing failed&quot;, &quot;number&quot;, results[index].Header.Number, &quot;hash&quot;, results[index].Header.Hash(), &quot;err&quot;, err)</span><br><span class=\"line\">        return errInvalidChain</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>processFullSyncContent方法比较简单：直接获取缓存的results数据，并插入到本地区块链中。</p>\n<p>总结：<br>Downloader看似非常复杂，其实逻辑还好，如果没有light模式，读起来会好很多。其实light模式不太成熟，基本也没什么用。fast模式比full模式逻辑上面多了一个pivot，处理起来就复杂很多。但是fast模式在本地存储了收据数据，大大减少了区块交易验证的时间。如果要更清楚明白fast模式的原理，可以看看以太坊白皮书关于fast模式同步这一部分：<a href=\"https://github.com/ethereum/go-ethereum/pull/1889\">文档</a></p>\n","site":{"data":{"projects":[{"name":"源","url":"https://github.com/xiaoxuez/xiaoxuez.github.io/tree/master","desc":"本站github地址💀, 欢迎交流讨论"},{"name":"更多笔记","url":"https://github.com/xiaoxuez/note/tree/master/text","desc":"未迁移到本博客的笔记..2019年前的大部分笔记都未迁移过来🙈"},{"name":"go-hello-world","url":"https://github.com/xiaoxuez/go-hello-world/tree/master/algorithm/","desc":""}]}},"excerpt":"","more":"<h4 id=\"ApplyTransaction\"><a href=\"#ApplyTransaction\" class=\"headerlink\" title=\"ApplyTransaction\"></a>ApplyTransaction</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// ApplyTransaction attempts to apply a transaction to the given state database</span><br><span class=\"line\">// and uses the input parameters for its environment. It returns the receipt</span><br><span class=\"line\">// for the transaction, gas used and an error if the transaction failed,</span><br><span class=\"line\">// indicating the block was invalid.</span><br><span class=\"line\">//应用交易到state database中</span><br><span class=\"line\">func ApplyTransaction(config *params.ChainConfig, bc ChainContext, author *common.Address, gp *GasPool, statedb *state.StateDB, header *types.Header, tx *types.Transaction, usedGas *uint64, cfg vm.Config) (*types.Receipt, uint64, error) &#123;</span><br><span class=\"line\">\t//构造交易消息</span><br><span class=\"line\">\tmsg, err := tx.AsMessage(types.MakeSigner(config, header.Number))</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn nil, 0, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//EVM进行交易处理，返回为处理结果、消耗gas、是否失败、err，logs是在evm处理时产生的</span><br><span class=\"line\">\t// Create a new context to be used in the EVM environment</span><br><span class=\"line\">\tcontext := NewEVMContext(msg, header, bc, author)</span><br><span class=\"line\">\t// Create a new environment which holds all relevant information</span><br><span class=\"line\">\t// about the transaction and calling mechanisms.</span><br><span class=\"line\">\tvmenv := vm.NewEVM(context, statedb, config, cfg)</span><br><span class=\"line\">\t// Apply the transaction to the current state (included in the env)</span><br><span class=\"line\">\t_, gas, failed, err := ApplyMessage(vmenv, msg, gp)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn nil, 0, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t//根据处理结果构建返回数据</span><br><span class=\"line\">\t// Update the state with pending changes</span><br><span class=\"line\">\tvar root []byte</span><br><span class=\"line\">\tif config.IsByzantium(header.Number) &#123;</span><br><span class=\"line\">\t\tstatedb.Finalise(true)</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\troot = statedb.IntermediateRoot(config.IsEIP158(header.Number)).Bytes()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t*usedGas += gas</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Create a new receipt for the transaction, storing the intermediate root and gas used by the tx</span><br><span class=\"line\">\t// based on the eip phase, we&apos;re passing whether the root touch-delete accounts.</span><br><span class=\"line\">\treceipt := types.NewReceipt(root, failed, *usedGas)</span><br><span class=\"line\">\treceipt.TxHash = tx.Hash()</span><br><span class=\"line\">\treceipt.GasUsed = gas</span><br><span class=\"line\">\t// if the transaction created a contract, store the creation address in the receipt.</span><br><span class=\"line\">\tif msg.To() == nil &#123;</span><br><span class=\"line\">\t\treceipt.ContractAddress = crypto.CreateAddress(vmenv.Context.Origin, tx.Nonce())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// Set the receipt logs and create a bloom for filtering</span><br><span class=\"line\">\treceipt.Logs = statedb.GetLogs(tx.Hash())</span><br><span class=\"line\">\treceipt.Bloom = types.CreateBloom(types.Receipts&#123;receipt&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn receipt, gas, err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (evm *EVM) Call(caller ContractRef, addr common.Address, input []byte, gas uint64, value *big.Int) (ret []byte, leftOverGas uint64, err error) &#123;</span><br><span class=\"line\">\tif evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 &#123;</span><br><span class=\"line\">\t\treturn nil, gas, nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Fail if we&apos;re trying to execute above the call depth limit</span><br><span class=\"line\">\tif evm.depth &gt; int(params.CallCreateDepth) &#123;</span><br><span class=\"line\">\t\treturn nil, gas, ErrDepth</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// Fail if we&apos;re trying to transfer more than the available balance</span><br><span class=\"line\">\tif !evm.Context.CanTransfer(evm.StateDB, caller.Address(), value) &#123;</span><br><span class=\"line\">\t\treturn nil, gas, ErrInsufficientBalance</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tvar (</span><br><span class=\"line\">\t\tto       = AccountRef(addr)</span><br><span class=\"line\">\t\tsnapshot = evm.StateDB.Snapshot()</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\tif !evm.StateDB.Exist(addr) &#123;</span><br><span class=\"line\">\t\tprecompiles := PrecompiledContractsHomestead</span><br><span class=\"line\">\t\tif evm.ChainConfig().IsByzantium(evm.BlockNumber) &#123;</span><br><span class=\"line\">\t\t\tprecompiles = PrecompiledContractsByzantium</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif precompiles[addr] == nil &amp;&amp; evm.ChainConfig().IsEIP158(evm.BlockNumber) &amp;&amp; value.Sign() == 0 &#123;</span><br><span class=\"line\">\t\t\t// Calling a non existing account, don&apos;t do anything, but ping the tracer</span><br><span class=\"line\">\t\t\tif evm.vmConfig.Debug &amp;&amp; evm.depth == 0 &#123;</span><br><span class=\"line\">\t\t\t\tevm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value)</span><br><span class=\"line\">\t\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, 0, 0, nil)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\treturn nil, gas, nil</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tevm.StateDB.CreateAccount(addr)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tevm.Transfer(evm.StateDB, caller.Address(), to.Address(), value)</span><br><span class=\"line\">\t// Initialise a new contract and set the code that is to be used by the EVM.</span><br><span class=\"line\">\t// The contract is a scoped environment for this execution context only.</span><br><span class=\"line\">\tcontract := NewContract(caller, to, value, gas)</span><br><span class=\"line\">\tcontract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr))</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Even if the account has no code, we need to continue because it might be a precompile</span><br><span class=\"line\">\tstart := time.Now()</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Capture the tracer start/end events in debug mode</span><br><span class=\"line\">\tif evm.vmConfig.Debug &amp;&amp; evm.depth == 0 &#123;</span><br><span class=\"line\">\t\tevm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tdefer func() &#123; // Lazy evaluation of the parameters</span><br><span class=\"line\">\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, gas-contract.Gas, time.Since(start), err)</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tret, err = run(evm, contract, input, false)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// When an error was returned by the EVM or when setting the creation code</span><br><span class=\"line\">\t// above we revert to the snapshot and consume any gas remaining. Additionally</span><br><span class=\"line\">\t// when we&apos;re in homestead this also counts for code storage gas errors.</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tevm.StateDB.RevertToSnapshot(snapshot)</span><br><span class=\"line\">\t\tif err != errExecutionReverted &#123;</span><br><span class=\"line\">\t\t\tcontract.UseGas(contract.Gas)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn ret, contract.Gas, err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"handleMsg\"><a href=\"#handleMsg\" class=\"headerlink\" title=\"handleMsg\"></a>handleMsg</h4><p>处理接收到的消息码</p>\n<ul>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StatusMsg</span><br></pre></td></tr></table></figure>\n\n<p>收到这个消息说明握手失败</p>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GetBlockHeadersMsg</span><br></pre></td></tr></table></figure>\n\n<p>查询区块头请求，回复区块头信息</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BlockHeadersMsg</span><br></pre></td></tr></table></figure>\n\n<p>区块头信息的回复</p>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GetBlockBodiesMsg</span><br></pre></td></tr></table></figure>\n\n<p>查询区块请求</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BlockBodiesMsg</span><br></pre></td></tr></table></figure>\n\n<p>区块请求查询的回复，</p>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GetNodeDataMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NodeDataMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GetReceiptsMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ReceiptsMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NewBlockHashesMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NewBlockMsg</span><br></pre></td></tr></table></figure>\n</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TxMsg</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h4 id=\"Start\"><a href=\"#Start\" class=\"headerlink\" title=\"Start\"></a>Start</h4><p>这四个goroutine 基本上就在不停的做广播区块、广播交易，同步到区块、同步到交易，再广播区块、广播交易。</p>\n<ul>\n<li><p>txBroadcastLoop</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (self *ProtocolManager) txBroadcastLoop() &#123;</span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case event := &lt;-self.txCh:</span><br><span class=\"line\">            self.BroadcastTx(event.Tx.Hash(), event.Tx)</span><br><span class=\"line\"></span><br><span class=\"line\">        // Err() channel will be closed when unsubscribing.</span><br><span class=\"line\">        case &lt;-self.txSub.Err():</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>core/tx_pool.go 产生新的交易的时候会send self.txCh，这时候会激活<br>self.BroadcastTx(event.Tx.Hash(), event.Tx)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (pm *ProtocolManager) BroadcastTx(hash common.Hash, tx *types.Transaction) &#123;</span><br><span class=\"line\">    // Broadcast transaction to a batch of peers not knowing about it</span><br><span class=\"line\">    peers := pm.peers.PeersWithoutTx(hash)</span><br><span class=\"line\">    //FIXME include this again: peers = peers[:int(math.Sqrt(float64(len(peers))))]</span><br><span class=\"line\">    for _, peer := range peers &#123;</span><br><span class=\"line\">        peer.SendTransactions(types.Transactions&#123;tx&#125;)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log.Trace(&quot;Broadcast transaction&quot;, &quot;hash&quot;, hash, &quot;recipients&quot;, len(peers))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>向缓存的没有这个交易hash的网络节点广播此次交易。</p>\n</li>\n<li><p>minedBroadcastLoop</p>\n<p>收到miner.go 里面NewMinedBlockEvent 挖到新区块的事件通知，激活self.BroadcastBlock(ev.Block, true)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Mined broadcast loop</span><br><span class=\"line\">func (self *ProtocolManager) minedBroadcastLoop() &#123;</span><br><span class=\"line\">    // automatically stops if unsubscribe</span><br><span class=\"line\">    for obj := range self.minedBlockSub.Chan() &#123;</span><br><span class=\"line\">        switch ev := obj.Data.(type) &#123;</span><br><span class=\"line\">        case core.NewMinedBlockEvent:</span><br><span class=\"line\">            self.BroadcastBlock(ev.Block, true)  // First propagate block to peers</span><br><span class=\"line\">            self.BroadcastBlock(ev.Block, false) // Only then announce to the rest</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (pm *ProtocolManager) BroadcastBlock(block *types.Block, propagate bool) &#123;</span><br><span class=\"line\">    hash := block.Hash()</span><br><span class=\"line\">    peers := pm.peers.PeersWithoutBlock(hash)</span><br><span class=\"line\"></span><br><span class=\"line\">    // If propagation is requested, send to a subset of the peer</span><br><span class=\"line\">    if propagate &#123;</span><br><span class=\"line\">        // Calculate the TD of the block (it&apos;s not imported yet, so block.Td is not valid)</span><br><span class=\"line\">        var td *big.Int</span><br><span class=\"line\">        if parent := pm.blockchain.GetBlock(block.ParentHash(), block.NumberU64()-1); parent != nil &#123;</span><br><span class=\"line\">            td = new(big.Int).Add(block.Difficulty(), pm.blockchain.GetTd(block.ParentHash(), block.NumberU64()-1))</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            log.Error(&quot;Propagating dangling block&quot;, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash)</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Send the block to a subset of our peers</span><br><span class=\"line\">        transfer := peers[:int(math.Sqrt(float64(len(peers))))]</span><br><span class=\"line\">        for _, peer := range transfer &#123;</span><br><span class=\"line\">            peer.SendNewBlock(block, td)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        log.Trace(&quot;Propagated block&quot;, &quot;hash&quot;, hash, &quot;recipients&quot;, len(transfer), &quot;duration&quot;, common.PrettyDuration(time.Since(block.ReceivedAt)))</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Otherwise if the block is indeed in out own chain, announce it</span><br><span class=\"line\">    if pm.blockchain.HasBlock(hash, block.NumberU64()) &#123;</span><br><span class=\"line\">        for _, peer := range peers &#123;</span><br><span class=\"line\">            peer.SendNewBlockHashes([]common.Hash&#123;hash&#125;, []uint64&#123;block.NumberU64()&#125;)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        log.Trace(&quot;Announced block&quot;, &quot;hash&quot;, hash, &quot;recipients&quot;, len(peers), &quot;duration&quot;, common.PrettyDuration(time.Since(block.ReceivedAt)))</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果propagate为true 向网络节点广播整个挖到的block，为false 只广播挖到的区块的hash值和number值。广播的区块还包括这个区块打包的所有交易。</p>\n</li>\n<li><p>syncer</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (pm *ProtocolManager) syncer() &#123;</span><br><span class=\"line\">    // Start and ensure cleanup of sync mechanisms</span><br><span class=\"line\">    pm.fetcher.Start()</span><br><span class=\"line\">    defer pm.fetcher.Stop()</span><br><span class=\"line\">    defer pm.downloader.Terminate()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Wait for different events to fire synchronisation operations</span><br><span class=\"line\">    forceSync := time.NewTicker(forceSyncCycle)</span><br><span class=\"line\">    defer forceSync.Stop()</span><br><span class=\"line\"></span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-pm.newPeerCh:</span><br><span class=\"line\">            // Make sure we have peers to select from, then sync</span><br><span class=\"line\">            if pm.peers.Len() &lt; minDesiredPeerCount &#123;</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            go pm.synchronise(pm.peers.BestPeer())</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-forceSync.C:</span><br><span class=\"line\">            // Force a sync even if not enough peers are present</span><br><span class=\"line\">            go pm.synchronise(pm.peers.BestPeer())</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-pm.noMorePeers:</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>pm.fetcher.Start()启动 fetcher，辅助同步区块数据</p>\n<p>当P2P server执行 ProtocolManager 的p2p.Protocol 的Run指针的时候会send pm.newPeerCh，这时候选择最优的网络节点（TD 总难度最大的）启动pm.synchronise(pm.peers.BestPeer()) goroutine。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// synchronise tries to sync up our local block chain with a remote peer.</span><br><span class=\"line\">func (pm *ProtocolManager) synchronise(peer *peer) &#123;</span><br><span class=\"line\">    // Short circuit if no peers are available</span><br><span class=\"line\">    if peer == nil &#123;</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Make sure the peer&apos;s TD is higher than our own</span><br><span class=\"line\">    currentBlock := pm.blockchain.CurrentBlock()</span><br><span class=\"line\">    td := pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())</span><br><span class=\"line\"></span><br><span class=\"line\">    pHead, pTd := peer.Head()</span><br><span class=\"line\">    if pTd.Cmp(td) &lt;= 0 &#123;</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Otherwise try to sync with the downloader</span><br><span class=\"line\">    mode := downloader.FullSync</span><br><span class=\"line\">    if atomic.LoadUint32(&amp;pm.fastSync) == 1 &#123;</span><br><span class=\"line\">        // Fast sync was explicitly requested, and explicitly granted</span><br><span class=\"line\">        mode = downloader.FastSync</span><br><span class=\"line\">    &#125; else if currentBlock.NumberU64() == 0 &amp;&amp; pm.blockchain.CurrentFastBlock().NumberU64() &gt; 0 &#123;</span><br><span class=\"line\">        // The database seems empty as the current block is the genesis. Yet the fast</span><br><span class=\"line\">        // block is ahead, so fast sync was enabled for this node at a certain point.</span><br><span class=\"line\">        // The only scenario where this can happen is if the user manually (or via a</span><br><span class=\"line\">        // bad block) rolled back a fast sync node below the sync point. In this case</span><br><span class=\"line\">        // however it&apos;s safe to reenable fast sync.</span><br><span class=\"line\">        atomic.StoreUint32(&amp;pm.fastSync, 1)</span><br><span class=\"line\">        mode = downloader.FastSync</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Run the sync cycle, and disable fast sync if we&apos;ve went past the pivot block</span><br><span class=\"line\">    if err := pm.downloader.Synchronise(peer.id, pHead, pTd, mode); err != nil &#123;</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if atomic.LoadUint32(&amp;pm.fastSync) == 1 &#123;</span><br><span class=\"line\">        log.Info(&quot;Fast sync complete, auto disabling&quot;)</span><br><span class=\"line\">        atomic.StoreUint32(&amp;pm.fastSync, 0)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    atomic.StoreUint32(&amp;pm.acceptTxs, 1) // Mark initial sync done</span><br><span class=\"line\">    if head := pm.blockchain.CurrentBlock(); head.NumberU64() &gt; 0 &#123;</span><br><span class=\"line\">        // We&apos;ve completed a sync cycle, notify all peers of new state. This path is</span><br><span class=\"line\">        // essential in star-topology networks where a gateway node needs to notify</span><br><span class=\"line\">        // all its out-of-date peers of the availability of a new block. This failure</span><br><span class=\"line\">        // scenario will most often crop up in private and hackathon networks with</span><br><span class=\"line\">        // degenerate connectivity, but it should be healthy for the mainnet too to</span><br><span class=\"line\">        // more reliably update peers or the local TD state.</span><br><span class=\"line\">        go pm.BroadcastBlock(head, false)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果最优的网络节点的TD值大于本地最新区块的TD值，调用pm.downloader.Synchronise(peer.id, pHead, pTd, mode)进行同步。同步完成后再屌用go pm.BroadcastBlock(head, false)，把自己最新的区块状态广播出去。</p>\n</li>\n<li><p>txsyncLoop</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (pm *ProtocolManager) txsyncLoop() &#123;</span><br><span class=\"line\">    var (</span><br><span class=\"line\">        pending = make(map[discover.NodeID]*txsync)</span><br><span class=\"line\">        sending = false               // whether a send is active</span><br><span class=\"line\">        pack    = new(txsync)         // the pack that is being sent</span><br><span class=\"line\">        done    = make(chan error, 1) // result of the send</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    // send starts a sending a pack of transactions from the sync.</span><br><span class=\"line\">    send := func(s *txsync) &#123;</span><br><span class=\"line\">        // Fill pack with transactions up to the target size.</span><br><span class=\"line\">        size := common.StorageSize(0)</span><br><span class=\"line\">        pack.p = s.p</span><br><span class=\"line\">        pack.txs = pack.txs[:0]</span><br><span class=\"line\">        for i := 0; i &lt; len(s.txs) &amp;&amp; size &lt; txsyncPackSize; i++ &#123;</span><br><span class=\"line\">            pack.txs = append(pack.txs, s.txs[i])</span><br><span class=\"line\">            size += s.txs[i].Size()</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Remove the transactions that will be sent.</span><br><span class=\"line\">        s.txs = s.txs[:copy(s.txs, s.txs[len(pack.txs):])]</span><br><span class=\"line\">        if len(s.txs) == 0 &#123;</span><br><span class=\"line\">            delete(pending, s.p.ID())</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Send the pack in the background.</span><br><span class=\"line\">        s.p.Log().Trace(&quot;Sending batch of transactions&quot;, &quot;count&quot;, len(pack.txs), &quot;bytes&quot;, size)</span><br><span class=\"line\">        sending = true</span><br><span class=\"line\">        go func() &#123; done &lt;- pack.p.SendTransactions(pack.txs) &#125;()</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // pick chooses the next pending sync.</span><br><span class=\"line\">    pick := func() *txsync &#123;</span><br><span class=\"line\">        if len(pending) == 0 &#123;</span><br><span class=\"line\">            return nil</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        n := rand.Intn(len(pending)) + 1</span><br><span class=\"line\">        for _, s := range pending &#123;</span><br><span class=\"line\">            if n--; n == 0 &#123;</span><br><span class=\"line\">                return s</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case s := &lt;-pm.txsyncCh:</span><br><span class=\"line\">            pending[s.p.ID()] = s</span><br><span class=\"line\">            if !sending &#123;</span><br><span class=\"line\">                send(s)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        case err := &lt;-done:</span><br><span class=\"line\">            sending = false</span><br><span class=\"line\">            // Stop tracking peers that cause send failures.</span><br><span class=\"line\">            if err != nil &#123;</span><br><span class=\"line\">                pack.p.Log().Debug(&quot;Transaction send failed&quot;, &quot;err&quot;, err)</span><br><span class=\"line\">                delete(pending, pack.p.ID())</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the next send.</span><br><span class=\"line\">            if s := pick(); s != nil &#123;</span><br><span class=\"line\">                send(s)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        case &lt;-pm.quitSync:</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当从网络节点同步过来最新的交易数据后，本地也会把新同步下来的交易数据广播给网络中的其他节点。</p>\n</li>\n</ul>\n<h4 id=\"fetch\"><a href=\"#fetch\" class=\"headerlink\" title=\"fetch\"></a>fetch</h4><p>fetcher是用来辅助同步区块数据的，记录各个区块头和区块体的同步状态，但它并不做真正下载区块数据的事情，下载的事情交由downloader来做。那fetcher具体是怎么工作的呢？<br>我们先看看pm.handleMsg 在收到 NewBlockHashesMsg广播通知的处理代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case msg.Code == NewBlockHashesMsg:</span><br><span class=\"line\">        var announces newBlockHashesData</span><br><span class=\"line\">        if err := msg.Decode(&amp;announces); err != nil &#123;</span><br><span class=\"line\">            return errResp(ErrDecode, &quot;%v: %v&quot;, msg, err)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Mark the hashes as present at the remote node</span><br><span class=\"line\">        for _, block := range announces &#123;</span><br><span class=\"line\">            p.MarkBlock(block.Hash)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Schedule all the unknown hashes for retrieval</span><br><span class=\"line\">        unknown := make(newBlockHashesData, 0, len(announces))</span><br><span class=\"line\">        for _, block := range announces &#123;</span><br><span class=\"line\">            if !pm.blockchain.HasBlock(block.Hash, block.Number) &#123;</span><br><span class=\"line\">                unknown = append(unknown, block)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        for _, block := range unknown &#123;</span><br><span class=\"line\">            pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n\n<p>从广播通知里会获取到一个newBlockHashesData的列表。newBlockHashesData只包括block的hash值和block的number值。<br>然后每个newBlockHashesData调用pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)方法，除了传入block的hash值和block的number值，还需要传入当前的时间戳，peer.go的两个函数指针。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (f *Fetcher) Notify(peer string, hash common.Hash, number uint64, time time.Time,</span><br><span class=\"line\">    headerFetcher headerRequesterFn, bodyFetcher bodyRequesterFn) error &#123;</span><br><span class=\"line\">    block := &amp;announce&#123;</span><br><span class=\"line\">        hash:        hash,</span><br><span class=\"line\">        number:      number,</span><br><span class=\"line\">        time:        time,</span><br><span class=\"line\">        origin:      peer,</span><br><span class=\"line\">        fetchHeader: headerFetcher,</span><br><span class=\"line\">        fetchBodies: bodyFetcher,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case f.notify &lt;- block:</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    case &lt;-f.quit:</span><br><span class=\"line\">        return errTerminated</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Notify()方法把传进来的参数拼成一个announce对象，然后send给f.notify。fetcher的loop()主回路里f.notify receive 到这个notification, 进行处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case notification := &lt;-f.notify:</span><br><span class=\"line\">            // A block was announced, make sure the peer isn&apos;t DOSing us</span><br><span class=\"line\">            propAnnounceInMeter.Mark(1)</span><br><span class=\"line\"></span><br><span class=\"line\">            count := f.announces[notification.origin] + 1</span><br><span class=\"line\">            if count &gt; hashLimit &#123;</span><br><span class=\"line\">                log.Debug(&quot;Peer exceeded outstanding announces&quot;, &quot;peer&quot;, notification.origin, &quot;limit&quot;, hashLimit)</span><br><span class=\"line\">                propAnnounceDOSMeter.Mark(1)</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // If we have a valid block number, check that it&apos;s potentially useful</span><br><span class=\"line\">            if notification.number &gt; 0 &#123;</span><br><span class=\"line\">                if dist := int64(notification.number) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist &#123;</span><br><span class=\"line\">                    log.Debug(&quot;Peer discarded announcement&quot;, &quot;peer&quot;, notification.origin, &quot;number&quot;, notification.number, &quot;hash&quot;, notification.hash, &quot;distance&quot;, dist)</span><br><span class=\"line\">                    propAnnounceDropMeter.Mark(1)</span><br><span class=\"line\">                    break</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // All is well, schedule the announce if block&apos;s not yet downloading</span><br><span class=\"line\">            if _, ok := f.fetching[notification.hash]; ok &#123;</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if _, ok := f.completing[notification.hash]; ok &#123;</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            f.announces[notification.origin] = count</span><br><span class=\"line\">            f.announced[notification.hash] = append(f.announced[notification.hash], notification)</span><br><span class=\"line\">            if f.announceChangeHook != nil &amp;&amp; len(f.announced[notification.hash]) == 1 &#123;</span><br><span class=\"line\">                f.announceChangeHook(notification.hash, true)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if len(f.announced) == 1 &#123;</span><br><span class=\"line\">                f.rescheduleFetch(fetchTimer)</span><br><span class=\"line\">            &#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，将收到的不满足条件的通知都丢弃掉，如果在f.fetching 状态列表里和f.completing 状态列表里，也直接返回。接着更新notification.origin 这个节点的announces 数量，添加到f.announced 等待fetch的表里。<br>2，如果len(f.announced[notification.hash]) == 1 说明f.announced只有这一个通知，则调用f.announceChangeHook。<br>3，如果len(f.announced) == 1 也说明只有一个通知，则启动fetchTimer的调度。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case &lt;-fetchTimer.C:</span><br><span class=\"line\">            // At least one block&apos;s timer ran out, check for needing retrieval</span><br><span class=\"line\">            request := make(map[string][]common.Hash)</span><br><span class=\"line\"></span><br><span class=\"line\">            for hash, announces := range f.announced &#123;</span><br><span class=\"line\">                if time.Since(announces[0].time) &gt; arriveTimeout-gatherSlack &#123;</span><br><span class=\"line\">                    // Pick a random peer to retrieve from, reset all others</span><br><span class=\"line\">                    announce := announces[rand.Intn(len(announces))]</span><br><span class=\"line\">                    f.forgetHash(hash)</span><br><span class=\"line\"></span><br><span class=\"line\">                    // If the block still didn&apos;t arrive, queue for fetching</span><br><span class=\"line\">                    if f.getBlock(hash) == nil &#123;</span><br><span class=\"line\">                        request[announce.origin] = append(request[announce.origin], hash)</span><br><span class=\"line\">                        f.fetching[hash] = announce</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Send out all block header requests</span><br><span class=\"line\">            for peer, hashes := range request &#123;</span><br><span class=\"line\">                log.Trace(&quot;Fetching scheduled headers&quot;, &quot;peer&quot;, peer, &quot;list&quot;, hashes)</span><br><span class=\"line\"></span><br><span class=\"line\">                // Create a closure of the fetch and schedule in on a new thread</span><br><span class=\"line\">                fetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes</span><br><span class=\"line\">                go func() &#123;</span><br><span class=\"line\">                    if f.fetchingHook != nil &#123;</span><br><span class=\"line\">                        f.fetchingHook(hashes)</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    for _, hash := range hashes &#123;</span><br><span class=\"line\">                        headerFetchMeter.Mark(1)</span><br><span class=\"line\">                        fetchHeader(hash) // Suboptimal, but protocol doesn&apos;t allow batch header retrievals</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the next fetch if blocks are still pending</span><br><span class=\"line\">            f.rescheduleFetch(fetchTimer)</span><br></pre></td></tr></table></figure>\n\n<p>1，首先遍历f.announced，如果超过了arriveTimeout-gatherSlack这个时间，把这个hash对应在fetcher里面的状态都清了。<br>这里随机拿这个announces里面任意一个announce，为啥随机取一个呢？因为都是同一个block的hash，这个hash下的哪一个announce都是一样的。<br>如果发现超时了还没有没有获取到这个hash的block，则把这个announce加到request列表中，同时重新把announce放到f.fetching状态列表。<br>2，然后遍历request列表，request列表里面的每个网络节点过来的所有的block的hash，都会调用fetchHeader(hash)方法来获取header数据。<br>这个fetchHeader(hash)方法是pm.fetcher.Notify传进来的，peer.go<br>里面的一个全局方法。<br>3， 这时候NewBlockHashesMsg 的fetcher处理就结束了，最后再启动fetchTimer的调度。</p>\n<p>三，Fetcher分析， 之FilterHeaders()<br>fetchHeader(hash)方法，调用了peer.go 里面的全局方法RequestOneHeader(hash common.Hash)  Send给网络节点一个GetBlockHeadersMsg 消息。<br>然后pm.handleMsg 收到 BlockHashesMsg广播通知</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case msg.Code == BlockHeadersMsg:</span><br><span class=\"line\">        // A batch of headers arrived to one of our previous requests</span><br><span class=\"line\">        var headers []*types.Header</span><br><span class=\"line\">        if err := msg.Decode(&amp;headers); err != nil &#123;</span><br><span class=\"line\">            return errResp(ErrDecode, &quot;msg %v: %v&quot;, msg, err)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // If no headers were received, but we&apos;re expending a DAO fork check, maybe it&apos;s that</span><br><span class=\"line\">        if len(headers) == 0 &amp;&amp; p.forkDrop != nil &#123;</span><br><span class=\"line\">            // Possibly an empty reply to the fork header checks, sanity check TDs</span><br><span class=\"line\">            verifyDAO := true</span><br><span class=\"line\"></span><br><span class=\"line\">            // If we already have a DAO header, we can check the peer&apos;s TD against it. If</span><br><span class=\"line\">            // the peer&apos;s ahead of this, it too must have a reply to the DAO check</span><br><span class=\"line\">            if daoHeader := pm.blockchain.GetHeaderByNumber(pm.chainconfig.DAOForkBlock.Uint64()); daoHeader != nil &#123;</span><br><span class=\"line\">                if _, td := p.Head(); td.Cmp(pm.blockchain.GetTd(daoHeader.Hash(), daoHeader.Number.Uint64())) &gt;= 0 &#123;</span><br><span class=\"line\">                    verifyDAO = false</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // If we&apos;re seemingly on the same chain, disable the drop timer</span><br><span class=\"line\">            if verifyDAO &#123;</span><br><span class=\"line\">                p.Log().Debug(&quot;Seems to be on the same side of the DAO fork&quot;)</span><br><span class=\"line\">                p.forkDrop.Stop()</span><br><span class=\"line\">                p.forkDrop = nil</span><br><span class=\"line\">                return nil</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Filter out any explicitly requested headers, deliver the rest to the downloader</span><br><span class=\"line\">        filter := len(headers) == 1</span><br><span class=\"line\">        if filter &#123;</span><br><span class=\"line\">            // If it&apos;s a potential DAO fork check, validate against the rules</span><br><span class=\"line\">            if p.forkDrop != nil &amp;&amp; pm.chainconfig.DAOForkBlock.Cmp(headers[0].Number) == 0 &#123;</span><br><span class=\"line\">                // Disable the fork drop timer</span><br><span class=\"line\">                p.forkDrop.Stop()</span><br><span class=\"line\">                p.forkDrop = nil</span><br><span class=\"line\"></span><br><span class=\"line\">                // Validate the header and either drop the peer or continue</span><br><span class=\"line\">                if err := misc.VerifyDAOHeaderExtraData(pm.chainconfig, headers[0]); err != nil &#123;</span><br><span class=\"line\">                    p.Log().Debug(&quot;Verified to be on the other side of the DAO fork, dropping&quot;)</span><br><span class=\"line\">                    return err</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                p.Log().Debug(&quot;Verified to be on the same side of the DAO fork&quot;)</span><br><span class=\"line\">                return nil</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Irrelevant of the fork checks, send the header to the fetcher just in case</span><br><span class=\"line\">            headers = pm.fetcher.FilterHeaders(p.id, headers, time.Now())</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if len(headers) &gt; 0 || !filter &#123;</span><br><span class=\"line\">            err := pm.downloader.DeliverHeaders(p.id, headers)</span><br><span class=\"line\">            if err != nil &#123;</span><br><span class=\"line\">                log.Debug(&quot;Failed to deliver headers&quot;, &quot;err&quot;, err)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果不是硬分叉的daoHeader，同时len(headers) == 1，则执行pm.fetcher.FilterHeaders(p.id, headers, time.Now())方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (f *Fetcher) FilterHeaders(peer string, headers []*types.Header, time time.Time) []*types.Header &#123;</span><br><span class=\"line\">    log.Trace(&quot;Filtering headers&quot;, &quot;peer&quot;, peer, &quot;headers&quot;, len(headers))</span><br><span class=\"line\"></span><br><span class=\"line\">    // Send the filter channel to the fetcher</span><br><span class=\"line\">    filter := make(chan *headerFilterTask)</span><br><span class=\"line\"></span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case f.headerFilter &lt;- filter:</span><br><span class=\"line\">    case &lt;-f.quit:</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Request the filtering of the header list</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case filter &lt;- &amp;headerFilterTask&#123;peer: peer, headers: headers, time: time&#125;:</span><br><span class=\"line\">    case &lt;-f.quit:</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Retrieve the headers remaining after filtering</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case task := &lt;-filter:</span><br><span class=\"line\">        return task.headers</span><br><span class=\"line\">    case &lt;-f.quit:</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>send 一个filter 到f.headerFilter，fetcher的loop()主回路里f.headerFilter receive 到这个filter，进行处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case filter := &lt;-f.headerFilter:</span><br><span class=\"line\">            // Headers arrived from a remote peer. Extract those that were explicitly</span><br><span class=\"line\">            // requested by the fetcher, and return everything else so it&apos;s delivered</span><br><span class=\"line\">            // to other parts of the system.</span><br><span class=\"line\">            var task *headerFilterTask</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case task = &lt;-filter:</span><br><span class=\"line\">            case &lt;-f.quit:</span><br><span class=\"line\">                return</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            headerFilterInMeter.Mark(int64(len(task.headers)))</span><br><span class=\"line\"></span><br><span class=\"line\">            // Split the batch of headers into unknown ones (to return to the caller),</span><br><span class=\"line\">            // known incomplete ones (requiring body retrievals) and completed blocks.</span><br><span class=\"line\">            unknown, incomplete, complete := []*types.Header&#123;&#125;, []*announce&#123;&#125;, []*types.Block&#123;&#125;</span><br><span class=\"line\">            for _, header := range task.headers &#123;</span><br><span class=\"line\">                hash := header.Hash()</span><br><span class=\"line\"></span><br><span class=\"line\">                // Filter fetcher-requested headers from other synchronisation algorithms</span><br><span class=\"line\">                if announce := f.fetching[hash]; announce != nil &amp;&amp; announce.origin == task.peer &amp;&amp; f.fetched[hash] == nil &amp;&amp; f.completing[hash] == nil &amp;&amp; f.queued[hash] == nil &#123;</span><br><span class=\"line\">                    // If the delivered header does not match the promised number, drop the announcer</span><br><span class=\"line\">                    if header.Number.Uint64() != announce.number &#123;</span><br><span class=\"line\">                        log.Trace(&quot;Invalid block number fetched&quot;, &quot;peer&quot;, announce.origin, &quot;hash&quot;, header.Hash(), &quot;announced&quot;, announce.number, &quot;provided&quot;, header.Number)</span><br><span class=\"line\">                        f.dropPeer(announce.origin)</span><br><span class=\"line\">                        f.forgetHash(hash)</span><br><span class=\"line\">                        continue</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    // Only keep if not imported by other means</span><br><span class=\"line\">                    if f.getBlock(hash) == nil &#123;</span><br><span class=\"line\">                        announce.header = header</span><br><span class=\"line\">                        announce.time = task.time</span><br><span class=\"line\"></span><br><span class=\"line\">                        // If the block is empty (header only), short circuit into the final import queue</span><br><span class=\"line\">                        if header.TxHash == types.DeriveSha(types.Transactions&#123;&#125;) &amp;&amp; header.UncleHash == types.CalcUncleHash([]*types.Header&#123;&#125;) &#123;</span><br><span class=\"line\">                            log.Trace(&quot;Block empty, skipping body retrieval&quot;, &quot;peer&quot;, announce.origin, &quot;number&quot;, header.Number, &quot;hash&quot;, header.Hash())</span><br><span class=\"line\"></span><br><span class=\"line\">                            block := types.NewBlockWithHeader(header)</span><br><span class=\"line\">                            block.ReceivedAt = task.time</span><br><span class=\"line\"></span><br><span class=\"line\">                            complete = append(complete, block)</span><br><span class=\"line\">                            f.completing[hash] = announce</span><br><span class=\"line\">                            continue</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        // Otherwise add to the list of blocks needing completion</span><br><span class=\"line\">                        incomplete = append(incomplete, announce)</span><br><span class=\"line\">                    &#125; else &#123;</span><br><span class=\"line\">                        log.Trace(&quot;Block already imported, discarding header&quot;, &quot;peer&quot;, announce.origin, &quot;number&quot;, header.Number, &quot;hash&quot;, header.Hash())</span><br><span class=\"line\">                        f.forgetHash(hash)</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    // Fetcher doesn&apos;t know about it, add to the return list</span><br><span class=\"line\">                    unknown = append(unknown, header)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            headerFilterOutMeter.Mark(int64(len(unknown)))</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case filter &lt;- &amp;headerFilterTask&#123;headers: unknown, time: task.time&#125;:</span><br><span class=\"line\">            case &lt;-f.quit:</span><br><span class=\"line\">                return</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the retrieved headers for body completion</span><br><span class=\"line\">            for _, announce := range incomplete &#123;</span><br><span class=\"line\">                hash := announce.header.Hash()</span><br><span class=\"line\">                if _, ok := f.completing[hash]; ok &#123;</span><br><span class=\"line\">                    continue</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                f.fetched[hash] = append(f.fetched[hash], announce)</span><br><span class=\"line\">                if len(f.fetched) == 1 &#123;</span><br><span class=\"line\">                    f.rescheduleComplete(completeTimer)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the header-only blocks for import</span><br><span class=\"line\">            for _, block := range complete &#123;</span><br><span class=\"line\">                if announce := f.completing[block.Hash()]; announce != nil &#123;</span><br><span class=\"line\">                    f.enqueue(announce.origin, block)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，遍历headerFilter里面的各个header，如果在 f.fetching状态列表，且不在f.fetched状态列表和 f.completing状态列表，就继续进行过滤，否则塞进unknown队列 发送给filter，FilterHeaders里面task 接收到filter，并作为FilterHeaders的返回值返回。<br>2，如果发现这个header的number和从f.fetching状态列表取到的announce的number不一样，说明有可能收到一个伪造的区块通知，此时就要把这个可能的伪造节点和可能的伪造的hash抛弃，另可错杀，不能放过。<br>3，如果本节点已经有这个hash的block，则放弃这个hash。如果这个block里面没有任何交易也没有任何叔区块，则把这个hash放入complete列表同时加入f.completing状态列表，否则放入incomplete列表。<br>4，在incomplete列表里面，且不在f.completing状态列表里，则加入f.fetched状态列表，启动completeTimer的调度。<br>5，在complete列表里面，同时也在f.completing状态列表，则调用f.enqueue(announce.origin, block)方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case &lt;-completeTimer.C:</span><br><span class=\"line\">            // At least one header&apos;s timer ran out, retrieve everything</span><br><span class=\"line\">            request := make(map[string][]common.Hash)</span><br><span class=\"line\"></span><br><span class=\"line\">            for hash, announces := range f.fetched &#123;</span><br><span class=\"line\">                // Pick a random peer to retrieve from, reset all others</span><br><span class=\"line\">                announce := announces[rand.Intn(len(announces))]</span><br><span class=\"line\">                f.forgetHash(hash)</span><br><span class=\"line\"></span><br><span class=\"line\">                // If the block still didn&apos;t arrive, queue for completion</span><br><span class=\"line\">                if f.getBlock(hash) == nil &#123;</span><br><span class=\"line\">                    request[announce.origin] = append(request[announce.origin], hash)</span><br><span class=\"line\">                    f.completing[hash] = announce</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Send out all block body requests</span><br><span class=\"line\">            for peer, hashes := range request &#123;</span><br><span class=\"line\">                log.Trace(&quot;Fetching scheduled bodies&quot;, &quot;peer&quot;, peer, &quot;list&quot;, hashes)</span><br><span class=\"line\"></span><br><span class=\"line\">                // Create a closure of the fetch and schedule in on a new thread</span><br><span class=\"line\">                if f.completingHook != nil &#123;</span><br><span class=\"line\">                    f.completingHook(hashes)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                bodyFetchMeter.Mark(int64(len(hashes)))</span><br><span class=\"line\">                go f.completing[hashes[0]].fetchBodies(hashes)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Schedule the next fetch if blocks are still pending</span><br><span class=\"line\">            f.rescheduleComplete(completeTimer)</span><br></pre></td></tr></table></figure>\n\n<p>1，首先遍历f.fetched，hash对应在fetcher里面的状态都清了。<br>如果发现超时了还没有没有获取到这个hash的block，则把这个announce加到request列表中，同时重新把announce放到f.completing状态列表。<br>2，然后遍历request列表，request列表里面的每个网络节点过来的所有的block的hash，都会调用fetchBodies(hashes)方法来获取区块body数据。这个fetchBodies(hashes)方法是peer.go里面的一个全局方法。<br>3， 这时候BlockHashesMsg 的fetcher处理就结束了，最后再启动completeTimer循环调度。</p>\n<p>四，Fetcher分析， 之FilterBodies() ，Enqueue(），<br>1，fetchBodies(hash)方法，调用了peer.go 里面的全局方法RequestBodies(hashes []common.Hash) Send给网络节点一个GetBlockBodiesMsg 消息。<br>2，然后pm.handleMsg 会收到 BlockBodiesMsg广播通知。<br>3，执行 pm.fetcher.FilterBodies(p.id, trasactions, uncles, time.Now())。<br>接下来就和FilterHeaders()流程类似，一顿啪啪啪验证，一顿啪啪啪改变状态，一顿啪啪啪通道跳转<br>4，庆幸的是，走完FilterBodies()就完事了，不用在走timer调度，也不用再发网络请求了。<br>5，在FilterHeaders()和FilterBodies()最后都走到了f.enqueue(announce.origin, block)方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (f *Fetcher) enqueue(peer string, block *types.Block) &#123;</span><br><span class=\"line\">    hash := block.Hash()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Ensure the peer isn&apos;t DOSing us</span><br><span class=\"line\">    count := f.queues[peer] + 1</span><br><span class=\"line\">    if count &gt; blockLimit &#123;</span><br><span class=\"line\">        log.Debug(&quot;Discarded propagated block, exceeded allowance&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;limit&quot;, blockLimit)</span><br><span class=\"line\">        propBroadcastDOSMeter.Mark(1)</span><br><span class=\"line\">        f.forgetHash(hash)</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Discard any past or too distant blocks</span><br><span class=\"line\">    if dist := int64(block.NumberU64()) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist &#123;</span><br><span class=\"line\">        log.Debug(&quot;Discarded propagated block, too far away&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;distance&quot;, dist)</span><br><span class=\"line\">        propBroadcastDropMeter.Mark(1)</span><br><span class=\"line\">        f.forgetHash(hash)</span><br><span class=\"line\">        return</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Schedule the block for future importing</span><br><span class=\"line\">    if _, ok := f.queued[hash]; !ok &#123;</span><br><span class=\"line\">        op := &amp;inject&#123;</span><br><span class=\"line\">            origin: peer,</span><br><span class=\"line\">            block:  block,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        f.queues[peer] = count</span><br><span class=\"line\">        f.queued[hash] = op</span><br><span class=\"line\">        f.queue.Push(op, -float32(block.NumberU64()))</span><br><span class=\"line\">        if f.queueChangeHook != nil &#123;</span><br><span class=\"line\">            f.queueChangeHook(op.block.Hash(), true)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        log.Debug(&quot;Queued propagated block&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;queued&quot;, f.queue.Size())</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>过滤掉太远的区块。并把hash加入到f.queue列表中。<br>在loop主回路里面遍历f.queue列表，并把列表中的block insert到本地的block chain中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (f *Fetcher) insert(peer string, block *types.Block) &#123;</span><br><span class=\"line\">    hash := block.Hash()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Run the import on a new thread</span><br><span class=\"line\">    log.Debug(&quot;Importing propagated block&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash)</span><br><span class=\"line\">    go func() &#123;</span><br><span class=\"line\">        defer func() &#123; f.done &lt;- hash &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">        // If the parent&apos;s unknown, abort insertion</span><br><span class=\"line\">        parent := f.getBlock(block.ParentHash())</span><br><span class=\"line\">        if parent == nil &#123;</span><br><span class=\"line\">            log.Debug(&quot;Unknown parent of propagated block&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;parent&quot;, block.ParentHash())</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Quickly validate the header and propagate the block if it passes</span><br><span class=\"line\">        switch err := f.verifyHeader(block.Header()); err &#123;</span><br><span class=\"line\">        case nil:</span><br><span class=\"line\">            // All ok, quickly propagate to our peers</span><br><span class=\"line\">            propBroadcastOutTimer.UpdateSince(block.ReceivedAt)</span><br><span class=\"line\">            go f.broadcastBlock(block, true)</span><br><span class=\"line\"></span><br><span class=\"line\">        case consensus.ErrFutureBlock:</span><br><span class=\"line\">            // Weird future block, don&apos;t fail, but neither propagate</span><br><span class=\"line\"></span><br><span class=\"line\">        default:</span><br><span class=\"line\">            // Something went very wrong, drop the peer</span><br><span class=\"line\">            log.Debug(&quot;Propagated block verification failed&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;err&quot;, err)</span><br><span class=\"line\">            f.dropPeer(peer)</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Run the actual import and log any issues</span><br><span class=\"line\">        if _, err := f.insertChain(types.Blocks&#123;block&#125;); err != nil &#123;</span><br><span class=\"line\">            log.Debug(&quot;Propagated block import failed&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;err&quot;, err)</span><br><span class=\"line\">            return</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // If import succeeded, broadcast the block</span><br><span class=\"line\">        propAnnounceOutTimer.UpdateSince(block.ReceivedAt)</span><br><span class=\"line\">        go f.broadcastBlock(block, false)</span><br><span class=\"line\"></span><br><span class=\"line\">        // Invoke the testing hook if needed</span><br><span class=\"line\">        if f.importedHook != nil &#123;</span><br><span class=\"line\">            f.importedHook(block)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>首先调用共识引擎的方法f.verifyHeader(block.Header())，验证blockHeader的有效性。<br>如果没问题就广播出去，告诉全世界我的区块链更新了一个新区块。<br>然后调用f.insertChain(types.Blocks{block}) 插入本地区块链。<br>插入成功，最后再广播一次(这是多么的自恋啊)，这次只广播block的hash。</p>\n<p>总结<br>fetcher.go 作为以太坊同步区块的一个辅助类，它的职责就是层层把关，层层过滤，抵制无效的区块进入，杜绝无用的同步请求。这块代码很多很乱，第一次看可能会有点晕，第二次看可能还是很晕，多看几次可能还会晕😄，不过只要知道它做什么就好了。</p>\n<h4 id=\"Downloader\"><a href=\"#Downloader\" class=\"headerlink\" title=\"Downloader\"></a>Downloader</h4><p>一，启动Downloader<br>ProtocolManager初始化的时候会进行Downloader的初始化：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func New(mode SyncMode, stateDb ethdb.Database, mux *event.TypeMux, chain BlockChain, lightchain LightChain, dropPeer peerDropFn) *Downloader &#123;</span><br><span class=\"line\">    if lightchain == nil &#123;</span><br><span class=\"line\">        lightchain = chain</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    dl := &amp;Downloader&#123;</span><br><span class=\"line\">        mode:           mode,</span><br><span class=\"line\">        stateDB:        stateDb,</span><br><span class=\"line\">        mux:            mux,</span><br><span class=\"line\">        queue:          newQueue(),</span><br><span class=\"line\">        peers:          newPeerSet(),</span><br><span class=\"line\">        rttEstimate:    uint64(rttMaxEstimate),</span><br><span class=\"line\">        rttConfidence:  uint64(1000000),</span><br><span class=\"line\">        blockchain:     chain,</span><br><span class=\"line\">        lightchain:     lightchain,</span><br><span class=\"line\">        dropPeer:       dropPeer,</span><br><span class=\"line\">        headerCh:       make(chan dataPack, 1),</span><br><span class=\"line\">        bodyCh:         make(chan dataPack, 1),</span><br><span class=\"line\">        receiptCh:      make(chan dataPack, 1),</span><br><span class=\"line\">        bodyWakeCh:     make(chan bool, 1),</span><br><span class=\"line\">        receiptWakeCh:  make(chan bool, 1),</span><br><span class=\"line\">        headerProcCh:   make(chan []*types.Header, 1),</span><br><span class=\"line\">        quitCh:         make(chan struct&#123;&#125;),</span><br><span class=\"line\">        stateCh:        make(chan dataPack),</span><br><span class=\"line\">        stateSyncStart: make(chan *stateSync),</span><br><span class=\"line\">        trackStateReq:  make(chan *stateReq),</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    go dl.qosTuner()</span><br><span class=\"line\">    go dl.stateFetcher()</span><br><span class=\"line\">    return dl</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>首先初始化Downloader对象的成员，然后启动dl.qosTuner() goroutine计算请求回路时间，启动dl.stateFetcher() goroutine 开启Downloader状态监控。</p>\n<p>ProtocolManager收到新的区块消息广播或者有新的P2P网络节点加入的时候会调用ProtocolManager的 synchronise(peer *peer)方法，这时候会调用Downloader的Synchronise(peer.id, pHead, pTd, mode)方法。</p>\n<p>Synchronise方法，重置d.queue和d.peers，清空d.bodyWakeCh, d.receiptWakeCh，d.headerCh, d.bodyCh, d.receiptCh，d.headerProcCh。调用d.syncWithPeer(p, hash, td)方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) syncWithPeer(p *peerConnection, hash common.Hash, td *big.Int) (err error) &#123;</span><br><span class=\"line\">    d.mux.Post(StartEvent&#123;&#125;)</span><br><span class=\"line\">    defer func() &#123;</span><br><span class=\"line\">        // reset on error</span><br><span class=\"line\">        if err != nil &#123;</span><br><span class=\"line\">            d.mux.Post(FailedEvent&#123;err&#125;)</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            d.mux.Post(DoneEvent&#123;&#125;)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\">    if p.version &lt; 62 &#123;</span><br><span class=\"line\">        return errTooOld</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    log.Debug(&quot;Synchronising with the network&quot;, &quot;peer&quot;, p.id, &quot;eth&quot;, p.version, &quot;head&quot;, hash, &quot;td&quot;, td, &quot;mode&quot;, d.mode)</span><br><span class=\"line\">    defer func(start time.Time) &#123;</span><br><span class=\"line\">        log.Debug(&quot;Synchronisation terminated&quot;, &quot;elapsed&quot;, time.Since(start))</span><br><span class=\"line\">    &#125;(time.Now())</span><br><span class=\"line\"></span><br><span class=\"line\">    // Look up the sync boundaries: the common ancestor and the target block</span><br><span class=\"line\">    latest, err := d.fetchHeight(p)</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        return err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    height := latest.Number.Uint64()</span><br><span class=\"line\"></span><br><span class=\"line\">    origin, err := d.findAncestor(p, height)</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        return err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    d.syncStatsLock.Lock()</span><br><span class=\"line\">    if d.syncStatsChainHeight &lt;= origin || d.syncStatsChainOrigin &gt; origin &#123;</span><br><span class=\"line\">        d.syncStatsChainOrigin = origin</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    d.syncStatsChainHeight = height</span><br><span class=\"line\">    d.syncStatsLock.Unlock()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Ensure our origin point is below any fast sync pivot point</span><br><span class=\"line\">    pivot := uint64(0)</span><br><span class=\"line\">    if d.mode == FastSync &#123;</span><br><span class=\"line\">        if height &lt;= uint64(fsMinFullBlocks) &#123;</span><br><span class=\"line\">            origin = 0</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            pivot = height - uint64(fsMinFullBlocks)</span><br><span class=\"line\">            if pivot &lt;= origin &#123;</span><br><span class=\"line\">                origin = pivot - 1</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    d.committed = 1</span><br><span class=\"line\">    if d.mode == FastSync &amp;&amp; pivot != 0 &#123;</span><br><span class=\"line\">        d.committed = 0</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Initiate the sync using a concurrent header and content retrieval algorithm</span><br><span class=\"line\">    d.queue.Prepare(origin+1, d.mode)</span><br><span class=\"line\">    if d.syncInitHook != nil &#123;</span><br><span class=\"line\">        d.syncInitHook(origin, height)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    fetchers := []func() error&#123;</span><br><span class=\"line\">        func() error &#123; return d.fetchHeaders(p, origin+1, pivot) &#125;, // Headers are always retrieved</span><br><span class=\"line\">        func() error &#123; return d.fetchBodies(origin + 1) &#125;,          // Bodies are retrieved during normal and fast sync</span><br><span class=\"line\">        func() error &#123; return d.fetchReceipts(origin + 1) &#125;,        // Receipts are retrieved during fast sync</span><br><span class=\"line\">        func() error &#123; return d.processHeaders(origin+1, pivot, td) &#125;,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if d.mode == FastSync &#123;</span><br><span class=\"line\">        fetchers = append(fetchers, func() error &#123; return d.processFastSyncContent(latest) &#125;)</span><br><span class=\"line\">    &#125; else if d.mode == FullSync &#123;</span><br><span class=\"line\">        fetchers = append(fetchers, d.processFullSyncContent)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return d.spawnSync(fetchers)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>首先调用latest, err := d.fetchHeight(p)获取到peer节点最新的区块头,这个方法有点绕，我们来分析一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) fetchHeight(p *peerConnection) (*types.Header, error) &#123;</span><br><span class=\"line\">    p.log.Debug(&quot;Retrieving remote chain height&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    // Request the advertised remote head block and wait for the response</span><br><span class=\"line\">    head, _ := p.peer.Head()</span><br><span class=\"line\">    go p.peer.RequestHeadersByHash(head, 1, 0, false)</span><br><span class=\"line\"></span><br><span class=\"line\">    ttl := d.requestTTL()</span><br><span class=\"line\">    timeout := time.After(ttl)</span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-d.cancelCh:</span><br><span class=\"line\">            return nil, errCancelBlockFetch</span><br><span class=\"line\"></span><br><span class=\"line\">        case packet := &lt;-d.headerCh:</span><br><span class=\"line\">            // Discard anything not from the origin peer</span><br><span class=\"line\">            if packet.PeerId() != p.id &#123;</span><br><span class=\"line\">                log.Debug(&quot;Received headers from incorrect peer&quot;, &quot;peer&quot;, packet.PeerId())</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Make sure the peer actually gave something valid</span><br><span class=\"line\">            headers := packet.(*headerPack).headers</span><br><span class=\"line\">            if len(headers) != 1 &#123;</span><br><span class=\"line\">                p.log.Debug(&quot;Multiple headers for single request&quot;, &quot;headers&quot;, len(headers))</span><br><span class=\"line\">                return nil, errBadPeer</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            head := headers[0]</span><br><span class=\"line\">            p.log.Debug(&quot;Remote head header identified&quot;, &quot;number&quot;, head.Number, &quot;hash&quot;, head.Hash())</span><br><span class=\"line\">            return head, nil</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-timeout:</span><br><span class=\"line\">            p.log.Debug(&quot;Waiting for head header timed out&quot;, &quot;elapsed&quot;, ttl)</span><br><span class=\"line\">            return nil, errTimeout</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-d.bodyCh:</span><br><span class=\"line\">        case &lt;-d.receiptCh:</span><br><span class=\"line\">            // Out of bounds delivery, ignore</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，调用peer.RequestHeadersByHash(head, 1, 0, false)，给网络节点发送一个GetBlockHeadersMsg的消息<br>2，然后阻塞住线程，直到收到d.headerCh或者timeout<br>3，本地节点会收到网络节点的BlockHeadersMsg的消息返回<br>4，调用downloader.DeliverHeaders(p.id, headers)<br>5，这时候会把p.id和headers打包发送给d.headerCh<br>6，这时候select收到d.headerCh，阻塞打开，并返回header内容</p>\n<p>syncWithPeer() 方法接着调用 d.findAncestor(p, height)来获取本地节点和网络节点共同的祖先：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) findAncestor(p *peerConnection, height uint64) (uint64, error) &#123;</span><br><span class=\"line\">    // Figure out the valid ancestor range to prevent rewrite attacks</span><br><span class=\"line\">    floor, ceil := int64(-1), d.lightchain.CurrentHeader().Number.Uint64()</span><br><span class=\"line\"></span><br><span class=\"line\">    if d.mode == FullSync &#123;</span><br><span class=\"line\">        ceil = d.blockchain.CurrentBlock().NumberU64()</span><br><span class=\"line\">    &#125; else if d.mode == FastSync &#123;</span><br><span class=\"line\">        ceil = d.blockchain.CurrentFastBlock().NumberU64()</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if ceil &gt;= MaxForkAncestry &#123;</span><br><span class=\"line\">        floor = int64(ceil - MaxForkAncestry)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    p.log.Debug(&quot;Looking for common ancestor&quot;, &quot;local&quot;, ceil, &quot;remote&quot;, height)</span><br><span class=\"line\"></span><br><span class=\"line\">    // Request the topmost blocks to short circuit binary ancestor lookup</span><br><span class=\"line\">    head := ceil</span><br><span class=\"line\">    if head &gt; height &#123;</span><br><span class=\"line\">        head = height</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    from := int64(head) - int64(MaxHeaderFetch)</span><br><span class=\"line\">    if from &lt; 0 &#123;</span><br><span class=\"line\">        from = 0</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Span out with 15 block gaps into the future to catch bad head reports</span><br><span class=\"line\">    limit := 2 * MaxHeaderFetch / 16</span><br><span class=\"line\">    count := 1 + int((int64(ceil)-from)/16)</span><br><span class=\"line\">    if count &gt; limit &#123;</span><br><span class=\"line\">        count = limit</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    go p.peer.RequestHeadersByNumber(uint64(from), count, 15, false)</span><br><span class=\"line\"></span><br><span class=\"line\">    // Wait for the remote response to the head fetch</span><br><span class=\"line\">    number, hash := uint64(0), common.Hash&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ttl := d.requestTTL()</span><br><span class=\"line\">    timeout := time.After(ttl)</span><br><span class=\"line\"></span><br><span class=\"line\">    for finished := false; !finished; &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-d.cancelCh:</span><br><span class=\"line\">            return 0, errCancelHeaderFetch</span><br><span class=\"line\"></span><br><span class=\"line\">        case packet := &lt;-d.headerCh:</span><br><span class=\"line\">            // Discard anything not from the origin peer</span><br><span class=\"line\">            if packet.PeerId() != p.id &#123;</span><br><span class=\"line\">                log.Debug(&quot;Received headers from incorrect peer&quot;, &quot;peer&quot;, packet.PeerId())</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Make sure the peer actually gave something valid</span><br><span class=\"line\">            headers := packet.(*headerPack).headers</span><br><span class=\"line\">            if len(headers) == 0 &#123;</span><br><span class=\"line\">                p.log.Warn(&quot;Empty head header set&quot;)</span><br><span class=\"line\">                return 0, errEmptyHeaderSet</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Make sure the peer&apos;s reply conforms to the request</span><br><span class=\"line\">            for i := 0; i &lt; len(headers); i++ &#123;</span><br><span class=\"line\">                if number := headers[i].Number.Int64(); number != from+int64(i)*16 &#123;</span><br><span class=\"line\">                    p.log.Warn(&quot;Head headers broke chain ordering&quot;, &quot;index&quot;, i, &quot;requested&quot;, from+int64(i)*16, &quot;received&quot;, number)</span><br><span class=\"line\">                    return 0, errInvalidChain</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Check if a common ancestor was found</span><br><span class=\"line\">            finished = true</span><br><span class=\"line\">            for i := len(headers) - 1; i &gt;= 0; i-- &#123;</span><br><span class=\"line\">                // Skip any headers that underflow/overflow our requested set</span><br><span class=\"line\">                if headers[i].Number.Int64() &lt; from || headers[i].Number.Uint64() &gt; ceil &#123;</span><br><span class=\"line\">                    continue</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Otherwise check if we already know the header or not</span><br><span class=\"line\">                if (d.mode == FullSync &amp;&amp; d.blockchain.HasBlock(headers[i].Hash(), headers[i].Number.Uint64())) || (d.mode != FullSync &amp;&amp; d.lightchain.HasHeader(headers[i].Hash(), headers[i].Number.Uint64())) &#123;</span><br><span class=\"line\">                    number, hash = headers[i].Number.Uint64(), headers[i].Hash()</span><br><span class=\"line\"></span><br><span class=\"line\">                    // If every header is known, even future ones, the peer straight out lied about its head</span><br><span class=\"line\">                    if number &gt; height &amp;&amp; i == limit-1 &#123;</span><br><span class=\"line\">                        p.log.Warn(&quot;Lied about chain head&quot;, &quot;reported&quot;, height, &quot;found&quot;, number)</span><br><span class=\"line\">                        return 0, errStallingPeer</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    break</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-timeout:</span><br><span class=\"line\">            p.log.Debug(&quot;Waiting for head header timed out&quot;, &quot;elapsed&quot;, ttl)</span><br><span class=\"line\">            return 0, errTimeout</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-d.bodyCh:</span><br><span class=\"line\">        case &lt;-d.receiptCh:</span><br><span class=\"line\">            // Out of bounds delivery, ignore</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // If the head fetch already found an ancestor, return</span><br><span class=\"line\">    if !common.EmptyHash(hash) &#123;</span><br><span class=\"line\">        if int64(number) &lt;= floor &#123;</span><br><span class=\"line\">            p.log.Warn(&quot;Ancestor below allowance&quot;, &quot;number&quot;, number, &quot;hash&quot;, hash, &quot;allowance&quot;, floor)</span><br><span class=\"line\">            return 0, errInvalidAncestor</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        p.log.Debug(&quot;Found common ancestor&quot;, &quot;number&quot;, number, &quot;hash&quot;, hash)</span><br><span class=\"line\">        return number, nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Ancestor not found, we need to binary search over our chain</span><br><span class=\"line\">    start, end := uint64(0), head</span><br><span class=\"line\">    if floor &gt; 0 &#123;</span><br><span class=\"line\">        start = uint64(floor)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    for start+1 &lt; end &#123;</span><br><span class=\"line\">        // Split our chain interval in two, and request the hash to cross check</span><br><span class=\"line\">        check := (start + end) / 2</span><br><span class=\"line\"></span><br><span class=\"line\">        ttl := d.requestTTL()</span><br><span class=\"line\">        timeout := time.After(ttl)</span><br><span class=\"line\"></span><br><span class=\"line\">        go p.peer.RequestHeadersByNumber(check, 1, 0, false)</span><br><span class=\"line\"></span><br><span class=\"line\">        // Wait until a reply arrives to this request</span><br><span class=\"line\">        for arrived := false; !arrived; &#123;</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case &lt;-d.cancelCh:</span><br><span class=\"line\">                return 0, errCancelHeaderFetch</span><br><span class=\"line\"></span><br><span class=\"line\">            case packer := &lt;-d.headerCh:</span><br><span class=\"line\">                // Discard anything not from the origin peer</span><br><span class=\"line\">                if packer.PeerId() != p.id &#123;</span><br><span class=\"line\">                    log.Debug(&quot;Received headers from incorrect peer&quot;, &quot;peer&quot;, packer.PeerId())</span><br><span class=\"line\">                    break</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Make sure the peer actually gave something valid</span><br><span class=\"line\">                headers := packer.(*headerPack).headers</span><br><span class=\"line\">                if len(headers) != 1 &#123;</span><br><span class=\"line\">                    p.log.Debug(&quot;Multiple headers for single request&quot;, &quot;headers&quot;, len(headers))</span><br><span class=\"line\">                    return 0, errBadPeer</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                arrived = true</span><br><span class=\"line\"></span><br><span class=\"line\">                // Modify the search interval based on the response</span><br><span class=\"line\">                if (d.mode == FullSync &amp;&amp; !d.blockchain.HasBlock(headers[0].Hash(), headers[0].Number.Uint64())) || (d.mode != FullSync &amp;&amp; !d.lightchain.HasHeader(headers[0].Hash(), headers[0].Number.Uint64())) &#123;</span><br><span class=\"line\">                    end = check</span><br><span class=\"line\">                    break</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                header := d.lightchain.GetHeaderByHash(headers[0].Hash()) // Independent of sync mode, header surely exists</span><br><span class=\"line\">                if header.Number.Uint64() != check &#123;</span><br><span class=\"line\">                    p.log.Debug(&quot;Received non requested header&quot;, &quot;number&quot;, header.Number, &quot;hash&quot;, header.Hash(), &quot;request&quot;, check)</span><br><span class=\"line\">                    return 0, errBadPeer</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                start = check</span><br><span class=\"line\"></span><br><span class=\"line\">            case &lt;-timeout:</span><br><span class=\"line\">                p.log.Debug(&quot;Waiting for search header timed out&quot;, &quot;elapsed&quot;, ttl)</span><br><span class=\"line\">                return 0, errTimeout</span><br><span class=\"line\"></span><br><span class=\"line\">            case &lt;-d.bodyCh:</span><br><span class=\"line\">            case &lt;-d.receiptCh:</span><br><span class=\"line\">                // Out of bounds delivery, ignore</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Ensure valid ancestry and return</span><br><span class=\"line\">    if int64(start) &lt;= floor &#123;</span><br><span class=\"line\">        p.log.Warn(&quot;Ancestor below allowance&quot;, &quot;number&quot;, start, &quot;hash&quot;, hash, &quot;allowance&quot;, floor)</span><br><span class=\"line\">        return 0, errInvalidAncestor</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    p.log.Debug(&quot;Found common ancestor&quot;, &quot;number&quot;, start, &quot;hash&quot;, hash)</span><br><span class=\"line\">    return start, nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，调用peer.RequestHeadersByNumber(uint64(from), count, 15, false)，获取header。这里传入 count和 15，指从本地最高的header往前数192个区块的头，每16个区块取一个区块头。为了后面select收到d.headerCh时加以验证。<br>2，select收到了headers，遍历header，看是否在本地是否存在这个header，如果有，并且不为空，就说明找到共同的祖先，返回祖先number<br>3，如果没有找到共同的祖先，再重新从本地的区块链MaxForkAncestry起的一半的位置开始取区块头，一一验证是否跟网络节点返回的header一致，如果有就说明有共同的祖先，并返回，没有的话就返回0.</p>\n<p>继续syncWithPeer()方法，找到同步的轴心的pivot，最后把要同步的数据和同步的方法传给d.spawnSync(fetchers)，并执行。d.spawnSync(fetchers)挨个执行传入的同步方法。</p>\n<p>二，Downloader同步数据方法<br>fetchHeaders()，fetchBodies() , fetchReceipts()</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) fetchHeaders(p *peerConnection, from uint64, pivot uint64) error &#123;</span><br><span class=\"line\">    p.log.Debug(&quot;Directing header downloads&quot;, &quot;origin&quot;, from)</span><br><span class=\"line\">    defer p.log.Debug(&quot;Header download terminated&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    // Create a timeout timer, and the associated header fetcher</span><br><span class=\"line\">    skeleton := true            // Skeleton assembly phase or finishing up</span><br><span class=\"line\">    request := time.Now()       // time of the last skeleton fetch request</span><br><span class=\"line\">    timeout := time.NewTimer(0) // timer to dump a non-responsive active peer</span><br><span class=\"line\">    &lt;-timeout.C                 // timeout channel should be initially empty</span><br><span class=\"line\">    defer timeout.Stop()</span><br><span class=\"line\"></span><br><span class=\"line\">    var ttl time.Duration</span><br><span class=\"line\">    getHeaders := func(from uint64) &#123;</span><br><span class=\"line\">        request = time.Now()</span><br><span class=\"line\"></span><br><span class=\"line\">        ttl = d.requestTTL()</span><br><span class=\"line\">        timeout.Reset(ttl)</span><br><span class=\"line\"></span><br><span class=\"line\">        if skeleton &#123;</span><br><span class=\"line\">            p.log.Trace(&quot;Fetching skeleton headers&quot;, &quot;count&quot;, MaxHeaderFetch, &quot;from&quot;, from)</span><br><span class=\"line\">            go p.peer.RequestHeadersByNumber(from+uint64(MaxHeaderFetch)-1, MaxSkeletonSize, MaxHeaderFetch-1, false)</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            p.log.Trace(&quot;Fetching full headers&quot;, &quot;count&quot;, MaxHeaderFetch, &quot;from&quot;, from)</span><br><span class=\"line\">            go p.peer.RequestHeadersByNumber(from, MaxHeaderFetch, 0, false)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Start pulling the header chain skeleton until all is done</span><br><span class=\"line\">    getHeaders(from)</span><br><span class=\"line\"></span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-d.cancelCh:</span><br><span class=\"line\">            return errCancelHeaderFetch</span><br><span class=\"line\"></span><br><span class=\"line\">        case packet := &lt;-d.headerCh:</span><br><span class=\"line\">            // Make sure the active peer is giving us the skeleton headers</span><br><span class=\"line\">            if packet.PeerId() != p.id &#123;</span><br><span class=\"line\">                log.Debug(&quot;Received skeleton from incorrect peer&quot;, &quot;peer&quot;, packet.PeerId())</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            headerReqTimer.UpdateSince(request)</span><br><span class=\"line\">            timeout.Stop()</span><br><span class=\"line\"></span><br><span class=\"line\">            // If the skeleton&apos;s finished, pull any remaining head headers directly from the origin</span><br><span class=\"line\">            if packet.Items() == 0 &amp;&amp; skeleton &#123;</span><br><span class=\"line\">                skeleton = false</span><br><span class=\"line\">                getHeaders(from)</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // If no more headers are inbound, notify the content fetchers and return</span><br><span class=\"line\">            if packet.Items() == 0 &#123;</span><br><span class=\"line\">                // Don&apos;t abort header fetches while the pivot is downloading</span><br><span class=\"line\">                if atomic.LoadInt32(&amp;d.committed) == 0 &amp;&amp; pivot &lt;= from &#123;</span><br><span class=\"line\">                    p.log.Debug(&quot;No headers, waiting for pivot commit&quot;)</span><br><span class=\"line\">                    select &#123;</span><br><span class=\"line\">                    case &lt;-time.After(fsHeaderContCheck):</span><br><span class=\"line\">                        getHeaders(from)</span><br><span class=\"line\">                        continue</span><br><span class=\"line\">                    case &lt;-d.cancelCh:</span><br><span class=\"line\">                        return errCancelHeaderFetch</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Pivot done (or not in fast sync) and no more headers, terminate the process</span><br><span class=\"line\">                p.log.Debug(&quot;No more headers available&quot;)</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case d.headerProcCh &lt;- nil:</span><br><span class=\"line\">                    return nil</span><br><span class=\"line\">                case &lt;-d.cancelCh:</span><br><span class=\"line\">                    return errCancelHeaderFetch</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            headers := packet.(*headerPack).headers</span><br><span class=\"line\"></span><br><span class=\"line\">            // If we received a skeleton batch, resolve internals concurrently</span><br><span class=\"line\">            if skeleton &#123;</span><br><span class=\"line\">                filled, proced, err := d.fillHeaderSkeleton(from, headers)</span><br><span class=\"line\">                if err != nil &#123;</span><br><span class=\"line\">                    p.log.Debug(&quot;Skeleton chain invalid&quot;, &quot;err&quot;, err)</span><br><span class=\"line\">                    return errInvalidChain</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                headers = filled[proced:]</span><br><span class=\"line\">                from += uint64(proced)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Insert all the new headers and fetch the next batch</span><br><span class=\"line\">            if len(headers) &gt; 0 &#123;</span><br><span class=\"line\">                p.log.Trace(&quot;Scheduling new headers&quot;, &quot;count&quot;, len(headers), &quot;from&quot;, from)</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case d.headerProcCh &lt;- headers:</span><br><span class=\"line\">                case &lt;-d.cancelCh:</span><br><span class=\"line\">                    return errCancelHeaderFetch</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                from += uint64(len(headers))</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            getHeaders(from)</span><br><span class=\"line\"></span><br><span class=\"line\">        case &lt;-timeout.C:</span><br><span class=\"line\">            if d.dropPeer == nil &#123;</span><br><span class=\"line\">                // The dropPeer method is nil when `--copydb` is used for a local copy.</span><br><span class=\"line\">                // Timeouts can occur if e.g. compaction hits at the wrong time, and can be ignored</span><br><span class=\"line\">                p.log.Warn(&quot;Downloader wants to drop peer, but peerdrop-function is not set&quot;, &quot;peer&quot;, p.id)</span><br><span class=\"line\">                break</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Header retrieval timed out, consider the peer bad and drop</span><br><span class=\"line\">            p.log.Debug(&quot;Header request timed out&quot;, &quot;elapsed&quot;, ttl)</span><br><span class=\"line\">            headerTimeoutMeter.Mark(1)</span><br><span class=\"line\">            d.dropPeer(p.id)</span><br><span class=\"line\"></span><br><span class=\"line\">            // Finish the sync gracefully instead of dumping the gathered data though</span><br><span class=\"line\">            for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123;</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case ch &lt;- false:</span><br><span class=\"line\">                case &lt;-d.cancelCh:</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case d.headerProcCh &lt;- nil:</span><br><span class=\"line\">            case &lt;-d.cancelCh:</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            return errBadPeer</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，getHeaders()调用peer.RequestHeadersByNumber()方法 获取网络节点的headers。<br>2，有两种获取方式，首先走的是skeleton方式，从查找到的共同祖先区块+192个区块位置开始，每隔192个区块，获取128个区块头。非skeleton方式，从共同祖先区块开始，获取192个区块头。<br>3，如果第一种方式获取不到区块头，则执行第二种获取方式，如果第二种方式还是没有获取到区块头的话，直接返回<br>4，如果是skeleton获取到的，调用fillHeaderSkeleton()方法加入到skeleton header chain<br>5，然后调整from值，再递归调用getHeaders()方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) fillHeaderSkeleton(from uint64, skeleton []*types.Header) ([]*types.Header, int, error) &#123;</span><br><span class=\"line\">    log.Debug(&quot;Filling up skeleton&quot;, &quot;from&quot;, from)</span><br><span class=\"line\">    d.queue.ScheduleSkeleton(from, skeleton)</span><br><span class=\"line\"></span><br><span class=\"line\">    var (</span><br><span class=\"line\">        deliver = func(packet dataPack) (int, error) &#123;</span><br><span class=\"line\">            pack := packet.(*headerPack)</span><br><span class=\"line\">            return d.queue.DeliverHeaders(pack.peerId, pack.headers, d.headerProcCh)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        expire   = func() map[string]int &#123; return d.queue.ExpireHeaders(d.requestTTL()) &#125;</span><br><span class=\"line\">        throttle = func() bool &#123; return false &#125;</span><br><span class=\"line\">        reserve  = func(p *peerConnection, count int) (*fetchRequest, bool, error) &#123;</span><br><span class=\"line\">            return d.queue.ReserveHeaders(p, count), false, nil</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        fetch    = func(p *peerConnection, req *fetchRequest) error &#123; return p.FetchHeaders(req.From, MaxHeaderFetch) &#125;</span><br><span class=\"line\">        capacity = func(p *peerConnection) int &#123; return p.HeaderCapacity(d.requestRTT()) &#125;</span><br><span class=\"line\">        setIdle  = func(p *peerConnection, accepted int) &#123; p.SetHeadersIdle(accepted) &#125;</span><br><span class=\"line\">    )</span><br><span class=\"line\">    err := d.fetchParts(errCancelHeaderFetch, d.headerCh, deliver, d.queue.headerContCh, expire,</span><br><span class=\"line\">        d.queue.PendingHeaders, d.queue.InFlightHeaders, throttle, reserve,</span><br><span class=\"line\">        nil, fetch, d.queue.CancelHeaders, capacity, d.peers.HeaderIdlePeers, setIdle, &quot;headers&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    log.Debug(&quot;Skeleton fill terminated&quot;, &quot;err&quot;, err)</span><br><span class=\"line\"></span><br><span class=\"line\">    filled, proced := d.queue.RetrieveHeaders()</span><br><span class=\"line\">    return filled, proced, err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>a) 把skeleton的headers加入queue.ScheduleSkeleton调度队列，<br>b) 然后执行d.fetchParts()方法。<br>d.fetchParts()方法主要做了这几件事情<br>1，对收到的headers执行d.queue.DeliverHeaders()方法。<br>2，如果d.queue.PendingHeaders有pending的headers，调用d.peers.HeaderIdlePeers获取到idle的peers<br>3，调用d.queue.ReserveHeaders把pending的headers储备到idle的peers里面<br>4，用idle的peers调用p.FetchHeaders(req.From, MaxHeaderFetch)去获取headers<br>c) 最后执行d.queue.RetrieveHeaders()，获取到filled进去的headers</p>\n<p>其他同步区块数据的方法d.fetchBodies() , d.fetchReceipts() 和fetchHeaders()流程类似，还更简单一些。</p>\n<p>三，Downloader同步数据过程<br>d.processHeaders(), d.processFastSyncContent(latest) , d.processFullSyncContent<br>1，d.processHeaders() 方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) processHeaders(origin uint64, pivot uint64, td *big.Int) error &#123;</span><br><span class=\"line\">    // Keep a count of uncertain headers to roll back</span><br><span class=\"line\">    rollback := []*types.Header&#123;&#125;</span><br><span class=\"line\">    defer func() &#123;</span><br><span class=\"line\">        if len(rollback) &gt; 0 &#123;</span><br><span class=\"line\">            // Flatten the headers and roll them back</span><br><span class=\"line\">            hashes := make([]common.Hash, len(rollback))</span><br><span class=\"line\">            for i, header := range rollback &#123;</span><br><span class=\"line\">                hashes[i] = header.Hash()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            lastHeader, lastFastBlock, lastBlock := d.lightchain.CurrentHeader().Number, common.Big0, common.Big0</span><br><span class=\"line\">            if d.mode != LightSync &#123;</span><br><span class=\"line\">                lastFastBlock = d.blockchain.CurrentFastBlock().Number()</span><br><span class=\"line\">                lastBlock = d.blockchain.CurrentBlock().Number()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            d.lightchain.Rollback(hashes)</span><br><span class=\"line\">            curFastBlock, curBlock := common.Big0, common.Big0</span><br><span class=\"line\">            if d.mode != LightSync &#123;</span><br><span class=\"line\">                curFastBlock = d.blockchain.CurrentFastBlock().Number()</span><br><span class=\"line\">                curBlock = d.blockchain.CurrentBlock().Number()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            log.Warn(&quot;Rolled back headers&quot;, &quot;count&quot;, len(hashes),</span><br><span class=\"line\">                &quot;header&quot;, fmt.Sprintf(&quot;%d-&gt;%d&quot;, lastHeader, d.lightchain.CurrentHeader().Number),</span><br><span class=\"line\">                &quot;fast&quot;, fmt.Sprintf(&quot;%d-&gt;%d&quot;, lastFastBlock, curFastBlock),</span><br><span class=\"line\">                &quot;block&quot;, fmt.Sprintf(&quot;%d-&gt;%d&quot;, lastBlock, curBlock))</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">    // Wait for batches of headers to process</span><br><span class=\"line\">    gotHeaders := false</span><br><span class=\"line\"></span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        select &#123;</span><br><span class=\"line\">        case &lt;-d.cancelCh:</span><br><span class=\"line\">            return errCancelHeaderProcessing</span><br><span class=\"line\"></span><br><span class=\"line\">        case headers := &lt;-d.headerProcCh:</span><br><span class=\"line\">            // Terminate header processing if we synced up</span><br><span class=\"line\">            if len(headers) == 0 &#123;</span><br><span class=\"line\">                // Notify everyone that headers are fully processed</span><br><span class=\"line\">                for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123;</span><br><span class=\"line\">                    select &#123;</span><br><span class=\"line\">                    case ch &lt;- false:</span><br><span class=\"line\">                    case &lt;-d.cancelCh:</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                if d.mode != LightSync &#123;</span><br><span class=\"line\">                    head := d.blockchain.CurrentBlock()</span><br><span class=\"line\">                    if !gotHeaders &amp;&amp; td.Cmp(d.blockchain.GetTd(head.Hash(), head.NumberU64())) &gt; 0 &#123;</span><br><span class=\"line\">                        return errStallingPeer</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                if d.mode == FastSync || d.mode == LightSync &#123;</span><br><span class=\"line\">                    head := d.lightchain.CurrentHeader()</span><br><span class=\"line\">                    if td.Cmp(d.lightchain.GetTd(head.Hash(), head.Number.Uint64())) &gt; 0 &#123;</span><br><span class=\"line\">                        return errStallingPeer</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Disable any rollback and return</span><br><span class=\"line\">                rollback = nil</span><br><span class=\"line\">                return nil</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Otherwise split the chunk of headers into batches and process them</span><br><span class=\"line\">            gotHeaders = true</span><br><span class=\"line\"></span><br><span class=\"line\">            for len(headers) &gt; 0 &#123;</span><br><span class=\"line\">                // Terminate if something failed in between processing chunks</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case &lt;-d.cancelCh:</span><br><span class=\"line\">                    return errCancelHeaderProcessing</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Select the next chunk of headers to import</span><br><span class=\"line\">                limit := maxHeadersProcess</span><br><span class=\"line\">                if limit &gt; len(headers) &#123;</span><br><span class=\"line\">                    limit = len(headers)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                chunk := headers[:limit]</span><br><span class=\"line\"></span><br><span class=\"line\">                // In case of header only syncing, validate the chunk immediately</span><br><span class=\"line\">                if d.mode == FastSync || d.mode == LightSync &#123;</span><br><span class=\"line\">                    // Collect the yet unknown headers to mark them as uncertain</span><br><span class=\"line\">                    unknown := make([]*types.Header, 0, len(headers))</span><br><span class=\"line\">                    for _, header := range chunk &#123;</span><br><span class=\"line\">                        if !d.lightchain.HasHeader(header.Hash(), header.Number.Uint64()) &#123;</span><br><span class=\"line\">                            unknown = append(unknown, header)</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    // If we&apos;re importing pure headers, verify based on their recentness</span><br><span class=\"line\">                    frequency := fsHeaderCheckFrequency</span><br><span class=\"line\">                    if chunk[len(chunk)-1].Number.Uint64()+uint64(fsHeaderForceVerify) &gt; pivot &#123;</span><br><span class=\"line\">                        frequency = 1</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    if n, err := d.lightchain.InsertHeaderChain(chunk, frequency); err != nil &#123;</span><br><span class=\"line\">                        // If some headers were inserted, add them too to the rollback list</span><br><span class=\"line\">                        if n &gt; 0 &#123;</span><br><span class=\"line\">                            rollback = append(rollback, chunk[:n]...)</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        log.Debug(&quot;Invalid header encountered&quot;, &quot;number&quot;, chunk[n].Number, &quot;hash&quot;, chunk[n].Hash(), &quot;err&quot;, err)</span><br><span class=\"line\">                        return errInvalidChain</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    // All verifications passed, store newly found uncertain headers</span><br><span class=\"line\">                    rollback = append(rollback, unknown...)</span><br><span class=\"line\">                    if len(rollback) &gt; fsHeaderSafetyNet &#123;</span><br><span class=\"line\">                        rollback = append(rollback[:0], rollback[len(rollback)-fsHeaderSafetyNet:]...)</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Unless we&apos;re doing light chains, schedule the headers for associated content retrieval</span><br><span class=\"line\">                if d.mode == FullSync || d.mode == FastSync &#123;</span><br><span class=\"line\">                    // If we&apos;ve reached the allowed number of pending headers, stall a bit</span><br><span class=\"line\">                    for d.queue.PendingBlocks() &gt;= maxQueuedHeaders || d.queue.PendingReceipts() &gt;= maxQueuedHeaders &#123;</span><br><span class=\"line\">                        select &#123;</span><br><span class=\"line\">                        case &lt;-d.cancelCh:</span><br><span class=\"line\">                            return errCancelHeaderProcessing</span><br><span class=\"line\">                        case &lt;-time.After(time.Second):</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    // Otherwise insert the headers for content retrieval</span><br><span class=\"line\">                    inserts := d.queue.Schedule(chunk, origin)</span><br><span class=\"line\">                    if len(inserts) != len(chunk) &#123;</span><br><span class=\"line\">                        log.Debug(&quot;Stale headers&quot;)</span><br><span class=\"line\">                        return errBadPeer</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                headers = headers[limit:]</span><br><span class=\"line\">                origin += uint64(limit)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Signal the content downloaders of the availablility of new tasks</span><br><span class=\"line\">            for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123;</span><br><span class=\"line\">                select &#123;</span><br><span class=\"line\">                case ch &lt;- true:</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，收到从fetchHeaders()方法 中d.headerProcCh发送过来的headers<br>2，如果是FastSync或者LightSync模式，直接调用lightchain.InsertHeaderChain(chunk, frequency)插入到headerChain。<br>3，如果是FullSync或者FastSyn模式，调用d.queue.Schedule(chunk, origin)，放入downloader.queue来调度</p>\n<p>2，processFastSyncContent() 方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) processFastSyncContent(latest *types.Header) error &#123;</span><br><span class=\"line\">    // Start syncing state of the reported head block. This should get us most of</span><br><span class=\"line\">    // the state of the pivot block.</span><br><span class=\"line\">    stateSync := d.syncState(latest.Root)</span><br><span class=\"line\">    defer stateSync.Cancel()</span><br><span class=\"line\">    go func() &#123;</span><br><span class=\"line\">        if err := stateSync.Wait(); err != nil &amp;&amp; err != errCancelStateFetch &#123;</span><br><span class=\"line\">            d.queue.Close() // wake up WaitResults</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\">    // Figure out the ideal pivot block. Note, that this goalpost may move if the</span><br><span class=\"line\">    // sync takes long enough for the chain head to move significantly.</span><br><span class=\"line\">    pivot := uint64(0)</span><br><span class=\"line\">    if height := latest.Number.Uint64(); height &gt; uint64(fsMinFullBlocks) &#123;</span><br><span class=\"line\">        pivot = height - uint64(fsMinFullBlocks)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // To cater for moving pivot points, track the pivot block and subsequently</span><br><span class=\"line\">    // accumulated download results separatey.</span><br><span class=\"line\">    var (</span><br><span class=\"line\">        oldPivot *fetchResult   // Locked in pivot block, might change eventually</span><br><span class=\"line\">        oldTail  []*fetchResult // Downloaded content after the pivot</span><br><span class=\"line\">    )</span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        // Wait for the next batch of downloaded data to be available, and if the pivot</span><br><span class=\"line\">        // block became stale, move the goalpost</span><br><span class=\"line\">        results := d.queue.Results(oldPivot == nil) // Block if we&apos;re not monitoring pivot staleness</span><br><span class=\"line\">        if len(results) == 0 &#123;</span><br><span class=\"line\">            // If pivot sync is done, stop</span><br><span class=\"line\">            if oldPivot == nil &#123;</span><br><span class=\"line\">                return stateSync.Cancel()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // If sync failed, stop</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case &lt;-d.cancelCh:</span><br><span class=\"line\">                return stateSync.Cancel()</span><br><span class=\"line\">            default:</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if d.chainInsertHook != nil &#123;</span><br><span class=\"line\">            d.chainInsertHook(results)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if oldPivot != nil &#123;</span><br><span class=\"line\">            results = append(append([]*fetchResult&#123;oldPivot&#125;, oldTail...), results...)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Split around the pivot block and process the two sides via fast/full sync</span><br><span class=\"line\">        if atomic.LoadInt32(&amp;d.committed) == 0 &#123;</span><br><span class=\"line\">            latest = results[len(results)-1].Header</span><br><span class=\"line\">            if height := latest.Number.Uint64(); height &gt; pivot+2*uint64(fsMinFullBlocks) &#123;</span><br><span class=\"line\">                log.Warn(&quot;Pivot became stale, moving&quot;, &quot;old&quot;, pivot, &quot;new&quot;, height-uint64(fsMinFullBlocks))</span><br><span class=\"line\">                pivot = height - uint64(fsMinFullBlocks)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        P, beforeP, afterP := splitAroundPivot(pivot, results)</span><br><span class=\"line\">        if err := d.commitFastSyncData(beforeP, stateSync); err != nil &#123;</span><br><span class=\"line\">            return err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if P != nil &#123;</span><br><span class=\"line\">            // If new pivot block found, cancel old state retrieval and restart</span><br><span class=\"line\">            if oldPivot != P &#123;</span><br><span class=\"line\">                stateSync.Cancel()</span><br><span class=\"line\"></span><br><span class=\"line\">                stateSync = d.syncState(P.Header.Root)</span><br><span class=\"line\">                defer stateSync.Cancel()</span><br><span class=\"line\">                go func() &#123;</span><br><span class=\"line\">                    if err := stateSync.Wait(); err != nil &amp;&amp; err != errCancelStateFetch &#123;</span><br><span class=\"line\">                        d.queue.Close() // wake up WaitResults</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;()</span><br><span class=\"line\">                oldPivot = P</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // Wait for completion, occasionally checking for pivot staleness</span><br><span class=\"line\">            select &#123;</span><br><span class=\"line\">            case &lt;-stateSync.done:</span><br><span class=\"line\">                if stateSync.err != nil &#123;</span><br><span class=\"line\">                    return stateSync.err</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                if err := d.commitPivotBlock(P); err != nil &#123;</span><br><span class=\"line\">                    return err</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                oldPivot = nil</span><br><span class=\"line\"></span><br><span class=\"line\">            case &lt;-time.After(time.Second):</span><br><span class=\"line\">                oldTail = afterP</span><br><span class=\"line\">                continue</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // Fast sync done, pivot commit done, full import</span><br><span class=\"line\">        if err := d.importBlockResults(afterP); err != nil &#123;</span><br><span class=\"line\">            return err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1，同步最新的状态信息，的到最新的pivot值<br>2，不停的从d.queue 的result缓存中获取要处理的result数据<br>3，如果results数据为空，同时pivot也为空的时候，说明同步完成了，并返回<br>4，根据pivot值和results计算：pivot值对应的result，和pivot值之前的results和pivot值之后的results<br>5，调用commitFastSyncData把pivot值之前的results 插入本地区块链中，带上收据和交易数据<br>6，更新同步状态信息后，把pivot值对应的result 调用commitPivotBlock插入本地区块链中，并调用FastSyncCommitHead，记录这个pivot的hash值<br>7，调用d.importBlockResults把pivot值之后的results插入本地区块链中，这时候不插入区块交易收据数据。</p>\n<p>3，processFullSyncContent()方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (d *Downloader) processFullSyncContent() error &#123;</span><br><span class=\"line\">    for &#123;</span><br><span class=\"line\">        results := d.queue.Results(true)</span><br><span class=\"line\">        if len(results) == 0 &#123;</span><br><span class=\"line\">            return nil</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if d.chainInsertHook != nil &#123;</span><br><span class=\"line\">            d.chainInsertHook(results)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if err := d.importBlockResults(results); err != nil &#123;</span><br><span class=\"line\">            return err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (d *Downloader) importBlockResults(results []*fetchResult) error &#123;</span><br><span class=\"line\">    // Check for any early termination requests</span><br><span class=\"line\">    if len(results) == 0 &#123;</span><br><span class=\"line\">        return nil</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    select &#123;</span><br><span class=\"line\">    case &lt;-d.quitCh:</span><br><span class=\"line\">        return errCancelContentProcessing</span><br><span class=\"line\">    default:</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Retrieve the a batch of results to import</span><br><span class=\"line\">    first, last := results[0].Header, results[len(results)-1].Header</span><br><span class=\"line\">    log.Debug(&quot;Inserting downloaded chain&quot;, &quot;items&quot;, len(results),</span><br><span class=\"line\">        &quot;firstnum&quot;, first.Number, &quot;firsthash&quot;, first.Hash(),</span><br><span class=\"line\">        &quot;lastnum&quot;, last.Number, &quot;lasthash&quot;, last.Hash(),</span><br><span class=\"line\">    )</span><br><span class=\"line\">    blocks := make([]*types.Block, len(results))</span><br><span class=\"line\">    for i, result := range results &#123;</span><br><span class=\"line\">        blocks[i] = types.NewBlockWithHeader(result.Header).WithBody(result.Transactions, result.Uncles)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if index, err := d.blockchain.InsertChain(blocks); err != nil &#123;</span><br><span class=\"line\">        log.Debug(&quot;Downloaded item processing failed&quot;, &quot;number&quot;, results[index].Header.Number, &quot;hash&quot;, results[index].Header.Hash(), &quot;err&quot;, err)</span><br><span class=\"line\">        return errInvalidChain</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>processFullSyncContent方法比较简单：直接获取缓存的results数据，并插入到本地区块链中。</p>\n<p>总结：<br>Downloader看似非常复杂，其实逻辑还好，如果没有light模式，读起来会好很多。其实light模式不太成熟，基本也没什么用。fast模式比full模式逻辑上面多了一个pivot，处理起来就复杂很多。但是fast模式在本地存储了收据数据，大大减少了区块交易验证的时间。如果要更清楚明白fast模式的原理，可以看看以太坊白皮书关于fast模式同步这一部分：<a href=\"https://github.com/ethereum/go-ethereum/pull/1889\">文档</a></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ck3fm69s20001t6xv2z74fwdn","category_id":"ck3fm69sg0004t6xv1be7s3d4","_id":"ck3fm69t6000ct6xvtmvlpb3x"},{"post_id":"ck3fm69sa0003t6xv6cp9rp4p","category_id":"ck3fm69sw0009t6xvkndkd51t","_id":"ck3fm69tc000ht6xvwdh0l4o5"},{"post_id":"ck3fm69so0006t6xvnm6lw2hr","category_id":"ck3fm69sw0009t6xvkndkd51t","_id":"ck3fm69tg000kt6xveoc0u80x"},{"post_id":"ck3fm69ss0007t6xvswwfzn4s","category_id":"ck3fm69tc000gt6xv4i87p24p","_id":"ck3fm69tk000ot6xvbdpgnw1t"},{"post_id":"ck3fm69ti000mt6xv2flevczd","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69tp000st6xvfhridrjy"},{"post_id":"ck3fm69su0008t6xvxv3i6uc9","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69tx000ut6xvc27ox9tp"},{"post_id":"ck3fm69tm000qt6xvso7pmbeq","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69u1000xt6xv0m9b3f2s"},{"post_id":"ck3fm69to000rt6xvlnk8foeu","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69u4000zt6xvdqw16od2"},{"post_id":"ck3fm69sy000at6xvf53jnzum","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69u70012t6xvow94io6s"},{"post_id":"ck3fm69t3000bt6xv9zo3a3ma","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69u90015t6xv4ymtnw6x"},{"post_id":"ck3fm69t8000et6xvr1hw6pbw","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69ui0019t6xvjkvnowk3"},{"post_id":"ck3fm69ua0016t6xvqq43x12d","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69un001ct6xvqgp37ypg"},{"post_id":"ck3fm69ta000ft6xvjpqm06lj","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69ur001ft6xvry2ofijg"},{"post_id":"ck3fm69uf0017t6xvmp2qho78","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69us001gt6xvbd4kptu2"},{"post_id":"ck3fm69uk001at6xvky7tryyj","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69uu001it6xv7sdgfixc"},{"post_id":"ck3fm69td000it6xvndl9kj9z","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69uu001jt6xvqarsltbw"},{"post_id":"ck3fm69um001bt6xveobfk3fd","category_id":"ck3fm69tc000gt6xv4i87p24p","_id":"ck3fm69uv001lt6xvvlk25di3"},{"post_id":"ck3fm69tf000jt6xv8e6xhjer","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69uw001mt6xvc7xt4oql"},{"post_id":"ck3fm69tj000nt6xvp9nabogf","category_id":"ck3fm69ut001ht6xvwn2qjqlv","_id":"ck3fm69ux001ot6xv9blhs8dk"},{"post_id":"ck3fm69tt000tt6xvauuq95uf","category_id":"ck3fm69uv001kt6xvvpu3me62","_id":"ck3fm69uz001qt6xv669s93qj"},{"post_id":"ck3fm69tz000wt6xvsu6r1yui","category_id":"ck3fm69uv001kt6xvvpu3me62","_id":"ck3fm69v1001st6xvyajxxuqv"},{"post_id":"ck3fm69u3000yt6xvl3p0o8tn","category_id":"ck3fm69uv001kt6xvvpu3me62","_id":"ck3fm69v2001tt6xvs8cbn86r"},{"post_id":"ck3fm69u50011t6xvixx4owv1","category_id":"ck3fm69v1001rt6xvnah1dc9l","_id":"ck3fm69v4001vt6xvondsbd96"},{"post_id":"ck3fm69u70013t6xv76lf3sqm","category_id":"ck3fm69v3001ut6xvf3tlgbyy","_id":"ck3fm69v6001xt6xvdo81ytxz"},{"post_id":"ck3fm69up001et6xvze4lg28j","category_id":"ck3fm69v4001wt6xvaua0bvbr","_id":"ck3fm69v6001yt6xvnsmkg6ke"},{"post_id":"ck3fm69wr001zt6xv3i73t48z","category_id":"ck3fm69tc000gt6xv4i87p24p","_id":"ck3fm69wy0023t6xvmuu3hmoz"},{"post_id":"ck3fm69ws0020t6xvh0q0kffa","category_id":"ck3fm69sg0004t6xv1be7s3d4","_id":"ck3fm69wz0025t6xvlbz9d1as"},{"post_id":"ck3fm69wu0021t6xv33u3pm35","category_id":"ck3fm69sg0004t6xv1be7s3d4","_id":"ck3fm69x10027t6xvaxqwsxjr"},{"post_id":"ck3fm69ww0022t6xvema0rqo6","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69x30029t6xvvc1a2xqm"},{"post_id":"ck3fm69wy0024t6xv77mus96g","category_id":"ck3fm69ut001ht6xvwn2qjqlv","_id":"ck3fm69x4002bt6xvpt3qjzkh"},{"post_id":"ck3fm69x00026t6xvys3yxl6f","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69x6002dt6xvhtcmeflj"},{"post_id":"ck3fm69x20028t6xvp0zgpc2l","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69x8002ft6xv5dhcgrc8"},{"post_id":"ck3fm69x3002at6xviyz6j1kt","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69x9002ht6xvzb5n5hcg"},{"post_id":"ck3fm69x5002ct6xve80e8m2u","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69xa002it6xvz2dul3u0"},{"post_id":"ck3fm69x7002et6xv66rijl73","category_id":"ck3fm69uv001kt6xvvpu3me62","_id":"ck3fm69xb002kt6xvzpxinz69"},{"post_id":"ck3fm69x8002gt6xvkj9hogtu","category_id":"ck3fm69xa002jt6xvgdhxo4vu","_id":"ck3fm69xc002lt6xvmyqnk08k"},{"post_id":"ck3fm69xm002mt6xvlj9v35rq","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69xo002ot6xvxrsurvyz"},{"post_id":"ck3fm69xn002nt6xv9knrcw58","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69xo002pt6xv0r1w7yy6"},{"post_id":"ck3fm69xv002qt6xvqekde64h","category_id":"ck3fm69uv001kt6xvvpu3me62","_id":"ck3fm69y0002tt6xvg0upyhdv"},{"post_id":"ck3fm69xw002rt6xvusmkhjt4","category_id":"ck3fm69tl000pt6xvbnuymqxi","_id":"ck3fm69y0002ut6xv9zl8hhkt"},{"post_id":"ck3fm69xy002st6xvbwt6358n","category_id":"ck3fm69xa002jt6xvgdhxo4vu","_id":"ck3fm69y1002vt6xvzwhz82b9"},{"post_id":"ck3fm69ys002wt6xvyonfly1j","category_id":"ck3fm69tg000lt6xvu8visr1f","_id":"ck3fm69yu002xt6xvb6idi7z4"}],"PostTag":[],"Tag":[]}}